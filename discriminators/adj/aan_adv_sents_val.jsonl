{"sent1": "The proposed method uses previous latest related story to extend current processing story, generates new dynamic models for computing the similarity between the current two stories.", "sent2": "We present extensive experimental results validating this finding.", "label": 0}
{"sent1": "We replace this intractable distribution by a sequence of tractable upper-bounds for which exact optimisers and samplers are easy to obtain.", "sent2": "In hierarchical translation, inference needs to be performed over a high-complexity distribution defined by the intersection of a translation hypergraph and a target language model.", "label": 1}
{"sent1": "WebAnno uses modern web technology for visualizing and editing annotations in a web browser.", "sent2": "We then included a cheap, language and domain independent feature based on the minimum edit distance between strings.", "label": 0}
{"sent1": "The task was designed to promote research on semantic inference over texts written in different languages, targeting at the same time a real application scenario.", "sent2": "We design a large amount of finegrained features that directly express the events where letters produce or do not produce abbreviations.", "label": 0}
{"sent1": "a statistically significant improvement over existing Chinese function label assignment systems.", "sent2": "We propose a language production model that uses dynamic discourse information to account for speakers?", "label": 0}
{"sent1": "However, these models suffer from a high number of dimensions and data sparsity in the matrix of contextual vectors.", "sent2": "They are based on the repetition of information occurring in the contexts of words to associate.", "label": 1}
{"sent1": "The notion of simplicity is biased towards non-native speakers of English.", "sent2": "these substitutes are.", "label": 1}
{"sent1": "We designed and compiled the lexicon of cooking actions required for the animation generation system.", "sent2": "The advantage of using a general dictionary lies in the coverage, and the availability of such resources, in general and also in specialised domains.", "label": 0}
{"sent1": "First, we generate naturally occurring online error correction data by logging users?", "sent2": "This paper presents a comparative study of spelling errors that are corrected as you type, vs. those that remain uncorrected.", "label": 1}
{"sent1": "To cope with sparseness, we use N-best phrase alignments and bilingual phrase clustering, and investigate a variety of combinations of conditioning factors.", "sent2": "We introduce the AnEM corpus, a domain- and species-independent resource manually annotated for anatomical entity mentions using a fine-grained classification system.", "label": 0}
{"sent1": "However, the validity of these automatic measures has not been fully proven.", "sent2": "Long segments benefit more than short segments.", "label": 0}
{"sent1": "To assess the quality of discovered relationships, we use the pattern clusters to automatically generate SAT analogy questions.", "sent2": "In this paper, we explore techniques to recover the desired sparsity in covariance matrices in two ways.", "label": 0}
{"sent1": "These dictionary graphs might therefore be considered as ?cognitive artifacts?.", "sent2": "This paper presents a probabilistic framework, QARLA, for the evaluation of text summarisation systems.", "label": 0}
{"sent1": "We study two different learning methods, one based on rule induction and one based on a probabilistic sequence model.", "sent2": "In this work, we develop a methodology that leverages the recent QA-SRL annotation to create a first independent and large scale Open IE annotation,1 and use it to automatically compare the most prominent Open IE systems.", "label": 0}
{"sent1": "However, in opinion mining, it is often desirable to mine the aspect specific opinion expressions (or aspectsentiment phrases) containing both the aspect and the opinion.", "sent2": "Most existing works focus on either generic subjective expression or aspect expression extraction.", "label": 1}
{"sent1": "Second, we devise an interactive alignment algorithm for matching latent topics from multiple models, and enable sensitivity evaluation across a large number of models.", "sent2": "First, from established guidelines on reproducible content analysis, we distill a set of design requirements on how to computationally assess the stability of an automated coding process.", "label": 1}
{"sent1": "To achieve this, we leverage on discourse analysis as we believe that it provides more useful semantic information than typical lexico-syntactic features.", "sent2": "We propose the use of several discourse analysis frameworks, including 1) Rhetorical Structure Theory (RST), 2) PDTB-styled discourse relations, and 3) topical text segmentation.", "label": 1}
{"sent1": "We show that previously reported comparisons greatly under-estimated the performance of context-free parsers for these tasks.", "sent2": "Multi-task learning is the problem of maximizing the performance of a system across a number of related tasks.", "label": 0}
{"sent1": "The first method exploits Spanish morphology, and achieves an F1 constituency score of 83.6%.", "sent2": "We present two methods for incorporating detailed features in a Spanish parser, building on a baseline model that is a lexicalized PCFG.", "label": 1}
{"sent1": "As a method of translation estimation for technical terms, we propose a compositional translation estimation technique.", "sent2": "Our method relies on the hypothesis that unknown lexical items will be structurally and semantically similar to known items for which annotations are available.", "label": 0}
{"sent1": "The two cues are combined in a Treebank PCFG whose states are split using a few simple tree transformations.", "sent2": "The other cue, syntactic parallelism, codifies the expectation that repairs continue a syntactic category that was left unfinished in the reparandum (Levelt, 1983).", "label": 1}
{"sent1": "We explore how incrementally adding richer features allows learning of more effective dialogue strategies.", "sent2": "We present an evaluation of the relevance of the candidates on a sample of the lexicon.", "label": 0}
{"sent1": "We look at two strategies and provide convergence bounds for a particular mode of distributed structured perceptron training based on iterative parameter mixing (or averaging).", "sent2": "Mining sentiment from user generated content is a very important task in Natural Language Processing.", "label": 0}
{"sent1": "We train a state-of-the-art MT system using MERT on many parameterizations of each metric and evaluate the resulting models on the other metrics and also using human judges.", "sent2": "Searching documents that are similar to a query document is an important component in modern information retrieval.", "label": 0}
{"sent1": "It has been gaining substantial attention, manifested by a large number of automatic Open IE extractors and downstream applications.", "sent2": "In spite of this broad attention, the Open IE task definition has been lacking ?", "label": 1}
{"sent1": "To address the second need, we propose a suffix-tree data structure to represent syntactic relationships between opinion targets and words in a sentence that are opinion-bearing.", "sent2": "The system is publicly available for download and has an online demonstration at http://clair.eecs.umich.edu/AttitudeMiner/.", "label": 0}
{"sent1": "Yet information-access technologies lack capabilities for predicting article quality at this level.", "sent2": "The task of abbreviation recognition is formalized as a sequential alignment problem, which finds the optimal alignment (origins of abbreviation letters) between two strings (abbreviation and full form).", "label": 0}
{"sent1": "This study focuses on the prediction of the occupational class for a public user profile.", "sent2": "Social media content can be used as a complementary source to the traditional methods for extracting and studying collective social attributes.", "label": 1}
{"sent1": "However, NLP applications would gain from the ability to detect and type all entities mentioned in text, including the long tail of entities not prominent enough to have their own Wikipedia articles.", "sent2": "In this paper we show that once the Wikipedia entities mentioned in a corpus of textual assertions are linked, this can further enable the detection and fine-grained typing of the unlinkable entities.", "label": 1}
{"sent1": "Regularities across these click patterns are then utilized for constructing a large and heterogeneous training corpus for answer ranking.", "sent2": "?", "label": 0}
{"sent1": "We propose a novel algorithm to estimate reordering probabilities from monolingual data.", "sent2": "Syntactic structures, by their nature, reflect first and foremost the formal constructions used for expressing meanings.", "label": 0}
{"sent1": "In this paper, we study convolution dependency tree kernels for automatic engineering of syntactic and semantic patterns exploiting lexical similarities.", "sent2": "A central topic in natural language processing is the design of lexical and syntactic features suitable for the target application.", "label": 1}
{"sent1": "We show that the binarized model is as powerful as the standard model and allows us to aggressively subsample negative training examples without sacrificing predictive performance.", "sent2": "Empirical results show that we can train MELM and NNLM at 1% ?", "label": 1}
{"sent1": "We compare our method with four baseline methods.", "sent2": "This novel classification system may supports the SMT research community with some helpful references.", "label": 0}
{"sent1": "Experiments show that crowd workers can answer these questions quickly, accurately and cheaply.", "sent2": "We apply the approach to a CCG parser, converting uncertain attachment decisions into natural language questions about the arguments of verbs.", "label": 1}
{"sent1": "proficiency.", "sent2": "Furthermore, the results were evaluated in terms of the available number of training items, the number of senses, and the sense distributions in the data set.", "label": 0}
{"sent1": "Our experimental results show that this model detected wrong labels with higher performance than baseline methods.", "sent2": "For example since can serve as either a temporal or causal connective.", "label": 0}
{"sent1": "The features are used for multi-class and binary classification using SVMs.", "sent2": "Using a combination of lexical, syntactic, and semantic features to create a cross-lingual textual entailment system, we report on experiments over the provided dataset.", "label": 1}
{"sent1": "Instead, we focus on the situation where there are two resource deprived languages, both having a very small amount of seed annotated data and a large amount of untagged data.", "sent2": "We then use bilingual bootstrapping, wherein, a model trained using the seed annotated data of L1 is used to annotate the untagged data of L2 and vice versa using parameter projection.", "label": 1}
{"sent1": "This paper aims at thoroughly representing the semantics of negation by revealing implicit positive meaning.", "sent2": "We show that dependency parsers have more difficulty parsing questions than constituency parsers.", "label": 0}
{"sent1": "We submitted one Random Forest regression system on each cross level text pair, i.e., Paragraph to Sentence (P-S), Sentence to Phrase (SPh), Phrase to Word (Ph-W) and Word to Sense (W-Se).", "sent2": "This paper reports our submissions to the Cross Level Semantic Similarity (CLSS) task in SemEval 2014.", "label": 1}
{"sent1": "Specifically, we address two questions: (1) Can we solve these two subtasks together?", "sent2": "a way to enable an XDG grammar to generate all paraphrases ?", "label": 0}
{"sent1": "Our code is open-source1, thread-safe, and integrated into the Moses, cdec, and Joshua translation systems.", "sent2": "Second, we compare various inference procedures for state-split PCFGs from the standpoint of risk minimization, paying particular attention to their practical tradeoffs.", "label": 0}
{"sent1": "In this work we use monolingual language resources to determine the set of prepositions that are most likely to occur with each verb.", "sent2": "While the former is better able to memorize, the latter provides a more principled model that captures dependencies across phrasal boundaries.", "label": 0}
{"sent1": "Simplification rules are learned from a comparable corpus, and the rules are applied in a context-aware fashion to input sentences.", "sent2": "We present a method for lexical simplification.", "label": 1}
{"sent1": "Most of this work assumes the existence of resources (e.g.", "sent2": "We also perform comparison experiments with the partially joint models.", "label": 0}
{"sent1": "A control set composed of 65 contexts has also been annotated in 12 languages (including 2 non-Indoeuropean languages) in order to estimate the correlation between parallel polysemy and language family distance.", "sent2": "A new parameter, sense stability, is introduced to assess the homogeneity of each individual sense definition.", "label": 1}
{"sent1": "We can thus achieve better attribute (and object) label retrieval by treating images as ?visual phrases?, and decomposing their linguistic representation into an attribute-denoting adjective and an object-denoting noun.", "sent2": "Our approach performs comparably to a method exploiting manual attribute annotation, it outperforms various competitive alternatives in both attribute and object annotation, and it automatically constructs attribute-centric representations that significantly improve performance in supervised object recognition.", "label": 1}
{"sent1": "Compared to previous approaches, our framework is able to combine different metrics and evaluate the quality of a set of metrics without any a-priori weighting of their relative importance.", "sent2": "We provide quantitative evidence about the effectiveness of the approach to improve the automatic evaluation of text summarisation systems by combining several similarity metrics.", "label": 1}
{"sent1": "By using simulated annealing in place of Viterbi decoding in sequence models such as HMMs, CMMs, and CRFs, it is possible to incorporate non-local structure while preserving tractable inference.", "sent2": "In addition, we propose TIMEMMR, a modification to Maximal Marginal Relevance that promotes temporal diversity by way of computing time span similarity, and show its utility in summarizing certain document sets.", "label": 0}
{"sent1": "The system produced a many-to-many argument mapping for all PropBank argument types by computing argument similarity based on automatic word alignment, achieving 80.5% F-score on numbered argument mapping and 64.6% F-score on all arguments.", "sent2": "We also demonstrate the use of an extremely large shallow-parsed corpus for calculating vector-space semantic similarity.", "label": 0}
{"sent1": "The system incorporates a phrase-based model of string generation that aims to take unordered bags of words and produce fluent, grammatical sentences.", "sent2": "Our experimental results on the task of aligning comparable documents shows the efficacy of sparse covariance matrices on two data sets from two different language pairs.", "label": 0}
{"sent1": "In particular, we address the task of detecting semantic relations between digital devices in the text of Web pages.", "sent2": "The project has developed two virtual worlds that each have a mystery or natural phenomenon requiring scientific explanation; by recording students?", "label": 0}
{"sent1": "Their models involve a number of parameters whose weight must be adjusted.", "sent2": "As an alternative, in this work, we study the behaviour of non-parametric schemes, in which metrics are combined without having to adjust their relative importance.", "label": 1}
{"sent1": "We additionally estimate wordby-word surprisal and total entropy over parses of the sentence using a probabilistic context-free grammar (PCFG).", "sent2": "Empirical evaluations show that these methods are as accurate as?and significantly faster than?", "label": 0}
{"sent1": "Each document is represented by a vertex within a weighted undirected graph and our proposed framework minimizes the weighted Kullback-Leibler divergence between distributions that encode the class membership probabilities of each vertex.", "sent2": "The proposed objective is convex with guaranteed convergence using an alternating minimization procedure.", "label": 1}
{"sent1": "We introduce the concept of groups of closely-related domains, called genres, and show how inter-genre adaptation is related to domain adaptation.", "sent2": "Searching documents that are similar to a query document is an important component in modern information retrieval.", "label": 0}
{"sent1": "This paper also proposes two methods of combining advantages of different specifications: a simple concatenation of training data and a feature interpolation approach in which the same types of features of translation models from various CWS schemes are linearly interpolated.", "sent2": "We also found the correlation between the CWS F-score and SMT BLEU score was very weak.", "label": 1}
{"sent1": "The limited set of candidate parents for each word render contrastive estimation feasible.", "sent2": "Our model consistently matches or outperforms five state-of-the-art systems on Arabic, English and Turkish.1", "label": 1}
{"sent1": "We address this problem with a semisupervised learning approach which acquires training instances for unseen verbs from an unlabeled corpus.", "sent2": "Unknown lexical items present a major obstacle to the development of broadcoverage semantic role labeling systems.", "label": 1}
{"sent1": "utterances and model predictions, indicating that speakers?", "sent2": "Our prior is theoretically appealing since it is motivated by languageindependent, universal properties of the CCG formalism.", "label": 0}
{"sent1": "Previous work often used a pipeline method ?", "sent2": "After briefly presenting the modules of the framework, the paper reports extrinsic evaluation results considering two applications: computer-aided lexicography and statistical machine translation.", "label": 0}
{"sent1": "We propose quasisynchronous grammar (QG) features for these structured learning tasks.", "sent2": "Initial experiments indicate that this technique can produce high-precision targeted detection and correction of misrecognized query words.", "label": 0}
{"sent1": "One of the biggest problems with dependency structure analysis in spontaneous speech is that clause boundaries are ambiguous.", "sent2": "Japanese dependency structure is usually represented by relationships between phrasal units called bunsetsus.", "label": 1}
{"sent1": "Lookup algorithms used for contiguous phrases no longer apply and the best approximate pattern matching algorithms are much too slow, taking several minutes per sentence.", "sent2": "Hierarchical phrasebased translation introduces the added wrinkle of source phrases with gaps.", "label": 1}
{"sent1": "In some scenarios, high quality transcriptions are needed and, therefore, fully automatic systems are not suitable for them.", "sent2": "Current automatic speech transcription systems can achieve a high accuracy although they still make mistakes.", "label": 1}
{"sent1": "Finally, we present an automatic method which leverages this association to detect domain-specific sentiment- and emotionbearing words.", "sent2": "We evaluate our method by comparison to human judgments, and analyze its strengths and weaknesses.", "label": 1}
{"sent1": "In addition, it is challenging to generate sufficient high quality labeled data for supervised models with low cost.", "sent2": "Due to the shortness of a tweet, a collective inference model incorporating global evidence from multiple mentions and concepts is more appropriate than a noncollecitve approach which links each mention at a time.", "label": 1}
{"sent1": "The framework recommends SMT outputs to a TM user when it predicts that SMT outputs are more suitable for post-editing than the hits provided by the TM.", "sent2": "We describe an implementation of this framework using an SVM binary classifier.", "label": 1}
{"sent1": "Our model utilizes a hierarchical prior to link the feature weights for shared features in several single-task models and the joint model.", "sent2": "Experiments on joint parsing and named entity recognition, using the OntoNotes corpus, show that our hierarchical joint model can produce substantial gains over a joint model trained on only the jointly annotated data.", "label": 1}
{"sent1": "YAGO, and (ii) any subset of Wikipedia documents.", "sent2": "We show that training data constituted by sentences containing pairs of named entities in target relations is enough to produce reliable supervision.", "label": 1}
{"sent1": "The experiments also show that the improvements in prediction accuracy apply to cases in which the presence of a that-complementizer arguably makes a substantial difference to fluency or intelligiblity.", "sent2": "Our ultimate goal is to improve the performance of a ranking model for surface realization, and to this end we conclude with a discussion of how we plan to combine the local complementizer-choice features with those in the global ranking model.", "label": 1}
{"sent1": "This feature yielded a significant improvement for data sets consisting of definite noun phrases and proper names, respectively.", "sent2": "Initial experiences show that simple translation grammars can be implemented on a time-scale of a few hours to a few days and produce signed output readily comprehensible to Deaf informants.", "label": 0}
{"sent1": "Dyna has many uses but was designed especially for rapid development of new statistical NLP systems.", "sent2": "A Dyna program is a small set of equations, resembling Prolog inference rules, that specify the abstract structure of a dynamic programming algorithm.", "label": 1}
{"sent1": "We describe an unsupervised approach, based on vector-space similarity, which does not require annotated examples but significantly outperforms their tagger.", "sent2": "We also demonstrate the use of an extremely large shallow-parsed corpus for calculating vector-space semantic similarity.", "label": 1}
{"sent1": "These methods exclude candidate prepositions that are not observed as valid corrections in the annotated corpus and take into account the likelihood of each preposition confusion in the non-native text.", "sent2": "We measured the performance both on synthetic data specifically produced for these two problems and on real social media data.", "label": 0}
{"sent1": "We use a combination of structures derived from phrase structure trees and dependency trees.", "sent2": "We show that our parser is both efficient and robust, although the grammar is very ambiguous.", "label": 0}
{"sent1": "No exhaustive research on a standard lexical representation of MWEs has been done for Dutch before.", "sent2": "This paper describes the design and implementation of a lexicon of Dutch multiword expressions (MWEs).", "label": 1}
{"sent1": "To develop our systems, we considered several approaches from rule based systems to statistical methods.", "sent2": "We conduct an empirical study to examine the effect of noisy annotations on the performance of sentiment classification models, and evaluate the utility of annotation selection on classification accuracy and efficiency.", "label": 0}
{"sent1": "Then, we design two separate pathways for translation from MSA into DA: a two-step domain and dialect adaptation system and a one-step simultaneous domain and dialect adaptation system.", "sent2": "Both variants of the adaptation systems are trained on a 100k sentence tri-parallel corpus of English, MSA, and Egyptian Arabic generated by a rule-based transformation.", "label": 1}
{"sent1": "There were 14 teams who submitted a total of 38 runs.", "sent2": "We build a model for speech disfluency detection based on conditional random fields (CRFs) using the Switchboard corpus.", "label": 0}
{"sent1": "Then we regard the Chinese S&T with heterogeneous corpora as two ?related?", "sent2": "We submitted one Random Forest regression system on each cross level text pair, i.e., Paragraph to Sentence (P-S), Sentence to Phrase (SPh), Phrase to Word (Ph-W) and Word to Sense (W-Se).", "label": 0}
{"sent1": "Within our framework, we carry out a large number of experiments to understand better and explain why phrase-based models outperform word-based models.", "sent2": "In principle, the global phrase reordering model is conditioned on the source and target phrases that are currently being translated, and the previously translated source and target phrases.", "label": 0}
{"sent1": "Thus, words, lemmas and senses are represented in the same space (the context space), and similarity measures can be defined between them.", "sent2": "We present a more principled, better performing model for this problem, based on the use of a hierarchical Bayesian prior.", "label": 0}
{"sent1": "The proposed model outperforms a word-level baseline at predicting user-annotated hashtags associated with the posts, doing significantly better when the input contains many outof-vocabulary words or unusual character sequences.", "sent2": "Our tweet2vec encoder is publicly available 1 .", "label": 1}
{"sent1": "The tagged output is then converted into segmented text.", "sent2": "The preliminary results show that this approach is competitive compared with other supervised machine-learning segmenters reported in previousstudies.", "label": 1}
{"sent1": "In this paper, we focus on analyzing the properties of the neural machine translation using two models; RNN Encoder?Decoder and a newly proposed gated recursive convolutional neural network.", "sent2": "We show that the neural machine translation performs relatively well on short sentences without unknown words, but its performance degrades rapidly as the length of the sentence and the number of unknown words increase.", "label": 1}
{"sent1": "Then, aligning pairs of related words translingually, it calculates the correlation between the senses of a first-language polysemous word and the words related to the polysemous word, which can be regarded as clues for determining the most suitable sense.", "sent2": "Performance is automatically evaluated via the Bleu score metric.", "label": 0}
{"sent1": "Borrowed words (or loanwords) are content words found in nearly all languages, occupying up to 70% of the vocabulary.", "sent2": "We define a probabilistic context-free grammar that describes the structure of the input (a corpus of database records and text describing some of them) and represent it compactly as a weighted hypergraph.", "label": 0}
{"sent1": "Penn Chinese Treebank (CTB) and PKU?s People?s Daily (PPD), on manually mapped data, and show that their linguistic annotations are systematically different and highly compatible.", "sent2": "The analysis is further exploited to improve processing accuracy by (1) integrating systems that are respectively trained on heterogeneous annotations to reduce the approximation error, and (2) re-training models with high quality automatically converted data to reduce the estimation error.", "label": 1}
{"sent1": "As a remedy, we learn to extract pieces of input text as justifications ?", "sent2": "Prediction without justification has limited applicability.", "label": 1}
{"sent1": "More specifically, we augment neural model with an external memory, which is shared by several tasks.", "sent2": "In this paper, we propose two deep architectures which can be trained jointly on multiple related tasks.", "label": 1}
{"sent1": "A bidirectional LSTM model is built to train over the abstract form of questions and infer their answer types.", "sent2": "It is also observed that if we convert a question into a statement form, our LSTM model achieves better accuracy.", "label": 1}
{"sent1": "We first build a sentence quotation graph that captures the conversation structure among emails.", "sent2": "We propose a technique that tackles these problems by de-conflating the representations of words based on the deep knowledge that can be derived from a semantic network.", "label": 0}
{"sent1": "Furthermore, unlike much recent work, our approach can identify expressions of various types and syntactic constructions.", "sent2": "We evaluate our method using a range of queries extracted from a web search log.", "label": 0}
{"sent1": "Since dependency relations capture the semantics of MNs well, the MN clusters constructed by using dependency relations should serve as a good gazetteer.", "sent2": "Implications for research and practice are discussed.", "label": 0}
{"sent1": "We combined two different similarity measures, distributional similarity, and orthographic similarity to calculate weights.", "sent2": "The quality function is calculated based on the weights of edges between nodes.", "label": 1}
{"sent1": "By integrating MT services directly into a messaging infrastructure (whatever the type of messages being serviced, e.g., text messages, Twitter feeds, blog postings, etc.", "sent2": "), MT can be used to provide first pass translations into a majority language, which can be more effectively triaged and then routed to the appropriate aid agencies.", "label": 1}
{"sent1": "Our experiments show that the use of rich syntactic features significantly outperforms shallow word-based features.", "sent2": "The best accuracy is obtained by combining SRL features with tree kernels.", "label": 1}
{"sent1": "This extends a previously proposed framework for cross-theory evaluation and allows us to compare a wider class of parsers.", "sent2": "This formulation enables us to encode some of the linguistic intuitions that have guided human decipherers.", "label": 0}
{"sent1": "We then aggregate these interactions and use a dynamic pooling to select the most informative features.", "sent2": "Specifically, we introduce two coupled ways to model the interdependences of two LSTMs, coupling the local contextualized interactions of two sentences.", "label": 1}
{"sent1": "Likey has a very light-weight preprocessing phase and no parameters to be tuned.", "sent2": "We thus describe separate treatment with two independent classifiers, outperforming the accuracy of a single classifier.", "label": 0}
{"sent1": "We investigated whether listeners perceive conversations with these improvements as natural (i.e., human-like) as human-human conversations.", "sent2": "We propose an efficient way to train maximum entropy language models (MELM) and neural network language models (NNLM).", "label": 0}
{"sent1": "In such cases, dialogue systems must be able to model the user?s (lexical) domain knowledge and use appropriate referring expressions.", "sent2": "bust?than?the?latter?in?the?domain?adaptation?", "label": 0}
{"sent1": "A key insight in our approach is to reduce the tasks of content selection (?what to say?)", "sent2": "This paper proposes a data-driven method for concept-to-text generation, the task of automatically producing textual output from non-linguistic input.", "label": 1}
{"sent1": "We use novel, disaster-specific features for salience prediction, including geo-locations and language models representing the language of disaster.", "sent2": "We present a system for update summarization which predicts the salience of sentences with respect to an event and then uses these predictions to directly bias a clustering algorithm for sentence selection, increasing the quality of the updates.", "label": 1}
{"sent1": "In order to test this approach, we perform an experiment using a computational learning system that receives as input utterances annotated with logical forms.", "sent2": "We propose an approach that uses semantically motivated preposition selection and frequency information to determine if a locative PP is an argument or an adjunct.", "label": 1}
{"sent1": "Experiments are performed in both Arabic-to-English and French-to-English translation demonstrating the efficacy of the proposed techniques.", "sent2": "We apply and extend the method described in (Resnik and Yarowsky, 1999), estimating proximity of sense pairs from the evidence collected from native-speaker translations of 508 contexts across 4 Indoeuropean languages representing 3 language families.", "label": 0}
{"sent1": "Standardisation adds to the interchange potential of the resources, making it easier to develop multilingual applications or to evaluate language technology tools across several languages.", "sent2": "The process of the harmonisation of morphosyntactic categories, esp.", "label": 1}
{"sent1": "In comparison, the same model augmented with active learning obtains 64.91%.", "sent2": "The model obtains an f-score of 53.8% on a dataset in which literal/nonliteral usages of 25 verbs were annotated by human experts.", "label": 1}
{"sent1": "By analyzing the coverage of these senses, it is shown that TPP provides potentially greater breadth and depth than other inventories of the range of semantic roles.", "sent2": "Results show that a small number of linguistically motivated lexical features are sufficient to achieve comparable performance to systems using sophisticated parse trees.", "label": 0}
{"sent1": "We treat the NomBank SRL task as a classification problem and explore the possibility of adapting features previously shown useful in PropBank-based SRL systems.", "sent2": "NomBank is a project at New York University to annotate the argument structures for common nouns in the Penn Treebank II corpus.", "label": 1}
{"sent1": "This approach extends the chunk tags for every problem by a tag-extension function.", "sent2": "1) We propose an approach to resolve the special problems of Chinese chunking.", "label": 1}
{"sent1": "We argue that the use of latent variables can help capture long range dependencies and improve the recall on segmenting long words, e.g., named-entities.", "sent2": "For the creation of the hand-tagged gold standard, all translations of a given polysemous English noun are retrieved in the five languages and clustered by meaning.", "label": 0}
{"sent1": "Current approaches to semantic inference in question answering and textual entailment have approximated the entailment problem as that of computing the best alignment of the hypothesis to the text, using a locally decomposable matching score.", "sent2": "We argue that there are significant weaknesses in this approach, including flawed assumptions of monotonicity and locality.", "label": 1}
{"sent1": "We report a comparative study of two methods for estimating word cooccurrence frequencies required by word similarity measures.", "sent2": "Targeted clarification questions focus specifically on the part of an utterance that is misrecognized, in contrast with generic requests to ?please repeat?", "label": 0}
{"sent1": "We extract features from the text based on prior work, and extend or modify it to construct different feature sets, and use support vector machines for classification.", "sent2": "A characteristic of our events (which distinguishes them from ACE events) is that the participating entities can be spread far across the parse trees.", "label": 0}
{"sent1": "Some studies have tried to exploit general dictionaries for that purpose, seeing them as graphs where words are related by the definition they appear in, in a complex network of an arguably semantic nature.", "sent2": "Synonyms extraction is a difficult task to achieve and evaluate.", "label": 1}
{"sent1": "To address this issue, we have proposed SemEval-2013 Task 2: Sentiment Analysis in Twitter, which included two subtasks: A, an expression-level subtask, and B, a messagelevel subtask.", "sent2": "Unfortunately, research has been hindered by the lack of suitable datasets, complicating the comparison between approaches.", "label": 1}
{"sent1": "In this paper, we consider how language impairments can affect segmentation methods, and compare the results of computing syntactic complexity metrics on automatically and manually segmented transcripts.", "sent2": "In this paper, we describe it in detail together with its data-collection method and annotation schemes.", "label": 0}
{"sent1": "Further, we extend this into a novel model, Switching FHMM, to allow for explicit modeling of cross-sequence dependencies based on linguistic knowledge.", "sent2": "All words having a MeSH synonym that was assessed as easier, were replaced in a corpus of medical text.", "label": 0}
{"sent1": "Moreover, our results suggest that presenting users with a brief summary of the irrelevant options increases users?", "sent2": "We evaluate our approach on several letter-to-phoneme and transliteration data sets.", "label": 0}
{"sent1": "We propose a novel family of reranking algorithms based on learning separate low-dimensional embeddings of the task?s input and output spaces.", "sent2": "The accuracy of many natural language processing tasks can be improved by a reranking step, which involves selecting a single output from a list of candidate outputs generated by a baseline system.", "label": 1}
{"sent1": "By using different linguistic features, we can easily adapt this system to other token-based linguistic tagging problems.", "sent2": "This paper describes some factors that add complexity to the task of engineering reusable NLP systems (beyond conventional software systems).", "label": 0}
{"sent1": "We describe the underlying context-free parser and how functional structures are efficiently computed on top of the CFG shared forest thanks to computation sharing, lazy evaluation, and compact data representation.", "sent2": "We show the SRL system can use incremental knowledge gain to switch from error-prone noun order features to a more accurate representation, demonstrating a possible mechanism for this process in child development.", "label": 0}
{"sent1": "In this paper, we show how to induce head-driven probabilistic parsers with latent heads from a tree-bank.", "sent2": "Thus, across domains, languages, and tree-bank annotations, a fundamental question arises: Is it possible to automatically induce an accurate parser from a tree-bank without resorting to full lexicalization?", "label": 1}
{"sent1": "Cross-language sentiment classification (CLSC) can leverage the rich resources in one language (source language) for sentiment classification in a resource-scarce language (target language).", "sent2": "For evaluation, we created a new dataset of 22,033 complex questions on Wikipedia tables, which is made publicly available.", "label": 0}
{"sent1": "However, for language pairs such as Arabic to English, phrasebased approaches continue to be competitive.", "sent2": "To recover such un-modeled inter-speaker information, we introduce an approach for conversational language modeling that considers words from other speakers when predicting words from the current one.", "label": 0}
{"sent1": "We present an input understanding method for a tutoring system teaching mathematical theorem proving.", "sent2": "Due to the lack of empirical data, little is known about the suitability of input analysis methods for mathematical discourse in a dialog setting.", "label": 1}
{"sent1": "Often such graphics convey information that is not contained elsewhere in the document.", "sent2": "Thus document summarization must be extended to include summarization of information graphics.", "label": 1}
{"sent1": "This restricts the techniques that can be used but makes the method useful for languages with few resources.", "sent2": "An important motivation is to reach a high level of language independence.", "label": 1}
{"sent1": "However, the significance of privacy policies greatly exceeds the attention paid to them: these documents are binding legal agreements between website operators and their users, and their opaqueness is a challenge not only to Internet users but also to policy regulators.", "sent2": "Website privacy policies are often ignored by Internet users, because these documents tend to be long and difficult to understand.", "label": 1}
{"sent1": "We modified a publicly available system (AkanePPI) to apply it to this new, but similar, protein interaction task.", "sent2": "AkanePPI has previously achieved state-of-the-art performance on all existing public PPI corpora, and only small changes were needed to achieve competitive results on this event extraction task.", "label": 1}
{"sent1": "In addition to presenting a fully Bayesian model for the PCFG, we also develop an efficient variational inference procedure.", "sent2": "The research described in this work focuses on identifying key components for the task of irony detection.", "label": 0}
{"sent1": "We create a self-trained relevant sentence classifier to identify relevant regions, and use a semantic affinity measure to automatically learn domain-relevant extraction patterns.", "sent2": "We then distinguish primary patterns from secondary patterns and apply the patterns selectively in the relevant regions.", "label": 1}
{"sent1": "We evaluated the reordering approach within the MOSES phrase-based SMT system (Koehn et al, 2007).", "sent2": "The reordering approach improved the BLEU score for the MOSES system from 28.52 to 30.86 on the NIST 2006 evaluation data.", "label": 1}
{"sent1": "Moreover, with a technique for performing inference given soft constraints, it is easy to automatically generate large families of constraints and learn their costs with a simple convex optimization problem during training.", "sent2": "This allows us to obtain substantial gains in accuracy on a new, challenging citation extraction dataset.", "label": 1}
{"sent1": "We evaluate our method on two tasks: cross-domain partof-speech tagging and cross-domain sentiment classification.", "sent2": "The corpus texts are selected randomly from citation abstracts and full-text papers with the aim of making the corpus representative of the entire available biomedical scientific literature.", "label": 0}
{"sent1": "We obtain the optimal combination of features on an aligned abbreviation corpus by using the maximum entropy framework.", "sent2": "Although some supervised hashing methods can derive effective hash functions from prior knowledge, they are either computationally expensive or poorly discriminative.", "label": 0}
{"sent1": "mantic  inter?sentential  discourse  rela?", "sent2": "We present a tool for annotation of se?", "label": 1}
{"sent1": "Current syntaxbased evaluation metrics try to introduce syntax information but suffer from the poor parsing results of the noisy machine translations.", "sent2": "More recently, computational work using distributional algorithms has shown that the information contained in the input is much richer than proposed by the nativist approach.", "label": 0}
{"sent1": "This paper presents a LCCT (Lexicon-based and Corpus-based, Co-Training) model for semi-supervised sentiment classification.", "sent2": "In addition, we want the algorithm being able to deal with missing labels and learning from incomplete sentiment lexicons.", "label": 1}
{"sent1": "Our primary aim is to understand what depth of language understanding is required to do well on this task.", "sent2": "In this paper, we conduct a thorough examination of this new reading comprehension task.", "label": 1}
{"sent1": "Large language and translation models are built using all the datasets provided by the shared task organisers, as well as the monolingual data from LDC.", "sent2": "Existing work in fine-grained sentiment analysis focuses on sentences and phrases but ignores the contribution of individual words and their grammatical connections.", "label": 0}
{"sent1": "We formulate the role induction problem as one of detecting alternations and finding a canonical syntactic form for them.", "sent2": "Moreover, we introduce two extensions related to dependency parsing: The first extension is to combine SS-SCMs with another semi-supervised approach, described in (Koo et al, 2008).", "label": 0}
{"sent1": "Our algorithms are designed for similarity functions that are sequence kernels in a general class of positive definite symmetric kernels.", "sent2": "Our experiments show that exact inference is then feasible using only a fraction of the time and space that would be required by the full intersection, without recourse to pruning techniques that only provide approximate solutions.", "label": 0}
{"sent1": "AdaRNN adaptively propagates the sentiments of words to target depending on the context and syntactic relationships between them.", "sent2": "It consists of more than one composition functions, and we model the adaptive sentiment propagations as distributions over these composition functions.", "label": 1}
{"sent1": "However, others have shown that simple lexical features perform well on their own.", "sent2": "This paper evaluates the effect of using different lexical and syntactic features both individually and in combination.", "label": 1}
{"sent1": "First, there is no effective mechanism available for predicting orders between neighboring blocks in the original BTG.", "sent2": "Second, the computational cost is high.", "label": 1}
{"sent1": "Sentences can then be generated based on such grammar rules with a log-linear model.", "sent2": "We assume access to a reward function that defines the quality of the executed actions.", "label": 0}
{"sent1": "In order to establish a fair and neutral comparison, the quality of each knowledge resource is indirectly evaluated using the same method on a Word Sense Disambiguation task.", "sent2": "translations.", "label": 0}
{"sent1": "First, this specific task is described from a linguistic point of view.", "sent2": "Then a methodology combining pattern mining and language processing is proposed.", "label": 1}
{"sent1": "We also apply a top performing TempEval 2013 system against this new resource to measure the difficulty of adapting systems to the clinical domain.", "sent2": "In particular, we use Senseval-3 and SemEval-2007 English Lexical Sample tasks as evaluation bechmarks to evaluate the relative quality of each resource.", "label": 0}
{"sent1": "Therefore, their identification is important for the automatic construction of knowledge bases.", "sent2": "Generic statements express rulelike knowledge about kinds or events.", "label": 1}
{"sent1": "Furthermore, unlike supervised learning methods which require a large corpus of expert adaptive behaviour to train on, we show that effective adaptive policies can be learned from a small dialogue corpus of non-adaptive human-machine interaction, by using a RL framework and a statistical user simulation.", "sent2": "We present a reinforcement learning (RL) framework in which the system learns REG policies which can adapt to unknown users online.", "label": 1}
{"sent1": "We perform a lexical, syntactic, and semantic analysis of the entailment pairs .", "sent2": "From this information we compute a set of semanticbased distances between sentences.", "label": 1}
{"sent1": "Moreover, we introduce two extensions related to dependency parsing: The first extension is to combine SS-SCMs with another semi-supervised approach, described in (Koo et al, 2008).", "sent2": "Participants were presented with datasets for different language pairs, where multi-directional entailment relations (?forward?, ?backward?, ?bidirectional?, ?no entailment?)", "label": 0}
{"sent1": "We introduce a method of converting these grammars to a weakly equivalent tree transducer for decoding.", "sent2": "In this paper, we describe a novel method for learning a type of Synchronous Tree Adjoining Grammar and associated probabilities from aligned tree/string training data.", "label": 1}
{"sent1": "However, they suffer from the generalizability problem when applied on test data from different domains.", "sent2": "We introduce a multi-layer Chinese word segmentation system which can integrate the outputs from multiple heterogeneous segmentation systems.", "label": 1}
{"sent1": "syntactic dependencies that fall into the primary empirical domain of TAG-Adjoining, namely, long-distance movement/filler-gap dependencies across a tensed clause boundary.", "sent2": "A theory that incorporates Adjoining as a recursive structure building device provides a novel and straightforward account of this gap, whereas existing theories of syntactic locality, e.g.", "label": 1}
{"sent1": "The problem of this approach is that ILP solvers are black-boxes and have no theoretical guarantee as to their computation complexity.", "sent2": "We propose a dynamic programming (DP) algorithm for tree trimming problems whose running time is O(NL logN), where N is the number of tree nodes and L is the length limit.", "label": 1}
{"sent1": "Although such statistics are semantically informative, they disregard the valuable information that is contained in semantic lexicons such as WordNet, FrameNet, and the Paraphrase Database.", "sent2": "Vector space word representations are learned from distributional information of words in large corpora.", "label": 1}
{"sent1": "In this paper, we investigate how different objective functions and optimization methods affect the performance of the classifiers in the discriminative learning framework.", "sent2": "Semantic role labeling techniques are typically trained on newswire text, and in tests their performance on fiction is as much as 19% worse than their performance on newswire text.", "label": 0}
{"sent1": "The connectionist models can be further trained by an EM procedure, similar to the previously used procedure for training the SLM.", "sent2": "Our empirical results, which hold for all examined language pairs, suggest that the highest levels of performance can be obtained through relatively simple means: heuristic learning of phrase translations from word-based alignments and lexical weighting of phrase translations.", "label": 0}
{"sent1": "However, existing models for learning word representations focus on either syntagmatic or paradigmatic relations alone.", "sent2": "Vector space representation of words has been widely used to capture fine-grained linguistic regularities, and proven to be successful in various natural language processing tasks in recent years.", "label": 1}
{"sent1": "In this study, we apply the Turku Event Extraction System, the best-performing system for these tasks, to all PubMed abstracts and all available PMC full-text articles, extracting 1.4M EPI events and 2.2M REL relations from 21M abstracts and 372K articles.", "sent2": "Why do certain combinations of words such as ?disadvantageous peace?", "label": 0}
{"sent1": "We are working with one of the largest nature conservation charities in Europe in this regard, focusing on a single species, the red kite.", "sent2": "Finally, we describe challenges and opportunities for the research community to use this corpus to advance research in both privacy and language technologies.", "label": 0}
{"sent1": "General search engines (GSEs) do not support queries over these types of data because they ignore the web document semantics.", "sent2": "At the same time, making the correct choice is often critical to the coherence of the output text.", "label": 0}
{"sent1": "language.", "sent2": "For centuries, the deep connection between languages has brought about major discoveries about human communication.", "label": 0}
{"sent1": "Since GATE comes with a customisable and extendable set of components, it allows students to get hands-on experience with building NLP applications.", "sent2": "As far as we know, this is the first work on joint Chinese word segmentation, POS tagging and parsing.", "label": 0}
{"sent1": "However, due to the lack of phrasal nodes in dependency graphs, application of RNN is not straightforward.", "sent2": "Our results illustrate how such a metric inspired by cognitive psychology can help answer critical questions regarding students?", "label": 0}
{"sent1": "In particular, in terms of F-score and NIST Error Rate the absolute improvement of ILP over CRFs exceeds 20% and 25% respectively.", "sent2": "We report a comparative study of two methods for estimating word cooccurrence frequencies required by word similarity measures.", "label": 0}
{"sent1": "However, the fact that these are manual tasks makes them expensive and slow.", "sent2": "Transcription and semantic annotation (annoscription) of utterances is crucial part of speech performance analysis and tuning of spoken dialog systems and other natural language processing disciplines.", "label": 1}
{"sent1": "We experimentally compare classification accuracies for several cases when an ASR confidence measure is used alone or in combination with the features based on the user?s utterance history.", "sent2": "In this paper, we present a two-stage approach to acquire Japanese unknown morphemes from text with full POS tags assigned to them.", "label": 0}
{"sent1": "AttitudeMiner uses linguistic techniques to analyze the text exchanged between participants of online discussion threads at different levels of granularity: the word level, the sentence level, the post level, and the thread level.", "sent2": "The goal of this analysis is to identify the polarity of the attitude the discussants carry towards one another.", "label": 1}
{"sent1": "Our model (with 97.06% on synthetic data) improves the state of the art results for diacritization of Turkish by 3.65 percentage points on ambiguous cases and for the vowel restoration by 45.77 percentage points over a rule based baseline with 62.66% accuracy.", "sent2": "The results on real data are 95.43% and 69.56% accordingly.", "label": 1}
{"sent1": "The combination is done by applying a Bayesian voting scheme.", "sent2": "Translation grammars are written in a version of Synchronous Context-Free Grammar adapted to the peculiarities of sign language.", "label": 0}
{"sent1": "This paper represents one of the first steps towards an XDG-based integrated generation architecture by tackling what is arguably the most basic among generation tasks: lexicalization.", "sent2": "The method developed by Li et al (2006) is extended in this paper to take a course description from one university as the input and suggest equivalent courses offered at another university.", "label": 0}
{"sent1": "for example all pairs of a person and the corresponding birthdate.", "sent2": "In this paper, we present LEILA, a system that can extract instances of arbitrary given binary relations from natural language Web documents ?", "label": 1}
{"sent1": "The corpus contains 731 sentences, each with one annotated CW.", "sent2": "We discuss what new challenges this creates for NLG systems.", "label": 0}
{"sent1": "We propose an extension to the Viterbi algorithm designed to improve the grammaticality of generated sentences.", "sent2": "Within a statistical framework, the extension favours those partially generated strings with a probable dependency tree structure.", "label": 1}
{"sent1": "We  also  describe  how the cascaded approach is embedded  in  a  large-scale  XML-based  application  (EBIMed) used for on-line access to biomedical  literature.", "sent2": "Such models ignore linguistic interactions at the sentence level and thus do poorly on mistakes that involve grammatical dependencies among several words.", "label": 0}
{"sent1": "The second, bilingual view consists of log-linear predictors learned over both languages on bilingual text.", "sent2": "We present a framework for using continuousspace vector representations of word meaning to derive new vectors representing the meaning of senses listed in a semantic network.", "label": 0}
{"sent1": "a very large, wide-coverage multilingual semantic network.", "sent2": "The resource is automatically constructed by means of a methodology that integrates lexicographic and encyclopedic knowledge from WordNet and Wikipedia.", "label": 1}
{"sent1": "The central challenge arises from two compounding factors: the broader domain results in an open-ended set of relations, and the deeper compositionality results in a combinatorial explosion in the space of logical forms.", "sent2": "confidence in having heard about all relevant options.", "label": 0}
{"sent1": "We evaluate on five languages and show that semi-supervised training provides a boost over unsupervised training, while the model selection method yields the best average results over all languages and is competitive with state-ofthe-art semi-supervised systems.", "sent2": "We also investigate how the two views (linguistic and social) can be combined and analyse how prediction accuracy changes over different age groups.", "label": 0}
{"sent1": "Word forming units are thus relevant cues for the identification of terms in domainspecific texts.", "sent2": "In this paper, we investigate the application of recurrent neural network language models (RNNLM) and factored language models (FLM) to the task of language modeling for Code-Switching speech.", "label": 0}
{"sent1": "Conventional title generation focuses on finding key expressions from the author?s wording in the document to give a compact summary and pays little attention to the reader?s interest.", "sent2": "The title of a document has two roles, to give a compact summary and to lead the reader to read the document.", "label": 1}
{"sent1": "We used a popular phrasebased machine translation system for English-Hindi machine transliteration.", "sent2": "Results from the formal evaluation show that both approaches are useful for determining the similarity in meaning between pairs of sentences with the best performance being obtained by the supervised approach.", "label": 0}
{"sent1": "Verbs or verb phrases are automatically extracted, yielding a ranked list of candidate relations.", "sent2": "The terms are instances of the pair of ontological classes under consideration, drawn from a populated knowledge base.", "label": 1}
{"sent1": "3) How much annotation is required for a pattern-based system to achieve good performance?", "sent2": "2) What kind of questions can be answered by pattern matching?", "label": 1}
{"sent1": "Structurally, our model is a semiMarkov conditional random field with features targeting characteristics unique to speech repairs.", "sent2": "We present a discriminative model for detecting disfluencies in spoken language transcripts.", "label": 1}
{"sent1": "We show that it is sometimes possible to eliminate this last bit of supervision, by trying many candidate seeds and selecting the one with the most plausible outcome.", "sent2": "Finally, we establish that combining the output of context-free and finitestate parsers gives much higher results than the previous-best published results, on several common tasks.", "label": 0}
{"sent1": "The extracted compound nouns and their multilingual contexts are a rich source that serves several purposes.", "sent2": "We demonstrate how our customised extensions to U-Compare allow the construction and testing of NLP applications that transform the input data in different ways, e.g., machine translation, automatic summarisation and text-to-speech.", "label": 0}
{"sent1": "In particular, the triangulation method, which translates by combining source-pivot and pivot-target translation models into a source-target model, is known for its high translation accuracy.", "sent2": "However, in the conventional triangulation method, information of pivot phrases is forgotten and not used in the translation process.", "label": 1}
{"sent1": "Although relevant for human readers with low reading skills or language disabilities, the process has direct applications in NLP.", "sent2": "In this paper we analyse the extraction of relative clauses through a tagging approach.", "label": 1}
{"sent1": "Most studies also use sizes of training data that are unrealistic for situations in which stylometry is applied (e.g., forensics), and thereby overestimate the accuracy of their approach in these situations.", "sent2": "The enhancements exploit the UIMA Subject of Analysis (Sofa) mechanism, that allows different facets of the input data to be represented.", "label": 0}
{"sent1": "The privacy requirements associated with utilizing everyday telephone conversations preclude manual annotations; hence, we explore semi-supervised methods in this task.", "sent2": "We apply semi-supervised topic modeling techniques to detect health-related discussions in everyday telephone conversations, which has applications in large-scale epidemiological studies and for clinical interventions for older adults.", "label": 1}
{"sent1": "We suggest various metrics to replace F 1 -score for the ?BAD?", "sent2": "We propose a method to harness such translations to improve automatic phoneme recognition.", "label": 0}
{"sent1": "Computationally precise lexica may use hundreds of paradigms, and it can be hard for a lexicographer to choose among them.", "sent2": "Morphological lexica are often implemented on top of morphological paradigms, corresponding to different ways of building the full inflection table of a word.", "label": 1}
{"sent1": "Furthermore, a comparison between RNNLMs and FLMs and a detailed analysis of perplexities on the different backoff levels are performed.", "sent2": "We present a way to integrate partof-speech tags (POS) and language information (LID) into these models which leads to significant improvements in terms of perplexity.", "label": 1}
{"sent1": "Our experiments demonstrate a clear anchoring effect and reveal unwanted consequences, including overestimation of parsing performance and lower quality of annotations in comparison with humanbased annotations.", "sent2": "We study the influence of anchoring on a standard approach to creation of syntactic resources where syntactic annotations are obtained via human editing of tagger and parser output.", "label": 1}
{"sent1": "Feature design focuses on target-side features as we hypothesise that the source side has little effect on the quality of human translations, which are included in task 1.1 of this year?s WMT Quality Estimation shared task.", "sent2": "Open information extraction (Open IE) was presented as an unrestricted variant of traditional information extraction.", "label": 0}
{"sent1": "This leads to a constrained optimization problem, and we present an approximation for the case when the distance function is the squared Euclidean.", "sent2": "This paper presents the Kazakh Language Corpus (KLC), which is one of the first attempts made within a local research community to assemble a Kazakh corpus.", "label": 0}
{"sent1": "We use its probabilistic output to control weighted interpolation of separate language models for easy and difficult reading.", "sent2": "We propose a new model that conjoins features and word embeddings while maintaing a small number of parameters by learning feature embeddings jointly with the parameters of a compositional model.", "label": 0}
{"sent1": "To the best of our knowledge, there is no previous work on reordering model (RM) adaptation for phrasebased SMT.", "sent2": "In this proof-ofconcept paper we address this by learning embeddings that simulate the behavior of first-order logic.", "label": 0}
{"sent1": "We find that these soft similarity methods generally outperformed our previous year?s systems, albeit they did not perform as well in the overall rankings.", "sent2": "A simple analysis of the soft similarity resources over two word phrases is provided, and future areas of improvement are described.", "label": 1}
{"sent1": "Along with its primary part KLC comprises such parts as: (i) annotated sub-corpus, containing segmented documents encoded in the eXtensible Markup Language (XML) that marks complete morphological, syntactic, and structural characteristics of texts; (ii) as well as a sub-corpus with the annotated speech data.", "sent2": "We demonstrate that, when done right, adjoining improves translation quality without becoming computationally intractable.", "label": 0}
{"sent1": "This work proposes a semanticbased approach for automatically identifying potential course equivalencies given their catalog descriptions.", "sent2": "Although related research provides some semantic-based algorithms, few applications exist.", "label": 1}
{"sent1": "One advantage of this approach is that, at the second stage, we can exploit syntactic clues in addition to morphological ones because as a result of the first stage acquisition, we can rely on automatic parsing.", "sent2": "The resulting translations improve by 1.3 BLEU.", "label": 0}
{"sent1": "First, we use an unsupervised method to collect training samples from Web documents.", "sent2": "Second, a set of expressions generally referring to troubles is acquired by a supervised learning method.", "label": 1}
{"sent1": "To assess to which extent it is necessary to deal with German compounds as a part of preprocessing in SMT systems, we have  tested  different  compound splitters and strategies, such as adding lists of compounds and their translations to the training set.", "sent2": "This work shows how to improve state-of-the-art monolingual natural language processing models using unannotated bilingual text.", "label": 0}
{"sent1": "We show when explicitly normalising neural models is necessary and what optimisation tricks one should use in such scenarios.", "sent2": "Statistical measures of word similarity have application in many areas of natural language processing, such as language modeling and information retrieval.", "label": 0}
{"sent1": "Our prior is theoretically appealing since it is motivated by languageindependent, universal properties of the CCG formalism.", "sent2": "The written form of Arabic, Modern Standard Arabic (MSA), differs quite a bit from the spoken dialects of Arabic, which are the true ?native?", "label": 0}
{"sent1": "Our goal is to learn from smaller amounts of supervised training data, by collecting a richer kind of training data: annotations with ?rationales.?", "sent2": "When annotating an example, the human teacher will also highlight evidence supporting this annotation?thereby teaching the machine learner why the example belongs to the category.", "label": 1}
{"sent1": "Currently, however, the scoring of the assessment depends either on manual grading of students?", "sent2": "Current approaches to semantic inference in question answering and textual entailment have approximated the entailment problem as that of computing the best alignment of the hypothesis to the text, using a locally decomposable matching score.", "label": 0}
{"sent1": "Evaluation on BioNLP Shared Task 2011 data indicates the method to outperform the negation/speculation components of state-of-theart event extraction systems.", "sent2": "The system and resources introduced in this work are publicly available for research purposes at: https://github.com/ninjin/eepura", "label": 1}
{"sent1": "We show that a Gibbs sampling technique is capable of parsing sentences in a wide variety of languages and producing results that are on-par with or surpass previous approaches.", "sent2": "We first present a Multiple-predicate Bootstrapping approach that consists of iteratively learning if-then rules based on an implicit observation model and then imputing new facts implied by the learned rules.", "label": 0}
{"sent1": "Finally, we introduce many-to-one block alignment features, which significantly improve our ITG models.", "sent2": "For efficiency, we describe a set of pruning techniques that together allow us to align sentences two orders of magnitude faster than naive bitext CKY parsing.", "label": 1}
{"sent1": "We propagate gender information through the videos and show that a user?s gender can be predicted from her social environment with the accuracy above 90%.", "sent2": "We also show that the gender can be predicted from language alone (89%).", "label": 1}
{"sent1": "Applied after rule binarization, weight pushing takes the weight from the original grammar rule and pushes it down across its binarized pieces, allowing the parser to make better pruning decisions earlier in the parsing process.", "sent2": "As far as we know, this is the first work on joint Chinese word segmentation, POS tagging and parsing.", "label": 0}
{"sent1": "In tasks like sentiment analysis, such approaches can result in limited effectiveness if the texts to be classified consist of a series of arguments.", "sent2": "In this paper, we claim that even a shallow model of the argumentation of a text allows for an effective and more robust classification, while providing intuitive explanations of the classification results.", "label": 1}
{"sent1": "We show that some of the oldest (and simplest) systems stand up surprisingly well against more recent approaches.", "sent2": "We conclude that ILP is an approach with great potential for speech disfluency detection when there is a lack or shortage of indomain data for training.", "label": 0}
{"sent1": "Maximum Entropy Markov Models are implemented to estimate conditional probability distribution and to do inference.", "sent2": "The submitted model yields 76.28% macro-average F1 performance, for the joint task, 85.75% syntactic dependencies LAS and 66.61% semantic dependencies F1.", "label": 1}
{"sent1": "Thus, in order to ?fill in the gaps?", "sent2": "We manually evaluate our trained model?s ability to assign quality scores to novel tuples, finding that it can propose tuples at the same quality level as mediumconfidence tuples from ConceptNet.", "label": 0}
{"sent1": "Existing work in the visual domain focuses on content selection for text generation and relies primarily on templates to generate surface realizations from underlying content choices.", "sent2": "In contrast, we seek to clarify the influence of visual perception on the linguistic form (as opposed to the content) of descriptions, modeling the variation in and constraints on the surface orderings in a description.", "label": 1}
{"sent1": "In order to handle a large set of translation units, these representations and the associated estimates are jointly computed using a multi-layer neural network with a SOUL architecture.", "sent2": "?", "label": 0}
{"sent1": "To overcome the problem of a large number of labelled negative stories, we classify them into some clusters.", "sent2": "Windows troubleshooting guides and game tutorials.", "label": 0}
{"sent1": "In interactive settings with a shared workspace, however, human dialog partners often split referring expressions into installments that adapt to changes in the context and to actions of their partners.", "sent2": "Attitude predictions are used to construct a signed network representation of the discussion thread.", "label": 0}
{"sent1": "Additionally, the DM problem is modeled as a Partially Observable Markov Decision Processes (POMDP) with sentence clusters.", "sent2": "Firstly, sentences are clustered not only based on the internal information such as words and sentence structures, but also based on the external information such as context in dialogue via Recurrent Neural Networks.", "label": 1}
{"sent1": "While early deletion is found to yield only modest benefit for in-domain parsing, significant improvement is achieved for out-of-domain adaptation.", "sent2": "using an extremely small amount of user provided training data.", "label": 0}
{"sent1": "Experiments on four government instructional videos show that 82% of the salient keywords appear in the top 50% of the highly ranked keywords.", "sent2": "The systems described in this paper use OSM (Operation Sequence Model).", "label": 0}
{"sent1": "Focusing on this binary task, we show that subjective human judgements can be effectively replaced with an automatic annotation procedure.", "sent2": "To this aim, we compare binary classifiers trained on different data: the human-annotated dataset from the 7th Workshop on Statistical Machine Translation (WMT-12), and an automatically labelled version of the same corpus.", "label": 1}
{"sent1": "We present (1) efficient, online inference for representing documents in several languages in a common topic space and (2) fast approximations for finding near neighbors in the probability simplex.", "sent2": "Empirical evaluations show that these methods are as accurate as?and significantly faster than?", "label": 1}
{"sent1": "This paper describes the first application of such techniques to ranked retrieval, evaluated using a newly created test collection.", "sent2": "In this paper, we present a method for annotating verbal reference to people in conversational speech, with a focus on reference to conversation participants.", "label": 0}
{"sent1": "Initial experiences show that simple translation grammars can be implemented on a time-scale of a few hours to a few days and produce signed output readily comprehensible to Deaf informants.", "sent2": "We evaluate the simplification according to three criteria: preservation of grammaticality, preservation of meaning, and degree of simplification.", "label": 0}
{"sent1": "We relate HMEANT to an established linguistic theory, highlighting the possibilities of reusing existing knowledge and resources for interpreting and automating HMEANT.", "sent2": "A recent successful attempt showed the advantage of using phrasebased search on top of an N-gram-based model.", "label": 0}
{"sent1": "The resulting classes are evaluated against a hand-annotated gold standard and achieve an f-score of 0.5 and 0.746 for locations and persons, respectively.", "sent2": "A target application is the Urdu ParGram grammar, where MWEs are needed to generate a more precise syntactic and semantic analysis.", "label": 1}
{"sent1": "The problem of generating such a 3D simulation can be divided into two subtasks: the linguistic analysis and the virtual scene generation.", "sent2": "hybridization ?", "label": 0}
{"sent1": "First, we can incorporate features on phrase pairs, in addition to word links.", "sent2": "This renders them sensitive to formal variation both within and across languages, and limits their value to semantic applications.", "label": 0}
{"sent1": "For evaluation, we use an English collection of MedLine records: OHSUMED.", "sent2": "The categorizer also benefits from the availability of large thesauri, where variants of MeSH terms can be found.", "label": 1}
{"sent1": "Sub-task 2 system also makes use of discourse-based rules.", "sent2": "logs.", "label": 0}
{"sent1": "While it follows a classical NLG pipeline, it diverges from most current NLG systems in that it exploits an ontology lexicon in order to capture context-specific lexicalisations of ontology concepts, and combines the use of such a lexicon with the choice of lexical items and syntactic structures based on statistical information extracted from a domain-specific corpus.", "sent2": "In this paper we develop and evaluate a Natural Language Generation (NLG) system that converts RDF data into natural language text based on an ontology and an associated ontology lexicon.", "label": 1}
{"sent1": "We partly defuse the Boolean challenge by showing that the data actually argue against a single type covering questions and propositions.", "sent2": "The Bayes decision rule for minimizing the number of string errors is widely used, e.g.", "label": 0}
{"sent1": "These tasks have focused on literal descriptions of the image.", "sent2": "Europarl), and (3) unannotated monolingual (e.g.", "label": 0}
{"sent1": "to fit HLR models, reducing error by 45%+ compared to several baselines at predicting student recall rates.", "sent2": "a popular online language learning application ?", "label": 1}
{"sent1": "We propose a model for joint dependency parsing and multiword expressions identification, in which complex function words are represented as individual tokens linked with morphological dependencies.", "sent2": "This is not always realistic, since they can be ambiguous.", "label": 1}
{"sent1": "The application of bootstrapping to time expression recognition is, to the best of our knowledge, novel.", "sent2": "Because the only supervision is in the form of seed examples, it becomes necessary to resort to heuristics to rank and filter out spurious patterns and candidate time expressions.", "label": 1}
{"sent1": "Even the pure phrase rules are includes in some of these models.", "sent2": "In these models, not only the conventional syntactic rules but also the non-syntactic rules can be applied.", "label": 1}
{"sent1": "Based on this hypothesis, we built a Japanese fully-lexicalized generative parser that includes coordination disambiguation.", "sent2": "Experimental results on web sentences indicated the effectiveness of our approach, and endorsed our hypothesis.", "label": 1}
{"sent1": "We introduce a range of feature sets and associated extraction techniques, and evaluate them thoroughly using a robust method new to the task: cost-based framework for pairwise clustering.", "sent2": "We present a bilayer directed graph to express probabilistic relationships between syntactic and semantic relations.", "label": 0}
{"sent1": "NPMI is typically used for recognition of strong word connections but in our solution we use it to recognise the weakest points within phrases to suggest the best place for division of a phrase into two parts.", "sent2": "Our experimental results show that this model detected wrong labels with higher performance than baseline methods.", "label": 0}
{"sent1": "By making use of Apache Lucene, we are able to do fuzzy string match to extract hedge cues, and to incorporate part-of-speech (POS) tags in hedge cues.", "sent2": "Distortion is the sum of the distances between the representative sentence of the cluster at each node and the other sentences in the same cluster.", "label": 0}
{"sent1": "Notably, only 16 features are used in our experiments.", "sent2": "These features describe, on the one hand, the quality of the association between the source sentence and each target word and, on the other hand, the fluency of the hypothesis.", "label": 1}
{"sent1": "In experiments using the Chinese Treebank (CTB), we show that the accuracies of the three tasks can be improved significantly over the baseline models, particularly by 0.6% for POS tagging and 2.4% for dependency parsing.", "sent2": "This  paper  summarizes  the results of our experiments and attempts to yield better translations of German nominal compounds into Spanish and shows how our approach improves by up to 1.4 Bleu points with respect to the baseline.", "label": 0}
{"sent1": "We demonstrate that allowing different values for these hyperparameters significantly improves performance over both a strong baseline and (Daume?", "sent2": "is actually equivalent, except our representation explicitly separates hyperparameters which were tied in his work.", "label": 1}
{"sent1": "Quadratic filters, a simplification of a theoretical model of V1 complex cells, reliably increase accuracy.", "sent2": "This paper presents the end-to-end evaluation of an automatic simultaneous translation system, built with state-of-the-art components.", "label": 0}
{"sent1": "We evaluate our approach on the SemEval 2016 Task 6 Twitter Stance Detection corpus achieving performance second best only to a system trained on semiautomatically labelled tweets for the test target.", "sent2": "Performance is improved further when the conditional model is augmented with bidirectional encoding.", "label": 1}
{"sent1": "First, a word can be ambiguous between discourse or non-discourse usage.", "sent2": "There are two types of ambiguity that need to be resolved during discourse processing.", "label": 1}
{"sent1": "We employ learning techniques to study 1) the decision to either stop and ask a clarification question or to continue the dialogue without clarification, and 2) the decision to ask a targeted clarification question or a more generic question.", "sent2": "This paper shows that using linguistically motivated features for English that-complementizer choice in an averaged perceptron model for classification can improve upon the prediction accuracy of a state-of-the-art realization ranking model.", "label": 0}
{"sent1": "Some semantic features were created using WordNet glosses with semantic relations tagged manually and automatically as part of eXtended WordNet project.", "sent2": "However, in our task, we find that mention detection is often the performance bottleneck.", "label": 0}
{"sent1": "These nouns themselves are unspecific, and can only be interpreted together with the shell content.", "sent2": "In this paper, we champion a third approach, in which computational models learn from naturalistic input and produce utterances that can be directly compared with the utterances of languagelearning children.", "label": 0}
{"sent1": "hybridization ?", "sent2": "We present a system to translate natural language sentences to formulas in a formal or a knowledge representation language.", "label": 0}
{"sent1": "During label prediction, the system automatically selects for each feature an appropriate level of smoothing.", "sent2": "Our system integrates the task of learning tree structure and learning labels in one step, using the same set of features for both tasks.", "label": 1}
{"sent1": "We use our system to construct a crowdsourced dataset of over 15,000 highquality, diverse questions.", "sent2": "Although related research provides some semantic-based algorithms, few applications exist.", "label": 0}
{"sent1": "We present a method for constructing interpretable word vectors from hand-crafted linguistic resources like WordNet, FrameNet etc.", "sent2": "with candidate answers this paper and a parser.", "label": 0}
{"sent1": "Several  machine learning based systems have  been developed and showed good performance in the challenge.", "sent2": "In this paper, we propose that MT is an important technology in crisis events, something that can and should be an integral part of a rapid-response infrastructure.", "label": 0}
{"sent1": "The merged list is then ranked according to the prospective post-editing effort and provided to the translators to aid their work.", "sent2": "Sentence Similarity [SS] computes a similarity score between two sentences.", "label": 0}
{"sent1": "We propose an alternative approach to generating forests that is based on combining sub-trees within the first best parse through binarization.", "sent2": "In this paper, we investigate how different objective functions and optimization methods affect the performance of the classifiers in the discriminative learning framework.", "label": 0}
{"sent1": "First, we use the Web 1T Google n-gram corpus for checking the applicability of a synonym in context, and we evaluate this method using data from the SemEval lexical substitution task.", "sent2": "The best result reported for the first subtask was F1 of 71.5% and 65.1% for the second one.", "label": 0}
{"sent1": "Significant progress has been made for inducing dependency grammars, however the models employed are overly simplistic, particularly in comparison to supervised parsing models.", "sent2": "Generalisation gives better results with the Jaccard index, narrow sliding windows and relations of lexical inclusion.", "label": 0}
{"sent1": "Threaded discussions include e-mails, e-mail lists, bulletin boards, newsgroups, and Internet forums.", "sent2": "We describe the process of using skilled annotators and a purpose-built annotation tool to produce the data.", "label": 0}
{"sent1": "Empirically, the parallel AL algorithm effectively has a batch size of one and a large candidate set size but eliminates the time an annotator would have to wait for a similarly parameterized batch scheme to select instances.", "sent2": "More specifically, we classify barge-in utterances into correctly and erroneously interpreted ones by using features of individual users?", "label": 0}
{"sent1": "Second, we show that lexicalizing the hierarchical models used in Frank and Bod (2011) significantly improves prediction accuracy relative to the unlexicalized versions.", "sent2": "In this approach, specialized memory-based wordexperts were trained per word-POS combination.", "label": 0}
{"sent1": "It shows whether, and for which situations, such a system might be advantageous when compared to a human interpreter.", "sent2": "This paper presents the end-to-end evaluation of an automatic simultaneous translation system, built with state-of-the-art components.", "label": 1}
{"sent1": "The proposed EE approach is: simple (most events are captured with simple lexico-syntactic patterns), powerful (the language can capture complex constructs, such as events taking other events as arguments, and regular expressions over syntactic graphs), robust (to recover from syntactic parsing errors, syntactic patterns can be freely mixed with surface, token-based patterns), and fast (the runtime environment processes 110 sentences/second in a real-world domain with a grammar of over 200 rules).", "sent2": "The experimental studies illustrate that AdaRNN improves the baseline methods.", "label": 0}
{"sent1": "Examples of these contextual information are social network structure, and conversational, author, and topic contexts.", "sent2": "Disregarding these information poses a problem because at times, context is needed to clearly infer the sentiment of a tweet.", "label": 1}
{"sent1": "The generalization is at the cost of asymptotic efficiency.", "sent2": "Researchers in textual entailment have begun to consider inferences involving downward-entailing operators, an interesting and important class of lexical items that change the way inferences are made.", "label": 0}
{"sent1": "To make sure that the resulting system is practically useful, several user groups have been identified, who drive the interface development process by providing practical use cases.", "sent2": "In this paper, we compare rating scales with an alternative evaluation paradigm, preferencestrength judgement experiments (PJEs), where evaluators have the simpler task of deciding which of two texts is better in terms of a given quality criterion.", "label": 0}
{"sent1": "Gains were observed in all conditions, with segments of either regular or varying length and abrupt or smooth topic shifts.", "sent2": "Experimental results on standard textual data sets and on a more challenging corpus of automatically transcribed broadcast news shows demonstrate the benefit of such a combination.", "label": 1}
{"sent1": "Then, a method that combines multiple ?weak?", "sent2": "In the experiment, we also found that our wrong label reduction boosted the performance of relation extraction.", "label": 0}
{"sent1": "We develop neural network models for scoring tuples on arbitrary phrases and evaluate them by their ability to distinguish true held-out tuples from false ones.", "sent2": "We find strong performance from a bilinear model using a simple additive architecture to model phrases.", "label": 1}
{"sent1": "In our recommendation system, we propose to (a) use latent topics to interpolate with content-based recommendation; (b) model latent user groups to utilize information from other users.", "sent2": "Our recent approach used a Bayesian non-parametric model to induce good derivations from treebanked input (Cohn et al, 2009), biasing towards small grammars composed of small generalisable productions.", "label": 0}
{"sent1": "misunderstanding.", "sent2": "This paper proposes a method for dealing with repairs in action control dialogue to resolve participants?", "label": 1}
{"sent1": "The results using two dictionaries show that the tagging accuracy increases from 83% and 91% to 93% and 94% for individual words or ?tokens?, and from 64% and 83% to 90% and 93% for contiguous ?phrases?", "sent2": "The empirical analysis against a humanlabeled data set demonstrates promising and reasonable performance of the proposed HL-SOT approach.", "label": 0}
{"sent1": "Qualitatively, however, we find that they perform well for different but complementary reasons.", "sent2": "We evaluate these approaches in a user study and find that they quantitatively perform equally well.", "label": 1}
{"sent1": "However, this word-based approach does not take different senses of a word into account, which might differ in whether and what kind of sentiment they evoke.", "sent2": "In this paper, we therefore introduce a human annotation scheme for judging both the subjectivity and polarity of word senses.", "label": 1}
{"sent1": "enables?", "sent2": "While lexicalized parsers often suffer from sparse data, manual mark-up is costly and largely based on individual linguistic intuition.", "label": 0}
{"sent1": "The task is to find the best matching between semantic roles and sentential spans, subject to structural constraints that come from expert linguistic knowledge (e.g., in the FrameNet lexicon).", "sent2": "We present a novel technique for jointly predicting semantic arguments for lexical predicates.", "label": 1}
{"sent1": "The systems described in this paper use OSM (Operation Sequence Model).", "sent2": "We explain different pre-/post-processing steps that we carried out for different language pairs.", "label": 1}
{"sent1": "In recent years, some statistical dialogue models have been proposed to cope with the dialogue problem.", "sent2": "In particular, in terms of F-score and NIST Error Rate the absolute improvement of ILP over CRFs exceeds 20% and 25% respectively.", "label": 0}
{"sent1": "As the distribution of unlabeled data is different from the training data, standard bootstrapping often has difficulty selecting informative data to add to the training set.", "sent2": "tasks and train our model on two heterogeneous corpora simultaneously.", "label": 0}
{"sent1": "We evaluate our approach on several letter-to-phoneme and transliteration data sets.", "sent2": "We enrich a curated resource of commonsense knowledge by formulating the problem as one of knowledge base completion (KBC).", "label": 0}
{"sent1": "In the second phase, we design Finite State Cascades (FSC) which can be automatically constructed depending on the recognition rule sets as a shallow parser for the recognition of NEs.", "sent2": "The advantages of that are reliable, accurate and easy to do maintenance for FSC.", "label": 1}
{"sent1": "Inspired by the co-training strategy, a number of machine learning models are trained on different views of the same data.", "sent2": "Using an MSLM and a conditional mutual information based word clustering algorithm, we achieve a 8.9% perplexity reduction on Switchboard and a 12.2% reduction on the ICSI Meeting Recorder data.", "label": 0}
{"sent1": "In contrast, low-dimensional embeddings (i.e.", "sent2": "distributional representations) are efficient and enable generalization, but it is unclear how reasoning with embeddings could support the full power of symbolic representations such as first-order logic.", "label": 1}
{"sent1": "We present statistical explorations to understand the characteristics of lexical compositions that give rise to the perception of being original, interesting, and at times even artistic.", "sent2": "not as much?", "label": 1}
{"sent1": "Using a small amount of annotated data, we train an information extraction (IE) system to identify veterinary patient attributes.", "sent2": "We create a text classifier that incorporates automatically generated attribute lists for veterinary patients to tackle this problem.", "label": 1}
{"sent1": "By augmenting a normal trigram context, our new multi-speaker language model (MSLM) improves on both Switchboard and ICSI Meeting Recorder corpora.", "sent2": "To recover such un-modeled inter-speaker information, we introduce an approach for conversational language modeling that considers words from other speakers when predicting words from the current one.", "label": 1}
{"sent1": "Whereas many methods are based on contextual clues of words, little attention has been paid to what kind of categories of contextual information are useful for the purpose.", "sent2": "This approach requires only a few seed extraction patterns and a collection of relevant and irrelevant documents for training.", "label": 0}
{"sent1": "Our main findings are (i) using QuestionBank training data improves parser performance to 89.75% labelled bracketing f-score, an increase of almost 11% over the baseline; (ii) back-testing experiments on nonquestion data (Penn-II WSJ Section 23) shows that the retrained parser does not suffer a performance drop on non-question material; (iii) ablation experiments show that the size of training material provided by QuestionBank is sufficient to achieve optimal results; (iv) our method for recovering empty nodes captures long distance dependencies in questions from the ATIS corpus with high precision (96.82%) and low recall (39.38%).", "sent2": "same?", "label": 0}
{"sent1": "In our model of this paper, we handle this problem by directly specifying the ordering information in head-dependents rules which represent the source side as head-dependents relations and the target side as strings.", "sent2": "The experiments show state-of-the-art performance among unsupervised systems on two SS datasets.", "label": 0}
{"sent1": "The global model is trained with a novel objective that encourages the parser to search both efficiently and accurately.", "sent2": "The approach uses unlabeled documents, along with a simple word translation oracle, in order to induce taskspecific, cross-lingual word correspondences.", "label": 0}
{"sent1": "Doing so delivers an increased performance that significantly improves over two state-ofthe-art systems, and shows potential for improving other word sense disambiguation tasks.", "sent2": "We report accuracies of 91.8% and 84.8% for coarse and fine-grained preposition sense disambiguation, respectively.", "label": 1}
{"sent1": "posts.", "sent2": "Our experiments on a large Twitter dataset show that there are more meaningful and unique bursty topics in the top-ranked results returned by our model than an LDA baseline and two degenerate variations of our model.", "label": 1}
{"sent1": "We experiment CRFs on the standard testbed corpus used for Japanese morphological analysis, and evaluate our results using the same experimental dataset as the HMMs and MEMMs previously reported in this task.", "sent2": "Second, influences of label and length bias are minimized.", "label": 1}
{"sent1": "The major purpose of this paper is to show that the form of the Bayes decision rule should not be taken for granted (as it is done in virtually all statistical NLP work), but should be adapted to the error measure being used.", "sent2": "To minimize the number of symbol errors as is more suitable for a task like POS tagging, we show that another form of the Bayes decision rule can be derived.", "label": 1}
{"sent1": "On the other hand, translations of the minority language into a major language are more easily acquired.", "sent2": "The main focus of the current paper is to investigate the impact of various local linguistic features for named entity recognition on the CoNLL2003 (Tjong Kim Sang and De Meulder, 2003) shared task data.", "label": 0}
{"sent1": "BFOS algorithm is used to eliminate redundancy which is one of the main issues in multi-document summarization.", "sent2": "Hierarchical Agglomerative Clustering algorithm(HAC) is employed to detect the redundancy.", "label": 1}
{"sent1": "This paper describes some factors that add complexity to the task of engineering reusable NLP systems (beyond conventional software systems).", "sent2": "In Natural Language Processing (NLP), research results from software engineering and software technology have often been neglected.", "label": 1}
{"sent1": "Existing measures of reading level are not well suited to this task, but previous work and our own pilot experiments have shown the benefit of using statistical language models.", "sent2": "This task can be addressed with natural language processing technology to assess reading level.", "label": 1}
{"sent1": "In this contribution, the question is answered positively, which is achieved with a construction that utilizes inside weights.", "sent2": "Due to the completeness of the semiring, the inside weights always exist, but the construction is only effective if they can be effectively determined.", "label": 1}
{"sent1": "This paper proposes a technique for inserting linefeeds into a Japanese spoken monologue text as an elemental technique to generate the readable captions.", "sent2": "Our method appropriately inserts linefeeds into a sentence by machine learning, based on the information such as dependencies, clause boundaries, pauses and line length.", "label": 1}
{"sent1": "In this paper, we champion a third approach, in which computational models learn from naturalistic input and produce utterances that can be directly compared with the utterances of languagelearning children.", "sent2": "We demonstrate the feasibility of this approach by showing how MOSAIC, a simple distributional analyser, simulates the optional-infinitive phenomenon in English, Dutch, and Spanish.", "label": 1}
{"sent1": "The axioms are also regular because proper embracement depth of represented D-trees is bounded.", "sent2": "We base the evaluation on one TOEFL question set and two practice questions sets, each consisting of a number of multiple choice questions seeking the best synonym for a given target word.", "label": 0}
{"sent1": "Therefore, data-driven linguistic generation needs to be able to cope with the projection between non-isomorphic structures that differ in their topology and number of nodes.", "sent2": "In this paper, we investigate the application of recurrent neural network language models (RNNLM) and factored language models (FLM) to the task of language modeling for Code-Switching speech.", "label": 0}
{"sent1": "Two approaches were developed.", "sent2": "In a nutshell, answers are extracted from clicked web-snippets originating from any class of web-site, including Knowledge Bases (KBs).", "label": 0}
{"sent1": "The evaluation is performed both in an artificial setting, in which the data is assumed to be properly morphologically segmented and POS-tagged, and in a real-world setting, in which the parsing is performed on automatically segmented and POS-tagged text.", "sent2": "Such approaches have largely focused on modeling the phone- or character-level processes that generate candidate lexical types, rather than tokens in context.", "label": 0}
{"sent1": "Regarding the algorithms, the comparisons show that lexicalized parsing models are outperformed by the unlexicalized Berkeley parser.", "sent2": "In this paper, we use a weighted vote method to transform discontinuous word alignment to continuous alignment, which enables SMT systems extract more phrase pairs.", "label": 0}
{"sent1": "As these two morphologically complex languages of relaxed word order are generally under-resourced ?", "sent2": "Results for the approach on ATIS data show 86% F-measure in recovering fully correct semantic analyses and 95.9% F-measure by a partial-match criterion, a more than 5% improvement over the 90.3% partial-match figure reported by He and Young (2006).", "label": 0}
{"sent1": "The latter can be further improved by introducing a prior on model parameters and using Variational Bayes inference.", "sent2": "The results show an improvement of between 10 and 15 absolute points in F-measure.", "label": 0}
{"sent1": "First, we compute a latent factor model for nouns from standard co-occurrence data.", "sent2": "Next, the latent factors are used to induce a latent model of three-way subject verb object interactions.", "label": 1}
{"sent1": "We formulate a joint optimization problem to learn embeddings for mentions and typepaths, and develop an iterative algorithm to solve the problem.", "sent2": "Experiments on three public datasets demonstrate the effectiveness and robustness of the proposed method, with an average 15% improvement in accuracy over the next best compared method1.", "label": 1}
{"sent1": "We thus describe separate treatment with two independent classifiers, outperforming the accuracy of a single classifier.", "sent2": "We report on an empirical study of sense relations in the Senseval-2 test suite.", "label": 0}
{"sent1": "The second research direction is to systematically integrate different NLP resources for our new semantic writing aid tool using again an interactive machine learning approach to provide contextual paraphrase suggestions.", "sent2": "To show the effectiveness of the approach, we further carry out a sequence tagging task on Amharic part-of-speech and are able to significantly reduce time used for annotation.", "label": 1}
{"sent1": "Currently, AD can only be diagnosed by examining the patient?s brain after death and Dementia is diagnosed typically through consensus using specific diagnostic criteria and extensive neuropsychological examinations with tools such as the Mini-Mental State Examination (MMSE) or the Montreal Cognitive Assessment (MoCA).", "sent2": "Early diagnosis of neurodegenerative disorders (ND) such as Alzheimer?s disease (AD) and related Dementias is currently a challenge.", "label": 1}
{"sent1": "Our results demonstrate that learning morphological models in tandem reduces error by up to 24% relative to monolingual models.", "sent2": "We apply our model to three Semitic languages: Arabic, Hebrew, Aramaic, as well as to English.", "label": 1}
{"sent1": "What is a good format to use for linguistic data of this type?", "sent2": "We used a graph-based clustering algorithm called Newman clustering.", "label": 0}
{"sent1": "WordNet) nor controlled, e.g.", "sent2": "Verbs or verb phrases are automatically extracted, yielding a ranked list of candidate relations.", "label": 0}
{"sent1": "The quality of each large-scale knowledge resource is indirectly evaluated on a Word Sense Disambiguation task.", "sent2": "Additionally, the DM problem is modeled as a Partially Observable Markov Decision Processes (POMDP) with sentence clusters.", "label": 0}
{"sent1": "The first uses unsupervised distributional methods to learn narrative relations between events sharing coreferring arguments.", "sent2": "We describe a three step process to learning narrative event chains.", "label": 1}
{"sent1": "Semantic role labeling techniques are typically trained on newswire text, and in tests their performance on fiction is as much as 19% worse than their performance on newswire text.", "sent2": "We investigate the ro?le that these co-ordinating temporal signals have in determining the type of temporal relations in discourse.", "label": 0}
{"sent1": "We employ a non-parametric Bayesian framework to simultaneously capture both low-level character mappings and highlevel morphemic correspondences.", "sent2": "This one-tag-per-type heuristic counters the tendency of Hidden Markov Model based taggers to over generate tags for a given word type.", "label": 0}
{"sent1": "We conduct experiments in the field of cross-language sentiment classification, employing English as source language, and German, French, and Japanese as target languages.", "sent2": "in speech recognition, POS tagging and machine translation, but its justification is rarely questioned.", "label": 0}
{"sent1": "The model adopts the Inductive Logic Programming (ILP) algorithm, which provides a relational way to organize different knowledge of entities and mentions.", "sent2": "Experiments show that our ranked output achieve 0.8747 precision at top 1 and 0.8134 precision at top 5.", "label": 0}
{"sent1": "This striking level of coordination is thought to have arisen as a way to achieve social goals, such as gaining approval or emphasizing difference in status.", "sent2": "We investigate the ro?le that these co-ordinating temporal signals have in determining the type of temporal relations in discourse.", "label": 0}
{"sent1": "A core component of the algorithm is a grammar transformation which represents an infinite tree substitution grammar in a finite context free grammar.", "sent2": "This enables efficient blocked inference for training and also improves the parsing algorithm.", "label": 1}
{"sent1": "As a case study, we apply our method to Romanian and show that our method yields good results.", "sent2": "By default, these classes run a generalization of agendabased parsing, prioritizing the partial parses by some figure of merit.", "label": 0}
{"sent1": "This one-tag-per-type heuristic counters the tendency of Hidden Markov Model based taggers to over generate tags for a given word type.", "sent2": "In this work we use monolingual language resources to determine the set of prepositions that are most likely to occur with each verb.", "label": 0}
{"sent1": "We present three pairs of evaluation experiments assessing text fluency and clarity for different data sets, where one of each pair of experiments is a rating-scale experiment, and the other is a PJE.", "sent2": "The results demonstrate that the proposed models can perform significantly better than all the state-of-the-art baseline methods on both tasks.", "label": 0}
{"sent1": "We extend the model to reveal changes in some authors?", "sent2": "faction memberships over time.", "label": 1}
{"sent1": "Addressing this issue by learning distinct representations for individual meanings of words has been the subject of several research studies in the past few years.", "sent2": "One major deficiency of most semantic representation techniques is that they usually model a word type as a single point in the semantic space, hence conflating all the meanings that the word can have.", "label": 1}
{"sent1": "Each object is annotated by social cues, indicating e.g., whether the caregiver is looking at or touching the object.", "sent2": "Likey has a very light-weight preprocessing phase and no parameters to be tuned.", "label": 0}
{"sent1": "Most available datasets in this field are limited in numbers of actions and objects.", "sent2": "Further, we extend this into a novel model, Switching FHMM, to allow for explicit modeling of cross-sequence dependencies based on linguistic knowledge.", "label": 0}
{"sent1": "(such as French ne ?", "sent2": "pas) makes the alignment space more symmetric; thus, it allows agreement between discontinuous alignments.", "label": 1}
{"sent1": "We explore systems trained using three types of corpora: (1) annotated (e.g.", "sent2": "Current approaches to semantic inference in question answering and textual entailment have approximated the entailment problem as that of computing the best alignment of the hypothesis to the text, using a locally decomposable matching score.", "label": 0}
{"sent1": "When the SRL was presented with representations of sentence structure consisting simply of an ordered set of nouns, it mimicked experimental findings with toddlers, including a striking error found in children.", "sent2": "We present the results of feature engineering and post-processing experiments conducted on a temporal expression recognition task.", "label": 0}
{"sent1": "Later, we explore different selection strategies to remove the noisy pairs based on the association scores.", "sent2": "First, we explore word association measures and bilingual dictionaries to weigh the word pairs.", "label": 1}
{"sent1": "We describe methods for global optimisation of lexical parameters of the sample based on a novel optimisation problem, the constrained multiset multicover problem, and for cluster-based sampling according to syntactic parameters.", "sent2": "We present a novel parameter based sample selection approach for creating good samples in terms of these measures.", "label": 1}
{"sent1": "These grammars lack robustness in the sense that they do not gracefully handle words missing from their lexicon.", "sent2": "reports ?", "label": 0}
{"sent1": "Although a number of resources and methods addressing aspects of the task have been introduced, there have so far been no annotated corpora for training and evaluating systems for broad-coverage, open-domain anatomical entity mention detection.", "sent2": "We introduce the AnEM corpus, a domain- and species-independent resource manually annotated for anatomical entity mentions using a fine-grained classification system.", "label": 1}
{"sent1": "Some work has been done to combine insights from these two frameworks.", "sent2": "While the former is better able to memorize, the latter provides a more principled model that captures dependencies across phrasal boundaries.", "label": 1}
{"sent1": "The recently suggested idea of partial textual entailment may remedy this problem.", "sent2": "We investigate whether we can predict when and who will ask what kind of questions, and also interest level of the audience.", "label": 0}
{"sent1": "Our model gives absolute improvements of 3.3 F1 for English parsing, 2.1 F1 for Chinese parsing, and 5.5 F1 for word alignment over each task?s independent baseline, giving the best reported results for both Chinese-English word alignment and joint parsing on the parallel portion of the Chinese treebank.", "sent2": "We apply and extend the method described in (Resnik and Yarowsky, 1999), estimating proximity of sense pairs from the evidence collected from native-speaker translations of 508 contexts across 4 Indoeuropean languages representing 3 language families.", "label": 0}
{"sent1": "We propose simple classifiers to learn translation boundaries for any source sentences.", "sent2": "The classifiers are trained directly on word-aligned corpus without using any additional resources.", "label": 1}
{"sent1": "Given these explicit constraints, the system then uses prior observations of spatial arrangements in a database of scenes to infer the most likely layout of the objects in the scene.", "sent2": "Through further user interaction, the system gradually adjusts and improves its estimates of where objects should be placed.", "label": 1}
{"sent1": "This paper briefly summarizes the original work and our reimplementation.", "sent2": "Here we present a principled protocol for evaluating parsing results across frameworks based on function trees, tree generalization and edit distance metrics.", "label": 0}
{"sent1": "They are almost as fast as current part-ofspeech taggers, and considerably more accurate than a basic unlexicalized PCFG parser.", "sent2": "The resulting parsers are surprisingly accurate and robust, considering their speed and simplicity.", "label": 1}
{"sent1": "In particular, we will propose a corporabased operational definition for Mapping Principles, which are explanations of why a conventional conceptual metaphor has a particular source-target domain pairing.", "sent2": "This paper describes a new digital infrastructure for language resource discovery, based on the Open Archives Initiative, and called OLAC ?", "label": 0}
{"sent1": "In this paper we provide an overview of our representation framework and demonstrate its applicability to syntactic annotation.", "sent2": "We show how the framework can contribute to comparative evaluation and merging of parser output and diverse syntactic annotation schemes.", "label": 1}
{"sent1": "The quality of the segmentations is measured using an evaluation method that compares the segmentations produced to an existing morphological analysis.", "sent2": "In the second method, Maximum Likelihood (ML) optimization is used.", "label": 1}
{"sent1": "We took part in all four subtasks (aspect term extraction, aspect term polarity, aspect category detection, aspect category polarity), using polarity items detection via various subjectivity lexicons and employing a rule-based system applied on dependency data.", "sent2": "Such models ignore linguistic interactions at the sentence level and thus do poorly on mistakes that involve grammatical dependencies among several words.", "label": 0}
{"sent1": "languages of Arabic speakers used in daily life.", "sent2": "In hierarchical translation, inference needs to be performed over a high-complexity distribution defined by the intersection of a translation hypergraph and a target language model.", "label": 0}
{"sent1": "In particular, we hypothesize that textual vandalism constitutes a unique genre where a group of people share a similar linguistic behavior.", "sent2": "The two systems achieve promising results on the shared task test data set.", "label": 0}
{"sent1": "In particular, we demonstrate the benefit of integrating opinion extraction and polarity classification into a joint model using features reflecting the global polarity structure.", "sent2": "However phrase-based approaches are much less able to model sentence level effects between different phrase-pairs.", "label": 0}
{"sent1": "The basic idea of S3H is to learn the optimal feature weights from prior knowledge to relocate the data such that similar data have similar hash codes.", "sent2": "The evaluation reported both for the monolingual and the multilingual expansion of FrameNet shows that the approach is promising.", "label": 0}
{"sent1": "We evaluate our method using a range of queries extracted from a web search log.", "sent2": "This task tries to establish the relative quality of available semantic resources (derived by manual or automatic means).", "label": 0}
{"sent1": "Emphasis is put on improvements and extensions of the previous years system, being highlighted and empirically compared.", "sent2": "Solutions to specific semantic problems dealing with equivalence of semantic representations are described.", "label": 0}
{"sent1": "Our tool indexes the entire Web1T dataset with an index size of only 100 MB and performs a retrieval of any N-gram with a single disk access.", "sent2": "With an increased index size of 420 MB and duplicate data, it also allows users to issue wild card queries provided that the wild cards in the query are contiguous.", "label": 1}
{"sent1": "However, it seems that treatment of space characters is necessary, especially in cases of extracting information from semi-structured documents.", "sent2": "However, few, if any, Chinese information extraction systems make full use of space characters.", "label": 1}
{"sent1": "The empirical analysis against a humanlabeled data set demonstrates promising and reasonable performance of the proposed HL-SOT approach.", "sent2": "In this paper, we propose a syntax-label clustering method that uses an exchange algorithm in which syntax labels are clustered together to reduce the number of rules.", "label": 0}
{"sent1": "et al, 2001).", "sent2": "For the full analysis of words in context, disambiguation is also required (Hakkani-Tu?r et al, 2000; Hajic?", "label": 1}
{"sent1": "Both are surprisingly good indicators of the processing difficulty of garden-path sentences.", "sent2": "Initial experiences show that simple translation grammars can be implemented on a time-scale of a few hours to a few days and produce signed output readily comprehensible to Deaf informants.", "label": 0}
{"sent1": "The approach is based on the idea of matching certain lexicosyntactic patterns conveying a certain semantic relation on the World Wide Web using standard search engines.", "sent2": "It is well known that parsing accuracies drop significantly on out-of-domain data.", "label": 0}
{"sent1": "Our proposal takes advantage of the one-sided error guarantees of the BF and simple inequalities that hold between related n-gram statistics in order to further reduce the BF storage requirements and the error rate of the derived probabilities.", "sent2": "Current affiliation: Thomas J. Watson Research Center, IBM, gdinu@us.ibm.com", "label": 0}
{"sent1": "using a particular classifier and a particular feature set ?", "sent2": "can be re-used to train classifiers different from the ones employed by AL, supplying alternative feature sets as well.", "label": 1}
{"sent1": "In task (1), cross-lingual measures are superior to conventional monolingual measures based on a wordnet.", "sent2": "This paper proposes a method for dealing with repairs in action control dialogue to resolve participants?", "label": 0}
{"sent1": "After briefly presenting the modules of the framework, the paper reports extrinsic evaluation results considering two applications: computer-aided lexicography and statistical machine translation.", "sent2": "In order to establish a fair and neutral comparison, the quality of each knowledge resource is indirectly evaluated using the same method on a Word Sense Disambiguation task.", "label": 0}
{"sent1": "Windows troubleshooting guides and game tutorials.", "sent2": "This paper describes the first application of such techniques to ranked retrieval, evaluated using a newly created test collection.", "label": 0}
{"sent1": "Thanks to input parse forests and a ?no pruning?", "sent2": "strategy during decoding, the obtained translations are competitive.", "label": 1}
{"sent1": "A text contains an acrostic, if the first letters of a range of consecutive lines form a word or phrase.", "sent2": "keystrokes, and by automatically deriving pre- and postcorrection strings from them.", "label": 0}
{"sent1": "Experiments show that our approach achieves significantly better results than baseline methods.", "sent2": "This approach requires only a few seed extraction patterns and a collection of relevant and irrelevant documents for training.", "label": 0}
{"sent1": "The same parser is used for both.", "sent2": "Our system uses a syntactic combinatorial categorial parser to parse natural language sentences and also to construct the semantic meaning of the sentences as directed by their parsing.", "label": 1}
{"sent1": "The experimental results show that our technique requires less labeled examples than those with the technique in previous research.", "sent2": "In addition, we propose a novel technique to use a large number of unlabeled examples effectively by adding them gradually to a pool.", "label": 1}
{"sent1": "While recent work has combined these word embeddings with hand crafted features for improved performance, it was restricted to a small number of features due to model complexity, thus limiting its applicability.", "sent2": "We propose a new model that conjoins features and word embeddings while maintaing a small number of parameters by learning feature embeddings jointly with the parameters of a compositional model.", "label": 1}
{"sent1": "Emerging technologies, such as social networks and serious games, offer a unique opportunity to change how we construct training data.", "sent2": "We present a Bayesian model and algorithms based on a Gibbs sampler for parsing with a grammar with latent annotations.", "label": 0}
{"sent1": "This is a significant challenge to conversational language understanding systems ?", "sent2": "More specifically, we augment neural model with an external memory, which is shared by several tasks.", "label": 0}
{"sent1": "In doing so, a good accuracy obtained on the classification task implies that the extracted features capture those aspects of the language that a trigram model may not.", "sent2": "Our analyses may help practitioners to choose an appropriate parser for their tasks, and help developers to improve parser robustness against ungrammatical sentences.", "label": 0}
{"sent1": "We integrate various ranking scores through support vector machines to leverage a robust ranking function and use it to extract aliases for a given name.", "sent2": "In this paper, we consider the problem of inductively learning rules from specific facts extracted from texts.", "label": 0}
{"sent1": "Those spelling mistakes have to be corrected automatically to avoid deteriorating the performance of such applications.", "sent2": "We exploit methods to fine-tune the classifier and investigate a variety of features of different types.", "label": 0}
{"sent1": "In this paper, we identify linguistic structures with interacting grammatical properties and propose to address such dependencies via joint inference and joint learning.", "sent2": "In response, we introduce TopicCheck, an interactive tool for assessing topic model stability.", "label": 0}
{"sent1": "In this paper, we show a formal description of the algorithm and discuss it theoretically with respect to time complexity.", "sent2": "In this paper, we study the answer sentence selection problem for question answering.", "label": 0}
{"sent1": "Previous work on relation discovery used a semantic space based on a term-bydocument matrix.", "sent2": "We find that representations based on term co-occurrence perform significantly better.", "label": 1}
{"sent1": "To facilitate reading comprehension, our technology presents mixed native language (L1) and second language (L2) sentences to a learner and allows them to interact with the sentences to make the sentences easier (more L1-like) or harder (more L2-like) to read.", "sent2": "Our learn-by-reading approach lets a human learner acquire new words and constructions by encountering them in context.", "label": 1}
{"sent1": "We address the problem of parsing efficiently with such grammars in three ways.", "sent2": "In this paper, we describe the analysis of a real-world dataset of manually categorized customer emails written in the German language.", "label": 0}
{"sent1": "First, the contribution of individual sparse features is estimated using large amounts of parallel data.", "sent2": "We investigate systems that identify opinion expressions and assigns polarities to the extracted expressions.", "label": 0}
{"sent1": "In the result of experimental evaluation, we show that a good proportion (79%) of a multiple-choice quiz ?Who wants to be a millionaire?", "sent2": "can be solved by the proposed method.", "label": 1}
{"sent1": "We also compare several approaches for utilizing context based on a new data set collected using the proposed solution.", "sent2": "The experimental results demonstrate that 1) IE-based techniques can help create a large scale context data with decent quality from online reviews, at least for restaurant recommendations; 2) context helps recommender systems rank items, however, does not help predict user ratings; 3) simply using context to filter items hurts recommendation performance, while a new probabilistic latent relational model we proposed helps.", "label": 1}
{"sent1": "We question the efficacy of this choice: The Markov assumption in the model prohibits it from making joint decisions about the begin, end, and internal context of a quotation.", "sent2": "data.", "label": 0}
{"sent1": "with learned costs.", "sent2": "In this paper a multiclassifier based approach is presented for a word sense disambiguation (WSD) problem.", "label": 0}
{"sent1": "The task targets the following goals: (a) the manual creation of a multilingual sense inventory for a lexical sample of English nouns and (b) the evaluation of systems on their ability to disambiguate new occurrences of the selected polysemous nouns.", "sent2": "For the creation of the hand-tagged gold standard, all translations of a given polysemous English noun are retrieved in the five languages and clustered by meaning.", "label": 1}
{"sent1": "This renders them sensitive to formal variation both within and across languages, and limits their value to semantic applications.", "sent2": "Syntactic structures, by their nature, reflect first and foremost the formal constructions used for expressing meanings.", "label": 1}
{"sent1": "First, we present a novel coarse-to-fine method in which a grammar?s own hierarchical projections are used for incremental pruning, including a method for efficiently computing projections of a grammar without a treebank.", "sent2": "In our experiments, hierarchical pruning greatly accelerates parsing with no loss in empirical accuracy.", "label": 1}
{"sent1": "In current practice, each free response is manually scored according to how well its meaning matches the target definition.", "sent2": "Manual scoring is not only time-consuming, but also limited in its flexibility and ability to detect partial learning effects.", "label": 1}
{"sent1": "We obtain our best results by using the two-layer architecture, in combination with 5 000 features selected by Information Gain.", "sent2": "We investigate two distributional methods for feature selection, Information Gain and Bi-Normal Separation; we also compare distributionally selected features to linguistically motivated features and two types of frameworks: a one-layer system where we aggregate all reviews and predict the rating vs. a two-layer system where ratings of individual reviews are predicted and then aggregated.", "label": 1}
{"sent1": "Unlike previous work, which primarily leverages syntactic analysis through dependency tree matching, we focus on improving the performance using models of lexical semantic resources.", "sent2": "Experiments show that our systems can be consistently and significantly improved with rich lexical semantic information, regardless of the choice of learning algorithms.", "label": 1}
{"sent1": "This means that researchers do not have a common development and test set for natural language processing of learner English such as for grammatical error detection.", "sent2": "Given this background, we created a novel learner corpus that was manually error-tagged and shallowparsed.", "label": 1}
{"sent1": "We evaluate their performance on a Chinese?English translation task.", "sent2": "Unfortunately, the presence of noise leads to dense covariance matrices which in turn leads to suboptimal document representations.", "label": 0}
{"sent1": "We describe properties of our queries and relevance judgements, and demonstrate the use of the test collection in an experimental setup.", "sent2": "We propose simple classifiers to learn translation boundaries for any source sentences.", "label": 0}
{"sent1": "The main innovation of WASP is its use of state-of-the-art statistical machine translation techniques.", "sent2": "A semantic parser is learned given a set of sentences annotated with their correct meaning representations.", "label": 1}
{"sent1": "We present here a new model of local coherences, viewing them as resulting from a belief-update process, and show that the relevant probabilities in our model are calculable from a probabilistic Earley parser.", "sent2": "In these models, not only the conventional syntactic rules but also the non-syntactic rules can be applied.", "label": 0}
{"sent1": "On the other hand, Armijo algorithm usually performs line search efficiently given a searching direction.", "sent2": "We introduce a scheme for optimally allocating a variable number of bits per LSH hyperplane.", "label": 0}
{"sent1": "data.", "sent2": "Our experiments on a realworld meeting dataset show that with even only 200 speaker-specific annotated dialogue acts, the performances on dialogue act recognition are significantly improved when compared to several baseline algorithms.", "label": 1}
{"sent1": "We treat the allocation of modifiers to heads as a weighted bipartite graph matching (or assignment) problem, a well studied problem in graph theory.", "sent2": "Despite these efforts, our two systems perform poorly in the competition.", "label": 0}
{"sent1": "We model the likely contexts of all words in an ASR system vocabulary by performing a lexical co-occurrence analysis using a large corpus of output from the speech system.", "sent2": "In this paper we present preliminary results of a novel unsupervised approach for highprecision detection and correction of errors in the output of automatic speech recognition systems.", "label": 1}
{"sent1": "Firstly, since lexicon features were shown to be effective in SemEval-2013 Task 2, various lexicons and pre-processors for them are introduced to enhance lexical information.", "sent2": "Secondly, since a distribution of sentiment on tweets is known to be unbalanced, an weighting scheme is introduced to bias an output of a machine learner.", "label": 1}
{"sent1": "Finally, it makes a graph where temporal expressions are used for the horizontal axis and the value of percentage is shown on the vertical axis.", "sent2": "This graph indicates the trend of Cabinet approval rating and is useful for investigating Cabinet approval rating.", "label": 1}
{"sent1": "Task 1 is a unique challenge because it starts from raw text, rather than pre-annotated text with known events and times.", "sent2": "Training data are often specialized for a particular language or Natural Language Processing (NLP) task.", "label": 0}
{"sent1": "The SS task differs from document level semantics tasks in that it features the sparsity of words in a data unit, i.e.", "sent2": "a sentence.", "label": 1}
{"sent1": "The reason is that messages on micro-blogs are short, noisy and informal texts with little context, and often contain phrases with ambiguous meanings.", "sent2": "In this paper, we describe it in detail together with its data-collection method and annotation schemes.", "label": 0}
{"sent1": "and ?as soon as?.", "sent2": "We propose an unsupervised approach to constructing templates from a large collection of semantic category names, and use the templates as the semantic representation of categories.", "label": 0}
{"sent1": "The latter is concerned with the use of this list for postprocessing the output of a system based on conditional random fields.", "sent2": "Our participation is characterized by using cross-lingual matching features extracted from lexical and semantic phrase tables and dependency relations.", "label": 0}
{"sent1": "The enhancements exploit the UIMA Subject of Analysis (Sofa) mechanism, that allows different facets of the input data to be represented.", "sent2": "We also present a new, online algorithm for inducing a weighted CCG.", "label": 0}
{"sent1": "We propose Two Dimensional Trie (2D Trie), a novel efficient feature indexing structure which takes advantage of relationship between templates: feature strings generated by a template are prefixes of the features from its extended templates.", "sent2": "By using simulated annealing in place of Viterbi decoding in sequence models such as HMMs, CMMs, and CRFs, it is possible to incorporate non-local structure while preserving tractable inference.", "label": 0}
{"sent1": "First, natural texts are radically incomplete since there are always too many facts to mention.", "sent2": "Second, natural texts are systematically biased towards novelty and surprise, which presents an unrepresentative sample to the learner.", "label": 1}
{"sent1": "These experiments  showed that a first step consisting in the extraction  of   information  to  be  coded  (such  as  diseases,  procedures,  aggravating factors, etc.)", "sent2": "A  series  of  four  experiments  was  conducted  on  a  baseline  method:  Na?ve  Bayes  with varying sets of attributes.", "label": 1}
{"sent1": "We use a sentiment treebank to show that these existing heuristics are poor estimators of sentiment.", "sent2": "Commonly used heuristics to estimate the sentiment of negated expressions rely simply on the sentiment of argument (and not on the negator or the argument itself).", "label": 1}
{"sent1": "As one implementation of the framework, we have developed a method for selecting the most appropriate speech understanding result from several candidates.", "sent2": "A  series  of  four  experiments  was  conducted  on  a  baseline  method:  Na?ve  Bayes  with varying sets of attributes.", "label": 0}
{"sent1": "Conventional word alignment methods allow discontinuous alignment, meaning that a source (or target) word links to several target (or source) words whose positions are discontinuous.", "sent2": "The resulting system is used as a preprocessor for both training and test sentences, transforming Chinese sentences to be much closer to English in terms of their word order.", "label": 0}
{"sent1": "However, the use of syntactic information may have a negative impact on the speed of translation because of the large number of rules, especially when syntax labels are projected from a parser in syntax-augmented machine translation.", "sent2": "This paper describes a complete event/time ordering system that annotates raw text with events, times, and the ordering relations between them at the SemEval-2013 Task 1.", "label": 0}
{"sent1": "The use of phrases was long seen as a natural way to improve retrieval performance over the common document models that ignore the sequential aspect of word occurrences in documents, considering them as ?bags of words?.", "sent2": "Path Ranking Algorithm (PRA) is a recently proposed method which aims to improve KB coverage by performing inference directly over the KB graph.", "label": 0}
{"sent1": "92%, demonstrating 1?3% absolute improvement over the previous best system.", "sent2": "Moreover, in two extrinsic evaluations our aligner outperforms existing aligners, and even a naive application of the aligner approaches state-ofthe-art performance in each extrinsic task.", "label": 1}
{"sent1": "Second, we consider the problem of automatically understanding and solving elementary school math word problems.", "sent2": "In order to address these quantitative reasoning problems we first develop a computational approach which we show to successfully recognize and normalize textual expressions of quantities.", "label": 1}
{"sent1": "In this study, we have adapted a method for assessing difficulty of words to make it more suitable to medical Swedish.", "sent2": "Replacing these difficult terms with easier synonyms can, however, lead to improved readability.", "label": 1}
{"sent1": "The input of the learned model is a representation of the free text, its output structured relations.", "sent2": "Thus, the model, once learned, can be applied to any arbitrary free text.", "label": 1}
{"sent1": "We also propose a new feature which can automatically learn the reordering rules to a certain extent.", "sent2": "Joint modeling of multiple natural language processing tasks outperforms single-task models learned from the same data, but still underperforms compared to single-task models learned on the more abundant quantities of available single-task annotated data.", "label": 0}
{"sent1": "In particular, we deal with the new task of linking FrameNet and Wikipedia using a word sense disambiguation system that, for a given pair frame ?", "sent2": "Bursty topics from microblogs reveal what events have attracted the most online attention.", "label": 0}
{"sent1": "The facts from MiNets are exploited in a novel random walk-based algorithm to iteratively propagate ranking scores across multiple data modalities.", "sent2": "We show the SRL system can use incremental knowledge gain to switch from error-prone noun order features to a more accurate representation, demonstrating a possible mechanism for this process in child development.", "label": 0}
{"sent1": "In the standard process, the parse selection model is trained over a hand-disambiguated treebank, meaning that without a significant investment of effort to produce the treebank, parse selection is not possible.", "sent2": "Parser disambiguation with precision grammars generally takes place via statistical ranking of the parse yield of the grammar using a supervised parse selection model.", "label": 1}
{"sent1": "We propose an uptraining procedure in which a deterministic parser is trained on the output of a more accurate, but slower, latent variable constituency parser (converted to dependencies).", "sent2": "Uptraining with 100K unlabeled questions achieves results comparable to having 2K labeled questions for training.", "label": 1}
{"sent1": "We also propose a filtering metric to discard noisy timelines generated by our automatic processes, to purify the timeline input for summarization.", "sent2": "By selectively using timelines guided by filtering, overall summarization performance is increased by a significant 5.9%.", "label": 1}
{"sent1": "Label disagreement preferences are another potentially rich source of information, but prior NLP work within the minimum-cut paradigm has not explicitly incorporated it.", "sent2": "The power of this approach lies in its ability to incorporate label-agreement preferences among pairs of instances in a provably tractable way.", "label": 1}
{"sent1": "One approach to the interpretation of noun-noun compounds assumes that people make use of distributional information about how the constituent words of compounds tend to combine; another assumes that people make use of information about the two constituent concepts?", "sent2": "Our approach utilizes automatic syntactic and semantic parsers to generate Chinese-English predicate-argument structures.", "label": 0}
{"sent1": "Our work is the first to directly tackle the retrieval of infographics and to design a system that takes into account their unique characteristics.", "sent2": "Unfortunately, information retrieval research has focused on the retrieval of text documents and images, with almost no attention specifically directed toward the retrieval of information graphics.", "label": 1}
{"sent1": "We introduce an informativeness score for determining the most precise relation of a mention entity pair regarding the coreference decisions.", "sent2": "Rating-scale evaluations are common in NLP, but are problematic for a range of reasons, e.g.", "label": 0}
{"sent1": "to the human evaluation of machine translation output.", "sent2": "The EM training procedure can improve the connectionist models further, by using hidden events obtained by the SLM parser.", "label": 0}
{"sent1": "Most of the work on authorship attribution focuses on scenarios with only a few candidate authors, but recently considered cases with tens to thousands of candidate authors were found to be much more challenging.", "sent2": "Due to the lack of annotated data sets,  there are few studies on machine learning  based approaches to extract named entities (NEs) in clinical text.", "label": 0}
{"sent1": "In order to better understand these results, we investigated whether classifiers trained on different information sources performed differently on the different part-of-speech categories.", "sent2": "The system is evaluated on the MPQA opinion corpus, where we compare it to the only previously published end-to-end system for opinion expression extraction and polarity classification.", "label": 0}
{"sent1": "In this framework, namely Computer Assisted Translation (CAT), human translators interact with a translation system, as an assistance tool, that dinamically offers, a list of translations that best completes the part of the sentence already translated.", "sent2": "The classifiers are trained directly on word-aligned corpus without using any additional resources.", "label": 0}
{"sent1": "Correspondence Analysis (CA) offers a solution to both these problems.", "sent2": "We use a previously published method (Mostow et al., 2011) to train the EEG classifier.", "label": 0}
{"sent1": "(2012) to hypergraphs and apply it to the cube-pruning parser of Zhang and McDonald (2012).", "sent2": "In this paper, we generalize the violation-fixing perceptron of Huang et al.", "label": 1}
{"sent1": "As a supplement to existing parallel training data, our automatically extracted parallel data yields substantial translation quality improvements in translating microblog text and modest improvements in translating edited news commentary.", "sent2": "In this work, we explore video lecture interaction in Massive Open Online Courses (MOOCs), which is central to student learning experience on these educational platforms.", "label": 0}
{"sent1": "If the parser can overlook problems such as grammar mistakes and produce a parse tree that closely resembles the correct analysis for the intended sentence, we say that the parser is robust.", "sent2": "For many NLP applications that require a parser, the sentences of interest may not be well-formed.", "label": 1}
{"sent1": "We investigate the nature of textual inference in this data, laying the ground for developing an inference-based email categorization system.", "sent2": "The system incorporates a phrase-based model of string generation that aims to take unordered bags of words and produce fluent, grammatical sentences.", "label": 0}
{"sent1": "For the first time, we demonstrate that addition of edges labeled with latent features mined from a large dependency parsed corpus of 500 million Web documents can significantly outperform previous PRAbased approaches on the KB inference task.", "sent2": "The latter is concerned with the use of this list for postprocessing the output of a system based on conditional random fields.", "label": 0}
{"sent1": "contents whose effect triggers a chain reaction on people.", "sent2": "Such reviews were posted on the basis of an online viral effect; i.e.", "label": 1}
{"sent1": "The aim of this work is to present and compare two different approaches to achieve this.", "sent2": "Critical to this task is the efficient and accurate identification of tweets which refer to a company distinguishing them from those which do not.", "label": 1}
{"sent1": "This article gives an overview of our project on multi-modal sensing, analysis and ?understanding?", "sent2": "This is not always realistic, since they can be ambiguous.", "label": 0}
{"sent1": "Moreover, our proposed token-level summarization approach, which is able to remove redundancies within utterances, outperforms existing utterance ranking based summarization methods.", "sent2": "Our best run achieved an accuracy of 50.4% on the Spanish-English dataset (with the average score and the median system respectively achieving 40.7% and 34.6%), demonstrating the effectiveness of a ?pure?", "label": 0}
{"sent1": "Extensibility is required to allow for the modification and addition of domains independent of other domains.", "sent2": "In this paper we present BabelNet ?", "label": 0}
{"sent1": "Tagged sentences are then passed to the Correctional Tagging phase, in which the sentences are re-tagged using extra information from the first round tagging results.", "sent2": "We present a study on two key characteristics of human syntactic annotations: anchoring and agreement.", "label": 0}
{"sent1": "Our method, dubbed Variable Bit Quantisation (VBQ), provides a datadriven non-uniform bit allocation across hyperplanes.", "sent2": "This neglects the fact that a subset of hyperplanes may be more informative than others.", "label": 1}
{"sent1": "In this paper, we consider the difficult problem of classifying sentiment in political blog snippets.", "sent2": "The possibility of recruiting annotators through Internet services (e.g., Amazon Mechanic Turk) is an appealing option that allows multiple labeling tasks to be outsourced in bulk, typically with low overall costs and fast completion rates.", "label": 1}
{"sent1": "First, I describe a generative technique that uses a strictly lexicalised parsing model, where all the parameters are based on words and do not use any partof-speech (POS) tags nor grammatical categories.", "sent2": "This paper focuses on translation of fullyand partially-assimilated foreign words, called ?borrowed words?.", "label": 0}
{"sent1": "The dictionary is parsed using a head-driven phrase structure grammar of Japanese.", "sent2": "), MT can be used to provide first pass translations into a majority language, which can be more effectively triaged and then routed to the appropriate aid agencies.", "label": 0}
{"sent1": "Solutions to specific semantic problems dealing with equivalence of semantic representations are described.", "sent2": "Experimental results on classification accuracy are also presented.", "label": 1}
{"sent1": "Our results suggest that preference grammars for GHKM translation are inferior to the plain targetsyntactified model, whereas the enhancement with soft source syntactic constraints provides consistent gains.", "sent2": "The model is trained using large-margin structured prediction methods.", "label": 0}
{"sent1": "Our results illustrate how such a metric inspired by cognitive psychology can help answer critical questions regarding students?", "sent2": "The classes can also perform an exact backward (outside) pass in the service of parameter training.", "label": 0}
{"sent1": "We also study the influence that the identified properties of light verb constructions have on the quality of their automatic alignment in a parallel corpus.", "sent2": "We show that parallel corpus data can provide new empirical evidence for better understanding the properties of light verbs.", "label": 1}
{"sent1": "We propose a new model to address this imbalance, based on a word-based Markov model of translation which generates target translations left-to-right.", "sent2": "We conduct an empirical study to examine the effect of noisy annotations on the performance of sentiment classification models, and evaluate the utility of annotation selection on classification accuracy and efficiency.", "label": 0}
