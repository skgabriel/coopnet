{"sent1": "The proposed method uses previous latest related story to extend current processing story, generates new dynamic models for computing the similarity between the current two stories.", "sent2": "The work is evaluated on the TDT4 Chinese corpus, and the experimental results indicate that story link detection using this method can make much better performance on all evaluation metrics.", "label": 1}
{"sent1": "We also present a first implementation of that method along with experimental results shedding light on some fundamental issues.", "sent2": "In hierarchical translation, inference needs to be performed over a high-complexity distribution defined by the intersection of a translation hypergraph and a target language model.", "label": 1}
{"sent1": "WebAnno uses modern web technology for visualizing and editing annotations in a web browser.", "sent2": "translations.", "label": 0}
{"sent1": "had to be identified.", "sent2": "Experiments on benchmark datasets for both English and Chinese generation tasks yield significant improvements over results obtained by two state-of-the-art machine translation models, in terms of both automatic metrics and human evaluation.", "label": 0}
{"sent1": "In this paper, we address the question of whether such method can be applied to other languages and Treebank resources.", "sent2": "Data-driven function tag assignment has been studied for English using Penn Treebank data.", "label": 1}
{"sent1": "They are based on the repetition of information occurring in the contexts of words to associate.", "sent2": "Vector space models implement the distributional hypothesis.", "label": 1}
{"sent1": "all deemed adequate ?", "sent2": "The task requires that annotators and systems rank a number of alternative substitutes ?", "label": 1}
{"sent1": "Preliminary evaluation shows that our lexicon contains most of the cooking actions that appear in Japanese recipes.", "sent2": "The lexicon includes the action plan used for animation generation, and the information about ingredients upon which the cooking action is taken.", "label": 1}
{"sent1": "First, we generate naturally occurring online error correction data by logging users?", "sent2": "This paper presents a comparative study of spelling errors that are corrected as you type, vs. those that remain uncorrected.", "label": 1}
{"sent1": "In principle, the global phrase reordering model is conditioned on the source and target phrases that are currently being translated, and the previously translated source and target phrases.", "sent2": ".", "label": 0}
{"sent1": "In this study, we first recruit human judges to assess the quality of three simulated dialog corpora and then use human judgments as the gold standard to validate the conclusions drawn from the automatic measures.", "sent2": "Experiments on benchmark datasets for both English and Chinese generation tasks yield significant improvements over results obtained by two state-of-the-art machine translation models, in terms of both automatic metrics and human evaluation.", "label": 0}
{"sent1": "We also compare to a set of known relationships, achieving very good results in both methods.", "sent2": "To assess the quality of discovered relationships, we use the pattern clusters to automatically generate SAT analogy questions.", "label": 1}
{"sent1": "In this work, we associate dictionaries with ?small world?", "sent2": "graphs.", "label": 1}
{"sent1": "We study two different learning methods, one based on rule induction and one based on a probabilistic sequence model.", "sent2": "Our system integrates the task of learning tree structure and learning labels in one step, using the same set of features for both tasks.", "label": 0}
{"sent1": "The hybrid model consists of (i) an unsupervised generative component for modeling the semantic coherence of terms (words/phrases) based on their collocations across different documents, and (ii) a supervised discriminative sequence modeling component for opinion phrase extraction.", "sent2": "Also, we perform a cross-linguistic analysis that suggests interesting connections to some findings in linguistic typology.", "label": 0}
{"sent1": "However, while the discourse on content analysis centers heavily on reproducibility, computer scientists often focus more on scalability and less on coding reliability, leading to growing skepticism on the usefulness of topic models for automated content analysis.", "sent2": "Within a statistical framework, the extension favours those partially generated strings with a probable dependency tree structure.", "label": 0}
{"sent1": "Experiments show that our proposal is effective in improving on the state-of-the-art significantly by as much as 16% in terms of F1, even if we only adopt less-than-perfect automatic discourse analyzers and parsers.", "sent2": "Preliminary experimental results are discussed and reveal promising avenues.", "label": 0}
{"sent1": "We show that previously reported comparisons greatly under-estimated the performance of context-free parsers for these tasks.", "sent2": "In this paper, we look at comparing highaccuracy context-free parsers with highaccuracy finite-state (shallow) parsers on several shallow parsing tasks.", "label": 1}
{"sent1": "The second model uses a reranking approach to add arbitrary global features of parse trees to the morphological model.", "sent2": "Semantic distance is typically measured by analyzing a set of documents or a list of terms and assigning a metric based on the likeness of their meaning or the concept they represent.", "label": 0}
{"sent1": "In the task of estimating bilingual term correspondences of technical terms, it is usually quite difficult to find an existing corpus for the domain of such technical terms.", "sent2": "One approach to the interpretation of noun-noun compounds assumes that people make use of distributional information about how the constituent words of compounds tend to combine; another assumes that people make use of information about the two constituent concepts?", "label": 0}
{"sent1": "The two cues are combined in a Treebank PCFG whose states are split using a few simple tree transformations.", "sent2": "The first is a sentence extractionbased approach while the second is a language generation-based approach.", "label": 0}
{"sent1": "Our results show that adding the dialogue moves of the last system and user turns increases the average reward of the automatically learned strategies by 65.9% over the original (hand-coded) COMMUNICATOR systems, and by 7.8% over a baseline RL policy that uses only slot-status features.", "sent2": "We use 2 user simulations learned from COMMUNICATOR data (Walker et al, 2001; Georgila et al, 2005b) to explore the effects of different features on learned dialogue strategies.", "label": 1}
{"sent1": "Like all structured prediction learning frameworks, the structured perceptron can be costly to train as training complexity is proportional to inference, which is frequently non-linear in example sequence length.", "sent2": "Focusing on this binary task, we show that subjective human judgements can be effectively replaced with an automatic annotation procedure.", "label": 0}
{"sent1": "Contrasting with TER?s good correlation with human judgments, we show that people tend to prefer BLEU and NIST trained models to those trained on edit distance based metrics like TER or WER.", "sent2": "Human preferences for METEOR trained models varies depending on the source language.", "label": 1}
{"sent1": "Subsequently, the various implementations of Open IE resorted to small scale posthoc evaluations, inhibiting an objective and reproducible cross-system comparison.", "sent2": "In this work, we develop a methodology that leverages the recent QA-SRL annotation to create a first independent and large scale Open IE annotation,1 and use it to automatically compare the most prominent Open IE systems.", "label": 1}
{"sent1": "We show that a factor graph derived from this data structure acquires these relationships with a small number of word-level features.", "sent2": "We consider the problem of automatically paraphrasing a text in order to find an equivalent text that contains a given acrostic.", "label": 0}
{"sent1": "In this paper we present first experiments on article quality prediction in the science journalism domain.", "sent2": "In the model selection method, we train unsupervised Adaptor Grammars using an over-articulated metagrammar, then use a small labelled data set to select which potential morph boundaries identified by the metagrammar should be returned in the final output.", "label": 0}
{"sent1": "The employed linear and, especially, non-linear methods can predict a user?s occupational class with strong accuracy for the coarsest level of a standard occupation taxonomy which includes nine classes.", "sent2": "We frame our task as classification using latent feature representations such as word clusters and embeddings.", "label": 1}
{"sent1": "In this paper we show that once the Wikipedia entities mentioned in a corpus of textual assertions are linked, this can further enable the detection and fine-grained typing of the unlinkable entities.", "sent2": "However, NLP applications would gain from the ability to detect and type all entities mentioned in text, including the long tail of entities not prominent enough to have their own Wikipedia articles.", "label": 1}
{"sent1": "The effectiveness of this corpus was assessed via training two state-of-the-art models, wherewith answers to unseen queries were distinguished.", "sent2": "In addition, this system introduces a target language model based on statistical classes, a feature for out-of-domain units and an improved optimization procedure.", "label": 0}
{"sent1": "We examine the degradation in translation performance when bilingually estimated translation probabilities are removed and show that 80%+ of the loss can be recovered with monolingually estimated features alone.", "sent2": "In this paper, we examine an idealization where a phrase-table is given.", "label": 1}
{"sent1": "The experiments with such kernels for question classification show an unprecedented results, e.g.", "sent2": "Here we evaluate seven different POS induction systems spanning nearly 20 years of work, using a variety of measures.", "label": 0}
{"sent1": "We show that the binarized model is as powerful as the standard model and allows us to aggressively subsample negative training examples without sacrificing predictive performance.", "sent2": "Through experimental evaluation, we show that the domain/topic specific corpus contributes to improving the performance of the compositional translation estimation.", "label": 0}
{"sent1": "We first develop an event-aspect LDA model to cluster sentences into aspects.", "sent2": "We then use extended LexRank algorithm to rank the sentences in each cluster.", "label": 1}
{"sent1": "For example, given the first sentence of this abstract, if the parser is uncertain about the subject of the verb ?pose,?", "sent2": "This work investigates supervised word alignment methods that exploit inversion transduction grammar (ITG) constraints.", "label": 0}
{"sent1": "proficiency.", "sent2": "Detailed user evaluation with 3 native and 23 non-native speakers of English shows that our methods achieve better reliability and validity than previous methods.", "label": 1}
{"sent1": "This noisy labeled data causes poor extraction performance.", "sent2": "In this paper, we propose a method to reduce the number of wrong labels.", "label": 1}
{"sent1": "Our best run achieved an accuracy of 50.4% on the Spanish-English dataset (with the average score and the median system respectively achieving 40.7% and 34.6%), demonstrating the effectiveness of a ?pure?", "sent2": "cross-lingual approach that avoids intermediate translations.", "label": 1}
{"sent1": "We then use bilingual bootstrapping, wherein, a model trained using the seed annotated data of L1 is used to annotate the untagged data of L2 and vice versa using parameter projection.", "sent2": "Instead, we focus on the situation where there are two resource deprived languages, both having a very small amount of seed annotated data and a large amount of untagged data.", "label": 1}
{"sent1": "The proposed representation relies on focus of negation detection.", "sent2": "The generator has been evaluated for English on the Penn-Treebank and for Spanish on the multi-layered AncoraUPF corpus.", "label": 0}
{"sent1": "We submitted one Random Forest regression system on each cross level text pair, i.e., Paragraph to Sentence (P-S), Sentence to Phrase (SPh), Phrase to Word (Ph-W) and Word to Sense (W-Se).", "sent2": "This paper proposes a novel embedding method to separately model ?clean?", "label": 0}
{"sent1": "Specifically, we address two questions: (1) Can we solve these two subtasks together?", "sent2": "This paper presents our approach to semantic relatedness and textual entailment subtasks organized as task 1 in SemEval 2014.", "label": 1}
{"sent1": "Compared with the widelyused SRILM, our PROBING model is 2.4 times as fast while using 57% of the memory.", "sent2": "The TRIE data structure is a trie with bit-level packing, sorted records, interpolation search, and optional quantization aimed at lower memory consumption.", "label": 1}
{"sent1": "We use this information in a transfer-based Arabic-to-Hebrew statistical machine translation system.", "sent2": "We show that incorporating linguistic knowledge on the distribution of prepositions significantly improves the translation quality.", "label": 1}
{"sent1": "We evaluate the simplification according to three criteria: preservation of grammaticality, preservation of meaning, and degree of simplification.", "sent2": "Constrained decoding is of great importance not only for speed but also for translation quality.", "label": 0}
{"sent1": "In this work, we describe a method based on constructing a multilingual network connecting English and foreign words.", "sent2": "Wordnet, seeds, etc) that do not exist in foreign languages.", "label": 1}
{"sent1": "A control set composed of 65 contexts has also been annotated in 12 languages (including 2 non-Indoeuropean languages) in order to estimate the correlation between parallel polysemy and language family distance.", "sent2": "We show how linguistic criteria can be used to extract compounds automatically and vice versa how the results of this extraction can shed new lights on linguistic theories about compounding.", "label": 0}
{"sent1": ". )", "sent2": "Most studies in statistical or machine learning based authorship attribution focus on two or a few authors.", "label": 0}
{"sent1": "Compared to previous approaches, our framework is able to combine different metrics and evaluate the quality of a set of metrics without any a-priori weighting of their relative importance.", "sent2": "We provide quantitative evidence about the effectiveness of the approach to improve the automatic evaluation of text summarisation systems by combining several similarity metrics.", "label": 1}
{"sent1": "We show how to solve this dilemma with Gibbs sampling, a simple Monte Carlo method used to perform approximate inference in factored probabilistic models.", "sent2": "Syntactic reordering on the source-side is an effective way of handling word order differences.", "label": 0}
{"sent1": "The system produced a many-to-many argument mapping for all PropBank argument types by computing argument similarity based on automatic word alignment, achieving 80.5% F-score on numbered argument mapping and 64.6% F-score on all arguments.", "sent2": "To automate this task, this paper introduces the notion of a smart paradigm.", "label": 0}
{"sent1": "Against the best previous results reported on this task, obtained using syntax driven models, we report huge quality improvements, with BLEU score gains of 20+ which we confirm with human fluency judgements.", "sent2": "We describe the generation grammars and introduce parsing procedures that address the computational complexity of generation under permutation of phrases.", "label": 1}
{"sent1": "This paper addresses the problem of text mining in the digital devices domain.", "sent2": "In particular, we address the task of detecting semantic relations between digital devices in the text of Web pages.", "label": 1}
{"sent1": "Their models involve a number of parameters whose weight must be adjusted.", "sent2": "The experimental results show the usefulness of the alignment model and corpus for improving abbreviation recognition.", "label": 0}
{"sent1": "Surprisal and total entropy, but not single step entropy, were significant predictors of reading times in different parts of the sentence.", "sent2": "This suggests that a complete model of sentence processing should incorporate both entropy and surprisal.", "label": 1}
{"sent1": "Further, it generalizes in a straightforward manner to multi-class problems.", "sent2": "We present results on two standard tasks, namely Reuters-21578 and WebKB, showing that the proposed algorithm significantly outperforms the state-of-the-art.", "label": 1}
{"sent1": "We also examine multitask learning, where two domains may be related, but where the concept to be learned in each case is distinct.", "sent2": "We show that our prior conveys useful information across domains, genres and tasks, while remaining robust to spurious signals not related to the target domain and concept.", "label": 1}
{"sent1": "We also found the correlation between the CWS F-score and SMT BLEU score was very weak.", "sent2": "We show that a Gibbs sampling technique is capable of parsing sentences in a wide variety of languages and producing results that are on-par with or surpass previous approaches.", "label": 0}
{"sent1": "We model word formation in terms of morphological chains, from base words to the observed words, breaking the chains into parent-child relations.", "sent2": "In this paper we present first experiments on article quality prediction in the science journalism domain.", "label": 0}
{"sent1": "Our method relies on the hypothesis that unknown lexical items will be structurally and semantically similar to known items for which annotations are available.", "sent2": "Accordingly, we represent known and unknown sentences as graphs, formalize the search for the most similar verb as a graph alignment problem and solve the optimization using integer linear programming.", "label": 1}
{"sent1": "Simulations show a close match between speakers?", "sent2": "Our model extends previous rational speech act models (Frank and Goodman, 2012) to more naturally distributed linguistic data, instead of assuming a controlled experimental setting.", "label": 1}
{"sent1": "In our approach, we train the three individual models separately during training, and incorporate them together in a unified framework during decoding.", "sent2": "We extend the CYK parsing algorithm so that it can deal with word segmentation and POS tagging features.", "label": 1}
{"sent1": "That is, we score a aligned pair of source and target trees based on local features of the trees and the alignment.", "sent2": "This leads to a constrained optimization problem, and we present an approximation for the case when the distance function is the squared Euclidean.", "label": 0}
{"sent1": "This paper describes a method for detecting the boundaries of quotations and inserted clauses and that for improving the dependency accuracy by applying the detected boundaries to dependency structure analysis.", "sent2": "The key idea is that compositionality is modeled as a multi-way interaction between latent factors, which are automatically constructed from corpus data.", "label": 0}
{"sent1": "In phrase-based models, this problem can be addressed by storing the training data in memory and using a suffix array as an efficient index to quickly lookup and extract rules on the fly.", "sent2": "The performance of the proposed system assessed with the Rouge-1 metric is seen to be better than the performance of the DUC-2002 winners on DUC-2002 data set.", "label": 0}
{"sent1": "With this idea we present an interactive speech recognition system integrated with a word processor in order to assists users when transcribing speech.", "sent2": "In this paper, we propose a syntax-label clustering method that uses an exchange algorithm in which syntax labels are clustered together to reduce the number of rules.", "label": 0}
{"sent1": "We then show that lengthening is strongly associated with subjectivity and sentiment.", "sent2": "We present the first version of a new declarative programming language.", "label": 0}
{"sent1": "To tackle these challenges, we propose a novel semi-supervised graph regularization model to incorporate both local and global evidence from multiple tweets through three fine-grained relations.", "sent2": "The method consists of two steps.", "label": 0}
{"sent1": "Experimental results show that our system can achieve 0.85 precision at 0.89 recall, excluding exact matches.", "sent2": "Furthermore, it is possible for the end-user to achieve a desired balance between precision and recall by adjusting confidence levels.", "label": 1}
{"sent1": "Joint modeling of multiple natural language processing tasks outperforms single-task models learned from the same data, but still underperforms compared to single-task models learned on the more abundant quantities of available single-task annotated data.", "sent2": "In this paper we present a novel model which makes use of additional single-task annotated data to improve the performance of a joint model.", "label": 1}
{"sent1": "YAGO, and (ii) any subset of Wikipedia documents.", "sent2": "In this paper, we tested the consequences of these representational assumptions via experiments with a system for automatic semantic role labeling (SRL), trained on a sample of child-directed speech.", "label": 0}
{"sent1": "Our experiments confirm the efficacy of the features based on Jaeger?s work, including information density?based features.", "sent2": "Finite-state approaches have been highly successful at describing the morphological processes of many languages.", "label": 0}
{"sent1": "We then included a cheap, language and domain independent feature based on the minimum edit distance between strings.", "sent2": "A closer examination of the performance of the features for different forms of anaphoric expressions showed good results for pronouns, moderate results for proper names, and poor results for definite noun phrases.", "label": 1}
{"sent1": "It will acquire more over time: we intend for it to generalize and encapsulate best practices, and serve as a testbed for new practices.", "sent2": "The resulting data could then be made available to relief groups on the ground, as well as to providers of MT services.", "label": 0}
{"sent1": "We describe an unsupervised approach, based on vector-space similarity, which does not require annotated examples but significantly outperforms their tagger.", "sent2": "Most modern machine translation systems use phrase pairs as translation units, allowing for accurate modelling of phraseinternal translation and reordering.", "label": 0}
{"sent1": "The standard approach to the problem assumes that the set of candidate corrections for a preposition consists of all preposition choices participating in the task.", "sent2": "We determine likely preposition confusions using an annotated corpus of nonnative text and use this knowledge to produce smaller sets of candidates.", "label": 1}
{"sent1": "We use syntactic and semantic insights to devise a new structure derived from dependency trees and show that this plays a role in achieving the best performing system for both social event detection and classification tasks.", "sent2": "We also use three data sampling approaches to solve the problem of data skewness.", "label": 1}
{"sent1": "The approach taken is innovative, since it is based on the Equivalence Class Method.", "sent2": "We evaluate our approach on the SemEval 2016 Task 6 Twitter Stance Detection corpus achieving performance second best only to a system trained on semiautomatically labelled tweets for the test target.", "label": 0}
{"sent1": "To develop our systems, we considered several approaches from rule based systems to statistical methods.", "sent2": "publicly available corpora and tools).", "label": 1}
{"sent1": "We create a core system to translate from English to MSA using a large bilingual parallel corpus.", "sent2": "We tested the proposed method on Japanese-English and Chinese-English translation tasks and found order-of-magnitude higher clustering speeds for reducing labels and gains in translation quality compared with previous clustering method.", "label": 0}
{"sent1": "Both subtasks have been very successful in participation and results.", "sent2": "Each of these approaches addresses a different aspect of the overall recognition performance.", "label": 0}
{"sent1": "Recently, it has attracted more and more research interests to exploit heterogeneous annotation corpora for Chinese S&T.", "sent2": "We demonstrate the usefulness and language independence of our procedure by evaluating constituency and dependency parsers on English and Swedish.", "label": 0}
{"sent1": "Within our framework, we carry out a large number of experiments to understand better and explain why phrase-based models outperform word-based models.", "sent2": "Cross-lingual parallelism and small-scale language variation have recently become subject of research in both computational and theoretical linguistics.", "label": 0}
{"sent1": "Instead of representing contexts as bags of terms and defining a similarity measure between contexts, we propose to represent terms as bags of contexts and define a similarity measure between terms.", "sent2": "Evaluation on BioNLP Shared Task 2011 data indicates the method to outperform the negation/speculation components of state-of-theart event extraction systems.", "label": 0}
{"sent1": "Informal language, spelling errors, abbreviations, and special characters are all commonplace in these posts, leading to a prohibitively large vocabulary size for word-level approaches.", "sent2": "We propose a character composition model, tweet2vec, which finds vectorspace representations of whole tweets by learning complex, non-local dependencies in character sequences.", "label": 1}
{"sent1": "An error-driven transformation-based tagger is then trained to clean up the tagging inconsistencies of the first tagger.", "sent2": "We show how to model the task of inferring which objects are being talked about (and which words refer to which objects) as standard grammatical inference, and describe PCFG-based unigram models and adaptor grammar-based collocation models for the task.", "label": 0}
{"sent1": "We show that the neural machine translation performs relatively well on short sentences without unknown words, but its performance degrades rapidly as the length of the sentence and the number of unknown words increase.", "sent2": "We report on analyses that reveal quantitative insights about the use of unlabeled data and the complexity of interlanguage correspondence modeling.", "label": 0}
{"sent1": "First, it extracts statistically significant pairs of related words from the corpus of each language.", "sent2": "An unsupervised method for word sense disambiguation using a bilingual comparable corpus was developed.", "label": 1}
{"sent1": "We use models of lexical borrowing in machine translation as a pivoting mechanism to obtain translations of out-of-vocabulary loanwords in a lowresource language.", "sent2": "We use our method to model the composition of subject verb object triples.", "label": 0}
{"sent1": "The analysis is further exploited to improve processing accuracy by (1) integrating systems that are respectively trained on heterogeneous annotations to reduce the approximation error, and (2) re-training models with high quality automatically converted data to reduce the estimation error.", "sent2": "It supports arbitrarily large documents, pluggable import/export filters, the curation of annotations across various users, and an interface to farming out annotations to a crowdsourcing platform.", "label": 0}
{"sent1": "Instead, the model is regularized by desiderata for rationales.", "sent2": "Publishers  of  biomedical  journals  increasingly  use  XML  as  the  underlying  document format.", "label": 0}
{"sent1": "More specifically, we augment neural model with an external memory, which is shared by several tasks.", "sent2": "syntactic dependencies that fall into the primary empirical domain of TAG-Adjoining, namely, long-distance movement/filler-gap dependencies across a tensed clause boundary.", "label": 0}
{"sent1": "It is also observed that if we convert a question into a statement form, our LSTM model achieves better accuracy.", "sent2": "Using the predicted type information to rerank the logical forms returned by AgendaIL, one of the leading semantic parsers, we are able to improve the F1-score from 49.7% to 52.6% on the WEBQUESTIONS data.", "label": 1}
{"sent1": "We adopt three cohesion measures: clue words, semantic similarity and cosine similarity as the weight of the edges.", "sent2": "We analyze the amount of staleness introduced by various AL schemes and then examine the effect of the staleness on performance on a part-of-speech tagging task on the Wall Street Journal.", "label": 0}
{"sent1": "Furthermore, unlike much recent work, our approach can identify expressions of various types and syntactic constructions.", "sent2": "We also study the influence that the identified properties of light verb constructions have on the quality of their automatic alignment in a parallel corpus.", "label": 0}
{"sent1": "However, the high level of computational cost has prevented the use of clustering for constructing gazetteers.", "sent2": "In contrast, low-dimensional embeddings (i.e.", "label": 0}
{"sent1": "(clip clop)?", "sent2": "The OLAC Metadata Set and the associated controlled vocabularies facilitate consistent description and focussed searching.", "label": 0}
{"sent1": "If done right, MT can dramatically increase the speed by which relief can be provided.", "sent2": "This distance is used to isolate candidate synonyms for a given word.", "label": 0}
{"sent1": "Different kernel functions are used with an SVM learner to integrate two sources of information from syntactic parse trees: (i) a large number of syntactic features that have been shown useful for Semantic Role Labeling (SRL) and applied here to the relation extraction task, and (ii) features from the entire parse tree using a tree kernel.", "sent2": "Our model gives improvements in alignment quality relative to state-of-the-art unsupervised and supervised baselines, as well as providing up to a 1.4 improvement in BLEU score in Chinese-to-English translation experiments.", "label": 0}
{"sent1": "Converting outputs from one framework to another is less than optimal as it easily introduces noise into the process.", "sent2": "One of the big challenges in understanding text, i.e., constructing an overall coherent representation of the text, is that much information needed in that representation is unstated (implicit).", "label": 0}
{"sent1": "However, most of the existing methods encode two sequences with separate encoders, in which a sentence is encoded with little or no information from the other sentence.", "sent2": "The input of the framework is a set of manual (reference) summaries, a set of baseline (automatic) summaries and a set of similarity metrics between summaries.", "label": 0}
{"sent1": "We test Likey having exactly the same configuration with 11 European languages.", "sent2": "In monologues, since a sentence tends to be long, each sentence is often displayed in multi lines on one screen, it is necessary to insert linefeeds into a text so that the text becomes easy to read.", "label": 0}
{"sent1": "We investigated whether listeners perceive conversations with these improvements as natural (i.e., human-like) as human-human conversations.", "sent2": "Our contributions are threefold.", "label": 0}
{"sent1": "In such cases, dialogue systems must be able to model the user?s (lexical) domain knowledge and use appropriate referring expressions.", "sent2": "This paper presents an in-depth investigation on integrating neural language models in translation systems.", "label": 0}
{"sent1": "A key insight in our approach is to reduce the tasks of content selection (?what to say?)", "sent2": "To address the second need, we propose a suffix-tree data structure to represent syntactic relationships between opinion targets and words in a sentence that are opinion-bearing.", "label": 0}
{"sent1": "We present a system for update summarization which predicts the salience of sentences with respect to an event and then uses these predictions to directly bias a clustering algorithm for sentence selection, increasing the quality of the updates.", "sent2": "The input to the model consists of (orthographically transcribed) child-directed utterances accompanied by the set of objects present in the non-linguistic context.", "label": 0}
{"sent1": "One problem is posed by the ambiguity between locative prepositional phrases as arguments of a verb or adjuncts.", "sent2": "Combining different metrics into a single measure of quality seems the most direct and natural way to improve over the quality of individual metrics.", "label": 0}
{"sent1": "It is able to model long-distance constituent motion and other syntactic phenomena without requiring a full parse in either language.", "sent2": "The project has developed two virtual worlds that each have a mystery or natural phenomenon requiring scientific explanation; by recording students?", "label": 0}
{"sent1": "The EU MULTEXT-East project developed corpora, lexica and tools for seven languages, with the focus being on morphosyntactic data, including formal, EAGLES-based specifications for lexical morphosyntactic descriptions.", "sent2": "We also perform comparison experiments with the partially joint models.", "label": 0}
{"sent1": "We also measure the number of examples required when model confidence is used to select examples for human correction as compared to random selection.", "sent2": "In all, parsing time reduces by 81%.", "label": 0}
{"sent1": "In addition, this rationalization can be used for developing a data-driven mapping of a semantic role hierarchy.", "sent2": "Through experimental evaluation, we show that the domain/topic specific corpus contributes to improving the performance of the compositional translation estimation.", "label": 0}
{"sent1": "On test section 23, our best system achieves F1 score of 72.73 (69.14) when correct (automatic) syntactic parse trees are used.", "sent2": "There were 14 teams who submitted a total of 38 runs.", "label": 0}
{"sent1": "1) We propose an approach to resolve the special problems of Chinese chunking.", "sent2": "In theory, such a covariance matrix should represent semantic equivalence, and should be highly sparse.", "label": 0}
{"sent1": "In this paper, we propose an alternative, a latent variable model, which uses hybrid information based on both word sequences and character sequences.", "sent2": "We argue that the use of latent variables can help capture long range dependencies and improve the recall on segmenting long words, e.g., named-entities.", "label": 1}
{"sent1": "Current approaches to semantic inference in question answering and textual entailment have approximated the entailment problem as that of computing the best alignment of the hypothesis to the text, using a locally decomposable matching score.", "sent2": "We argue that there are significant weaknesses in this approach, including flawed assumptions of monotonicity and locality.", "label": 1}
{"sent1": "Our frequency estimates are generated from a terabyte-sized corpus of Web data, and we study the impact of corpus size on the effectiveness of the measures.", "sent2": "heel of the system, the results show that the system can keep at least half of the information, becoming potentially useful for final users.", "label": 0}
{"sent1": "We extract features from the text based on prior work, and extend or modify it to construct different feature sets, and use support vector machines for classification.", "sent2": "A common problem for clustering techniques is that clusters overlap, which makes graphing the statistical structure in the data difficult.", "label": 0}
{"sent1": "Some studies have tried to exploit general dictionaries for that purpose, seeing them as graphs where words are related by the definition they appear in, in a complex network of an arguably semantic nature.", "sent2": "Synonyms extraction is a difficult task to achieve and evaluate.", "label": 1}
{"sent1": "Unfortunately, research has been hindered by the lack of suitable datasets, complicating the comparison between approaches.", "sent2": "In recent years, sentiment analysis in social media has attracted a lot of research interest and has been used for a number of applications.", "label": 1}
{"sent1": "We find that the important boundary indicators and the resulting segmentation accuracy can vary depending on the type of impairment observed, but that results on patient data are generally similar to control data.", "sent2": "We also find that a number of syntactic complexity metrics are robust to the types of segmentation errors that are typically made.", "label": 1}
{"sent1": "Further, we extend this into a novel model, Switching FHMM, to allow for explicit modeling of cross-sequence dependencies based on linguistic knowledge.", "sent2": "We report tagging/chunking accuracies for varying dataset sizes and show that our approach is relatively robust to data sparsity.", "label": 1}
{"sent1": "We show that our approach presents complex tradeoffs understandably, increases overall user satisfaction, and significantly improves the user?s overview of the available options.", "sent2": "Moreover, our results suggest that presenting users with a brief summary of the irrelevant options increases users?", "label": 1}
{"sent1": "This embedding is learned in such a way that prediction becomes a low-dimensional nearest-neighbor search, which can be done computationally efficiently.", "sent2": "We propose a novel family of reranking algorithms based on learning separate low-dimensional embeddings of the task?s input and output spaces.", "label": 1}
{"sent1": "We show that the system performance can be enhanced significantly with some relative simple token-based features that are available for many languages.", "sent2": "Although more sophisticated linguistic features will also be helpful, they provide much less improvement than might be expected.", "label": 1}
{"sent1": "We describe the underlying context-free parser and how functional structures are efficiently computed on top of the CFG shared forest thanks to computation sharing, lazy evaluation, and compact data representation.", "sent2": "In this paper, we champion a third approach, in which computational models learn from naturalistic input and produce utterances that can be directly compared with the utterances of languagelearning children.", "label": 0}
{"sent1": "In this paper, we show how to induce head-driven probabilistic parsers with latent heads from a tree-bank.", "sent2": "In this paper, we introduce self-annotation as a new supervised learning approach for developing and implementing a system that extracts finegrained relations between entities.", "label": 0}
{"sent1": "However, these resources are imbalanced in different languages.", "sent2": "It is because Japanese has no orthographic distinction between common and proper nouns and no apparent morphosyntactic distinction between them.", "label": 0}
{"sent1": "However, for language pairs such as Arabic to English, phrasebased approaches continue to be competitive.", "sent2": "Until now, our understanding of these results has been limited to differences in BLEU scores.", "label": 1}
{"sent1": "The adopted deep analysis strategy is motivated by the complexity of the language phenomena observed in a corpus collected in a Wizard-of-Oz experiment.", "sent2": "In this paper, we propose an approach of answer validation based on the strengths of lexical association between the keywords extracted from a question sentence and each answer candidate.", "label": 0}
{"sent1": "Thus document summarization must be extended to include summarization of information graphics.", "sent2": "Often such graphics convey information that is not contained elsewhere in the document.", "label": 1}
{"sent1": "An important motivation is to reach a high level of language independence.", "sent2": "This restricts the techniques that can be used but makes the method useful for languages with few resources.", "label": 1}
{"sent1": "One proposed alternative to the status quo is to automate or semi-automate the extraction of salient details from privacy policy text, using a combination of crowdsourcing, natural language processing, and machine learning.", "sent2": "However, there has been a relative dearth of datasets appropriate for identifying data practices in privacy policies.", "label": 1}
{"sent1": "It also contains some error analysis and a brief discussion of the results.", "sent2": "This document describes the methods and results for our participation in the BioNLP?09 Shared Task #1 on Event Extraction.", "label": 1}
{"sent1": "On synthetic data, we recover the correct grammar without having to specify its complexity in advance.", "sent2": "We also show that our techniques can be applied to full-scale parsing applications by demonstrating its effectiveness in learning state-split grammars.", "label": 1}
{"sent1": "We create a self-trained relevant sentence classifier to identify relevant regions, and use a semantic affinity measure to automatically learn domain-relevant extraction patterns.", "sent2": "We  also  describe  how the cascaded approach is embedded  in  a  large-scale  XML-based  application  (EBIMed) used for on-line access to biomedical  literature.", "label": 0}
{"sent1": "The reordering approach improved the BLEU score for the MOSES system from 28.52 to 30.86 on the NIST 2006 evaluation data.", "sent2": "classifier by taking advantage of their complementarity is presented and experimented.", "label": 0}
{"sent1": "Previous work has shown that modeling soft constraints, where the model is encouraged, but not require to obey the constraints, can substantially improve segmentation performance.", "sent2": "We suggest various metrics to replace F 1 -score for the ?BAD?", "label": 0}
{"sent1": "We propose an unsupervised method to predict the distribution of a word in one domain, given its distribution in another domain.", "sent2": "We evaluate our method on two tasks: cross-domain partof-speech tagging and cross-domain sentiment classification.", "label": 1}
{"sent1": "We obtain the optimal combination of features on an aligned abbreviation corpus by using the maximum entropy framework.", "sent2": "We design a large amount of finegrained features that directly express the events where letters produce or do not produce abbreviations.", "label": 1}
{"sent1": "mantic  inter?sentential  discourse  rela?", "sent2": "We propose a new framework for supervised machine learning.", "label": 0}
{"sent1": "To alleviate this problem, we propose a novel dependency-based evaluation metric which only employs the dependency information of the references.", "sent2": "However, finding topical texts at an appropriate reading level for foreign and second language learners is a challenge for teachers.", "label": 0}
{"sent1": "The proposed method combines the idea of lexicon-based learning and corpus-based learning in a unified cotraining framework.", "sent2": "It is capable of incorporating both domain-specific and domainindependent knowledge.", "label": 1}
{"sent1": "Our primary aim is to understand what depth of language understanding is required to do well on this task.", "sent2": "This research is motivated by the importance of MWEs for NLP applications.", "label": 0}
{"sent1": "We then interpolate the translation models, minimising the perplexity on the development sets, to obtain our final SMT system.", "sent2": "The latter are acquired automatically from corpus data using a fully unsupervised method.", "label": 0}
{"sent1": "Unfortunately, the reliance on manual annotations, which are both difficult and highly expensive to produce, presents a major obstacle to the widespread application of these systems across different languages and text genres.", "sent2": "Our results show that human labels are less suitable for the task.", "label": 0}
{"sent1": "We also describe the application of our algorithms to machine translation and report the results of experiments with several translation data sets which demonstrate a substantial speed-up.", "sent2": "In particular, our results show a speed-up by two orders of magnitude with respect to the original method of Tromble et al (2008) and by a factor of 3 or more even with respect to an approximate algorithm specifically designed for that task.", "label": 1}
{"sent1": "AdaRNN adaptively propagates the sentiments of words to target depending on the context and syntactic relationships between them.", "sent2": "We propose Adaptive Recursive Neural Network (AdaRNN) for target-dependent Twitter sentiment classification.", "label": 1}
{"sent1": "This paper evaluates the effect of using different lexical and syntactic features both individually and in combination.", "sent2": "A text contains an acrostic, if the first letters of a range of consecutive lines form a word or phrase.", "label": 0}
{"sent1": "However, there are two major issues for BTG-based SMT.", "sent2": "We evaluate their performance on a Chinese?English translation task.", "label": 0}
{"sent1": "The approach is built on top of a novel reduction-based weighted synchronous context free grammar formalism, which facilitates the transformation process from typed lambda calculus into natural language sentences.", "sent2": "Sentences can then be generated based on such grammar rules with a log-linear model.", "label": 1}
{"sent1": "In order to establish a fair and neutral comparison, the quality of each knowledge resource is indirectly evaluated using the same method on a Word Sense Disambiguation task.", "sent2": "The evaluation framework selected has been the Senseval-3 English Lexical Sample Task.", "label": 1}
{"sent1": "In the absence of an authoritative annotated corpus, our approach has the advantage of being weakly-supervised.", "sent2": "Preliminary experimental results are discussed and reveal promising avenues.", "label": 1}
{"sent1": "We also apply a top performing TempEval 2013 system against this new resource to measure the difficulty of adapting systems to the clinical domain.", "sent2": "Textual entailment is an asymmetric relation between two text fragments that describes whether one fragment can be inferred from the other.", "label": 0}
{"sent1": "Generic statements express rulelike knowledge about kinds or events.", "sent2": "We present a novel algorithm for Japanese dependency analysis.", "label": 0}
{"sent1": "The best learned policy also takes less dialogue time (average 1.07 min less) than the best hand-coded policy.", "sent2": "Automatically inducing the syntactic partof-speech categories for words in text is a fundamental task in Computational Linguistics.", "label": 0}
{"sent1": "Our system uses a Machine Learning approach with Support Vector Machines and AdaBoost to deal with the RTE challenge.", "sent2": "Furthermore, we introduce a manually annotated dataset for target-dependent Twitter sentiment analysis.", "label": 0}
{"sent1": "We describe an extension of semisupervised structured conditional models (SS-SCMs) to the dependency parsing problem, whose framework is originally proposed in (Suzuki and Isozaki, 2008).", "sent2": "Moreover, we introduce two extensions related to dependency parsing: The first extension is to combine SS-SCMs with another semi-supervised approach, described in (Koo et al, 2008).", "label": 1}
{"sent1": "In this paper, we describe a novel method for learning a type of Synchronous Tree Adjoining Grammar and associated probabilities from aligned tree/string training data.", "sent2": "We introduce a method of converting these grammars to a weakly equivalent tree transducer for decoding.", "label": 1}
{"sent1": "By training a second layer of large margin classifier on top of the outputs from several Conditional Random Fields classifiers, it can utilize a small amount of in-domain training data to improve the performance.", "sent2": "This paper presents an in-depth investigation on integrating neural language models in translation systems.", "label": 0}
{"sent1": "A theory that incorporates Adjoining as a recursive structure building device provides a novel and straightforward account of this gap, whereas existing theories of syntactic locality, e.g.", "sent2": "Results show that a small number of linguistically motivated lexical features are sufficient to achieve comparable performance to systems using sophisticated parse trees.", "label": 0}
{"sent1": "Previous approaches require integer linear programming (ILP) solvers to obtain exact solutions.", "sent2": "We also show an improvement of 1.2 BLEU in downstream MT evaluation over basic HMM alignments.", "label": 0}
{"sent1": "This paper proposes a method for refining vector space representations using relational information from semantic lexicons by encouraging linked words to have similar vector representations, and it makes no assumptions about how the input vectors were constructed.", "sent2": "Evaluated on a battery of standard lexical semantic evaluation tasks in several languages, we obtain substantial improvements starting with a variety of word vector models.", "label": 1}
{"sent1": "Previous research has shown that they are advantageous over generative models.", "sent2": "is essential.", "label": 0}
{"sent1": "The connectionist models use a distributed representation of the items in the history and make much better use of contexts than currently used interpolated or back-off models, not only because of the inherent capability of the connectionist model in fighting the data sparseness problem, but also because of the sublinear growth in the model size when the context length is increased.", "sent2": "To address this issue, we have proposed SemEval-2013 Task 2: Sentiment Analysis in Twitter, which included two subtasks: A, an expression-level subtask, and B, a messagelevel subtask.", "label": 0}
{"sent1": "The proposed models are trained on a public Wikipedia corpus, and the learned representations are evaluated on word analogy and word similarity tasks.", "sent2": "We propose two novel distributional models for word representation using both syntagmatic and paradigmatic relations via a joint training objective.", "label": 1}
{"sent1": "This normalization effort allows direct mapping of the extracted events and relations with posttranslational modifications from UniProt, epigenetics from PubMeth, functional domains from InterPro and macromolecular structures from PDB.", "sent2": "We introduce several entity normalization algorithms for genes, proteins, protein complexes and protein components, aiming to uniquely identify these biological entities.", "label": 1}
{"sent1": "Our motivation is to use such automatically generated texts to enhance public engagement with a specific species reintroduction programme, although the protocols developed here can be applied to any animal or other movement study that involves signal data from tags.", "sent2": "We are working with one of the largest nature conservation charities in Europe in this regard, focusing on a single species, the red kite.", "label": 1}
{"sent1": "For example, a digital camera?s description may include its price and megapixels whereas a professor?s description may include her name, university, and research interests.", "sent2": "Both types of pages may include additional ambiguous information.", "label": 1}
{"sent1": "translation into French, a ?non prodrop?", "sent2": "language.", "label": 1}
{"sent1": "Since GATE comes with a customisable and extendable set of components, it allows students to get hands-on experience with building NLP applications.", "sent2": "In the current entity linking literature, mention detection and entity disambiguation are frequently cast as equally important but distinct problems.", "label": 0}
{"sent1": "However, due to the lack of phrasal nodes in dependency graphs, application of RNN is not straightforward.", "sent2": "In such cases RNN cannot be trained effectively in a timely manner.", "label": 1}
{"sent1": "We show that a technique for detecting speech disfluencies based on Integer Linear Programming (ILP) (Georgila, 2009) significantly outperforms CRFs.", "sent2": "This model is then applied to a new domain without any adaptation.", "label": 1}
{"sent1": "However, the fact that these are manual tasks makes them expensive and slow.", "sent2": "More specifically, we classify barge-in utterances into correctly and erroneously interpreted ones by using features of individual users?", "label": 0}
{"sent1": "More specifically, we classify barge-in utterances into correctly and erroneously interpreted ones by using features of individual users?", "sent2": "utterance histories such as their barge-in rates and estimated automatic speech recognition (ASR) accuracies.", "label": 1}
{"sent1": "AttitudeMiner uses linguistic techniques to analyze the text exchanged between participants of online discussion threads at different levels of granularity: the word level, the sentence level, the post level, and the thread level.", "sent2": "Through this technique, Twitter users can be grouped into different types of communities such as those who have the same interests, those who interact a lot, or those who have similar sentiments about certain topics.", "label": 0}
{"sent1": "Our model (with 97.06% on synthetic data) improves the state of the art results for diacritization of Turkish by 3.65 percentage points on ambiguous cases and for the vowel restoration by 45.77 percentage points over a rule based baseline with 62.66% accuracy.", "sent2": "Our system uses a Machine Learning approach with Support Vector Machines and AdaBoost to deal with the RTE challenge.", "label": 0}
{"sent1": "The approach has been applied to a database of 100 words made available by the lexical sample WSD subtask of SemEval-2007 (task 17) organizers.", "sent2": "With 100K unlabeled and 2K labeled questions, uptraining is able to improve parsing accuracy to 84%, closing the gap between in-domain and out-of-domain performance.", "label": 0}
{"sent1": "a way to enable an XDG grammar to generate all paraphrases ?", "sent2": "Herein we present a constraint-based account of disjunction in lexicalization, i.e.", "label": 1}
{"sent1": "without human interaction.", "sent2": "Transcription and semantic annotation (annoscription) of utterances is crucial part of speech performance analysis and tuning of spoken dialog systems and other natural language processing disciplines.", "label": 0}
{"sent1": "There is no basis for comparison of current techniques and, prior to this work, there has been no standard corpus or evaluation technique for the CW identification task.", "sent2": "This paper evaluates the effect of using different lexical and syntactic features both individually and in combination.", "label": 0}
{"sent1": "Within a statistical framework, the extension favours those partially generated strings with a probable dependency tree structure.", "sent2": "We used crowdsourcing on Amazon Mechanical Turk to label a large Twitter training dataset along with additional test sets of Twitter and SMS messages for both subtasks.", "label": 0}
{"sent1": "In  particular,  we  argue  that  the  pragmatic  and tailored solutions allow for reduction  in  the need for overlapping annotations  ?", "sent2": "The proposed unsupervised system outperforms existing unsupervised methods on all benchmark data sets.", "label": 0}
{"sent1": "For the task of named entity recognition, using bilingual predictors increases F1 by 16.1% absolute over a supervised monolingual model, and retraining on bilingual predictions increases monolingual model F1 by 14.6%.", "sent2": "Our training procedure estimates the parameters of the bilingual model using the output of the monolingual model, and we show how to combine the two models to account for dependence between views.", "label": 1}
{"sent1": "The resource is automatically constructed by means of a methodology that integrates lexicographic and encyclopedic knowledge from WordNet and Wikipedia.", "sent2": "In addition Machine Translation is also applied to enrich the resource with lexical information for all languages.", "label": 1}
{"sent1": "While existing work trades off one aspect for another, this paper simultaneously makes progress on both fronts through a new task: answering complex questions on semi-structured tables using question-answer pairs as supervision.", "sent2": "The central challenge arises from two compounding factors: the broader domain results in an open-ended set of relations, and the deeper compositionality results in a combinatorial explosion in the space of logical forms.", "label": 1}
{"sent1": "We compare three training methods: unsupervised training, semisupervised training, and a novel model selection method.", "sent2": "This paper explores the use of Adaptor Grammars, a nonparametric Bayesian modelling framework, for minimally supervised morphological segmentation.", "label": 1}
{"sent1": "This article describes a method for the automatic extraction of terms relying on the detection of classical prefixes and word-initial combining forms.", "sent2": "Our method is unsupervised.", "label": 0}
{"sent1": "To make the title play its second role properly, it is indispensable to clarify the content (?what to say?)", "sent2": "The idea is to use various syntactic and semantic features extracted from a language for classifying between real-world articles and articles generated by sampling a trigram language model.", "label": 0}
{"sent1": "We have achieved an accuracy of 38.1% on the test set.", "sent2": "We used some basic rules to modulate the existing phrased-based transliteration system.", "label": 1}
{"sent1": "Verbs or verb phrases are automatically extracted, yielding a ranked list of candidate relations.", "sent2": "The terms are instances of the pair of ontological classes under consideration, drawn from a populated knowledge base.", "label": 1}
{"sent1": "We answer four questions in this study: 1) How helpful are linguistic analysis and pattern learning?", "sent2": "The proposed method achieves clustering by directly maximizing the likelihood of synchronous rules, whereas previous work considered only the similarity of probabilistic distributions of labels.", "label": 0}
{"sent1": "Structurally, our model is a semiMarkov conditional random field with features targeting characteristics unique to speech repairs.", "sent2": "Implications for research and practice are discussed.", "label": 0}
{"sent1": "We discuss such ?strapping?", "sent2": "methods in general, and exhibit a particular method for strapping wordsense classifiers for ambiguous words.", "label": 1}
{"sent1": "We show how linguistic criteria can be used to extract compounds automatically and vice versa how the results of this extraction can shed new lights on linguistic theories about compounding.", "sent2": "So far, we have labeled 108K sentences, 41% of which as having dialectal content.", "label": 0}
{"sent1": "However, in the conventional triangulation method, information of pivot phrases is forgotten and not used in the translation process.", "sent2": "In this paper, we propose a novel approach to remember the pivot phrases in the triangulation stage, and use a pivot language model as an additional information source at translation time.", "label": 1}
{"sent1": "A dataset covering three genres was manually annotated and used to develop and compare several approaches for automatically detecting appositions and non-restrictive relative clauses.", "sent2": "The best results are obtained by a ML model developed using crfsuite, followed by a rule based method.", "label": 1}
{"sent1": "A more realistic interpretation of the task is as an authorship verification problem that we approximate by pooling data from many different authors as negative examples.", "sent2": "In this paper, we show, on the basis of a new corpus with 145 authors, what the effect is of many authors on feature selection and learning, and show robustness of a memory-based learning approach in doing authorship attribution and verification with many authors and limited training data when compared to eager learning methods such as SVMs and maximum entropy learning.", "label": 1}
{"sent1": "We adopt a semi-supervised version of Latent Dirichlet Allocation (LDA) to guide the learning process.", "sent2": "The privacy requirements associated with utilizing everyday telephone conversations preclude manual annotations; hence, we explore semi-supervised methods in this task.", "label": 1}
{"sent1": "We compare the metrics?", "sent2": "The latter can be further improved by introducing a prior on model parameters and using Variational Bayes inference.", "label": 0}
{"sent1": "It is a metaparadigm, which inspects the base form and tries to infer which low-level paradigm applies.", "sent2": "While indisputably useful as a source of features in downstream tasks, such vectors tend to consist of uninterpretable components whose relationship to the categories of traditional lexical semantic theories is tenuous at best.", "label": 0}
{"sent1": "The final combined language model provides 37.8% relative improvement in terms of perplexity on the SEAME development set and a relative improvement of 32.7% on the evaluation set compared to the traditional n-gram language model.", "sent2": "language.", "label": 0}
{"sent1": "Our experiments demonstrate a clear anchoring effect and reveal unwanted consequences, including overestimation of parsing performance and lower quality of annotations in comparison with humanbased annotations.", "sent2": "We study the influence of anchoring on a standard approach to creation of syntactic resources where syntactic annotations are obtained via human editing of tagger and parser output.", "label": 1}
{"sent1": "Despite these efforts, our two systems perform poorly in the competition.", "sent2": "An directed graphical model is put forward to integrate dependency relation classification and semantic role labeling.", "label": 0}
{"sent1": "This leads to a constrained optimization problem, and we present an approximation for the case when the distance function is the squared Euclidean.", "sent2": "The system is publicly available for download and has an online demonstration at http://clair.eecs.umich.edu/AttitudeMiner/.", "label": 0}
{"sent1": "We use its probabilistic output to control weighted interpolation of separate language models for easy and difficult reading.", "sent2": "This noisy labeled data causes poor extraction performance.", "label": 0}
{"sent1": "We find that, surprisingly, different training corpora can vary widely in their reordering characteristics for particular phrase pairs.", "sent2": "We model the likely contexts of all words in an ASR system vocabulary by performing a lexical co-occurrence analysis using a large corpus of output from the speech system.", "label": 0}
{"sent1": "The neural language model systems used vector representations of individual words, where these vectors were derived by training them against the context of words encountered, and thus reflect the distributional characteristics of their usage.", "sent2": "Snowball or TextToOnto).", "label": 0}
{"sent1": "KLC is designed to be a large scale corpus containing over 135 million words and conveying five stylistic genres: literary, publicistic, official, scientific and informal.", "sent2": "In the paper we describe a dependency parser that uses exact search and global learning (Crammer et al, 2006) to produce labelled dependency trees.", "label": 0}
{"sent1": "The method developed by Li et al (2006) is extended in this paper to take a course description from one university as the input and suggest equivalent courses offered at another university.", "sent2": "This work proposes a semanticbased approach for automatically identifying potential course equivalencies given their catalog descriptions.", "label": 1}
{"sent1": "One advantage of this approach is that, at the second stage, we can exploit syntactic clues in addition to morphological ones because as a result of the first stage acquisition, we can rely on automatic parsing.", "sent2": "In the paper, we test the impact of the proposed nested terms recognition method applied together with the C-value ranking method to the automatic term recognition task.", "label": 0}
{"sent1": "Finally, the acquired troubles are associated with objects so that each of the resulting pairs consists of an object and a trouble or obstacle in using that object.", "sent2": "We then use these capabilities to further develop algorithms to assist reasoning in the context of the aforementioned tasks.", "label": 0}
{"sent1": "In the case of SMT, German compounds are split into their constituents to decrease the number of  unknown words  and  improve  the  results of evaluation measures like the Bleu score.", "sent2": "To assess to which extent it is necessary to deal with German compounds as a part of preprocessing in SMT systems, we have  tested  different  compound splitters and strategies, such as adding lists of compounds and their translations to the training set.", "label": 1}
{"sent1": "Scaling neural language models is a difficult task, but crucial for real-world applications.", "sent2": "This paper evaluates the impact on end-to-end MT quality of both new and existing scaling techniques.", "label": 1}
{"sent1": "Empirically, we show that it yields substantial improvements over previous work that used similar biases to initialize an EM-based learner.", "sent2": "for example all pairs of a person and the corresponding birthdate.", "label": 0}
{"sent1": "We provide some rationale-annotated data and present a learning method that exploits the rationales during training to boost performance significantly on a sample task, namely sentiment classification of movie reviews.", "sent2": "When annotating an example, the human teacher will also highlight evidence supporting this annotation?thereby teaching the machine learner why the example belongs to the category.", "label": 1}
{"sent1": "behavior as they investigate the mystery, these worlds can be used to assess their understanding of the scientific method.", "sent2": "The project has developed two virtual worlds that each have a mystery or natural phenomenon requiring scientific explanation; by recording students?", "label": 1}
{"sent1": "We demonstrate the feasibility of our approach by constructing a method that uses cue-and-scope analyses together with a small set of features motivated by data analysis to predict event negation and speculation.", "sent2": "This paper presents a method for semantic classi?cation of onomatopoetic words like ???????", "label": 0}
{"sent1": "We show that a Gibbs sampling technique is capable of parsing sentences in a wide variety of languages and producing results that are on-par with or surpass previous approaches.", "sent2": "KLC is also open for contributors, who are willing to make suggestions, donate texts and help with annotation of existing materials.", "label": 0}
{"sent1": "We consider maximum margin and conditional likelihood objectives, including the presentation of a new normal form grammar for canonicalizing derivations.", "sent2": "While collaborative games have been used in information retrieval, it is an open issue whether users can contribute accurate annotations in a collaborative game context for a problem that requires an exact answer, such as games that would create named entity recognition training data.", "label": 0}
{"sent1": "We also show that the gender can be predicted from language alone (89%).", "sent2": "We propagate gender information through the videos and show that a user?s gender can be predicted from her social environment with the accuracy above 90%.", "label": 1}
{"sent1": "This process can be viewed as generalizing weight pushing from transducers to hypergraphs.", "sent2": "Applied after rule binarization, weight pushing takes the weight from the original grammar rule and pushes it down across its binarized pieces, allowing the parser to make better pruning decisions earlier in the parsing process.", "label": 1}
{"sent1": "In tasks like sentiment analysis, such approaches can result in limited effectiveness if the texts to be classified consist of a series of arguments.", "sent2": "We also examine aspects of lexical transfer, suggesting and exploring a concept of translation coercion across parts of speech, as well as a transfer model based on lemma-to-lemma translation probabilities, which holds promise for improving machine translation of low-density languages.", "label": 0}
{"sent1": "Since most of these systems were developed and tested using data from the WSJ corpus, we compare their generalization abilities by testing on both WSJ and the multilingual Multext-East corpus.", "sent2": "We show that some of the oldest (and simplest) systems stand up surprisingly well against more recent approaches.", "label": 1}
{"sent1": "We present a bilayer directed graph to express probabilistic relationships between syntactic and semantic relations.", "sent2": "In current practice, each free response is manually scored according to how well its meaning matches the target definition.", "label": 0}
{"sent1": "about WordNet?s most commonly used terms; and adding in simple representations of scripts.", "sent2": "The second relates to adjectival modification of question and propositional entities.", "label": 0}
{"sent1": "In contrast, we seek to clarify the influence of visual perception on the linguistic form (as opposed to the content) of descriptions, modeling the variation in and constraints on the surface orderings in a description.", "sent2": "Existing work in the visual domain focuses on content selection for text generation and relies primarily on templates to generate surface realizations from underlying content choices.", "label": 1}
{"sent1": "In order to handle a large set of translation units, these representations and the associated estimates are jointly computed using a multi-layer neural network with a SOUL architecture.", "sent2": "We are working with one of the largest nature conservation charities in Europe in this regard, focusing on a single species, the red kite.", "label": 0}
{"sent1": "For a small number of labelled positive stories, we extract story pairs which consist of positive and its associated stories from bilingual comparable corpora.", "sent2": "To overcome the problem of a large number of labelled negative stories, we classify them into some clusters.", "label": 1}
{"sent1": "In interactive settings with a shared workspace, however, human dialog partners often split referring expressions into installments that adapt to changes in the context and to actions of their partners.", "sent2": "In this paper we aim to identify the native language and language family of a non-native English author, given his/her English writings.", "label": 0}
{"sent1": "Most of the existing studies on DM use Dialogue Act (DA) to represent semantic information of sentence, which might not represent the nuanced meaning sometimes.", "sent2": "In this paper, we model DM based on sentence clusters which have more powerful semantic representation ability than DAs.", "label": 1}
{"sent1": "Readability studies have shown that disfluencies (fillers and speech repairs) may be deleted from transcripts without compromising meaning (Jones et al, 2003), and deleting repairs prior to parsing has been shown to improve its accuracy (Charniak and Johnson, 2001).", "sent2": "We explore whether this strategy of early deletion is also beneficial with regard to fillers.", "label": 1}
{"sent1": "Specifically, we propose to extract domain-specific keywords for videos by integrating various cues from linguistic and statistical knowledge, as well as derived sound classes and characteristic visual content types.", "sent2": "Extensive experiments show that it achieves very competitive classification accuracy, even with a small portion of labeled data.", "label": 0}
{"sent1": "Focusing on this binary task, we show that subjective human judgements can be effectively replaced with an automatic annotation procedure.", "sent2": "Hand-coded scripts were used in the 1970-80s as knowledge backbones that enabled inference and other NLP tasks requiring deep semantic knowledge.", "label": 0}
{"sent1": "Empirical evaluations show that these methods are as accurate as?and significantly faster than?", "sent2": "Incorporating information from WordNet also improves performance for both approaches.", "label": 0}
{"sent1": "Recently, however, methods have been demonstrated for matching spoken terms to spoken content without the need for language-tuned transcription.", "sent2": "In addition Machine Translation is also applied to enrich the resource with lexical information for all languages.", "label": 0}
{"sent1": "All processing is carried out on a remote server, with content uploaded and accessed through a web interface.", "sent2": "Translation grammars are written in a version of Synchronous Context-Free Grammar adapted to the peculiarities of sign language.", "label": 1}
{"sent1": "We apply HMEANT to a new language, Czech in particular, by evaluating a set of Englishto-Czech MT systems.", "sent2": "We relate HMEANT to an established linguistic theory, highlighting the possibilities of reusing existing knowledge and resources for interpreting and automating HMEANT.", "label": 1}
{"sent1": "The MWEs are extracted by an unsupervised method and classified into two distinct classes, namely locations and person names.", "sent2": "These vectors are binary (i.e, contain only 0 and 1) and are 99.9% sparse.", "label": 0}
{"sent1": "The problem of generating such a 3D simulation can be divided into two subtasks: the linguistic analysis and the virtual scene generation.", "sent2": "Our evaluation on a standard set of retrospective events using ROUGE shows that salience prediction provides a significant improvement over other approaches.", "label": 0}
{"sent1": "Extraction set models provide two principle advantages over word-factored alignment models.", "sent2": "We continue this line of work by adapting the TrueSkill TM algorithm ?", "label": 0}
{"sent1": "The categorizer also benefits from the availability of large thesauri, where variants of MeSH terms can be found.", "sent2": "Unlike usual automatic text categorization systems, which rely on dataintensive models induced from large training data, our automatic text categorization tool applies data-independent classifiers: a vector-space engine and a pattern matcher are combined to improve ranking of Medical Subject Headings (MeSH).", "label": 1}
{"sent1": "Two systems are explained: Sub-task 1 system for identifying habitat mentions in unstructured biomedical text and normalizing them through the OntoBiotope ontology and Sub-task 2 system for extracting localization and partof relations between bacteria and habitats.", "sent2": "Likey has a very light-weight preprocessing phase and no parameters to be tuned.", "label": 0}
{"sent1": "We apply the developed approach to the cooking domain, providing both an ontology and an ontology lexicon in lemon format.", "sent2": "This paper addresses our work on graphic summarization.", "label": 0}
{"sent1": "We show that by analyzing both propositions and questions as records within Type Theory with Records (TTR), we can define Boolean operations over these distinct semantic types.", "sent2": "We account for the adjectival challenge by embedding the record types defined to deal with Boolean operations within a theory of semantic frames formulated within TTR.", "label": 1}
{"sent1": "Evaluation results show that while such models ask reasonable questions for a variety of images, there is still a wide gap with human performance which motivates further work on connecting images with commonsense knowledge and pragmatics.", "sent2": "We train and test several generative and retrieval models to tackle the task of VQG.", "label": 1}
{"sent1": "a popular online language learning application ?", "sent2": "We use data from Duolingo ?", "label": 1}
{"sent1": "This is not always realistic, since they can be ambiguous.", "sent2": "We propose a model for joint dependency parsing and multiword expressions identification, in which complex function words are represented as individual tokens linked with morphological dependencies.", "label": 1}
{"sent1": "In this paper, we describe one such architecture for bootstrapping Information Extraction (IE) patterns ?suited to the extraction of entities, as opposed to events or relations?", "sent2": "The application of bootstrapping to time expression recognition is, to the best of our knowledge, novel.", "label": 1}
{"sent1": "Even the pure phrase rules are includes in some of these models.", "sent2": "Although the better performances are reported over the conventional phrase model and syntax model, the mixture of diversified rules still leaves much room for study.", "label": 1}
{"sent1": "In this paper, we present an alternative method for coordination disambiguation, which does not use similarities.", "sent2": "Conventional word alignment methods allow discontinuous alignment, meaning that a source (or target) word links to several target (or source) words whose positions are discontinuous.", "label": 0}
{"sent1": "Interestingly, they are obtained with sophisticated feature sets which include lexical and semantic information about selectional preferences of verbs.", "sent2": "The latter are acquired automatically from corpus data using a fully unsupervised method.", "label": 1}
{"sent1": "By creating only two nested phrases in each step we introduce a binary hierarchical term structure.", "sent2": "We employ a non-parametric Bayesian framework to simultaneously capture both low-level character mappings and highlevel morphemic correspondences.", "label": 0}
{"sent1": "By making use of Apache Lucene, we are able to do fuzzy string match to extract hedge cues, and to incorporate part-of-speech (POS) tags in hedge cues.", "sent2": "We consider the task of predicting the gender of the YouTube1 users and contrast two information sources: the comments they leave and the social environment induced from the affiliation graph of users and videos.", "label": 0}
{"sent1": "These features describe, on the one hand, the quality of the association between the source sentence and each target word and, on the other hand, the fluency of the hypothesis.", "sent2": "We present example generated scenes and user interaction scenarios.", "label": 0}
{"sent1": "Based on an extension of the incremental joint model for POS tagging and dependency parsing (Hatori et al., 2011), we propose an efficient character-based decoding method that can combine features from state-of-the-art segmentation, POS tagging, and dependency parsing models.", "sent2": "The paper presents these morphosyntactic specifications, giving their background and structure, including the encoding of the tables as TEI feature structures.", "label": 0}
{"sent1": "Each domain has its own domain-specific parameter for each feature but, rather than a constant prior over these parameters, the model instead links them via a hierarchical Bayesian global prior.", "sent2": "Forestto-string translation approaches mitigate the risk of propagating parser errors into translation errors by considering a forest of alternative trees, as generated by a source language parser.", "label": 0}
{"sent1": "In fact, logistic regression with quadratic filters outperforms a standard single hidden layer neural network.", "sent2": "The model accounts for young children?s tendency to use both correct finites and incorrect (optional) infinitives in finite contexts, for the generality of this phenomenon across languages, and for the sparseness of other types of errors (e.g., word order errors).", "label": 0}
{"sent1": "We experiment with conditional LSTM encoding, which builds a representation of the tweet that is dependent on the target, and demonstrate that it outperforms encoding the tweet and the target independently.", "sent2": "This paper considers the more challenging version of this task, where targets are not always mentioned and no training data is available for the test targets.", "label": 1}
{"sent1": "For example since can serve as either a temporal or causal connective.", "sent2": "Secondly, some connectives are ambiguous in terms of the relation they mark.", "label": 1}
{"sent1": "Our experiments show that linguistic features, in particular the inferred part-ofspeech of a misrecognized word are predictive of human clarification decisions.", "sent2": "Our goal is to generate targeted clarification strategies for handling errors in spoken dialogue systems, when appropriate.", "label": 1}
{"sent1": "We used topical, syntactic and semantic features.", "sent2": "We apply HMEANT to a new language, Czech in particular, by evaluating a set of Englishto-Czech MT systems.", "label": 0}
{"sent1": "We propose a general approach to automatically identify shell content of shell nouns.", "sent2": "Our approach exploits lexicosyntactic knowledge derived from the linguistics literature.", "label": 1}
{"sent1": "allowed ?", "sent2": "access ?", "label": 1}
{"sent1": "We report on several experiments that we conducted with our system.", "sent2": "In the shared task evaluation, it scored better than average.", "label": 1}
{"sent1": "We use our system to construct a crowdsourced dataset of over 15,000 highquality, diverse questions.", "sent2": "We first build a system to access data in infoboxes in a structured manner.", "label": 1}
{"sent1": "While indisputably useful as a source of features in downstream tasks, such vectors tend to consist of uninterpretable components whose relationship to the categories of traditional lexical semantic theories is tenuous at best.", "sent2": "These testing queries were also submitted by search engine users, and their answer candidates were taken from their respective returned web-snippets.", "label": 0}
{"sent1": "In addition, we systematically investigated various types of features for NER in clinical  text.", "sent2": "model utilizing?a?dialogue?plan?to?communicate information?from?domain?level?planner?to dialogue?management?and?from?there?to?a separate?", "label": 0}
{"sent1": "Experiments show that our ranked output achieve 0.8747 precision at top 1 and 0.8134 precision at top 5.", "sent2": "The merged list is then ranked according to the prospective post-editing effort and provided to the translators to aid their work.", "label": 1}
{"sent1": "Combining the two techniques, we show that using a fast shift-reduce parser we can achieve significant quality gains in NIST 2008 English-to-Chinese track (1.3 BLEU points over a phrase-based system, 0.8 BLEU points over a hierarchical phrase-based system).", "sent2": "Consistent and significant gains are also shown in WMT 2010 in the English to German, French, Spanish and Czech tracks.", "label": 1}
{"sent1": "Second, we address the problem that arises from words with more than one sense, which creates a potential ambiguity in terms of which bits are encoded by a particular word.", "sent2": "We develop a novel method in which words are the vertices in a graph, synonyms are linked by edges, and the bits assigned to a word are determined by a vertex colouring algorithm.", "label": 1}
{"sent1": "Significant progress has been made for inducing dependency grammars, however the models employed are overly simplistic, particularly in comparison to supervised parsing models.", "sent2": "Inducing a grammar directly from text is one of the oldest and most challenging tasks in Computational Linguistics.", "label": 1}
{"sent1": "Threaded discussions include e-mails, e-mail lists, bulletin boards, newsgroups, and Internet forums.", "sent2": "Experiments are still underway to achieve the best use of these heuristics and other parameters of the bootstrapping algorithm.", "label": 0}
{"sent1": "Empirically, the parallel AL algorithm effectively has a batch size of one and a large candidate set size but eliminates the time an annotator would have to wait for a similarly parameterized batch scheme to select instances.", "sent2": "The exact performance of our method on other tasks will depend on the relative ratios of time spent annotating, training, and scoring, but in general we expect our parameterless method to perform favorably compared to batch when accounting for wait time.", "label": 1}
{"sent1": "Third, we show that using stateof-the-art lexicalized hierarchical models further improves prediction accuracy.", "sent2": "Moreover, our proposed token-level summarization approach, which is able to remove redundancies within utterances, outperforms existing utterance ranking based summarization methods.", "label": 0}
{"sent1": "Using speeches in English translated into Spanish, we present the evaluation procedure and we discuss the results both for the recognition and translation components as well as for the overall system.", "sent2": "Specifically, we address two questions: (1) Can we solve these two subtasks together?", "label": 0}
{"sent1": "We used this framework to develop a grammar for the biochemical domain, which approached human performance.", "sent2": "Our EE framework is accompanied by a web-based user interface for the rapid development of event grammars and visualization of matches.", "label": 1}
{"sent1": "Examples of these contextual information are social network structure, and conversational, author, and topic contexts.", "sent2": "Disregarding these information poses a problem because at times, context is needed to clearly infer the sentiment of a tweet.", "label": 1}
{"sent1": "The generalization is at the cost of asymptotic efficiency.", "sent2": "To account for this, cube pruning for decoding is utilized (Chiang, 2007).", "label": 1}
{"sent1": "The OpenSoNaR project aims to facilitate the use of the SoNaR corpus by providing a user-friendly online interface.", "sent2": "Due to the size of the corpus, accessing the information contained in the dataset has proven to be difficult for less technically inclined researchers.", "label": 1}
{"sent1": "Experimental results on standard textual data sets and on a more challenging corpus of automatically transcribed broadcast news shows demonstrate the benefit of such a combination.", "sent2": "Gains were observed in all conditions, with segments of either regular or varying length and abrupt or smooth topic shifts.", "label": 1}
{"sent1": "After the experiments with all features, we deploy a ?Feature Selection?", "sent2": "misunderstanding.", "label": 0}
{"sent1": "However, the tuples in ConceptNet (Speer and Havasi, 2012) define relations between an unbounded set of phrases.", "sent2": "Most work in KBC focuses on knowledge bases like Freebase that relate entities drawn from a fixed set.", "label": 1}
{"sent1": "For example, content generated by users in online forums contains more noise compared to formal documents.", "sent2": "Experimental results show that our system can achieve 0.85 precision at 0.89 recall, excluding exact matches.", "label": 0}
{"sent1": "The proposed method identifies the repair target based on common grounding rather than surface expressions.", "sent2": "We extend Traum?s grounding act model by introducing degree of groundedness, and partial and mid-discourse unit grounding.", "label": 1}
{"sent1": "We use transformationbased learning (TBL) as a postprocessor at two points in our system to improve performance.", "sent2": "The results using two dictionaries show that the tagging accuracy increases from 83% and 91% to 93% and 94% for individual words or ?tokens?, and from 64% and 83% to 90% and 93% for contiguous ?phrases?", "label": 1}
{"sent1": "Qualitatively, however, we find that they perform well for different but complementary reasons.", "sent2": "We evaluate these approaches in a user study and find that they quantitatively perform equally well.", "label": 1}
{"sent1": "In this paper, we therefore introduce a human annotation scheme for judging both the subjectivity and polarity of word senses.", "sent2": "However, this word-based approach does not take different senses of a word into account, which might differ in whether and what kind of sentiment they evoke.", "label": 1}
{"sent1": "presented.", "sent2": "The?", "label": 1}
{"sent1": "Compared to a baseline that makes local predictions, we achieve better argument identification scores and avoid all structural violations.", "sent2": "We formulate this task as an integer linear program (ILP); instead of using an off-the-shelf tool to solve the ILP, we employ a dual decomposition algorithm, which we adapt for exact decoding via a branch-and-bound technique.", "label": 1}
{"sent1": "For German-English we used constituent parsing for reordering and compound splitting as preprocessing steps.", "sent2": "We explain different pre-/post-processing steps that we carried out for different language pairs.", "label": 1}
{"sent1": "In recent years, some statistical dialogue models have been proposed to cope with the dialogue problem.", "sent2": "Dialogue systems are one of the most challenging applications of Natural Language Processing.", "label": 1}
{"sent1": "In this paper, we consider the problem of domain adaptation: the situation where training data may not be scarce, but belongs to a different domain from the target application domain.", "sent2": "We introduce a new method for recovering empty nodes and their antecedents (capturing long distance dependencies) from parser output in CFG trees using LFG f-structure reentrancies.", "label": 0}
{"sent1": "However, they encode this context in different ways, providing their respective models with different information.", "sent2": "We show how the framework can contribute to comparative evaluation and merging of parser output and diverse syntactic annotation schemes.", "label": 0}
{"sent1": "In the second phase, we design Finite State Cascades (FSC) which can be automatically constructed depending on the recognition rule sets as a shallow parser for the recognition of NEs.", "sent2": "Due to their brevity and idiosyncratic structure, search queries pose a challenge to existing NLP tools.", "label": 0}
{"sent1": "Inspired by the co-training strategy, a number of machine learning models are trained on different views of the same data.", "sent2": "We explain different pre-/post-processing steps that we carried out for different language pairs.", "label": 0}
{"sent1": "distributional representations) are efficient and enable generalization, but it is unclear how reasoning with embeddings could support the full power of symbolic representations such as first-order logic.", "sent2": "The information on automatically analyzed dependency structure is also used to detect the beginning of the clauses.", "label": 0}
{"sent1": "or ?metal to the petal?", "sent2": "Knowledge captured by a specific set of training data is not easily transferable, even to the same NLP task in another language.", "label": 0}
{"sent1": "Using a small amount of annotated data, we train an information extraction (IE) system to identify veterinary patient attributes.", "sent2": "Our hypothesis is that coordinate structures are supported by surrounding dependency relations, and that such dependency relations rather yield similarity between conjuncts, which humans feel.", "label": 0}
{"sent1": "To recover such un-modeled inter-speaker information, we introduce an approach for conversational language modeling that considers words from other speakers when predicting words from the current one.", "sent2": "By building on the recent ?zeroshot learning?", "label": 0}
{"sent1": "Whereas many methods are based on contextual clues of words, little attention has been paid to what kind of categories of contextual information are useful for the purpose.", "sent2": "To our knowledge, this is the first large-scale discriminative training algorithm capable of showing improvements over the MERT baseline with only rule indicator features in addition to the standard MERT features.", "label": 0}
{"sent1": "Our main findings are (i) using QuestionBank training data improves parser performance to 89.75% labelled bracketing f-score, an increase of almost 11% over the baseline; (ii) back-testing experiments on nonquestion data (Penn-II WSJ Section 23) shows that the retrained parser does not suffer a performance drop on non-question material; (iii) ablation experiments show that the size of training material provided by QuestionBank is sufficient to achieve optimal results; (iv) our method for recovering empty nodes captures long distance dependencies in questions from the ATIS corpus with high precision (96.82%) and low recall (39.38%).", "sent2": "It is because Japanese has no orthographic distinction between common and proper nouns and no apparent morphosyntactic distinction between them.", "label": 0}
{"sent1": "However, previous works on dependency structure based models typically resort to insertion operations to complete translations, which make it difficult to specify ordering information in translation rules.", "sent2": "This study describes an effective automatic method for scoring free responses to definition production tests.", "label": 0}
{"sent1": "Although this space is exponentially large in the sentence length, we show it is possible to learn an efficient A* parser.", "sent2": "This paper evaluates the impact on end-to-end MT quality of both new and existing scaling techniques.", "label": 0}
{"sent1": "We examine the parameters that must be considered in preposition disambiguation, namely context, features, and granularity.", "sent2": "We explore this idea for prepositions, an often overlooked word class.", "label": 1}
{"sent1": "To find topics that have bursty patterns on microblogs, we propose a topic model that simultaneously captures two observations: (1) posts published around the same time are more likely to have the same topic, and (2) posts published by the same user are more likely to have the same topic.", "sent2": "Part-of-speech (POS) induction is one of the most popular tasks in research on unsupervised NLP.", "label": 0}
{"sent1": "CRFs offer a solution to the long-standing problems in corpus-based or statistical Japanese morphological analysis.", "sent2": "We show how CRFs can be applied to situations where word boundary ambiguity exists.", "label": 1}
{"sent1": "The major purpose of this paper is to show that the form of the Bayes decision rule should not be taken for granted (as it is done in virtually all statistical NLP work), but should be adapted to the error measure being used.", "sent2": "To minimize the number of symbol errors as is more suitable for a task like POS tagging, we show that another form of the Bayes decision rule can be derived.", "label": 1}
{"sent1": "Manual or automatic transcription at the word level is typically not possible because of the absence of an orthography or prior lexicon, and though manual phonemic transcription is possible, it is prohibitively slow.", "sent2": "On the other hand, translations of the minority language into a major language are more easily acquired.", "label": 1}
{"sent1": "The sentences assigned to the leaves of the resultant tree are included in the summary.", "sent2": "The performance of the proposed system assessed with the Rouge-1 metric is seen to be better than the performance of the DUC-2002 winners on DUC-2002 data set.", "label": 1}
{"sent1": "This paper describes some factors that add complexity to the task of engineering reusable NLP systems (beyond conventional software systems).", "sent2": "In Natural Language Processing (NLP), research results from software engineering and software technology have often been neglected.", "label": 1}
{"sent1": "Existing measures of reading level are not well suited to this task, but previous work and our own pilot experiments have shown the benefit of using statistical language models.", "sent2": "The main result is that predictability does not decrease when the complexity of morphology grows, which means that smart paradigms provide an efficient tool for the manual construction and/or automatically bootstrapping of lexica.", "label": 0}
{"sent1": "In this contribution, the question is answered positively, which is achieved with a construction that utilizes inside weights.", "sent2": "Fundamenta Informaticae 111(2), 2011] asks whether weighted linear extended tree transducers preserve recognizability in countably complete commutative semirings.", "label": 1}
{"sent1": "This paper proposes a technique for inserting linefeeds into a Japanese spoken monologue text as an elemental technique to generate the readable captions.", "sent2": "In monologues, since a sentence tends to be long, each sentence is often displayed in multi lines on one screen, it is necessary to insert linefeeds into a text so that the text becomes easy to read.", "label": 1}
{"sent1": "In this paper, we champion a third approach, in which computational models learn from naturalistic input and produce utterances that can be directly compared with the utterances of languagelearning children.", "sent2": "However, neither of these approaches has been developed to the point of providing detailed and quantitative predictions about the developmental data.", "label": 1}
{"sent1": "The axiomatized representation constitutes a string that can encode non-projective D-trees of restricted structural complexity.", "sent2": "The global model is trained with a novel objective that encourages the parser to search both efficiently and accurately.", "label": 0}
{"sent1": "We present a fully stochastic generator that is able to cope with projection between non-isomorphic structures.", "sent2": "So far, such a projection has been a challenge in data-driven generation and was largely avoided.", "label": 1}
{"sent1": "Two approaches were developed.", "sent2": "The first is an unsupervised technique based on the widely used vector space model and information from WordNet.", "label": 1}
{"sent1": "We establish some baseline unlabeled dependency parsing performance on Hebrew, based on two state-of-the-art parsers, MST-parser and MaltParser.", "sent2": "The evaluation is performed both in an artificial setting, in which the data is assumed to be properly morphologically segmented and POS-tagged, and in a real-world setting, in which the parsing is performed on automatically segmented and POS-tagged text.", "label": 1}
{"sent1": "Regarding the treebanks, we observe that, depending on the parsing model, a tag set with specific features has direct influence over evaluation results.", "sent2": "Regarding the algorithms, the comparisons show that lexicalized parsing models are outperformed by the unlexicalized Berkeley parser.", "label": 1}
{"sent1": "we make use of the two available dependency treebanks of Croatian to produce state-of-the-art parsing models for both languages.", "sent2": "features to produce interpretations.", "label": 0}
{"sent1": "We show considerable improvements over standard baselines, both for predicted label accuracy and trustworthiness estimates.", "sent2": "Eventually, our system should continuously track a learner?s knowledge and learning style by modeling their interactions, including performance on a pop quiz feature.", "label": 0}
{"sent1": "First, we compute a latent factor model for nouns from standard co-occurrence data.", "sent2": "The method consists of two steps.", "label": 1}
{"sent1": "This paper proposes a novel embedding method to separately model ?clean?", "sent2": "The Task 2 definition includes target word spans that range in size from a single word to entire sentences.", "label": 0}
{"sent1": "The Task 2 definition includes target word spans that range in size from a single word to entire sentences.", "sent2": "2) We propose two novel voting methods based on the characteristics of chunking task.", "label": 0}
{"sent1": "To show the effectiveness of the approach, we further carry out a sequence tagging task on Amharic part-of-speech and are able to significantly reduce time used for annotation.", "sent2": "which exist in every language, especially Japanese being rich in onomatopoetic words.", "label": 0}
{"sent1": "Currently, AD can only be diagnosed by examining the patient?s brain after death and Dementia is diagnosed typically through consensus using specific diagnostic criteria and extensive neuropsychological examinations with tools such as the Mini-Mental State Examination (MMSE) or the Montreal Cognitive Assessment (MoCA).", "sent2": "A vector representation is used for training and testing cases and the Singular Value Decomposition (SVD) technique is applied to reduce the dimension of the representation.", "label": 0}
{"sent1": "In particular, we study the task of morphological segmentation of multiple languages.", "sent2": "In this paper we investigate how this powerful source of information can be exploited for unsupervised language learning.", "label": 1}
{"sent1": "Questions like these dominate many mailing lists, since web search engines are an unreliable way to find language resources.", "sent2": "This paper describes a new digital infrastructure for language resource discovery, based on the Open Archives Initiative, and called OLAC ?", "label": 1}
{"sent1": "The SV regressor effectively combines the different models, learning a scoring function that weights individual scores in a unique resulting STS.", "sent2": "syntactic vs. lexical or topical vs. paradigmatic similarity.", "label": 1}
{"sent1": "In particular, we use Senseval-3 and SemEval-2007 English Lexical Sample tasks as evaluation bechmarks to evaluate the relative quality of each resource.", "sent2": "Furthermore, trying to be as neutral as possible with respect the knowledge bases studied, we apply systematically the same disambiguation method to all the resources.", "label": 1}
{"sent1": "Finally, the third prunes and clusters self-contained chains from the space of events.", "sent2": "The second applies a temporal classifier to partially order the connected events.", "label": 1}
{"sent1": "We investigate techniques for building open-domain semantic role labeling systems that approach the ideal of a train-once, use-anywhere system.", "sent2": "Semantic role labeling techniques are typically trained on newswire text, and in tests their performance on fiction is as much as 19% worse than their performance on newswire text.", "label": 1}
{"sent1": "Given a non-parallel corpus in a known related language, our model produces both alphabetic mappings and translations of words into their corresponding cognates.", "sent2": "Our solutions to these two problems are based on building a generative observation model of what is mentioned and what is extracted given what is true.", "label": 0}
{"sent1": "We conduct experiments in the field of cross-language sentiment classification, employing English as source language, and German, French, and Japanese as target languages.", "sent2": "What is less known is that some parsers suffer more from domain shifts than others.", "label": 0}
{"sent1": "The model adopts the Inductive Logic Programming (ILP) algorithm, which provides a relational way to organize different knowledge of entities and mentions.", "sent2": "The results of this model reveal the great influence that the availability of a correct segmentation has in obtaining an accurate annotation of the dialogues.", "label": 0}
{"sent1": "We argue that fictional dialogs offer a way to study this question, since authors create the conversations but don?t receive the social benefits (rather, the imagined characters do).", "sent2": "It uses two ideas: first, that vectors for polysemous words can be decomposed into a convex combination of sense vectors; secondly, that the vector for a sense is kept similar to those of its neighbors in the network.", "label": 0}
{"sent1": "The blocked sampler makes considerably larger moves than the local sampler and consequently converges in less time.", "sent2": "A core component of the algorithm is a grammar transformation which represents an infinite tree substitution grammar in a finite context free grammar.", "label": 1}
{"sent1": "As a case study, we apply our method to Romanian and show that our method yields good results.", "sent2": "We propose the first approach that can be applied to the many languages for which there is no pre-existing high-precision database of NPIs.", "label": 1}
{"sent1": "In doing so we are able to incorporate a soft bias towards inducing few tags per type.", "sent2": "We develop a particle filter for drawing samples from the posterior of our model and present empirical results that show that our model is competitive with and faster than the state-of-the-art without making any unrealistic restrictions.", "label": 1}
{"sent1": "In this paper, we compare rating scales with an alternative evaluation paradigm, preferencestrength judgement experiments (PJEs), where evaluators have the simpler task of deciding which of two texts is better in terms of a given quality criterion.", "sent2": "Monitoring and summarizing a text stream during such an event remains a difficult problem.", "label": 0}
{"sent1": "We conduct an exploratory data analysis on the ACL Anthology.", "sent2": "The model reveals latent factions, or groups of individuals whom we expect to collaborate more closely within their faction, cite within the faction using language distinct from citation outside the faction, and be largely understandable through the language used when cited from without.", "label": 1}
{"sent1": "Our approach provides multiple advantages in comparison to the previous approaches, including its high coverage and the ability to generate accurate representations even for infrequent word senses.", "sent2": "We carry out evaluations on six datasets across two semantic similarity tasks and report state-of-the-art results on most of them.", "label": 1}
{"sent1": "The input to the model consists of (orthographically transcribed) child-directed utterances accompanied by the set of objects present in the non-linguistic context.", "sent2": "HLR model weights also shed light on which linguistic concepts are systematically challenging for second language learners.", "label": 0}
{"sent1": "We review publicly available datasets, describe the annotation process of our image collection and some statistics of this dataset.", "sent2": "Different kernel functions are used with an SVM learner to integrate two sources of information from syntactic parse trees: (i) a large number of syntactic features that have been shown useful for Semantic Role Labeling (SRL) and applied here to the relation extraction task, and (ii) features from the entire parse tree using a tree kernel.", "label": 0}
{"sent1": "Expanding the state space to include ?gappy phrases?", "sent2": "(such as French ne ?", "label": 1}
{"sent1": "We explore systems trained using three types of corpora: (1) annotated (e.g.", "sent2": "Commonly, the result of referring expression generation algorithms is a single noun phrase.", "label": 0}
{"sent1": "The structure-mapping account proposes that children start with a shallow structural analysis of sentences: children treat the number of nouns in the sentence as a cue to its semantic predicateargument structure, and represent language experience in an abstract format that permits rapid generalization to new verbs.", "sent2": "In this paper, we propose an alternative, a latent variable model, which uses hybrid information based on both word sequences and character sequences.", "label": 0}
{"sent1": "First, we explore word association measures and bilingual dictionaries to weigh the word pairs.", "sent2": "Later, we explore different selection strategies to remove the noisy pairs based on the association scores.", "label": 1}
{"sent1": "We present a novel parameter based sample selection approach for creating good samples in terms of these measures.", "sent2": "Third, we show that using stateof-the-art lexicalized hierarchical models further improves prediction accuracy.", "label": 0}
{"sent1": "These grammars lack robustness in the sense that they do not gracefully handle words missing from their lexicon.", "sent2": "We define efficient and powerful kernels for measuring the similarity between dependency structures, whose surface forms of the lexical nodes are in part or completely different.", "label": 0}
{"sent1": "The combined system demonstrates a promising level of performance, approaching 80% F-score for mention detection for a relaxed matching criterion.", "sent2": "This paper describes a novel probabilistic approach for generating natural language sentences from their underlying semantics in the form of typed lambda calculus.", "label": 0}
{"sent1": "Some work has been done to combine insights from these two frameworks.", "sent2": "Such features can be used to improve the existing trigram language models.", "label": 0}
{"sent1": "We investigate partial entailment under the faceted entailment model and the possibility of adapting existing textual entailment methods to this setting.", "sent2": "An alternative approach is to induce a controller for a given parsing automaton.", "label": 0}
{"sent1": "Our model gives absolute improvements of 3.3 F1 for English parsing, 2.1 F1 for Chinese parsing, and 5.5 F1 for word alignment over each task?s independent baseline, giving the best reported results for both Chinese-English word alignment and joint parsing on the parallel portion of the Chinese treebank.", "sent2": "Our model is (i) efficient, yielding strong propagation, (ii) modular and (iii) favourable to synergy inasmuch as it allows collaboration between modules, notably semantics and syntax.", "label": 0}
{"sent1": "The classifiers are trained directly on word-aligned corpus without using any additional resources.", "sent2": "We report the accuracy of our translation boundary classifiers.", "label": 1}
{"sent1": "A user provides input natural language text from which we extract explicit constraints on the objects that should appear in the scene.", "sent2": "The new Akane program can be used freely for academic purposes.", "label": 0}
{"sent1": "Therefore, we apply a re-implementation of a state-of-the-art, discriminative L2P system (Jiampojamarn et al, 2008) to the problem, without further modification.", "sent2": "We consider the task of predicting the gender of the YouTube1 users and contrast two information sources: the comments they leave and the social environment induced from the affiliation graph of users and videos.", "label": 0}
{"sent1": "The resulting parsers are surprisingly accurate and robust, considering their speed and simplicity.", "sent2": "Our work is the first to directly tackle the retrieval of infographics and to design a system that takes into account their unique characteristics.", "label": 0}
{"sent1": "This paper will examine 2000 random examples of ?economy?", "sent2": "In particular, we will propose a corporabased operational definition for Mapping Principles, which are explanations of why a conventional conceptual metaphor has a particular source-target domain pairing.", "label": 1}
{"sent1": "), which can be instantiated in different ways depending on the annotator?s approach and goals.", "sent2": "To answer this need, we have developed a representation framework comprised of an abstract model for a variety of different annotation types (e.g., morpho-syntactic tagging, syntactic annotation, co-reference annotation, etc.", "label": 1}
{"sent1": "The first method is based on the Minimum Description Length (MDL) principle and works online.", "sent2": "We present an automatic method which leverages word lengthening to adapt a sentiment lexicon specifically for Twitter and similar social messaging networks.", "label": 0}
{"sent1": "We took part in all four subtasks (aspect term extraction, aspect term polarity, aspect category detection, aspect category polarity), using polarity items detection via various subjectivity lexicons and employing a rule-based system applied on dependency data.", "sent2": "92%, demonstrating 1?3% absolute improvement over the previous best system.", "label": 0}
{"sent1": "We present the Arabic Online Commentary Dataset, a 52M-word monolingual dataset rich in dialectal content, and we describe our long-term annotation effort to identify the dialect level (and dialect itself) in each sentence of the dataset.", "sent2": "The proposed approach is language independent and requires only a dictionary and text data for building a language model.", "label": 0}
{"sent1": "In this paper, we explore more linguistically motivated approaches to vandalism detection.", "sent2": "In particular, we hypothesize that textual vandalism constitutes a unique genre where a group of people share a similar linguistic behavior.", "label": 1}
{"sent1": "The system is evaluated on the MPQA opinion corpus, where we compare it to the only previously published end-to-end system for opinion expression extraction and polarity classification.", "sent2": "The model is trained using large-margin structured prediction methods.", "label": 1}
{"sent1": "Some existing hashing methods can be used for efficient document similarity search.", "sent2": "However, unsupervised hashing methods cannot incorporate prior knowledge for better hashing.", "label": 1}
{"sent1": "Then, we stack additional classifiers on the independent annotations, and exploit the dependencies between them to further improve the accuracy, even with a very limited amount of available training data.", "sent2": "We evaluate our method using a range of queries extracted from a web search log.", "label": 1}
{"sent1": "Mainly, these include a novel word ordering strategy based on: (1) statistically monotonizing the training source corpus and (2) a novel reordering approach based on weighted reordering graphs.", "sent2": "Emphasis is put on improvements and extensions of the previous years system, being highlighted and empirically compared.", "label": 1}
{"sent1": "Furthermore, we also implement some of the smoothing algorithms that are designed specifically for large datasets and are shown to yield better language models than the traditional ones on the Web1T 5gram corpus (Yuret, 2008).", "sent2": "(hum)?", "label": 0}
{"sent1": "This paper also introduces two post processing filters to further improve treatment of space characters.", "sent2": "The bestperforming team achieved an F1 of 88.9% and 69% for subtasks A and B, respectively.", "label": 0}
{"sent1": "The empirical analysis against a humanlabeled data set demonstrates promising and reasonable performance of the proposed HL-SOT approach.", "sent2": "We evaluate their performance on a Chinese?English translation task.", "label": 0}
{"sent1": "The source model is a factored, conditionally-estimated random field (Lafferty et al, 2001) that learns to disambiguate the full sentence by modeling local contexts.", "sent2": "Compared with baseline state-of-the-art methods, our method achieves statistically significant error rate reductions on Korean, Arabic, and Czech, for various training set sizes and accuracy measures.", "label": 1}
{"sent1": "We use two modes of evaluation: one that relies on comparison with a control sentence, paralleling practice in human studies; another that measures probability drop in the disambiguating region of the sentence.", "sent2": "However, in our task, we find that mention detection is often the performance bottleneck.", "label": 0}
{"sent1": "The approach is based on the idea of matching certain lexicosyntactic patterns conveying a certain semantic relation on the World Wide Web using standard search engines.", "sent2": "Our method is unsupervised.", "label": 0}
{"sent1": "Here we present a general framework for deriving smoothed language model probabilities from BFs.", "sent2": "For a small number of labelled positive stories, we extract story pairs which consist of positive and its associated stories from bilingual comparable corpora.", "label": 0}
{"sent1": "We also address the issue whether a corpus annotated by means of AL ?", "sent2": "using a particular classifier and a particular feature set ?", "label": 1}
{"sent1": "In task (1), cross-lingual measures are superior to conventional monolingual measures based on a wordnet.", "sent2": "problems.", "label": 1}
{"sent1": "After briefly presenting the modules of the framework, the paper reports extrinsic evaluation results considering two applications: computer-aided lexicography and statistical machine translation.", "sent2": "We introduce several entity normalization algorithms for genes, proteins, protein complexes and protein components, aiming to uniquely identify these biological entities.", "label": 0}
{"sent1": "During training, the learner repeatedly constructs action sequences for a set of documents, executes those actions, and observes the resulting reward.", "sent2": "We use a policy gradient algorithm to estimate the parameters of a log-linear model for action selection.", "label": 1}
{"sent1": "strategy during decoding, the obtained translations are competitive.", "sent2": "Thanks to input parse forests and a ?no pruning?", "label": 1}
{"sent1": "Our approach turns this paraphrasing task into an optimization problem: we use various existing and also new paraphrasing techniques as operators applicable to intermediate versions of a text (e.g., replacing synonyms), and we search for an operator sequence with minimum text quality loss.", "sent2": "A text contains an acrostic, if the first letters of a range of consecutive lines form a word or phrase.", "label": 1}
{"sent1": "Statistical data and semantic knowledge are extracted from a web corpus to improve template generation.", "sent2": "The main challenge is that many terms have multiple meanings, resulting in a lot of wrong templates.", "label": 1}
{"sent1": "Together with this, we use an existing statistical learning approach to assign weights to deal with multiple meanings of words.", "sent2": "This paper also introduces two post processing filters to further improve treatment of space characters.", "label": 0}
{"sent1": "It is found that in the early stage of training with a larger pool, more labeled examples are required to achieve a given level of accuracy than those with a smaller pool.", "sent2": "In particular, we discuss how the size of a pool affects the learning curve.", "label": 1}
{"sent1": "The result is a method that can scale to more features and more labels, while avoiding overfitting.", "sent2": "We propose a new model that conjoins features and word embeddings while maintaing a small number of parameters by learning feature embeddings jointly with the parameters of a compositional model.", "label": 1}
{"sent1": "Knowledge captured by a specific set of training data is not easily transferable, even to the same NLP task in another language.", "sent2": "Emerging technologies, such as social networks and serious games, offer a unique opportunity to change how we construct training data.", "label": 1}
{"sent1": "This is a significant challenge to conversational language understanding systems ?", "sent2": "Word forming units are thus relevant cues for the identification of terms in domainspecific texts.", "label": 0}
{"sent1": "The idea is to use various syntactic and semantic features extracted from a language for classifying between real-world articles and articles generated by sampling a trigram language model.", "sent2": "The effectiveness of this corpus was assessed via training two state-of-the-art models, wherewith answers to unseen queries were distinguished.", "label": 0}
{"sent1": "Words in anchor texts are represented as nodes in the co-occurrence graph and an edge is formed between nodes which link to the same url.", "sent2": "In this paper, we show a formal description of the algorithm and discuss it theoretically with respect to time complexity.", "label": 0}
{"sent1": "After choosing candidate corrections, a language model is used to assign scores the candidate corrections and choose best correction in the given context.", "sent2": "This paper describes a system which generates animations for cooking actions in recipes, to help people understand recipes written in Japanese.", "label": 0}
{"sent1": "We show that it is possible to identify interactions well enough to facilitate a joint approach and, consequently, that joint methods correct incoherent predictions that independentlytrained classifiers tend to produce.", "sent2": "In this paper, we identify linguistic structures with interacting grammatical properties and propose to address such dependencies via joint inference and joint learning.", "label": 1}
{"sent1": "The algorithm allows us to analyze dependency structures of a sentence in linear-time while keeping a state-of-the-art accuracy.", "sent2": "Our method appropriately inserts linefeeds into a sentence by machine learning, based on the information such as dependencies, clause boundaries, pauses and line length.", "label": 0}
{"sent1": "We describe a detailed experimental design that compares various configurations of conceptual representations and similarity measures across six different subsets of the ACE relation extraction data.", "sent2": "The basic idea of S3H is to learn the optimal feature weights from prior knowledge to relocate the data such that similar data have similar hash codes.", "label": 0}
{"sent1": "To facilitate reading comprehension, our technology presents mixed native language (L1) and second language (L2) sentences to a learner and allows them to interact with the sentences to make the sentences easier (more L1-like) or harder (more L2-like) to read.", "sent2": "Our learn-by-reading approach lets a human learner acquire new words and constructions by encountering them in context.", "label": 1}
{"sent1": "We also describe a coarse-to-fine pruning scheme for forest-based language model reranking that allows a 100-fold increase in beam size while reducing decoding time.", "sent2": "In all, parsing time reduces by 81%.", "label": 1}
{"sent1": "Second, a small development corpus is used to determine the relative contributions of the sparse features and standard dense features.", "sent2": "In this paper we classify the temporal relations between pairs of events on an article-wide basis.", "label": 0}
{"sent1": "In the result of experimental evaluation, we show that a good proportion (79%) of a multiple-choice quiz ?Who wants to be a millionaire?", "sent2": "The merged list is then ranked according to the prospective post-editing effort and provided to the translators to aid their work.", "label": 0}
{"sent1": "We also compare several approaches for utilizing context based on a new data set collected using the proposed solution.", "sent2": "The experimental results demonstrate that 1) IE-based techniques can help create a large scale context data with decent quality from online reviews, at least for restaurant recommendations; 2) context helps recommender systems rank items, however, does not help predict user ratings; 3) simply using context to filter items hurts recommendation performance, while a new probabilistic latent relational model we proposed helps.", "label": 1}
{"sent1": "We perform an extensive analysis with two new model architectures.", "sent2": "State-of-the-art Chinese word segmentation systems have achieved high performance when training data and testing data are from the same domain.", "label": 0}
{"sent1": "with learned costs.", "sent2": "Evaluated on a new corpus of human-judged free responses, our method achieved significant improvements over random and cosine baselines in both rank correlation and label error.", "label": 0}
{"sent1": "Systems can participate in 5 bilingual evaluation subtasks (English - Dutch, English - German, etc.)", "sent2": "For the creation of the hand-tagged gold standard, all translations of a given polysemous English noun are retrieved in the five languages and clustered by meaning.", "label": 1}
{"sent1": "We demonstrate UCCA?s portability across domains and languages, and its relative insensitivity to meaning-preserving syntactic variation.", "sent2": "In this paper, we therefore introduce a human annotation scheme for judging both the subjectivity and polarity of word senses.", "label": 0}
{"sent1": "Second, we compare various inference procedures for state-split PCFGs from the standpoint of risk minimization, paying particular attention to their practical tradeoffs.", "sent2": "Finally, we present multilingual experiments which show that parsing with hierarchical state-splitting is fast and accurate in multiple languages and domains, even without any language-specific tuning.", "label": 1}
{"sent1": "This study describes an effective automatic method for scoring free responses to definition production tests.", "sent2": "Then we exploited the same feature set to solve the both subtasks by considering them as a regression and a classification task respectively and performed a study of influence of different features.", "label": 0}
{"sent1": "We obtain our best results by using the two-layer architecture, in combination with 5 000 features selected by Information Gain.", "sent2": "We investigate two distributional methods for feature selection, Information Gain and Bi-Normal Separation; we also compare distributionally selected features to linguistically motivated features and two types of frameworks: a one-layer system where we aggregate all reviews and predict the rating vs. a two-layer system where ratings of individual reviews are predicted and then aggregated.", "label": 1}
{"sent1": "When evaluated on a benchmark dataset, the MAP and MRR scores are increased by 8 to 10 points, compared to one of our baseline systems using only surface-form matching.", "sent2": "On test section 23, our best system achieves F1 score of 72.73 (69.14) when correct (automatic) syntactic parse trees are used.", "label": 0}
{"sent1": "In this paper, we describe it in detail together with its data-collection method and annotation schemes.", "sent2": "Our model utilizes a hierarchical prior to link the feature weights for shared features in several single-task models and the joint model.", "label": 0}
{"sent1": "In this paper, we extend these techniques to learn latent refinements of single-category synchronous grammars, so as to improve translation performance.", "sent2": "Our best results on test data in the above datasets achieve 93.79% parent-prediction accuracy for English, and 88.05% for Czech.", "label": 0}
{"sent1": "The resultant test collection is different from TREC?s in that it comprises scientific articles rather than newspaper text and, thus, allows for IR experiments that include citation information.", "sent2": "The test collection currently consists of 170 queries with relevance judgements; the document collection is the ACL Anthology.", "label": 1}
{"sent1": "A word alignment model is used for lexical acquisition, and the parsing model itself can be seen as a syntax-based translation model.", "sent2": "The main innovation of WASP is its use of state-of-the-art statistical machine translation techniques.", "label": 1}
{"sent1": "We present here a new model of local coherences, viewing them as resulting from a belief-update process, and show that the relevant probabilities in our model are calculable from a probabilistic Earley parser.", "sent2": "First, we use the Web 1T Google n-gram corpus for checking the applicability of a synonym in context, and we evaluate this method using data from the SemEval lexical substitution task.", "label": 0}
{"sent1": "Traditional simplexdownhill has the advantage of derivative-free computations of objective functions, yet still gives satisfactory searching directions in most scenarios.", "sent2": "Second, we can optimize for an extraction-based loss function that relates directly to the end task of generating translations.", "label": 0}
{"sent1": "First, we analyze idiosyncracy in dialogue verbal acts by qualitatively studying the differences and conflicts among speakers and by quantitively comparing speaker-specific models.", "sent2": "A negated statement often carries positive implicit meaning, but to pinpoint the positive part from the negative part is rather difficult.", "label": 0}
{"sent1": "We couch statistical sentence generation as a spanning tree problem in order to search for the best dependency tree spanning a set of chosen words.", "sent2": "Stance detection is the task of classifying the attitude Previous work has assumed that either the target is mentioned in the text or that training data for every target is given.", "label": 0}
{"sent1": "We then identify regions in the data that contain likely contexts for a given query word.", "sent2": "Finally, we detect words or sequences of words in the contextual regions that are unlikely to appear in the context and that are phonetically similar to the query word.", "label": 1}
{"sent1": "Secondly, since a distribution of sentiment on tweets is known to be unbalanced, an weighting scheme is introduced to bias an output of a machine learner.", "sent2": "For the test run, the system was tuned towards Twitter texts and successfully achieved high scoring results on Twitter data, average F 1 70.96 on Twitter2014 and average F 1 56.50 on Twitter2014Sarcasm.", "label": 1}
{"sent1": "Finally, it makes a graph where temporal expressions are used for the horizontal axis and the value of percentage is shown on the vertical axis.", "sent2": "It next extracts values related to ?%?.", "label": 1}
{"sent1": "A working system first identifies events and times, then identifies which events and times should be ordered, and finally labels the ordering relation between them.", "sent2": "This formulation enables us to encode some of the linguistic intuitions that have guided human decipherers.", "label": 0}
{"sent1": "Accordingly it is crucial to robustly model each word in a sentence to capture the complete semantic picture of the sentence.", "sent2": "In this paper, we hypothesize that by better modeling lexical semantics we can obtain better sentential semantics.", "label": 1}
{"sent1": "In the current entity linking literature, mention detection and entity disambiguation are frequently cast as equally important but distinct problems.", "sent2": "We present the results of feature engineering and post-processing experiments conducted on a temporal expression recognition task.", "label": 0}
{"sent1": "and ?as soon as?.", "sent2": "In conventional language modeling, the words from only one speaker at a time are represented, even for conversational tasks such as meetings and telephone calls.", "label": 0}
{"sent1": "Each of these approaches addresses a different aspect of the overall recognition performance.", "sent2": "We introduce a method for using these phrases in information retrieval and present our experiments.", "label": 0}
{"sent1": "In line with METANET?s aims of increasing communication between citizens of different European countries, U-Compare has been extended to facilitate the development of a wider range of applications, including both multilingual and multimodal workflows.", "sent2": "The enhancements exploit the UIMA Subject of Analysis (Sofa) mechanism, that allows different facets of the input data to be represented.", "label": 1}
{"sent1": "We propose Two Dimensional Trie (2D Trie), a novel efficient feature indexing structure which takes advantage of relationship between templates: feature strings generated by a template are prefixes of the features from its extended templates.", "sent2": "We apply our technique to Maximum Spanning Tree dependency parsing.", "label": 1}
{"sent1": "Second, natural texts are systematically biased towards novelty and surprise, which presents an unrepresentative sample to the learner.", "sent2": "First, natural texts are radically incomplete since there are always too many facts to mention.", "label": 1}
{"sent1": "A  series  of  four  experiments  was  conducted  on  a  baseline  method:  Na?ve  Bayes  with varying sets of attributes.", "sent2": "We also propose a new feature which can automatically learn the reordering rules to a certain extent.", "label": 0}
{"sent1": "Commonly used heuristics to estimate the sentiment of negated expressions rely simply on the sentiment of argument (and not on the negator or the argument itself).", "sent2": "We use a sentiment treebank to show that these existing heuristics are poor estimators of sentiment.", "label": 1}
{"sent1": "Instead, we have designed and developed a new framework that uses multiple LMs and LUMs to improve speech understanding accuracy under various situations.", "sent2": "AttitudeMiner uses linguistic techniques to analyze the text exchanged between participants of online discussion threads at different levels of granularity: the word level, the sentence level, the post level, and the thread level.", "label": 0}
{"sent1": "In this paper, we use a weighted vote method to transform discontinuous word alignment to continuous alignment, which enables SMT systems extract more phrase pairs.", "sent2": "By introducing extra linguistic resources and tuning parameters, the new metric gets the state-of-the-art performance which is better than METEOR and SEMPOS on system level, and is comparable with METEOR on sentence level on WMT 2012 and WMT 2013.", "label": 0}
{"sent1": "In this paper, we propose a syntax-label clustering method that uses an exchange algorithm in which syntax labels are clustered together to reduce the number of rules.", "sent2": "Predictability and complexity are estimated for four different languages: English, French, Swedish, and Finnish.", "label": 0}
{"sent1": "We introduce a method for using these phrases in information retrieval and present our experiments.", "sent2": "We report tagging/chunking accuracies for varying dataset sizes and show that our approach is relatively robust to data sparsity.", "label": 0}
{"sent1": "In two intrinsic evaluations on alignment test data, our system achieves F1 scores of 88?", "sent2": "This paper proposes a hybrid generative-discriminative framework for extracting such expressions.", "label": 0}
{"sent1": "In order to address these quantitative reasoning problems we first develop a computational approach which we show to successfully recognize and normalize textual expressions of quantities.", "sent2": "We then use these capabilities to further develop algorithms to assist reasoning in the context of the aforementioned tasks.", "label": 1}
{"sent1": "Replacing these difficult terms with easier synonyms can, however, lead to improved readability.", "sent2": "Negation is present in all human languages and it is used to reverse the polarity of part of statements that are otherwise affirmative by default.", "label": 0}
{"sent1": "self-annotation.", "sent2": "the annotation of texts with relations that are included in the structured data ?", "label": 1}
{"sent1": "We also propose a new feature which can automatically learn the reordering rules to a certain extent.", "sent2": "The experimental results show that the MT systems using the data reordered by our proposed model outperform the baseline systems by 6.42% and 3.08% relative points in terms of the BLEU score on PB-SMT and hierarchical phrase-based MT respectively.", "label": 1}
{"sent1": "lexical unit (F, l), finds the Wikipage that best expresses the the meaning of l. The mapping can be exploited to straightforwardly acquire new example sentences and new lexical units, both for English and for all languages available in Wikipedia.", "sent2": "In this way, it is possible to easily acquire good-quality data as a starting point for the creation of FrameNet in new languages.", "label": 1}
{"sent1": "time and effort that is consumed in browsing.", "sent2": "a ranked list of inter-connected texts and images) from massive amounts of cross-media and cross-genre data can significantly save users?", "label": 1}
{"sent1": "In the standard process, the parse selection model is trained over a hand-disambiguated treebank, meaning that without a significant investment of effort to produce the treebank, parse selection is not possible.", "sent2": "This paper explores the use of Adaptor Grammars, a nonparametric Bayesian modelling framework, for minimally supervised morphological segmentation.", "label": 0}
{"sent1": "We propose an uptraining procedure in which a deterministic parser is trained on the output of a more accurate, but slower, latent variable constituency parser (converted to dependencies).", "sent2": "Uptraining with 100K unlabeled questions achieves results comparable to having 2K labeled questions for training.", "label": 1}
{"sent1": "In addition, we propose TIMEMMR, a modification to Maximal Marginal Relevance that promotes temporal diversity by way of computing time span similarity, and show its utility in summarizing certain document sets.", "sent2": "reviews.", "label": 0}
{"sent1": "Here, we report on work in progress that examines several novel heuristics for incorporating such information.", "sent2": "We provide quantitative evidence about the effectiveness of the approach to improve the automatic evaluation of text summarisation systems by combining several similarity metrics.", "label": 0}
{"sent1": "One approach to the interpretation of noun-noun compounds assumes that people make use of distributional information about how the constituent words of compounds tend to combine; another assumes that people make use of information about the two constituent concepts?", "sent2": "features to produce interpretations.", "label": 1}
{"sent1": "Learning-to-rank algorithms are applied on a large set of features to develop several models for infographics retrieval.", "sent2": "We evaluate our method by comparison to human judgments, and analyze its strengths and weaknesses.", "label": 0}
{"sent1": "We introduce an informativeness score for determining the most precise relation of a mention entity pair regarding the coreference decisions.", "sent2": "Experimental results demonstrated the effectiveness of our MiNets-based approach and the power of cross-media cross-genre inference.", "label": 0}
{"sent1": "to the human evaluation of machine translation output.", "sent2": "strategy during decoding, the obtained translations are competitive.", "label": 0}
{"sent1": "attributing texts to their original authors ?", "sent2": "This allows us to bootstrap the treebanking process and provide better parsers faster, and with less resources.", "label": 0}
{"sent1": "In the competition, this word-expert architecture resulted in accuracies of 63.6% (fine-grained) and 64.5% (coarse-grained) on the SENSEVAL-2 test data.", "sent2": "Through optimization by crossvalidation of the individual component classifiers and the voting scheme for combining them, the best possible word-expert was determined.", "label": 1}
{"sent1": "In this framework, namely Computer Assisted Translation (CAT), human translators interact with a translation system, as an assistance tool, that dinamically offers, a list of translations that best completes the part of the sentence already translated.", "sent2": "In this paper, finite state transducers are presented as a candidate technology in the CAT paradigm.", "label": 1}
{"sent1": "Correspondence Analysis (CA) offers a solution to both these problems.", "sent2": "Data-driven representation learning for words is a technique of central importance in NLP.", "label": 0}
{"sent1": "In this paper, we generalize the violation-fixing perceptron of Huang et al.", "sent2": "(2012) to hypergraphs and apply it to the cube-pruning parser of Zhang and McDonald (2012).", "label": 1}
{"sent1": "We have been able to extract over 1M Chinese-English parallel segments from Sina Weibo (the Chinese counterpart of Twitter) using only their public APIs.", "sent2": "We present an efficient method for detecting these messages and extracting parallel segments from them.", "label": 1}
{"sent1": "This paper compares the performances of eight state-of-the-art dependency parsers on two domains of ungrammatical sentences: learner English and machine translation outputs.", "sent2": "If the parser can overlook problems such as grammar mistakes and produce a parse tree that closely resembles the correct analysis for the intended sentence, we say that the parser is robust.", "label": 1}
{"sent1": "This is the first analysis of this kind on German data.", "sent2": "Due to the completeness of the semiring, the inside weights always exist, but the construction is only effective if they can be effectively determined.", "label": 0}
{"sent1": "Path Ranking Algorithm (PRA) is a recently proposed method which aims to improve KB coverage by performing inference directly over the KB graph.", "sent2": "Automatically constructed Knowledge Bases (KBs) are often incomplete and there is a genuine need to improve their coverage.", "label": 1}
{"sent1": "contents whose effect triggers a chain reaction on people.", "sent2": "The structured form is machinereadable and can be used to augment the textual data.", "label": 0}
{"sent1": "The aim of this work is to present and compare two different approaches to achieve this.", "sent2": "The goal of our research is to distinguish veterinary message board posts that describe a case involving a specific patient from posts that ask a general question.", "label": 0}
{"sent1": "of poster conversations.", "sent2": "We focus on the audience?s feedback behaviors such as non-lexical backchannels (reactive tokens) and noddings as well as joint eye-gaze events by the presenter and the audience.", "label": 1}
{"sent1": "Concretely, a series of unsupervised topic models is explored and experimental results show that fine-grained topic models, which discover topics at the utterance-level rather than the document-level, can better identify the gist of the decisionmaking process.", "sent2": "We evaluate our method on two tasks: cross-domain partof-speech tagging and cross-domain sentiment classification.", "label": 0}
{"sent1": "Domain selection was based on three choices: (I) the previous domain, (II) the domain in which the speech recognition result can be accepted with the highest recognition score, and (III) other domains.", "sent2": "Our system was constructed on an extensible architecture and is equipped with a robust and extensible domain selection method.", "label": 1}
{"sent1": "Two training methods, Separated Mode and Integrated Mode, are proposed to construct the models.", "sent2": "Tagged sentences are then passed to the Correctional Tagging phase, in which the sentences are re-tagged using extra information from the first round tagging results.", "label": 1}
{"sent1": "Our method, dubbed Variable Bit Quantisation (VBQ), provides a datadriven non-uniform bit allocation across hyperplanes.", "sent2": "(1984) and extended by Chou et al.", "label": 0}
{"sent1": "Analysis confirm the utility of these criteria on improving data quality.", "sent2": "Three selection criteria are identified to select high-quality annotations: noise level, sentiment ambiguity, and lexical uncertainty.", "label": 1}
{"sent1": "Then, I incorporate two ideas from probabilistic parsing?word similarity smoothing and local estimation?to improve the large margin approach.", "sent2": "First, I describe a generative technique that uses a strictly lexicalised parsing model, where all the parameters are based on words and do not use any partof-speech (POS) tags nor grammatical categories.", "label": 1}
{"sent1": "Knowledge is extracted from the semantic representation (Minimal Recursion Semantics).", "sent2": "The model accounts for young children?s tendency to use both correct finites and incorrect (optional) infinitives in finite contexts, for the generality of this phenomenon across languages, and for the sparseness of other types of errors (e.g., word order errors).", "label": 0}
{"sent1": "Solutions to specific semantic problems dealing with equivalence of semantic representations are described.", "sent2": "By combining structural learning and a variety of firstorder, second-order, and context-sensitive features, our system is able to outperform existing state-of-the art entity linking systems by 15% F1.", "label": 0}
{"sent1": "(2.)", "sent2": "In the standard process, the parse selection model is trained over a hand-disambiguated treebank, meaning that without a significant investment of effort to produce the treebank, parse selection is not possible.", "label": 0}
{"sent1": "As a research contribution, we operationalize video lecture clickstreams of students into cognitively plausible higher level behaviors, and construct a quantitative information processing index, which can aid instructors to better understand MOOC hurdles and reason about unsatisfactory learning outcomes.", "sent2": "This paper describes a prototype system to visualize and animate 3D scenes from car accident reports, written in French.", "label": 0}
{"sent1": "We show that parallel corpus data can provide new empirical evidence for better understanding the properties of light verbs.", "sent2": "We also study the influence that the identified properties of light verb constructions have on the quality of their automatic alignment in a parallel corpus.", "label": 1}
{"sent1": "This mechanism implicitly supports not only traditional phrase pairs, but also gapping phrases which are non-consecutive in the source.", "sent2": "We tested the proposed method on Japanese-English and Chinese-English translation tasks and found order-of-magnitude higher clustering speeds for reducing labels and gains in translation quality compared with previous clustering method.", "label": 0}
