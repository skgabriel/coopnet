{"sent1": "We also propose a novel back-transliteration method for this language pair, a previously unstudied problem.", "sent2": "Our new model improves the English to Persian transliteration accuracy by 14% over an n-gram baseline.", "label": 1}
{"sent1": "traverse the route using prerecorded route segments.", "sent2": "There is hardly any cooperation between the acoustic and the translation knowledge sources.", "label": 0}
{"sent1": "When these factors change, for example when an agent joins a conversation, the agents must dynamically move to a new location and/or orientation to accommodate.", "sent2": "NLP systems for tasks such as question answering and information extraction typically rely on statistical parsers.", "label": 0}
{"sent1": "A total of seven teams participated in the task and submitted 42 system runs.", "sent2": "The evaluation showed that language identification at the token level is more difficult when the languages present are closely related, as in the case of MSA-DA, where the prediction performance was the lowest among all language pairs.", "label": 1}
{"sent1": "Manual evaluation shows that the performance of automatic detection varies significantly depending on the primary language.", "sent2": "We focus on the Canadian Hansard, and automatically detect mixed language segments based on simple corpus-based rules and an existing word-level language tagger.", "label": 1}
{"sent1": "We gather features from substring pairs consistent with a character-based alignment of the two strings.", "sent2": "This approach achieves exceptional performance; on nine separate cognate identification experiments using six language pairs, we more than double the precision of traditional orthographic measures like Longest Common Subsequence Ratio and Dice?s Coefficient.", "label": 1}
{"sent1": "The corpus is designed to support the development and evaluation of models learning rather complex grounded linguistic structures, e.g.", "sent2": "We show that the results are rather inconsistent and ask for detailed analyses as well as clarification.", "label": 0}
{"sent1": "In particular, the Baldwin effect in a naming game model is elaborated on by describing a set of experimental simulations.", "sent2": "The paper looks at the main theories of language evolution: biological evolution, learning, and cultural evolution.", "label": 1}
{"sent1": "Some existing CTS implementations are discussed and it is explained why there is a need for one that is able to scale to much larger text collections.", "sent2": "To differentiate them is useful for deep semantic processing and will thus benefit NLP applications such as question answering and machine translation, etc.", "label": 0}
{"sent1": "Candidate spatial relations, in the form of triples, are heuristically extracted from sentences with high recall.", "sent2": "This sparse prototype information is then propagated across a corpus using distributional similarity features, which augment an otherwise standard PCFG model.", "label": 0}
{"sent1": "It uses a simple log-linear regression model, trained on the training data, to combine multiple text similarity measures of varying complexity.", "sent2": "We compare DTKs and DDTKs in two tasks: approximating tree kernels TK (Collins and Duffy, 2002); performing textual entailment recognition (RTE).", "label": 0}
{"sent1": "Most of the research on semantic similarity of textual content focuses on large documents.", "sent2": "Work in progress aims to capture this natural implicitation of discourse connectives in current statistical machine translation models.", "label": 0}
{"sent1": "Our contribution consists of an unsupervised method, Heterogeneity Based Ranking (HBR), to combine similarity measures.", "sent2": "Our runs focus on combining standard similarity measures for Machine Translation.", "label": 1}
{"sent1": "for linguistically-complex identifiers and analyse a large corpus of OWL ontologies to identify common patterns among all defining axioms.", "sent2": "By generating texts from ontologies, and selectively including or omitting these defining axioms, we show by surveys that human readers are typically capable of inferring information implicitly encoded in identifier phrases, and that texts which do not make such ?obvious?", "label": 1}
{"sent1": "Our hypothesis, therefore, is that the quality of the corpus is more important than the quantity and ensures the quality of the acquired terminological resources.", "sent2": "More importantly, as terms are defined vis-?-vis a specific domain with a restricted register, it is expected that the quality rather than the quantity of the corpus matters more in terminology mining.", "label": 1}
{"sent1": "To determine the principles governing referential chains, we gathered data from three languages: English, Swedish and Hebrew, and studied how coreference is expressed in a discourse.", "sent2": "Semi-supervised learning techniques try to leverage the intrinsic information in unlabeled examples to improve classification models.", "label": 0}
{"sent1": "is composed by ?risky?", "sent2": "1", "label": 0}
{"sent1": "We then present a sequence tagging model that jointly infers lexical expressions and their supersenses.", "sent2": "We develop an efficient bootstrapping online learner with this focus in mind, and evaluate it on child-directed speech.", "label": 0}
{"sent1": "sentiment towards factual (objective) content and towards its entities (subject and object).", "sent2": "ACT is a theory of affective reasoning that uses empirically derived equations to predict the sentiments and emotions that arise from events.", "label": 1}
{"sent1": "Theories of categorization largely agree that categories are characterized by features such as function or appearance and that feature and category acquisition go hand-in-hand, however previous work has considered these problems in isolation.", "sent2": "We present the first model that jointly learns categories and their features.", "label": 1}
{"sent1": "This increase was derived from a predicted increase in context, but the context itself was not quantified.", "sent2": "We use microblog texts from Twitter, tied to a single shared event (the baseball World Series), to quantify both linguistic and non-linguistic context.", "label": 1}
{"sent1": "In this paper, we show that embeddings can likewise add value to the problem of unsupervised POS induction.", "sent2": "Unsupervised word embeddings have been shown to be valuable as features in supervised learning problems; however, their role in unsupervised problems has been less thoroughly explored.", "label": 1}
{"sent1": "Second, we generate preliminary sentence candidates in the ILP model and then rerank them using sentence level features.", "sent2": "First, these features are used in a supervised model to predict the weights of the concepts used in the ILP model.", "label": 1}
{"sent1": "Our model uses a new approximation for computing local regression coefficients that is explicitly designed to preserve memory locality.", "sent2": "In addition, we have found that the displays are useful as debugging tools for experienced researchers.", "label": 0}
{"sent1": "In this paper, we propose a novel time-aware KB embedding approach taking advantage of the happening time of facts.", "sent2": "Code assignment is important for handling large amounts of electronic medical data in the modern hospital.", "label": 0}
{"sent1": "We investigate techniques for building open-domain sequence labeling systems that approach the ideal of a system whose accuracy is high and constant across domains.", "sent2": "In particular, we investigate unsupervised techniques for representation learning that provide new features which are stable across domains, in that they are predictive in both the training and out-of-domain test data.", "label": 1}
{"sent1": "This paper explores a number of metrics that attempt to predict the cross-domain performance of an NLP tool through statistical inference.", "sent2": "This makes it hard to develop NLP tools for domains for which annotated corpora are not available.", "label": 1}
{"sent1": "Our proposed approach (EA++) builds on the notion of augmented space (introduced in EA) and harnesses unlabeled data in target domain to ameliorate the transfer of information from source to target.", "sent2": "III, 2007).", "label": 1}
{"sent1": "Rather than making local decisions when writing and conditioning rules, goodness of translation was modeled numerically and free parameters were selected to optimize that goodness.", "sent2": "capitalizer trained on 20Mwds of Wall Street Journal (WSJ) text from 1987 is adapted to two Broadcast News (BN) test sets ?", "label": 0}
{"sent1": "The empirical investigation here reported sheds some light on the role played by these spaces as complex kernels for supervised (i.e.", "sent2": "We show that we can successfully project the contextual cues for these classes across pairs of languages and retain a high quality class model in languages with no supervised class data.", "label": 0}
{"sent1": "We build a vector-based semantic space from a lemmatised version of the BNC, where the most frequent A-N lemma pairs are treated as single tokens.", "sent2": "Experimental results show that the performance of our algorithm is competitive with the recently proposed hierarchical classification algorithms.", "label": 0}
{"sent1": "These methods use hashing to deal with massive amounts of the streaming text.", "sent2": "Using an existing search engine to extend the word clusters and generalize the examples.", "label": 0}
{"sent1": "The proposed algorithm induces a contextfree grammar of the language in question in an iterative manner.", "sent2": "Accurate high-coverage translation is a vital component of reliable cross language information access (CLIA) systems.", "label": 0}
{"sent1": "All translations are generated using phrase-based translation systems, using different kinds of word-based, part-ofspeech-based and cluster-based language models trained on the provided data.", "sent2": "In this paper, we propose a novel approach to finding translations for oov words.", "label": 0}
{"sent1": "Two systems are explained: System A for determining the sentiment of a phrase within a tweet and System B for determining the sentiment of a tweet.", "sent2": "Both approaches rely on rich feature sets, which are explained in detail.", "label": 1}
{"sent1": "We find that the simple self-identification pattern ?I am a ?", "sent2": "Motivated by work predicting coarsegrained author categories in social media, such as gender or political preference, we explore whether Twitter contains information to support the prediction of finegrained categories, or social roles.", "label": 1}
{"sent1": "Our method is simple and easy to implement.", "sent2": "Experiments on SIGHAN 2003 and 2005 evaluation datasets show that our method achieves the best reported results to date on 6 out of 7 datasets.", "label": 1}
{"sent1": "To alleviate this problem, we propose to use the query lattice, which is a compact representation of exponentially many queries containing translation alternatives.", "sent2": "For example, we learn that ?war?", "label": 0}
{"sent1": "Then, each word in a chunk is translated.", "sent2": "The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines.", "label": 0}
{"sent1": "but we find this contribution does not generalize outside the training corpus.", "sent2": "We present a novel approach to natural language generation (NLG) that applies hierarchical reinforcement learning to text generation in the wayfinding domain.", "label": 0}
{"sent1": "We present a simple approach which completely modularizes these three aspects.", "sent2": "In contrast to much current work, which focuses on learning and on the discourse component, our system is deterministic and is driven entirely by syntactic and semantic compatibility as learned from a large, unlabeled corpus.", "label": 1}
{"sent1": "We present a unified solution to include features derived from unlabeled data to a discriminative learning model.", "sent2": "The evaluation showed that language identification at the token level is more difficult when the languages present are closely related, as in the case of MSA-DA, where the prediction performance was the lowest among all language pairs.", "label": 0}
{"sent1": "This method also generates an enhanced probabilistic resolution of logical metonymies.", "sent2": "The experimental results indicate substantial improvements the detection of coercions and the ranking of metonymic interpretations.", "label": 1}
{"sent1": "In particular, the traditional definitions of depth and density as ordinal integer values in the hierarchical structure of WordNet does not always correlate with human judgment of lexical semantic similarity, which imposes strong limitations on their contribution to an accurate similarity measure.", "sent2": "This study is an attempt to analyze the structure of languages via a purely structural technique, namely spectral analysis, which is ideally suited for discovering the global correlations in a network.", "label": 0}
{"sent1": "We make use of a factorization model in which words, together with their window-based context words and their dependency relations, are linked to latent dimensions.", "sent2": "This paper presents a novel method for the computation of word meaning in context.", "label": 1}
{"sent1": "Also Natural Language Processing (NLP) applications benefit from taxonomic classifications because they vary in terms of the granularity they require from a classification.", "sent2": "We introduce a new clustering method called Hierarchical Graph Factorization Clustering (HGFC) and extend it so that it is optimal for the task.", "label": 1}
{"sent1": "We propose a new measure of word association based on a new notion of statistical significance for lexical co-occurrences.", "sent2": "We describe a machine learning system based on large margin structure perceptron for unrestricted coreference resolution that introduces two key modeling techniques: latent coreference trees and entropy guided feature induction.", "label": 0}
{"sent1": "Since word senses used as features show promise, we also examine the possibility of using similarity metrics defined on WordNet to address the problem of not finding a sense in the training corpus.", "sent2": "Finally, we show that even if a WSD engine disambiguates between a limited set of words in a document, a sentiment classifier still performs better than what it does in absence of sense annotation.", "label": 1}
{"sent1": "Understanding the connotation of words would seem to require common sense and world knowledge.", "sent2": "This method aggregates statements that are relevant to the topic, and shows contradictory and contrastive relations among them.", "label": 0}
{"sent1": "We show the effectiveness of these solutions presenting comparative results obtained reranking hypotheses generated by a very accurate Conditional Random Field model.", "sent2": "a distribution of pointwise mutual information between all pairs of content word types in a text.", "label": 0}
{"sent1": "A hill climbing method (iterative decoding) is proposed to search over islands of confusability in the word lattice.", "sent2": "The first criterion is used for evaluating locally the modules in the system, which contribute in selecting documents that are likely to contain the answer.", "label": 0}
{"sent1": "Using a corpus of dialogues containing 16,358 referring expressions, we explore this question via the generation of subsequent references in shared visual scenes.", "sent2": "This raises the question as to which is a more accurate characterisation of what people do.", "label": 1}
{"sent1": "We extend bilingual paraphrase extraction to syntactic paraphrases and demonstrate its ability to learn a variety of general paraphrastic transformations, including passivization, dative shift, and topicalization.", "sent2": "and ?disease?", "label": 0}
{"sent1": "Experimentally, we observed that a performance correlation function in a space defined by all parameters was relatively smooth and had a single maximum achievable by ?hill climbing.?", "sent2": "Furthermore, our approach is capable of recognizing negation and the speculative character of extracted statements.", "label": 0}
{"sent1": "We find that parser performance on incorrect English sentences, which is standardly ignored in parser evaluation, is key in model selection.", "sent2": "It disambiguates the meaning of each sentence while simultaneously learning a semantic parser that maps sentences into logical form.", "label": 0}
{"sent1": "We introduce the first unsupervised approach to this problem, learning clusters of semantically equivalent English and French relations between referring expressions, based on their named-entity arguments in large monolingual corpora.", "sent2": "The clusters can be used as language-independent semantic relations, by mapping clustered expressions in different languages onto the same relation.", "label": 1}
{"sent1": "The method decomposes a target relation into four pairs of endpoints with three target relations.", "sent2": "This paper investigates this question empirically, using machine-learning techniques on a new corpus of dialogues involving multimodal references to objects.", "label": 0}
{"sent1": "This system consists of a SVM classifier with features extracted from texts (and their translations SMT) based on a cardinality function.", "sent2": "Results using multiple assisting languages are mixed and it helps in boosting MultiPRF accuracy only in some cases.", "label": 0}
{"sent1": "Our system aims at yielding both the denoted chemical structure and a classification of a given name.", "sent2": "This paper introduces the architecture of a system for the syntactic and semantic analysis of such names.", "label": 1}
{"sent1": "Our analysis uses a phonologically comparable subset of 562 items for all 424 localities in the Netherlands.", "sent2": "Hence, the English Wikipedia is used to bootstrap the NEs for other languages.", "label": 0}
{"sent1": "The number of frame components is inferred by a novel application of a split-merge method from syntactic parsing.", "sent2": "In this paper, we propose the first probabilistic approach to frame induction, which incorporates frames, events, and participants as latent topics and learns those frame and event transitions that best explain the text.", "label": 1}
{"sent1": "For evaluation, we compare our system output with multiple human references.", "sent2": "In the second step, we use a discriminative training approach to capture sentence level global information from the candidates and rerank them.", "label": 1}
{"sent1": "A statistical phrase-based approach to computer-assisted translation is described in this article.", "sent2": "A new decoder algorithm for interactive search is also presented, that combines monotone and nonmonotone search.", "label": 1}
{"sent1": "We evaluate this hypothesis with two experiments with cruiser, a DS for in-car or mobile users to access restaurant information.", "sent2": "We present the first systematic assessment of several diverse classes of metrics designed to capture various aspects of well-written text.", "label": 0}
{"sent1": "While significant progress has been made in this area for text sources and for English audio sources, little work has been done in automatic, acoustic feature-based segmentation of other languages.", "sent2": "In this paper, we consider exploiting both prosodic and text-based features for topic segmentation of Mandarin Chinese.", "label": 1}
{"sent1": "Large-scale experiments show an absolute improvement of 1.7 BLEU points over the 1-best baseline.", "sent2": "This result is also 0.8 points higher than decoding with 30-best parses, and takes even less time.", "label": 1}
{"sent1": "resemble constituent edges.", "sent2": "such as English determiners ?", "label": 1}
{"sent1": "Different filters handle different situations and the filtering strategies are designed manually.", "sent2": "This paper describes a pure rule-based method, which assembles different filters in a proper order.", "label": 1}
{"sent1": "We participated in the closed tasks for English and Chinese.", "sent2": "Entities are obtained via greedy clustering.", "label": 1}
{"sent1": "We apply a multilingual methodology for the development of the system?s language resources, based on adaptation of language-independent grammars and on weakly-supervised learning of lexical resources.", "sent2": "Two sets of features are proposed: one constrained, i.e.", "label": 0}
{"sent1": "Integrated solutions, which may also be used by designers and researchers without technical background, are missing.", "sent2": "Yet, existing tools often require complex client-server configurations and setup routines, or suffer from compatibility problems with different platforms.", "label": 1}
{"sent1": "In this paper, we propose an unsupervised method called HeterogeneityBased Ranking (HBR) that combines summarization evaluation measures without requiring human assessments.", "sent2": "Our empirical results indicate that HBR achieves a similar correspondence with human assessments than the best single measure for every observed corpus.", "label": 1}
{"sent1": "However, based on the DUC and the TAC evaluation results, (Conroy and Schlesinger, 2008; Dang and Owczarzak, 2008) showed that the performance gap between humangenerated summaries and system-generated summaries is clearly visible in manual evaluations but is often not reflected in automated evaluations using ROUGE scores.", "sent2": "This paper applies finite state technologies to verify the typological validity of Turbid Spreading, a theory of vowel harmony in Optimality Theory (OT) (Prince & Smolensky, 1993/2004).", "label": 0}
{"sent1": "The dominant approach since several decades are back-off language models.", "sent2": "Language models play an important role in large vocabulary speech recognition and statistical machine translation systems.", "label": 1}
{"sent1": "These approaches have used a variety of pattern models (schemes which define the parts of the dependency tree which can be used to form extraction patterns).", "sent2": "We propose an algorithm that exploits these insights to cluster the observed attributes of hundreds of millions of Twitter users.", "label": 0}
{"sent1": "Automating SFG annotation is challenging because the theory uses a minimal constituency model, allocating as much of the work as possible to a set of hierarchically organised features.", "sent2": "In this paper we show that despite the unorthodox organisation of SFG, adapting existing resources remains the most practical way to create an annotated corpus.", "label": 1}
{"sent1": "Based on Chomsky?s generative grammar for its grammatical aspects, and on objectoriented (OO) sofware engineering techniques for its implementation, Fips is designed to efficiently parse the four Swiss ?national?", "sent2": "languages (German, French, Italian and English) to which we also added Spanish and (more recently) Greek.", "label": 1}
{"sent1": "Evaluating the resource entails sampling from a very large space of language types, the type and range of which preclude the use of standard test suites development techniques.", "sent2": "We present a validation methodology for a cross-linguistic grammar resource which produces output in the form of small grammars based on elicited typological descriptions.", "label": 1}
{"sent1": "We use three corpus based measures and present the results obtained from them and show how these results relate to linguistic and historical knowledge.", "sent2": "Automatic discourse causality recognition can further improve their workload by suggesting possible causal connections and aiding in the curation of pathway models.", "label": 0}
{"sent1": "We analyze technical terminology in patents and define the concept of technical term based on the analysis.", "sent2": "We used our method to track the salience of members of the US Senate using data from the US Congressional Record.", "label": 0}
{"sent1": "Next, we show that using the latent representation from matrix factorization as features in a classification algorithm substantially improves accuracy.", "sent2": "Each instance identified a preposition to be tagged in a full sentence taken from the FrameNet corpus (mostly from the British National Corpus).", "label": 0}
{"sent1": "However, no work is done for comparing different corpora in the polarity classification task.", "sent2": "Nowadays, Twitter has aggregated huge amount of data that are full of people?s sentiments.", "label": 1}
{"sent1": "This paper presents a pre-computation step as a way to discover these multiwords in the corpus automatically and tags them in the termdocument matrix.", "sent2": "In this paper, we propose to employ the Model Driven Development (MDD) approach to software engineering, which provides rich structural and behavioral modeling capabilities and solid software support for model transformation and code generation.", "label": 0}
{"sent1": "The selection model utilized ambiguity properties extracted from queries to train a composite of Support Vector Regression (SVR) models to predict a text normalization technique that yields the highest Mean Average Precision (MAP).", "sent2": "Moreover, our model performs better than syntactic models on datasets with high syntactic variance.", "label": 0}
{"sent1": "We handle this task as both a regression and a classification modeling problem and explore several combinations of syntactic and semantic features.", "sent2": "However, the manual word class taxonomy may be unreliable and irrational for statistical natural language processing, aside from its insufficient linguistic phenomena coverage and domain adaptivity.", "label": 0}
{"sent1": "In this paper we also propose a heuristic method for the treatment of social networking profiles.", "sent2": "Our approach is compared with four gold standard collections for this task obtaining really competitive results, comparable to those obtained by some approaches with supervision.", "label": 1}
{"sent1": "Our motivation is to quantify the degree to which language models can make the simplest scanning interfaces ?", "sent2": "We present preliminary experiments of a binary-switch, static-grid typing interface making use of varying language model contributions.", "label": 1}
{"sent1": "Towards this end, we first formalize a preliminary communication channel model, in which users provide explicit feedback regarding issues with the communication channel, and the system implicitly alters its amplitude to accommodate the user?s optimal volume.", "sent2": "This criterion is shown to be related to the entropy of a random variable associated with the tree structures, and it is demonstrated that it selects linguistically plausible constituents.", "label": 0}
{"sent1": "Furthermore, we demonstrate that dysarthric speech is more precisely portrayed as a noisy-channel distortion of an abstract representation of articulatory goals, rather than as a distortion of non-dysarthric speech.", "sent2": "In this paper, we demonstrate that articulatory knowledge can remove ambiguities in the acoustics of dysarthric speakers by reducing entropy relatively by 18.3%, on average.", "label": 1}
{"sent1": "We synthesize the contributions of researchers working on parsing Arabic, Basque, French, German, Hebrew, Hindi and Korean to point out shared solutions across languages.", "sent2": "The overarching analysis suggests itself as a source of directions for future investigations.", "label": 1}
{"sent1": "The method, originally applied and evaluated for English, is often used in bootstrapping sentiment lexicons for European languages where no such resources typically exist.", "sent2": "With the widespread use of email, we now have access to unprecedented amounts of text that we ourselves have written.", "label": 0}
{"sent1": "In contrast to k-valued classical categorial grammars, k-valued Lambek grammars are not learnable from strings.", "sent2": "This result was shown for several variants but the question was left open for the weakest one, the non-associative variant NL.", "label": 1}
{"sent1": "The stemming model is based on statistical machine translation and it uses an English stemmer and a small (10K sentences) parallel corpus as its sole training resources.", "sent2": "This paper presents an unsupervised learning approach to building a non-English (Arabic) stemmer.", "label": 1}
{"sent1": "As a new countermeasure to this problem, we propose a feedback cleaning method using automatic evaluation of MT quality, which removes incorrect/redundant rules as a way to increase the evaluation score.", "sent2": "BLEU is utilized for the automatic evaluation.", "label": 1}
{"sent1": "FactChecker differs from prior approaches in that it does not rely on iterative peer voting, instead it leverages language to infer believability of fact candidates.", "sent2": "Our results show that each of the presented reordering methods leads to improved translation quality on its own.", "label": 0}
{"sent1": "We conduct a thorough evaluation of the proposed methodology both manually as well as through comparison with WordNet.", "sent2": "Event schemas have important connections to early NLP research on frames and scripts, as well as modern applications like template extraction.", "label": 0}
{"sent1": "To overcome this, we extend standard within sentence joint inference to inference across multiple sentences.", "sent2": "This context can come in several forms, including observations in nonlinguistic semantic domains, as well as the linguistic context in which the new word was presented.", "label": 0}
{"sent1": "This task is especially difficult in microblogs, as there is little additional text to provide disambiguating context; rather, authors rely on an implicit common ground of shared knowledge with their readers.", "sent2": "In this paper, we attempt to capture some of this implicit context by exploiting the social network structure in microblogs.", "label": 1}
{"sent1": "The Smoothed Partial Tree Kernel is applied, i.e.", "sent2": "a convolution kernel that enhances both syntactic and lexical properties of the examples, avoiding the need of a manual feature engineering phase.", "label": 1}
{"sent1": "We propose in this paper a new multi-span architecture, which separately models the short and long context information while it dynamically merges them to perform the language modeling task.", "sent2": "This is done through a novel recurrent Long-Short Range Context (LSRC) network, which explicitly models the local (short) and global (long) context using two separate hidden states that evolve in time.", "label": 1}
{"sent1": "Multiple hypotheses are also shown to be crucial to improved multiple-module reasoning.", "sent2": "Overall, the performance achieved is 85.21% F-score and 44.11% F-score in Task1 and Task2, respectively.", "label": 0}
{"sent1": "In this paper we show that such phenomenon is due to a discrepancy between the full sequence margin and the per-element margin enforced by the locally conditioned training objective of a encoder-decoder model.", "sent2": "We introduce an incremental model for coreference resolution that competed in the CoNLL 2011 shared task (open regular).", "label": 0}
{"sent1": "In this paper, we describe experiments on a modestsized corpus of regulation annotated with a novel variant of logical form, called abstract syntax trees (ASTs).", "sent2": "Logical form encodes the resolution of scope ambiguities.", "label": 1}
{"sent1": "We propose a distortion model that can consider the word at the CP, a word at an NP candidate, and the context of the CP and the NP candidate simultaneously.", "sent2": "Moreover, we propose a further improved model that considers richer context by discriminating label sequences that specify spans from the CP to NP candidates.", "label": 1}
{"sent1": "Dependencies in an input parse tree are revised by selecting, for a given dependent, the best governor from within a small set of candidates.", "sent2": "For a set of essays written by college graduates on a number of general topics, we show that the higher scoring essays tend to have higher percentages of both highly associated and dis-associated pairs, and lower percentages of mildly associated pairs of words.", "label": 0}
{"sent1": "In addition, we show the application of CI to a domain adaptation task for question words, which are largely missing in the Penn Treebank.", "sent2": "In order to find out if and to what degree the presence of VPCs causes problems for statistical machine translation systems, we collected a set of 59 verb pairs, each consisting of a German VPC and a synonymous simplex verb.", "label": 0}
{"sent1": "Furthermore, no commonly used parser provides additional shallow semantic interpretation, such as preposition sense disambiguation and noun compound interpretation.", "sent2": "However, currently available dependency parsers each exhibit at least one of several weaknesses, including high running time, limited accuracy, vague dependency labels, and lack of nonprojectivity support.", "label": 1}
{"sent1": "and ?hard?", "sent2": "First we propose to employ an iteratively trained target grammar parser to perform grammar formalism conversion, eliminating predefined heuristic rules as required in previous methods.", "label": 0}
{"sent1": "In an ablative analysis, we first demonstrate that this context-dependence is crucial to the superior performance of gold tags ?", "sent2": "Our system advances current state-of-the-art improving ROUGE scores by ?7%.", "label": 0}
{"sent1": "We explore several different classifier types on this dataset.", "sent2": "This paper describes the construction of a large, multilingual dataset labeled with gender, and investigates statistical models for determining the gender of uncharacterized Twitter users.", "label": 1}
{"sent1": "Previous work focused on aggregation of sentiment from all users.", "sent2": "Information published in online stock investment message boards, and more recently in stock microblogs, is considered highly valuable by many investors.", "label": 1}
{"sent1": "Our method is algorithmically and conceptually simple, especially with respect to how problem-specific knowledge is incorporated into the model.", "sent2": "Experimental results on the CoNLL 2008 benchmark dataset demonstrate that our model is competitive with other unsupervised approaches in terms of F1 whilst attaining significantly higher cluster purity.", "label": 1}
{"sent1": "The architecture provides perceptual, procedural, and affordance representations for grounding words.", "sent2": "A perceptuallycoupled on-line simulator enables sensorymotor representations that can shift points of view.", "label": 1}
{"sent1": "We then show recent work in ?semantic basis functions?", "sent2": "?", "label": 1}
{"sent1": "between the different disciplines.", "sent2": "Therefore, we use an interactive web-interface which is easily usable by non-experts.", "label": 1}
{"sent1": "Of the NLP techniques that has been treated as ?solved?", "sent2": "To match passage answers to questions accommodating their complex semantic relations, unlike most previous work that utilizes a single deep learning structure, we develop hybrid models that process the text using both convolutional and recurrent neural networks, combining the merits on extracting linguistic information from both structures.", "label": 0}
{"sent1": "Therefore we propose a character-level dependency scheme to represent primary linguistic relationships within a Chinese sentence.", "sent2": "The usefulness of character dependencies are verified through two specialized dependency parsing tasks.", "label": 1}
{"sent1": "One of the approaches that helped recently is the use of latent semantic analysis to capture the semantic fabric of the document and enhance the n-gram model.", "sent2": "However most of the works found in the literature have focused on identifying and understanding temporal expressions in newswire texts.", "label": 0}
{"sent1": "It also embraces Unicode fully and supports various different formats for specifying regular expressions: the Xerox/PARC format, a Perl-like format, and a mathematical format that takes advantage of the ?Mathematical Operators?", "sent2": "Furthermore, the proposed method conducts a probabilistic evaluation of target word reorderings.", "label": 0}
{"sent1": "We evaluate our system on two data sets for two sequence labeling tasks ?", "sent2": "Penn Treebank WSJ corpus for part-of-speech (POS) tagging and CoNLL 2003 corpus for named entity recognition (NER).", "label": 1}
{"sent1": "The standard translation evaluation metrics, including BLEU, NIST, multiple reference word error rate and its position independent counterpart, were optimized to solve the weights of the features in the log-linear model.", "sent2": "The semi-supervised learning plus the gazetteers alleviate the lack of training data.", "label": 0}
{"sent1": "Classification is done by ranking the topic-conditional posterior probabilities of a response.", "sent2": "The RNNLMs associate a broad range of responses with each topic, incorporate sequence information and scale better with additional training data, unlike standard methods.", "label": 1}
{"sent1": "First, we build a classifier that identifies spans of the input text that can be translated into a single compound word in the target language.", "sent2": "Then, for each identified span, we generate a pool of possible compounds which are added to the translation model as ?synthetic?", "label": 1}
{"sent1": "Experimental results show that by using the proposed subset selection scheme we can get significant performance improvement in both Word Error Rate (WER) and Perplexity (PPL) over the models built from the entire web-corpus by using just 10% of the data.", "sent2": "In addition incremental data selection enables us to achieve significant reduction in the vocabulary size as well as number of n-grams in the adapted language model.", "label": 1}
{"sent1": "Verbs are clustered into groups that share semantic elements of meaning as they exhibit similar syntactic behavior.", "sent2": "We present first results using paraphrase as well as textual entailment data to test the language universal constraint posited by Wu?s (1995, 1997) Inversion Transduction Grammar (ITG) hypothesis.", "label": 0}
{"sent1": "Our experimental strategies achieve a mean performance of 98.9% with respect to a predefined evaluation metric.", "sent2": "Our approach also produces a dramatic reduction in strategy size when compared with conventional reinforcement learning techniques (87% in one experiment).", "label": 1}
{"sent1": "The RC passages are often constrained in their lengths and the target answer sentence usually occurs very few times.", "sent2": "In order to generate/extract a specific precise answer, this paper proposes the integration of two types of ?deep?", "label": 1}
{"sent1": "These non-verbal signals have tight temporal and semantic links to spoken content.", "sent2": "In my thesis, I am working on incorporating non-verbal cues into a multimodal model to better predict the structural events to further improve the understanding of human communication.", "label": 1}
{"sent1": "While this framework is known to work well for standard classification, its suitability for fusing rankers has not been studied.", "sent2": "Rather than commit to either view, we adapt a contextsensitive metaclassification framework to this problem to combine the rankings produced by different algorithms as well as different views.", "label": 1}
{"sent1": "Experimental results on MillerCharles?", "sent2": "This paper presents recent work on a  new  method  to  automatically  extract finegrained duration  information for  common  verbs using  a  large  corpus  of  Twitter  tweets.", "label": 0}
{"sent1": "The method queries an information retrieval engine to estimate the degree of association between a word and its sense descriptions.", "sent2": "Experiments on the Senseval test materials yield state-ofthe-art performance.We also show that the estimated sense frequencies correlate reliably with native speakers?", "label": 1}
{"sent1": "Evaluation experiments show that this method performs better than a previous method on the same task.", "sent2": "We also propose and evaluate two more methods, one that uses anticollocations, and one that uses supervised learning.", "label": 1}
{"sent1": "Letter-classes, such as vowels/non-vowels, are integrated to further improve transliteration accuracy.", "sent2": "The framework leverages features in letteralignment and letter n-gram pairs learned from available bilingual dictionaries.", "label": 1}
{"sent1": "The many-to-many alignments result in significant improvements over the traditional one-to-one approach.", "sent2": "of the ensemble into a single model.", "label": 0}
{"sent1": "The revision stage has linear complexity and preserves the efficiency of the base parser.", "sent2": "Our experiments show a statistically significant improvement of 1.33%, 1.58%, and 2.25% for ROUGE-1, ROUGE-2 and ROUGEL scores, respectively, when compared with the performance of the state of the art in automatic summarization with reinforcement learning on the DUC2004 dataset.", "label": 0}
{"sent1": "In this paper a system for categorisation and automatic authoring of news streams in different languages is presented.", "sent2": "Furthermore, we show how to utilize the toolkit to rapidly build a fast and accurate statistical machine translation system.", "label": 0}
{"sent1": "This paper describes our configuration of Reconcile as well as the changes that we had to implement to integrate with the OntoNotes task definition and data formats.", "sent2": "Our entry for the CoNLL closed task is a configuration of Reconcile intended to do well on OntoNotes data.", "label": 1}
{"sent1": "We call these two words a correlated pair.", "sent2": "This report describes a method for obtaining the most highly correlated pairs of a given size.", "label": 1}
{"sent1": "However, the Asian languages required the addition of a small number of new standard analyses to cover constructions and analysis techniques not found in the European languages.", "sent2": "With these additional standards, the ParGram project can now be applied to other typologically distinct languages.", "label": 1}
{"sent1": "the spoken document ranking accuracy was improved by 20% relative over the commonly used baseline of indexing the 1-best output from an automatic speech recognizer.", "sent2": "MIT iCampus data ?", "label": 1}
{"sent1": "For coreference resolution, we propose a link type based pre-cluster pair model.", "sent2": "cognitive representations of entities in the discourse.", "label": 0}
{"sent1": "Instead, we propose a statistic that takes the structural properties of the tagset into account, and we discuss the application of this statistic in an annotation experiment.", "sent2": "We argue that especially for such highly structured annotation schemes the well-known kappa statistic is not an adequate measure of inter-annotator agreement.", "label": 1}
{"sent1": "In addition, we also show that the initial translations that the MT system provides can be quickly improved by an expert by only performing additional Mouse Actions.", "sent2": "Inspired by the observation that pressing backspace is one of the most common user behaviors to modify the errors, we collect 54, 309, 334 error-correction pairs from a realworld data set that contains 2, 277, 786 users via backspace operations.", "label": 0}
{"sent1": "This paper further proposes a method for learning the HTM model.", "sent2": "Experimental results show that HTM outperforms the baselines on topic discovery and document classification in three datasets.", "label": 1}
{"sent1": "In this paper, we consider the application of this idea to collecting semantic relations between words, such as hypernym/hyponym relationships.", "sent2": "Recently, online games have been proposed as a new way of obtaining labeled data; games attract users by being fun to play.", "label": 1}
{"sent1": "We propose and evaluate a method called ?Seed and Grow?", "sent2": "It is able to identify utterances with grammatical errors with an F1-score as high as 0.623, as compared to a baseline F1 of 0.350 on the same data.", "label": 0}
{"sent1": "We demonstrate that concept drift is an important consideration.", "sent2": "We investigate the problems inherent in learning to triage bug reports from time-varying data.", "label": 1}
{"sent1": "Our main findings are: (a) human raters can label monolingual English utterances as T or V fairly well, given sufficient context; (b), a bilingual corpus can be exploited to induce a supervised classifier for T/V without human annotation.", "sent2": "It assigns T/V at sentence level with up to 68% accuracy, relying mainly on lexical features; (c), there is a marked asymmetry between lexical features for formal speech (which are conventionalized and therefore general) and informal speech (which are text-specific).", "label": 1}
{"sent1": "Current representations lack abstraction, focusing too closely on events.", "sent2": "We describe a modified method for the phrase extraction which deals with larger phrases while keeping a reasonable number of phrases.", "label": 0}
{"sent1": "Experimental results show that our proposed LDA-based approach can outperform the corresponding PLSA-based approach.", "sent2": "The effects of different amounts of training data and different numbers of latent topics on the two approaches are studied.", "label": 1}
{"sent1": "In this work, we introduce a model and beamsearch training scheme, based on the work of Daume?", "sent2": "Our sentiment classification model achieves approximately 1% greater accuracy than a state-of-the-art approach based on elementary discourse units.", "label": 0}
{"sent1": "Our model tackles the bottleneck of vanilla encoder-decoders that have to read and memorize the entire input sequence in their fixedlength hidden states before producing any output.", "sent2": "We represent the amount of association in a text using word association profile ?", "label": 0}
{"sent1": "Applying weight pruning on top of knowledge distillation results in a student model that has 13?", "sent2": "This is a necessary substep when associating and representing corresponding lexical concepts in different languages by using bilingual lexical resources.", "label": 0}
{"sent1": "The system is initially designed to process a single sequence but we also demonstrate how to integrate it with an encoder-decoder architecture.", "sent2": "However, in general, we find that MTurk is a valuable resource for gathering cheap and simple annotations for most of the languages that we explored, and these annotations provide useful feedback in building a larger, more accurate lexicon.", "label": 0}
{"sent1": "We construct a new QA dataset with over 5,000 logical form-question pairs, associated with answers from the knowledge base, and show that datasets constructed in this way enable finegrained analyses of QA systems.", "sent2": "Our work is the first to generate questions with explicitly specified characteristics for QA evaluation.", "label": 1}
{"sent1": "The motivation for this problem is an unobtrusive biometric setting in which a user is observed during access to a document, but no specific challenge protocol requiring the user?s time and attention is carried out.", "sent2": "perception on the usefulness of automatic termlists.", "label": 0}
{"sent1": "We combine domain-specific word embeddings with a label propagation framework to induce accurate domain-specific sentiment lexicons using small sets of seed words, achieving state-of-the-art performance competitive with approaches that rely on hand-curated resources.", "sent2": "Second, it progresses from easier to harder sentences, to minimize any hindrance on preposition learning that might be posed by difficult vocabulary.", "label": 0}
{"sent1": "Since it provides more complete and in-depth results, aspect-level sentiment analysis has received much attention these years.", "sent2": "Aspect-level sentiment classification is a finegrained task in sentiment analysis.", "label": 1}
{"sent1": "We propose an original method for acquisition of elementary synonyms based on exploitation of structured terminologies, analysis of syntactic structure of complex (multi-unit) terms and their compositionality.", "sent2": "Unlike previous work, our final model does not require any additional resources at run-time.", "label": 0}
{"sent1": "We find considerable gains in accuracy on the range of standard metrics.", "sent2": "Furthermore, when combined with labeled examples, our method yields significant improvements over state-of-the-art supervised methods, achieving best reported numbers to date on Chinese OntoNotes and German CoNLL-03 datasets.", "label": 0}
{"sent1": "By evaluating the predictive ability of the extracted features, we can also assess their relevance to the target socioeconomic phenomena.", "sent2": "Therefore, our approach can be formulated as a potential NLP tool, particularly suitable to the computational social science community, as it can be used to interpret connections between vast amounts of textual content and measurable societydriven factors.", "label": 1}
{"sent1": "In this work we seek to identify non-geotagged tweets that originate from within the crisis region.", "sent2": "with explicit location information.", "label": 1}
{"sent1": "The densest documents are potentially the most efficient use of time, likely to include the most information.", "sent2": "Existing approaches typically don?t include lexical features, which are not transferable across languages.", "label": 0}
{"sent1": "sprite) higher than types (e.g.", "sent2": "Such method should rank brands (e.g.", "label": 1}
{"sent1": "Each word instance is represented by a feature vector that combines information from the target word and probable substitutes sampled from an n-gram model representing its context.", "sent2": "Modeling ambiguity using an instance based model does not lead to significant gains in overall accuracy in part-of-speech tagging because most words in running text are used in their most frequent class (e.g.", "label": 1}
{"sent1": "We believe the disconnect stems from the way in which the two communities measure the benefits and costs of IE, as well as academia?s perception that rulebased IE is devoid of research challenges.", "sent2": "We surveyed the landscape of IE technologies and identified a major disconnect between industry and academia: while rule-based IE dominates the commercial world, it is widely regarded as dead-end technology by the academia.", "label": 1}
{"sent1": "This robustness led to the third best overall average labeled attachment score in the task, despite using no discriminative methods.", "sent2": "We also demonstrate that the parser is quite fast, and can provide even faster parsing times without much loss of accuracy.", "label": 1}
{"sent1": "We extend the projective parsing algorithm of Eisner (1996) for our case, and train models using the averaged perceptron.", "sent2": "Our model represents dependency trees with factors that include three types of relations between the tokens of a dependency and their children.", "label": 1}
{"sent1": "We present two techniques for training the MST parser: tree-normalized and graphnormalized conditional training.", "sent2": "A wish is ?a desire or hope for something to happen.?", "label": 0}
{"sent1": "Our learned similarity measure outperforms previously proposed automatic methods for sense clustering on the task of predicting human sense merging judgments, yielding an absolute F-score improvement of 4.1% on nouns, 13.6% on verbs, and 4.0% on adjectives.", "sent2": "Our goal is to generate reading lists for students that help them optimally learn technical material.", "label": 0}
{"sent1": "This is done by using topic features constructed using the latent dirichlet alocation (LDA) algorithm on unlabeled data.", "sent2": "The features are incorporated into a modified na?", "label": 1}
{"sent1": "First we investigate the hypothesis that MWEs can be detected by the distinct statistical properties of their component words, regardless of their type, comparing 3 statistical measures: mutual information (MI), ?2 and permutation entropy (PE).", "sent2": "We present a new method for joint entity and relation extraction using a graph we call a ?card-pyramid.?", "label": 0}
{"sent1": "We then explain these initial results by analyzing the different types of distribution difference between natural and artificial implicit data.", "sent2": "This paper presents a machine learning approach to question classification.", "label": 0}
{"sent1": "We define an opinion unit as a quadruple consisting of the opinion holder, the subject being evaluated, the part or the attribute in which the subject is evaluated, and the value of the evaluation that expresses a positive or negative assessment.", "sent2": "The technology of opinion extraction allows users to retrieve and analyze people?s opinions scattered over Web documents.", "label": 1}
{"sent1": "This involved the collection of a small set of task-based dialogues and annotating them with a revised tag set.", "sent2": "The system automatically extracts events from the raw text, formalized as a sequence of temporally ordered predicate-arguments.", "label": 0}
{"sent1": "The technique is the key to the automatic generation of summaries similar to those written by humans.", "sent2": "Our learnt lexicons when used with a discriminative parser such as C&C also significantly improve its performance on unseen words.", "label": 0}
{"sent1": "It is a key technology of Information Extraction and Open-Domain Question Answering.", "sent2": "Named Entity (NE) recognition is a task in which proper nouns and numerical information are extracted from documents and are classified into categories such as person, organization, and date.", "label": 1}
{"sent1": "In addition, a pattern construction method is described through which paraphrasing patterns can be efficiently learned from a paraphrase corpus and human experience.", "sent2": "In this paper, a pattern-based approach to paraphrasing is proposed for which only morphological analysis is required.", "label": 1}
{"sent1": "The method can robustly cope with inversion phenomena and bunsetsus which don?t have the head bunsetsu by relaxing the syntactic dependency constraints.", "sent2": "We learn to rank using judgments collected from expert human tutors, and we show that adding features derived from a rich, multi-layer dialogue act representation improves system performance over baseline lexical and syntactic features to a level in agreement with the judges.", "label": 0}
{"sent1": "We conduct experiments that show that this goal appears to be realizable.", "sent2": "As these systems mature and become more complex, it would be desirable for a system developer if there were an automatic method for creating natural language generation components that can produce quality output efficiently.", "label": 1}
{"sent1": "This paper describes our recent work in this direction for our participation in NEWS2010 transliteration evaluation.", "sent2": "The official results confirm its effectiveness in English-Chinese bidirectional transliteration.", "label": 1}
{"sent1": "We apply unsupervised acquisition methods to construct a gold standard dataset for FG-NERC.", "sent2": "This paper quantifies the difficulty of fine-grained NERC (FG-NERC) when performed at large scale on the people domain.", "label": 1}
{"sent1": "We show that combining the global distributional characteristics along with the local context information improves the NEI performance over statistical baseline systems that employ only local context.", "sent2": "However, by using an SVM ranker to combine the realizer?s model score together with features from multiple parsers, including ones designed to make the ranker more robust to parsing mistakes, we show that significant increases in BLEU scores can be achieved.", "label": 0}
{"sent1": "This enables our mechanism to cope with noisy input in terms of wording, beliefs and argument structure; and reduces its reliance on a particular knowledge representation.", "sent2": "The performance of our system was evaluated by distorting automatically generated arguments, and passing them to the system for interpretation.", "label": 1}
{"sent1": "In particular, we extend the Pageranklike ranking algorithm from previous work to partition event graphs and thereby detect finegrained aspects of the event to be summarized.", "sent2": "In this paper, we propose an event-graph based method using information extraction techniques that is able to create summaries of variable length for different topics.", "label": 1}
{"sent1": "Among these separators we distinguish those which trigger new levels in the parse tree.", "sent2": "When considering dialogues with congruent and incongruent interlocutor interests, dialogue partners are facing the constant challenge of finding a balance between cooperation and competition.", "label": 0}
{"sent1": "We run a base tagger with different random initializations, and select the best tagging using the quality test.", "sent2": "In this paper we approach Label Propagation as solution to a system of linear equations which can be implemented as a scalable parallel algorithm using the map-reduce framework.", "label": 0}
{"sent1": "Type level evaluation casts light on the merits of algorithms, and for some applications is a more natural measure of the algorithm?s quality.", "sent2": "The registers run in a near-unbroken sequence form 1398 to the present day; the early volumes are a UNESCO UK listed cultural artefact.", "label": 0}
{"sent1": "The learner attains an F-score of 86.69% in ideal conditions and 85.05% when word recall is unreliable and stress in the input is reduced.", "sent2": "Our experiments show that our approach outperforms previous approaches utilizing POS correlations and is competitive with recent state-of-the-art approaches on nine different languages.", "label": 0}
{"sent1": "By reformulating the alignment problem as an Integer Linear Program, we can use standard machinery from global optimization theory to compute the solutions.", "sent2": "Furthermore, little degradation in performance is observed when pruning PSPL lattices, resulting in even smaller indexes ?", "label": 0}
{"sent1": "The inherently ambiguous nature of sarcasm sometimes makes it hard even for humans to decide whether an utterance is sarcastic or not.", "sent2": "This paper explores how getting more information about the syntactic, semantic, and discourse context of uses of { (DE) can facilitate producing an appropriate English translation strategy.", "label": 0}
{"sent1": "A second contribution concerns devising a lexicalized phrase reordering mechanism that has complimentary strengths to Chiang?s model.", "sent2": "Binary ITG).", "label": 1}
{"sent1": "Simulation experiments on an English-to-Pashto translation task show that the proposed strategy not only outperforms the random selection baseline, but also traditional active learning techniques based on dissimilarity to existing training data.", "sent2": "We propose to alleviate this problem with a novel, semisupervised, batch-mode active learning strategy that attempts to maximize indomain coverage by selecting sentences, which represent a balance between domain match, translation difficulty, and batch diversity.", "label": 1}
{"sent1": "We present three hierarchical Bayesian models for cross-caption coreference resolution.", "sent2": "Consequently current systems primarily assess fluency and pronunciation.", "label": 0}
{"sent1": "A family of provably fast decoding algorithms can be derived from the basic techniques underlying the framework and we present a few illustrations.", "sent2": "This paper describes MIMUS, a multimodal and multilingual dialogue system for the in?", "label": 0}
{"sent1": "However, these descriptions are independent and do not comprise a condensed text as in hand-crafted encyclopedias.", "sent2": "Our results show that the use of LTAG based tree kernel gives rise to a 17% relative difference in f -score improvement over the use of a linear kernel without LTAG based features.", "label": 0}
{"sent1": "However, such an approach does not work well when there is no distinctive attribute among objects.", "sent2": "To this end, we set out to explore different contextual variations and different similarity measures handling the sparsity in the possible contexts via four different parameter variations.", "label": 0}
{"sent1": "However the 2013 Dialog State Tracking Challenge (DSTC) introduced a common dataset and metrics that allow to evaluate the performance of trackers on a standardized task.", "sent2": "For example, combining an adverb (e.g., ?very?)", "label": 0}
{"sent1": "The method employs two similarities.", "sent2": "One is string similarity based on edit distance.", "label": 1}
{"sent1": "We report experiments conducted on a multilingual corpus to estimate the number of analogies among the sentences that it contains.", "sent2": "While the presence of conventional subjectivity keywords appears significant in the success of this technique, we are able to find the most domain-relevant keywords without sacrificing recall.", "label": 0}
{"sent1": "Since there is no guarantee that chronological ordering of extracted sentences, which is widely used by conventional summarization system, arranges each sentence behind presupposed information of the sentence, we improve chronological ordering by resolving antecedent sentences of arranged sentences.", "sent2": "The feature design process leverages aggregate statistics over the entire social network to balance sparsity and informativeness.", "label": 0}
{"sent1": "The algorithm aims to extract utterances carrying the essential content of dialogues.", "sent2": "We evaluate the system on 20 Switchboard dialogues.", "label": 1}
{"sent1": "We will introduce the new framework by outlining some modeling elements and indicating major differences to the UML.", "sent2": "An extended example will be discussed in more detail.", "label": 1}
{"sent1": "According to our assumption, most of the words with similar context features in each author?s corpus tend not to be synonymous expressions.", "sent2": "is clearly a better choice for cross-instance tuning.", "label": 0}
{"sent1": "The paper outlines major sources of gender imbalances in German texts.", "sent2": "The main contribution of this research is in devising a divide-and-conquer strategy to alleviate the speech recognition errors.", "label": 0}
{"sent1": "Named Entity recognition is an important task for today?s natural language applications, but it still suffers from data sparseness.", "sent2": "Here, we show how to improve rates of correct speech recognition by preprocessing acoustic noise and by modifying the vocabulary according to the task.", "label": 0}
{"sent1": "By relying on automatic parses to extract noun phrases, we can scale up the training data by orders of magnitude.", "sent2": "Information of interest to users is often distributed over a set of documents.", "label": 0}
{"sent1": "For each word that collocates with a near-synonym we use a differential test to learn whether the word forms a less-preferred collocation or an anti-collocation with other near-synonyms in the same cluster.", "sent2": "By combining morphological, phonetic and syllabic segmentations, we demonstrate substantial performance gains.", "label": 0}
{"sent1": "We present empirical results showing the relative contribution of the component knowledge sources and the different learning algorithms.", "sent2": "The learning algorithms evaluated include Support Vector Machines (SVM), Naive Bayes, AdaBoost, and decision tree algorithms.", "label": 1}
{"sent1": "We show how these problems can be handled via intelligent sample selection and error-driven pruning of classification rulesets.", "sent2": "SenseClusters is a freely available system that clusters similar contexts.", "label": 0}
{"sent1": "We apply maximum marginal decoding to the unsupervised analyzer, and show that this yields the best published segmentation accuracy for Arabic, while also making segmentation output more stable.", "sent2": "Our approach gives an 18% relative BLEU gain for Levantine dialectal Arabic.", "label": 1}
{"sent1": "Our model aims to identify highly informative sentences that are aspect-specific in online custom reviews.", "sent2": "The primary advantages of our model are two-fold: first, it performs document-level and sentence-level sentiment polarity classification jointly; second, it is able to find informative sentences that are closely related to some respects in a review, which may be helpful for aspect-level sentiment analysis such as aspect-oriented summarization.", "label": 1}
{"sent1": "The monolingual measure is based on the notion of partition refinements and the bilingual measure is based on structural properties of the graph that represents phrase segments and word alignments.", "sent2": "These two measures are incorporated in a basic adaptation of the Cross-Entropy method for the purpose of extracting an N -best list of bilingual phrase-level segmentations.", "label": 1}
{"sent1": "mentions.", "sent2": "This paper presents a comparative evaluation of several state-of-the-art English parsers based on different frameworks.", "label": 0}
{"sent1": "In order to alleviate the sparsity problem caused by using relatively small datasets, we incorporate in our hierarchical model an informed prior on word distributions.", "sent2": "We use a statistical model over permutations which captures event ordering constraints in a more flexible way than previous approaches.", "label": 1}
{"sent1": "CoMeT obtained the best result (73.1% accuracy) for the 3-way unseen answers in Beetle among all challenge participants.", "sent2": "We sketch the functionality of all sub-systems and evaluate their performance against the official test set of the challenge.", "label": 1}
{"sent1": "But for the unit of super character, we didn?t find a curve that can be fitted well enough by a straight line even if we combine all the n-grams for n = 1, 2, .", "sent2": ".", "label": 1}
{"sent1": "We combine these feature types and we train our classifiers.", "sent2": "The correlation between humanrated scores and features based on manual transcription was 0.43 and the same based on ASR-hypothesis was slightly lower, 0.42.", "label": 0}
{"sent1": "We additionally experiment with adding quality estimation features in addition to the error analysis-based ones.", "sent2": "The essence of distantly supervised relation extraction is that it is an incomplete multi-label classification problem with sparse and noisy features.", "label": 0}
{"sent1": "Thus, it would be possible to build a new clinical healthcare terminology for Basque.", "sent2": "Clinical Terms) terminology content to Basque, a less resourced language.", "label": 1}
{"sent1": "With character \u0007 -gram models, our approach avoids word segmentation.", "sent2": "Experiments show that our max-margin method significantly outperforms the traditional twostep pipeline for synchronous rule extraction by 1.3 BLEU points and is also better than previous max-likelihood estimation method.", "label": 0}
{"sent1": "Evaluations using a large-scale test collection on JapaneseEnglish and different weighting schemes of SMART retrieval system confirmed the effectiveness of the proposed combination of two-stages comparable corpora and linguistics-based pruning on CrossLanguage Information Retrieval.", "sent2": "We propose and explore a two-stages translation model for the acquisition of bilingual terminology from comparable corpora, disambiguation and selection of best translation alternatives on the basis of their morphological knowledge.", "label": 1}
{"sent1": "The first feature is the partial disambiguation function of the Bi-directional Retriever, which can be used for search request translation in cross-language IR.", "sent2": "This framework allows the use of paraphrasing units ranging from words to large sub-sentential fragments for which context information from the sentence can be successfully exploited.", "label": 0}
{"sent1": "Comparable document-side expansion is a relatively more recent development motivated by error-prone transcription and translation processes in spoken document and cross-language retrieval.", "sent2": "Our evaluation and comparisons show that the proposed model outperforms previous state-of-the-art systems.", "label": 0}
{"sent1": "The surprisingly small requirements of the SVD dimension resolve the computation restrictions.", "sent2": "Moreover, on the condition that several relevant sample documents are available, application of low-dimensional LSI to these documents yielded comparable IR performance to local RF but in a different manner.", "label": 1}
{"sent1": "This method is as effective as a conventional information retrieval system, even though it is capable of approximate matching.", "sent2": "It is also as efficient as a conventional system.", "label": 1}
{"sent1": "This is the highest performance seen so far on this dataset.", "sent2": "questions (Mohammad et al., 2008).", "label": 1}
{"sent1": "To understand these debates, a key challenge is inferring the stances of the participants, all of which are interrelated and dependent.", "sent2": "Online debate forums present a valuable opportunity for the understanding and modeling of dialogue.", "label": 1}
{"sent1": "The development of SRL systems for the biomedical area is frustrated by the lack of large-scale domain specific corpora that are annotated with semantic roles.", "sent2": "Word Sense Induction (WSI) aims to automatically induce meanings of a polysemous word from unlabeled corpora.", "label": 0}
{"sent1": "Our approach is simpler and better suited to NLP than other related cascade methods.", "sent2": "The combined resources, containing more than twenty million lexical items, are queried using a recently proposed fast and efficient approximate string matching algorithm that allows us to query large resources without severely impacting system performance.", "label": 0}
{"sent1": "Not only does this allow us to generalize to paths unseen at training time, but also, with a single high-capacity RNN, to predict new relation types not seen when the compositional model was trained (zero-shot learning).", "sent2": "This paper presents an approach that reasons about conjunctions of multi-hop relations non-atomically, composing the implications of a path using a recurrent neural network (RNN) that takes as inputs vector embeddings of the binary relation in the path.", "label": 1}
{"sent1": "NELL uses a coupled semi-supervised bootstrapping approach to learn new facts from text, given an initial ontology and a small number of ?seeds?", "sent2": "for each ontology category.", "label": 1}
{"sent1": "The sequence tagging system outperforms a system that does not utilize any sequence information modeled using a Maximum Entropy classifier.", "sent2": "We achieved a better accuracy for assigning function labels than a predicate-argument structure analyzer by using grammatical functions as dependency label.", "label": 0}
{"sent1": "Specifically, near-perfect performance is achieved in resolving if a patient experienced a condition.", "sent2": "Our results show that our novel Score-based feature approach outperforms the standard Linguistic and Contextual features described in the related literature.", "label": 1}
{"sent1": "We use an optimization framework to estimate parameters for these projections in a way which bounds the true costs.", "sent2": "In our approach, we project a complex model onto multiple simpler models for which exact inference is efficient.", "label": 1}
{"sent1": "A frequency-based term recognition approach is applied for extracting bilingual abbreviations.", "sent2": "We classify parenthetical translations into bilingual abbreviations, transliterations, and translations.", "label": 1}
{"sent1": "We prove bounds on the number of color-coding iterations necessary to guarantee any desired likelihood of finding the correct solution.", "sent2": "Improvements between 0.4 and 0.9 TER reduction are obtained with the n-best list reranking task using the proposed confidence measure.", "label": 0}
{"sent1": "A critical technology is an algorithm to automatically verify the appropriateness of the student?s translation using linguistic analysis.", "sent2": "It incorporates a number of project management functions and sophisticated progress monitoring capabilities.", "label": 0}
{"sent1": "In the second stage, we instantiate specific alternative derivations from this hypergraph, using the LM to drive this search process, recovering from search errors made in the first pass.", "sent2": "The models are trained using the maximum entropy principle.", "label": 0}
{"sent1": "(Smith et al, 2010), seek for extracting parallel sentences from comparable corpora, we present PARADOCS, a system designed to recognize pairs of parallel documents in a (large) bilingual collection of texts.", "sent2": "While several recent works on dealing with large bilingual collections of texts, e.g.", "label": 1}
{"sent1": "We investigate datatext alignment at the document level and at the sentence level, reporting results for several methodological variants as well as baselines.", "sent2": "given a research area as a query, it returns names of experts in this area.", "label": 0}
{"sent1": "Without using any additional labeled data this new approach obtained 38.5% relative improvement in Precision and 86.7% relative improvement in Recall over several state-of-the-art approaches.", "sent2": "In this paper we analyze the types of errors produced by five different baseline approaches, and present a novel supervised rescoring based validation approach to incorporate global evidence from very large bilingual comparable corpora.", "label": 1}
{"sent1": "Submission preserves the integrity of the work, allows asynchronous updates, and facilitates scholarly citation.", "sent2": "In this paper we study the problem of interpreting and verbalizing visual information using abstract scenes created from collections of clip art images.", "label": 0}
{"sent1": "We then compute measures that might cue semantic anomaly, and compare each model?s results for the two classes of ANs.", "sent2": "For each model, we generate composite vectors for a set of AN combinations unattested in the source corpus and which have been deemed either acceptable or semantically deviant.", "label": 1}
{"sent1": "DTs and DDTs are exploited for defining distributed tree kernels (DTKs) and distributional distributed tree kernels (DDTKs).", "sent2": "We compare DTKs and DDTKs in two tasks: approximating tree kernels TK (Collins and Duffy, 2002); performing textual entailment recognition (RTE).", "label": 1}
{"sent1": "Many groups reported features that intuitively should work, yet showed no correlation with the training data.", "sent2": "The proposed method is based on the analysis of feature cooccurrences in unlabeled data.", "label": 0}
{"sent1": "First, we show how adding a specific transition to create either a left or right arc of length one between the first two buffer nodes produces improvements in the accuracy of Nivre?s arc-eager projective parser on a number of datasets from the CoNLL-X shared task.", "sent2": "This model is complemented by a structured vector space representing attribute dimensions of noun meanings.", "label": 0}
{"sent1": "We then cast our task in the framework of supervised learning, where each known language serves as a training example, and predictions are made on unknown languages.", "sent2": "We induce an undirected graphical model that learns phonotactic regularities, thus relating textual patterns to plausible phonemic interpretations across the entire range of languages.", "label": 1}
{"sent1": "The final learned transducer can quickly link any test name into the final phylogeny, thereby locating variants of the test name.", "sent2": "We find that our method can effectively find name variants in a corpus of web strings used to refer to persons inWikipedia, improving over standard untrained distances such as Jaro-Winkler and Levenshtein distance.", "label": 1}
{"sent1": "Our solution harnesses the rich type system provided by knowledge bases in the web of linked data, to constrain our semantic-coherence objective function.", "sent2": "Our method is based on an integer linear program to solve several disambiguation tasks jointly: the segmentation of questions into phrases; the mapping of phrases to semantic entities, classes, and relations; and the construction of SPARQL triple patterns.", "label": 1}
{"sent1": "In order to generate appropriate answers from the review fragments, we develop a multi-criteria optimization approach for answer generation by simultaneously taking into account review salience, coherence, diversity, and parent-child relations among the aspects.", "sent2": "We conduct evaluations on 11 popular products in four domains.", "label": 1}
{"sent1": "The performance of the system is evaluated for the English language in three different domains, travel, tourism and finance and in the travel domain, for Greek.", "sent2": "Semantic patterns are useful for a variety of text understanding tasks, in particular for locating events in text for information extraction.", "label": 0}
{"sent1": "The subtask of aspect term extraction is cast as a sequence labeling problem modeled with Conditional Random Fields that obtains the F-score of 0.683 for Laptops and 0.791 for Restaurants by exploiting both word-based features and context features.", "sent2": "This is a supervised method which requires a small amount of segmented compounds as input.", "label": 0}
{"sent1": "The toolkit is webbased and multi-user, allowing large scale and remotely managed manual annotation projects.", "sent2": "adequacy and fluency, relative ranking of alternative translations), and word alignment.", "label": 1}
{"sent1": "An early, influential work by Cynthia Whissell, the Dictionary of Affect in Language (DAL), allows rating words along three dimensions: pleasantness, activation and imagery.", "sent2": "Given the lack of such tools in Spanish, we decided to replicate Whissell?s work in that language.", "label": 1}
{"sent1": "Of the 135 explicitly marked tweets on this day, we detect 101 (75%) when we remove the hashtag.", "sent2": "We annotate the top of the ranked list of tweets most likely to be sarcastic that do not have the explicit hashtag.", "label": 1}
{"sent1": "In this paper we focus on the detection of deceptive opinion spam, which consists of fictitious opinions that have been deliberately written to sound authentic, in order to deceive the consumers.", "sent2": "Due to the economic importance of these reviews there is a growing trend to incorporate spam on such sites, and, as a consequence, to develop methods for opinion spam detection.", "label": 1}
{"sent1": "Additionally, we propose a ring-based strategy, in which the chaining process is iterated several times, with the goal of further improving the performance of our method.", "sent2": "Local classifiers are trained for each part of the documents and their outputs are combined by a chain strategy: predictions of a local classifier are used as extra inputs for the next local classifier.", "label": 1}
{"sent1": "We adopted a random graph walk approach to extend the Arabic SSA lexicon using ArabicEnglish phrase tables, leading to improvements for SSA on Arabic microblogs.", "sent2": "However, currently available dependency parsers each exhibit at least one of several weaknesses, including high running time, limited accuracy, vague dependency labels, and lack of nonprojectivity support.", "label": 0}
{"sent1": "Moreover, in addition to our newly created social media dataset, we also report results on other widely popular domains, such as movie and product reviews.", "sent2": "We believe that this article will not only extend the current sentiment analysis research to another family of languages, but will also encourage competition which potentially leads to the production of high-end commercial solutions.", "label": 1}
{"sent1": "In this paper we address the problems of: identifying Arabizi in text and converting it to Arabic characters.", "sent2": "Cooccurrence features are a simple way to mimic Topic Signatures (Mart?", "label": 0}
{"sent1": "In this paper, we present a new approach for exploiting knowledge obtained from nearby entities by making use of timegraphs and applying the stacked learning method to the temporal relation classification task.", "sent2": "Entities that have temporal connections to the pair of temporal entities under inspection are not considered even though they provide valuable clues to the prediction.", "label": 1}
{"sent1": "?ve Bayes classifier.", "sent2": "Wikipedia articles on 30 languages.", "label": 0}
{"sent1": "We describe two template-based description generation models that operate over visual dependency representations.", "sent2": "Previous work demonstrated that non-professional annotation through Amazon?s Mechanical Turk can match professional quality.", "label": 0}
{"sent1": "To accomplish this, the model introduces Viterbi parsing under two-dimensional stochastic CFGs.", "sent2": "In reality, test data may be diverse, relating to the training data in some ways but not others.", "label": 0}
{"sent1": "Even with minimal cleaning and filtering, the resulting data boosts translation performance across the board for five different language pairs in the news domain, and on open domain test sets we see improvements of up to 5 BLEU.", "sent2": "In preprocessing, we calculate the possible readings each kanji character can take and different types of phonological and conjugational changes that can occur, and associate a probability with each.", "label": 0}
{"sent1": "One possible reason could be the use of inappropriate set of meanings.", "sent2": "These components and the way they are integrated are different in the two systems: they exploit corpus-based and linguistic resources, and supervised and unsupervised learning methods.", "label": 0}
{"sent1": "Our quantitative evaluation shows that our approach which combines the advantages of graphical modeling and sparsity modeling techniques significantly outperforms various standard and stateof-the-art text classification algorithms.", "sent2": "We compare the results of machine learning experiments using different feature sets to predict the annotated emotions.", "label": 0}
{"sent1": "For ecommerce companies, it is very important to make rapid and correct response to these hot trends in order to improve product sales.", "sent2": "might lead to a significant increase of the sales of related products, e.g., mouth mask.", "label": 1}
{"sent1": "These gold standards measure the maximum keystroke savings under two different approximations of an ideal language model.", "sent2": "The gold standards additionally narrow the scope of deficiencies in a word prediction system.", "label": 1}
{"sent1": "Experiments on Chinese data sets with the technique show it can be effective.", "sent2": "Finally, in order to encode this in an LFG grammar, we propose linking nouns with templates that describe preferable combinations with light verbs.", "label": 0}
{"sent1": "By removing the intermediate word segmentation, the unified parser no longer needs separate notions for words and phrases.", "sent2": "Normalization and paraphrase detection tasks are built on top of a robust analyzer for English and are exclusively achieved using symbolic methods.", "label": 0}
{"sent1": "We study how to correlate multiple types of activities to derive a global bursty pattern.", "sent2": "This output forms the basis of a parallel treebank covering a diverse set of phenomena.", "label": 0}
{"sent1": "We propose an algorithm for mining simple humorous scripts from a semantic network (ConceptNet) by specifically searching for dual scripts that jointly maximize overlap and incongruity metrics in line with Raskin?s Semantic-Script Theory of Humor.", "sent2": "This criterion is shown to be related to the entropy of a random variable associated with the tree structures, and it is demonstrated that it selects linguistically plausible constituents.", "label": 0}
{"sent1": "One common approach for geolocating texts is rooted in information retrieval.", "sent2": "We conclude with a general discussion on comparability and evaluation of short answer assessment systems.", "label": 0}
{"sent1": "In this model, we treat query spelling correction as a multiclass classification problem with structured input and output.", "sent2": "Deceivers may dynamically adjust their deceptive statements according to the reactions of victims.", "label": 0}
{"sent1": "The formalism that has received most attention has been inversion transduction grammars (ITGs) (Wu, 1997).", "sent2": "Empirical lower bounds studies in which the frequency of alignment configurations that cannot be induced by a particular formalism is estimated, have been important for the development of syntax-based machine translation formalisms.", "label": 1}
{"sent1": "While the domain-oriented semantic structures are direct targets of Text Mining (TM), their extraction from text is not straghtforward due to the diversity of linguistic expressions.", "sent2": "This paper compares domain-oriented and linguistically-oriented semantics, based on the GENIA event corpus and FrameNet.", "label": 1}
{"sent1": "Yet, it is rarely evaluated in a direct manner.", "sent2": "When evaluated against WMT?2012 rankings, the systemlevel agreement is rather high for several language pairs.", "label": 0}
{"sent1": "We model the acousticprosodic stream with two different models, one a maximum entropy model and the other a traditional HMM.", "sent2": "Experiments with an incremental statistical parser show that performance is severely degraded when the search for the most probable parse is pruned to only the most probable analysis after each prefix.", "label": 0}
{"sent1": "Finally, the Unibuc team ranked third in the closed NLI Shared Task.", "sent2": "We detail our approach, outline our implementation and provide an evaluation of the method for the language pair English/Brazilian-Portuguese.", "label": 0}
{"sent1": "We introduce a semi-supervised manifold ranking algorithm for this task, which relies on a small set of labeled individual reviews for training.", "sent2": "And whereas past work has focused on identifying individual fake reviews, this paper aims to identify offerings (e.g., hotels) that contain fake reviews.", "label": 1}
{"sent1": "The system includes a new similarity measure keeping up both the accuracy of rating predictions and coverage.", "sent2": "We gather features from substring pairs consistent with a character-based alignment of the two strings.", "label": 0}
{"sent1": "and present methods for efficiently integrating them during search.", "sent2": "Since standard regularizers such as `2 are inapplicable to MERT due to the scale invariance of its objective function, we turn to two regularizers?`0 and a modification of `2?", "label": 1}
{"sent1": "Recently, the distributional approach has been extended to models that record the cooccurrence of words with visual features in image collections.", "sent2": "These image-based models should be complementary to text-based ones, providing a more cognitively plausible view of meaning grounded in visual perception.", "label": 1}
{"sent1": "In this paper, we examine a new feature, accent ratio, which captures how likely it is that a word will be realized as prominent or not.", "sent2": "The immense prosodic variation of natural conversational speech makes it challenging to predict which words are prosodically prominent in this genre.", "label": 1}
{"sent1": "Nonetheless, our final system1 outperforms the Stanford system (Lee et al.", "sent2": "These features are successful on syntax and discourse; however, they do not model semantic compatibility well, nor do we see gains from experiments with shallow semantic features from the literature, suggesting that this approach to semantics is an ?uphill battle.?", "label": 1}
{"sent1": "The approach is simple and modular, in that it will work with any language representation whose training can be formulated as optimizing a probability model.", "sent2": "We evaluate the system using a data set of labeled discussions and show that it achieves good results.", "label": 0}
{"sent1": "We conduct a linguistic analysis on how the distinct categories of it are usually mapped to their Czech counterparts.", "sent2": "Our system improves the baseline performance by as much as 25%.", "label": 0}
{"sent1": "A method called snapshot learning is also proposed to facilitate learning from supervised sequential signals by applying a companion cross-entropy objective function to the conditioning vector.", "sent2": "In this work we study various model architectures and different ways to represent and aggregate the source information in an endto-end neural dialogue system framework.", "label": 1}
{"sent1": "We find that the model strongly learns to identify hypernyms using Hearst patterns, which are well known to be predictive of lexical relations.", "sent2": "or ?long, startup?", "label": 0}
{"sent1": "SimVerb-3500 covers all normed verb types from the USF free-association database, providing at least three examples for every VerbNet class.", "sent2": "In addition, we introduce the idea about transductive, document-level segmentation, which is designed to improve the system recall for out-ofvocabulary (OOV) words which appear more than once inside a document.", "label": 0}
{"sent1": "This paper presents a new method for building such a resource and the resource itself, called POLY.", "sent2": "Language resources that systematically organize paraphrases for binary relations are of great value for various NLP tasks and have recently been advanced in projects like PATTY, WiseNet and DEFIE.", "label": 1}
{"sent1": "In this paper, we present a model that learns to jointly align constituents of two sentences and also predict their similarities.", "sent2": "We address the challenge of evaluating the emergent model with a qualitative visualization and an intrinsic conversation ordering task.", "label": 0}
{"sent1": "However, these supervised methods do not work well when we deal with a new different domain without enough annotated corpus.", "sent2": "Currently most of state-of-the-art methods for Chinese word segmentation (CWS) are based on supervised learning, which depend on large scale annotated corpus.", "label": 1}
{"sent1": "In this paper, we treat POS tagging as a single-token independent multiclass classification task.", "sent2": "We show that the intelligent use of one small piece of contextual information?a document?s publication date?can improve the performance of classifiers trained on a text categorization task.", "label": 0}
{"sent1": "Our method can identify more suitable word order than conventional word reordering methods by concurrently performing dependency parsing and word reordering instead of sequentially performing the two processing steps.", "sent2": "The challenge of our work lies in scaling semantic parsers to the lexical diversity of opendomain databases.", "label": 0}
{"sent1": "In addition, an evaluation experiment was carried out using the peer outputs for the TUNAREG task.", "sent2": "The first factor is the temporal history of preceding utterances that grants higher importance to recent utterances than old ones, and the second is topic relevance that forces only the preceding utterances relevant to the current utterance to be considered in keyword extraction.", "label": 0}
{"sent1": "We build a linear regression model which, given the keyword and the sentence, predicts the creativity score.", "sent2": "MedTag combines three corpora, MedPost, ABGene and GENETAG, within a common relational database data model.", "label": 0}
{"sent1": "Analysis shows that story boundaries cannot be clearly discriminated from utterance boundaries by speaker-normalized pitch reset due to its large variations across different syllable tone pairs.", "sent2": "This paper investigates the combined use of pause duration and pitch reset for automatic story segmentation in Mandarin broadcast news.", "label": 1}
{"sent1": "In addition, we show that structural features are superior to lexical features and our summarizer performs surprisingly well at the average F-measure of 0.3914 by using only acoustic features.", "sent2": "We demonstrate the applicability of our model on three diverse tasks: a new color description task, a new financial news task and an established direction-following task.", "label": 0}
{"sent1": "We show specifically how to enhance a shift-reduce dependency parser with alignment features to resolve shift-reduce conflicts.", "sent2": "Here we propose a much simpler alternative, bilingually-constrained monolingual parsing, where a source-language parser learns to exploit reorderings as additional observation, but not bothering to build the target-side tree as well.", "label": 1}
{"sent1": "The previous authors?", "sent2": "We suggest improvements to a previously proposed framework for integrating Conditional Random Fields and Hidden Markov Models, dubbed a Crandem system (2009).", "label": 1}
{"sent1": "Most semi-supervised learning algorithms also perform full inference on at least one instance before each parameter update.", "sent2": "Most importantly, we report on an unpublished study of annotator agreement for grammatical error correction.", "label": 0}
{"sent1": "Accordingly, they implicitly assume that children know how to undo phonetic variation when they learn to extract words from speech.", "sent2": "Arabic Dialects present many challenges for machine translation, not least of which is the lack of data resources.", "label": 0}
{"sent1": "We then examine the outcome of repeated transmission of languages using a mathematical analysis, a computer simulation, and an experiment with human participants, and show several ways in which greater learnability may not result in a property becoming prevalent.", "sent2": "Lexical similarity and shallow-semantics are used as indicators of adequacy between machine and reference translations.", "label": 0}
{"sent1": "In this paper, we discuss previous work identifying language errors associated with atypical language in ASD and describe a procedure for reproducing those results.", "sent2": "We describe our data set, which consists of transcribed data from a widely used clinical diagnostic instrument (the ADOS) for children with autism, children with developmental language disorder, and typically developing children.", "label": 1}
{"sent1": "We focus especially on abstract concepts and emotions to show that even though they cannot be physically visualized, they too tend to have strong colour associations.", "sent2": "Finally, we show how word?colour associations manifest themselves in language, and quantify usefulness of co-occurrence and polarity cues in automatically detecting colour associations.1", "label": 1}
{"sent1": "to anyone they want, at any time, in any location, about any topic.", "sent2": "Submission preserves the integrity of the work, allows asynchronous updates, and facilitates scholarly citation.", "label": 0}
{"sent1": "In this paper, we investigate the writing conventions that different groups of users use to express themselves in microtexts.", "sent2": "Microtexts, like SMS messages, Twitter posts, and Facebook status updates, are a popular medium for real-time communication.", "label": 1}
{"sent1": "This system maintains a supervised machine learning approach to classify the tweet overall sentiment, but with a change in the used features and the algorithm.", "sent2": "Based on the dependency language model, we represent a set of features for the parsing model.", "label": 0}
{"sent1": "Moreover, investigating these deviations provides new insights and a deeper understanding of the examined techniques.", "sent2": "We identify five aspects that can influence the outcomes of experiments that are typically not addressed in research papers.", "label": 1}
{"sent1": "selection.", "sent2": "Many implementations of Latent Dirichlet Allocation (LDA), including those described in Blei et al (2003), rely at some point on the removal of stopwords, words which are assumed to contribute little to the meaning of the text.", "label": 0}
{"sent1": "To the best of our knowledge, this is the first work that uses both intra- and inter-sentential causal relations for why-QA.", "sent2": "In this paper, we explore ways of reducing this high resource requirement by leveraging the available parallel data between subsets of the n languages, transitively.", "label": 0}
{"sent1": "We employ integer linear optimization for conducting phrase selection and merging simultaneously in order to achieve the global optimal solution for a summary.", "sent2": "Experimental results on the benchmark data set TAC 2011 show that our framework outperforms the state-ofthe-art models under automated pyramid evaluation metric, and achieves reasonably well results on manual linguistic quality evaluation.", "label": 1}
{"sent1": "Date selection has up to now been handled via supervised machine learning approaches that estimate the importance of each date separately, using features such as the frequency of date mentions in news corpora.", "sent2": "0.7% higher than using gold tags.", "label": 0}
{"sent1": "We trained a variety of unsupervised language models on the original BNC, and tested them to see the extent to which they could predict mean speakers?", "sent2": "This set was annotated for acceptability judgements through crowd sourcing.", "label": 1}
{"sent1": "Given two bilingual lexicons between language pairs L f ?L p and L p ?L e , we assume these lexicons as parallel corpora.", "sent2": "Then, we merge the extracted two phrase tables into one phrase table between L f and L e .", "label": 1}
{"sent1": "In particular, we find that lasting friendships exhibit a form of balance that manifests itself through language.", "sent2": "Both manual and automatic evaluations were performed using a dataset made of clusters of newswire sentences.", "label": 0}
{"sent1": "In addition, we present a supervised approach for predicting the subject of a disease/symptom.", "sent2": "The results of our experiments demonstrate the impact of subject identification on the effective detection of an episode of a disease/symptom.", "label": 1}
{"sent1": "Moreover, our model performs better than syntactic models on datasets with high syntactic variance.", "sent2": "While our model is syntactically-ignorant, we show significant improvements over previous bag-of-words models by deepening our network and applying a novel variant of dropout.", "label": 1}
{"sent1": "To overcome the limitations, this paper presents SOLAR ?", "sent2": "However, names and loan words typically originate from various languages, obey different transliteration rules, and therefore may benefit from being modeled independently.", "label": 0}
{"sent1": "We evaluate whether we can combine comments to form larger documents to improve the quality of clusters.", "sent2": "This task is potentially beneficial for a number of NLP applications, such as information extraction, question answering or text summarization.", "label": 0}
{"sent1": "We annotated a corpus of Twitter data streamed across two Arab countries, extracted linguistic features and trained a classifier achieving an average Arabizi identification accuracy of 94.5%.", "sent2": "We address the challenge of identifying Arabizi from multi-lingual data in Twitter, a preliminary step for analysing sentiment from Arabizi data.", "label": 1}
{"sent1": "Its aim is to make further processing of long sentences more tractable.", "sent2": "Based on these devices, this paper further discusses possible extensions to the ISO standard lexical markup framework (LMF).", "label": 0}
{"sent1": "Such text comprise of advice, recommendations and tips on a variety of points of interest.", "sent2": "The granularity of word senses in current general purpose sense inventories is often too fine-grained, with narrow sense distinctions that are irrelevant for many NLP applications.", "label": 0}
{"sent1": "Both rely on a notion of preferred attributes that can be learned from human descriptions.", "sent2": "We compare two REG algorithms in terms of their performance: the classic Incremental Algorithm and the more recent Graph algorithm.", "label": 1}
{"sent1": "However, recent experiments with CoNLL 2009 corpora show that these popular resources, which serve well for other applications, may not do so for generation.", "sent2": "The attempts to adapt them for generation resulted so far in a better performance of the realizers, but not yet in a genuinely semantic generationoriented annotation schema.", "label": 1}
{"sent1": "Whilst personality perception of our dialogues is consistent with perceptions of human behaviour, we find that the introduction of alignment leads to negative perceptions of the dialogues and the interlocutors?", "sent2": "The constraining grammar typically allows ambiguity and is itself poorly suited for an incremental parsing model, since it gives rise to a high degree of nondeterminism in parsing.", "label": 0}
{"sent1": "We derive an efficient algorithm for learning the factorization, analyze its complexity, and provide proof of convergence.", "sent2": "This framework is evaluated in terms of automatic translation evaluation metrics, and an improvement of translation quality is observed.", "label": 0}
{"sent1": "Second, we construct the following hidden layers using convolutional restricted Boltzmann machines (CRBM), which can abstract the information of reviews effectively.", "sent2": "First, we construct the previous several hidden layers using restricted Boltzmann machines (RBM), which can reduce the dimension and abstract the information of the reviews quickly.", "label": 1}
{"sent1": "The baseline model is a CRF classification model with plural latent variables, dynamically constructed from the dependency parsed tree.", "sent2": "Training a probabilistic model with a number of latent variables is found unstable in some cases; thus this paper presents how to construct a stable model for opinion classification by constraining classification transitions.", "label": 1}
{"sent1": "A major problem of current research is that this task focuses on customer reviews, which are natural or spontaneous, thus posing a challenge to syntactic parsers.", "sent2": "Target-polarity word (T-P) collocation extraction, a basic sentiment analysis task, relies primarily on syntactic features to identify the relationships between targets and polarity words.", "label": 1}
{"sent1": "The improvements are stable across parameters such as number of clusters, minimum frequency and granularity.", "sent2": "We evaluate our training method with Noun Phrase Chunking, Text Chunking and Extended Named Entity Recognition.", "label": 0}
{"sent1": "We model anomaly detection as a binary classification problem and show that the model learns useful features to classify anomaly.", "sent2": "The software we have  developed based on this platform has been  shown to handle large data sets.", "label": 0}
{"sent1": "In this paper, we focus on email formality and explore the factors that could affect the sender?s choice of formality.", "sent2": "Email is an important way of communication in our daily life and it has become the subject of various NLP and social studies.", "label": 1}
{"sent1": "In Basque, NV expressions are considered those combinations in which a noun, inflected or not, is co-occurring with a verb, as erabakia hartu (?to make a decision?", "sent2": "Taking as a starting-point the development on cooccurrence techniques for several languages, we focus on the aspects that should be considered in a NV extraction task for Basque.", "label": 1}
{"sent1": "We also introduce several associated operators, written to be as generic as  possible.", "sent2": "We have employed an HMM statistical framework for both speech recognition and synthesis which provides transformation mechanisms to adapt the synthesized voice in TTS (text-to-speech) using the recognized voice in ASR (automatic speech recognition).", "label": 0}
{"sent1": "In this study, we also construct a balanced benchmark dataset with 2,162 sentences from BNC for English LVCs.", "sent2": "And this data set is publicly available and is also a useful computational resource for research on MWEs in general.", "label": 1}
{"sent1": "We showed that our tagger reaches state-of-the-art results for French in the standard evaluation conditions (i.e.", "sent2": "It was implemented in a finite-state framework composed of a preliminary finite-state lexical analysis and a CRF decoding using weighted finitestate transducer composition.", "label": 1}
{"sent1": "We found that the agreement between the taggers ranged from 34% to 58%, depending on the class and that more than 40% of the globally ambiguous entities co-occur within the same document.", "sent2": "Until recently, few information extraction approaches were capable of resolving the level of detail in text required to support the annotation of such pathway representations.", "label": 0}
{"sent1": "These CPs are classified into idiomatic and less idiomatic.", "sent2": "Our system ranked second in the English closed task.", "label": 0}
{"sent1": "In this study, we use an alternative technique to overcome these limitations.", "sent2": "In this paper we show that the framework can be achieved by using our aligned parallel treebank corpus.", "label": 0}
{"sent1": "The aim of this paper is to apply techniques for the automatic extraction of MWEs from corpora to index them as a single unit.", "sent2": "Intuitively, with the appropriate treatment of MWEs, the results of an Information Retrieval (IR) system could be improved.", "label": 1}
{"sent1": "The distinction was possible by obtaining several metrics of the networks, including the in-degree, out-degree, shortest paths, clustering coefficient, betweenness and global efficiency.", "sent2": "We show that other characteristics such as domain, instance granularity, feature space, instance selection strategy and proportion of relevant text, have a significant effect on benefit from feature feedback.", "label": 0}
{"sent1": "We exploit the fact that the semantic relation, which is underspecified in most cases, is partially made explicit by the preposition.", "sent2": "We develop an annotation framework around five different semantic relations, which we use to create a corpus of 1700 Italian CNs, obtaining an inter-annotator agreement of K=.695.", "label": 1}
{"sent1": "we refer to beliefs, states of knowledge, points of view, and suppositions, all of which may change over time.", "sent2": "In this paper, we propose an approach for automatically extracting and understanding multiple mental states in stories.", "label": 1}
{"sent1": "The model is a class of synchronous-CFG with a Greibach Normal Form-like structure for the projected production rule: The paired target-side of a production rule takes a phrase prefixed form.", "sent2": "The decoder for the targetnormalized form is based on an Earlystyle top down parser on the source side.", "label": 1}
{"sent1": "Previous algorithms for taxonomy induction have typically focused on independent classifiers for discovering new single relationships based on hand-constructed or automatically discovered textual patterns.", "sent2": "By contrast, our algorithm flexibly incorporates evidence from multiple classifiers over heterogenous relationships to optimize the entire structure of the taxonomy, using knowledge of a word?s coordinate terms to help in determining its hypernyms, and vice versa.", "label": 1}
{"sent1": "However, many languages lack such resources.", "sent2": "Current approaches often employ machine learning techniques and require supervised data.", "label": 1}
{"sent1": "Finally, a short extractive summary is generated for each abstract to populate the clusters.", "sent2": "Word alignment is an important preprocessing step for machine translation.", "label": 0}
{"sent1": "Experiments using WordNet as a gold standard show promising results.", "sent2": "Maximum entropy (Maxent) is useful in many areas.", "label": 0}
{"sent1": "The system automatically extracts events from the raw text, formalized as a sequence of temporally ordered predicate-arguments.", "sent2": "We focus on the story rewriting task, in which an exemplar story is read to the students and the students rewrite the story in their own words.", "label": 1}
{"sent1": "Our discriminative parsing method has no generative component, yet surpasses a generative baseline on constituent parsing, and does so with minimal linguistic cleverness.", "sent2": "The present work advances the accuracy and training speed of discriminative parsing.", "label": 1}
{"sent1": "Unfortunately, we made a mistake when we generate the final output that results in a lower score of 56.31% in term of Labeled Attachment Score (LAS), reported by organizers.", "sent2": "We propose a principled framework of embedding entities that integrates hierarchical information from large-scale knowledge bases.", "label": 0}
{"sent1": "We estimate the maximum benefit feature feedback may provide; our estimate does not depend on how the feedback is solicited and incorporated into the model.", "sent2": "We extend the complexity measures proposed in the literature and propose some new ones to categorize learning problems, and find that they are strong indicators of the benefit from feature feedback.", "label": 1}
{"sent1": "However, it has not been addressed using statistical approaches to dialogue management, which have always been trained for co-operative dialogue.", "sent2": "Though much research has been conducted on Subjectivity and Sentiment Analysis (SSA) during the last decade, little work has focused on Arabic.", "label": 0}
{"sent1": "Our results show that language model based pre-sorting yields a small improvement in translation quality and a speedup by a factor of 2.", "sent2": "A lot of effort has been devoted to aspect detection and sentiment analysis under the assumption that every review has the same utility for related tasks.", "label": 0}
{"sent1": "The resulting sentences can be used as candidate paraphrases of the source sentence.", "sent2": "The resulting system identifies opinion sources with 79.3% precision and 59.5% recall using a head noun matching measure, and 81.2% precision and 60.6% recall using an overlap measure.", "label": 0}
{"sent1": "Our sampling-based approach naturally extends to joint prediction scenarios, such as joint parsing and POS correction.", "sent2": "Findings include the following.", "label": 0}
{"sent1": "In this work, we reintroduce sparsity to GPU parsing by adapting a coarse-to-fine pruning approach to the constraints of a GPU.", "sent2": "The resulting system is capable of computing over 404 Viterbi parses per second?more than a 2x speedup?on the same hardware.", "label": 1}
{"sent1": "A challenge arises from the fact that the oracle needs to keep track of exponentially many goldstandard derivations, which is solved by integrating a packed parse forest with the beam-search decoder.", "sent2": "Standard CCGBank tests show the model achieves up to 1.05 labeled F-score improvements over three existing, competitive CCG parsing models.", "label": 1}
{"sent1": "On the SPMRL 2013 multilingual constituency parsing shared task (Seddah et al., 2013), our system outperforms the top single parser system of Bj?orkelund et al.", "sent2": "Large-scale web-search engines are generally designed for linear text.", "label": 0}
{"sent1": "This paper presents a method to reduce this demand using active learning, which selects what samples to annotate, instead of annotating blindly the whole training corpus.", "sent2": "Acquisition of such a corpus is costly and time-consuming.", "label": 1}
{"sent1": "Expanding training data beyond the traditional miniature datasets pushes performance numbers well above those previously reported.", "sent2": "We have not yet succeeded, however, in combining the benefits of both prosody and the HBM.", "label": 0}
{"sent1": "One of the main challenges is how to assign appropriate weights to expanded terms.", "sent2": "In this paper, we re-examine this problem using recently proposed axiomatic approaches and find that, with appropriate term weighting strategy, we are able to exploit the information from lexical resources to significantly improve the retrieval performance.", "label": 1}
{"sent1": "Another line of work has produced handcrafted rule-based systems to control specific stylistic dimensions, such as politeness and personality.", "sent2": "We applied the  system to an English database on estuaries.", "label": 0}
{"sent1": "A basic approach is template matching on parse trees.", "sent2": "We first split a dataset consisting of pairs of sentences into clusters according to their similarities, and then construct a classifier for each cluster to identify equivalence relations.", "label": 0}
{"sent1": "for chart realization in OpenCCG, an open-source NLP toolkit for CCG.", "sent2": "We call this approach hypertagging, as it operates at a level ?above?", "label": 1}
{"sent1": "In this paper we explore the use of transductive semi-supervised methods for the effective use of monolingual data from the source language in order to improve translation quality.", "sent2": "including conversations, it will be important to provide users with the ability to seek informational content, rather than socially motivated small talk that appears in many conversational sources.", "label": 0}
{"sent1": "In this paper we present Babelfy, a unified graph-based approach to EL and WSD based on a loose identification of candidate meanings coupled with a densest subgraph heuristic which selects high-coherence semantic interpretations.", "sent2": "Most recent efforts along this line are not scalable (training on the small dev set with features from top ?100 most frequent words) and overly complicated.", "label": 0}
{"sent1": "The narratives were analyzed for differences in filled pauses used by attending (experienced) and resident (in-training) physicians and by male and female physicians.", "sent2": "We find that models using part-of-speech tags, context-free grammar production rules and function words are highly effective, achieving a maximum accuracy of 71% .", "label": 0}
{"sent1": "An important problem in this context is cross-document coreference resolution (CCR): computing equivalence classes of textual mentions denoting the same entity, within and across documents.", "sent2": "Identifying and linking named entities across information sources is the basis of knowledge acquisition and at the heart of Web search, recommendations, and analytics.", "label": 1}
{"sent1": "The algorithm tractably captures a majority of the structural constraints examined by prior work in this area, which has resorted to either approximate methods or off-theshelf integer linear programming solvers.", "sent2": "In addition, it allows training a globally-normalized log-linear model with respect to constrained conditional likelihood.", "label": 1}
{"sent1": "Topics are informed by the entire document, while senses are informed by the local context surrounding the ambiguous word.", "sent2": "We also discuss unsupervised ways of enriching the original corpus in order to improve model performance, including using neural word embeddings and external corpora to expand the context of each data instance.", "label": 1}
{"sent1": "In terms of end-to-end translation, with decoding on the CPU, we increase throughput by roughly two thirds on a standard MT evaluation dataset.", "sent2": "?cause?", "label": 0}
{"sent1": "This paper presents several methods for information retrieval, focusing on care episode retrieval, based on textual similarity, where similarity is measured through domain-specific modelling of the distributional semantics of words.", "sent2": "This paper describes the Aalto submission for the German-to-English and the Czechto-English translation tasks of the ACL 2010 Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR.", "label": 0}
{"sent1": "Our hypothesis that such readability features can successfully distinguish between spoken language targeting different age groups is fully confirmed.", "sent2": "The learning algorithm uses varied supervision, including either full equations or just the final answers.", "label": 0}
{"sent1": "The empirical results reported in this paper provide a basis for future opinion analysis systems that have to compute the sentiment orientation at the sentence or at the clause level.", "sent2": "We show that each type has a specific effect on the opinion expression in its scope: both on the polarity and the strength for negation, and on the strength and/or the degree of certainty for modality.", "label": 1}
{"sent1": "It aims to identify the linguistic phenomena involved in the manual simplification of French texts and organise them within a typology.", "sent2": "ReNoun?s approach is based on leveraging a large ontology of noun attributes mined from a text corpus and from user queries.", "label": 0}
{"sent1": "Mikolov et al.", "sent2": "Continuous space word representations extracted from neural network language models have been used effectively for natural language processing, but until recently it was not clear whether the spatial relationships of such representations were interpretable.", "label": 1}
{"sent1": "It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality.", "sent2": "Recent word-embedding models based on distributional semantics hypothesis are known to be weak for modeling lexical contrast.", "label": 0}
{"sent1": "By leveraging linguisticallyinformed features within conditional random fields (CRFs) trained to minimize empirical risk, our best models in Spanish significantly outperform a strong baseline, and reach around 90% accuracy on the combined task of named entity recognition and sentiment prediction.", "sent2": "We compare performance in both Spanish and English on microblog data, using only a sentiment lexicon as an external resource.", "label": 1}
{"sent1": "In this paper, we present a novel unsupervised learning approach to query segmentation based on principal eigenspace similarity of queryword-frequency matrix derived from web statistics.", "sent2": "Experimental results show that our approach could achieve superior performance of 35.8% and 17.7% in Fmeasure over the two baselines respectively, i.e.", "label": 1}
{"sent1": "Multi-level hierarchies are helpful in both approaches, but are more effective in the coarseto-fine case because of accumulated slack in A?", "sent2": "heuristics.", "label": 1}
{"sent1": "Specifically we explore the combination of citation information and summarization techniques.", "sent2": "Even though prior work (Teufel et al., 2006) argues that citation text is unsuitable for summarization, we show that in the framework of multi-document survey creation, citation texts can play a crucial role.", "label": 1}
{"sent1": "In the TFIDF (term frequency, inverse document frequency) weighting framework, we incorporated partof-speech (POS) information, word clustering, and sentence salience score.", "sent2": "We also evaluated a graph-based approach that measures the importance of a word based on its connection with other sentences or words.", "label": 1}
{"sent1": "We describe a system for detecting elements of interactional style: whether a speaker is awkward, friendly, or flirtatious.", "sent2": "Nilsson and Nivre (2009) introduced a treebased model of persons?", "label": 0}
{"sent1": "Syntactic and case structure are simultaneously analyzed based on wide-coverage case frames that are constructed from a huge raw corpus in an unsupervised manner.", "sent2": "Two simple and computationally inexpensive ideas have proven to be surprisingly effective: (i) reordering the English source sentence as per Hindi syntax, and (ii) using the suffixes of Hindi words.", "label": 0}
{"sent1": "For English pitch accent in broadcast news materials, results reach 78%.", "sent2": "Irony, a creative use of language, has received very little attention from the computational linguistics research point of view.", "label": 0}
{"sent1": "To predict student learning, we also use a third type: 3) user affect.", "sent2": "Alhough generic parameters are useful predictors of user satisfaction in other PARADISE applications, overall our parameters produce less useful user satisfaction models in our system.", "label": 1}
{"sent1": "Our algorithm, instead of searching for the original query, searches for multiple, automatically chosen translations of the sense in several languages.", "sent2": "However, it involves time consuming manual inspection of the extracted output.", "label": 0}
{"sent1": "We use state-of-the-art classification techniques and experiment with five feature classes: Surface, Lexical, Syntactic, Forum specific and Similarity features.", "sent2": "While quality is currently assessed manually, we propose an algorithm to assess the quality of forum posts automatically and test it on data provided by Nabble.com.", "label": 1}
{"sent1": "Besides, our method does not require a document collection, which is indispensable for keyword extraction techniques but is hard to obtain.", "sent2": "For many languages, a CFG is derived from a large-scale syntactically annotated corpus, and many parsing algorithms using CFGs have been proposed.", "label": 0}
{"sent1": "No knowledge of semantic concepts or the metaphor?s source domain is required.", "sent2": "We propose a statistical approach to metaphor detection that utilizes the rarity of novel metaphors, marking words that do not match a text?s typical vocabulary as metaphor candidates.", "label": 1}
{"sent1": "This article examines in detail various existing similarity functions and proposes a hybrid technique for the following task: among the list of possible names, occupations and places extracted from historical documents, identify those that are variations of the same person name, occupation and place respectively.", "sent2": "The performance of our method is evaluated on three manually constructed datasets and one public dataset in terms of precision, recall and F-measure.", "label": 1}
{"sent1": "We carried out comprehensive experiments on multiple training data of varied sizes to prove this.", "sent2": "This paper proposed a novel angle to the problem by modeling PU (positive unlabeled) learning.", "label": 0}
{"sent1": "However, due to the lack of engagement, it is difficult to infer the expertise levels of newcomers.", "sent2": "Users are the most important resource for CQA services, and the awareness of user expertise at early stage is critical to improve user experience and reduce churn rate.", "label": 1}
{"sent1": "A valid opinion relation has three requirements: a correct opinion word, a correct opinion target and the linking relation between them.", "sent2": "Detecting opinion relation is a crucial step for fine-gained opinion summarization.", "label": 1}
{"sent1": "We examine the effectiveness of our approach via datasets gathered from real world microblogs.", "sent2": "Experimental results demonstrate a 20.2% improvement in terms of F1-score over the state-of-the-art discriminative method.", "label": 1}
{"sent1": "We find their performance to be competitive with near state-of-art methods in English, Danish and Swedish.", "sent2": "We quantitatively demonstrate the utility of our word embeddings by using them as the sole features for training a part of speech tagger for a subset of these languages.", "label": 1}
{"sent1": "Some experiments in a Spanish task evaluated with input French utterances and text are presented.", "sent2": "In this paper we give a detailed evaluation of a CCG parser on object extraction dependencies found in WSJ text.", "label": 0}
{"sent1": "in the form of foreign phrases obtained from bilingual parallel data and automatic word-alignment.", "sent2": "The empirical evaluation on ACE 2005 domains shows that a suitable combination of syntax and lexical generalization is very promising for domain adaptation.", "label": 0}
{"sent1": "Intuitively, our approach works by converting a comparable document-aligned corpus into a parallel topic-aligned corpus, then learning word alignments using co-occurrence statistics.", "sent2": "In this paper, we re-evaluate both methods for Chinese, using more accurate dependency parsers than in previous work.", "label": 0}
{"sent1": "Being able to detect such aspects represents an important subtask of aspect-based review mining systems, which aim at automatically generating structured summaries of customer opinions.", "sent2": "We analyze our proposed model both for its ability to capture word repetition via the cache and for its suitability as a language model for speech recognition and retrieval.", "label": 0}
{"sent1": "Some psycholinguistic theories attribute this lag to conceptual differences between the two classes, while others suggest that syntactic differences are responsible.", "sent2": "Through computational experiments, we show that a probabilistic verb learning model exhibits the pattern of acquisition, even though there is no difference in the model in the difficulty of the semantic or syntactic properties of Belief vs.", "label": 1}
{"sent1": "degree of depression most often increases from summer to winter.", "sent2": "Extensive phrase-based translation experiments on both Chinese-to-English and Spanish-to-English tasks show substantial gains in BLEU by up to +2.3/+2.0 on dev/test over MERT, thanks to 20M+ sparse features.", "label": 0}
{"sent1": "Originally, SOUL translation models were applied to n-gram-based translation systems that use tuples as translation units instead of phrase pairs.", "sent2": "This method based on automatic alignment is used by an understanding system based on conditional random fields and is evaluated on a spoken dialogue task using either manual or automatic transcripts.", "label": 0}
{"sent1": "It is more accurate than standard inside-outside re-estimation (classic EM), significantly faster, and simpler.", "sent2": "EM is well-suited to unsupervised grammar induction.", "label": 1}
{"sent1": "We present a new algorithm (JNNSE) that can incorporate a measure of semantics not previously used to create VSMs: brain activation data recorded while people read words.", "sent2": "billingual multi-word expression extractor and named-entity recognizer to improve SMT quality and (ii) the introduction of a novel filter method based on sentence-alignment features.", "label": 0}
{"sent1": "First, we try to define more precisely the context within which a figurative expression may occur, by parsing a corpus annotated for metaphor.", "sent2": "Finally we investigate effects of corpus selection for recasing.", "label": 0}
{"sent1": "Two main challenges are the errors propagated from named entity recognition (NER) and the dearth of information in a single tweet.", "sent2": "The patterns, however, are designed manually and thus are not necessarily the most effective ones in terms of accuracy and breadth.", "label": 0}
{"sent1": "However, notwithstanding their success, word embeddings are by their very nature unable to capture polysemy, as different meanings of a word are conflated into a single representation.", "sent2": "72.73 (P&K) and 67.09 (C&C) F -score on ????", "label": 0}
{"sent1": "Identifying the root of a given word in a Semitic language is an important task, in some cases a crucial part of morphological analysis.", "sent2": "The morphology of Semitic languages is unique in the sense that the major word-formation mechanism is an inherently non-concatenative process of interdigitation, whereby two morphemes, a root and a pattern, are interwoven.", "label": 1}
{"sent1": "Lexical  tightness  captures  aspects  of  prose  complexity that are not covered by classic readability indexes, especially for literary texts.", "sent2": "We find that all embeddings yield significant parsing gains, including some recent ones that can be trained in a fraction of the time of others.", "label": 0}
{"sent1": "Most question answering systems incorporate three major steps: classify questions according to answer types, formulate queries for document retrieval, and extract actual answers.", "sent2": "Anticipating the availability of large questionanswer datasets, we propose a principled, datadriven Instance-Based approach to Question Answering.", "label": 1}
{"sent1": "It is shown that human labelers can perform this task with a high agreement (Fscore of .95).", "sent2": "Difficulty of reading scholarly papers is significantly reduced by reader-friendly writing principles.", "label": 0}
{"sent1": "To the best of our knowledge, our formulation is the first to optimize multi-variate non-linear performance measures such as F ?", "sent2": "for a latent variable structure prediction task.", "label": 1}
{"sent1": "Our results show an improvement over previously reported methods and our model has several advantages.", "sent2": "We report 98% precision and 93% recall on a standard data set, and 95% precision and 91% recall on an additional test set.", "label": 1}
{"sent1": "On a test set of frequently occurring words, for the best combination (the Jaccard similarity measure with or without tf:idf weighting), the correct translation is ranked first for 20% of our test words, and is found in the top 10 candidates for 50% of them.", "sent2": "Next, the dependencies over clause boundaries are identified stochastically, and the dependency structure of the entire sentence is thus completed.", "label": 0}
{"sent1": "We explore the relationship between normal English and simplified English and compare language models trained on varying amounts of text from each.", "sent2": "Unlike some text-to-text translation tasks, text simplification is a monolingual translation task allowing for text in both the input and output domain to be used for training the language model.", "label": 1}
{"sent1": "To realize this, we extract such statements and relations, including cross-document implicit contrastive relations between statements, in an unsupervised manner.", "sent2": "In terms of end-to-end translation, with decoding on the CPU, we increase throughput by roughly two thirds on a standard MT evaluation dataset.", "label": 0}
{"sent1": "Compared to a previous generative model for semantic alignment, it also supports full semantic parsing.", "sent2": "The new methods achieve observed performance comparable to the previously published quadratic complexity method.", "label": 0}
{"sent1": "?ve Bayes or maximum entropy models, on Senseval-2 data.", "sent2": "Combining web link and Wikipedia models produces the best-known disambiguation accuracy of 88.7 on standard newswire test data.", "label": 0}
{"sent1": "The issue is how to allocate training data to statistical modules and the selection module in order to avoid overfitting in training and obtain better performance.", "sent2": "This paper presents an automatic training data allocation method that is based on the change in the coefficients of the logistic regression functions used in the selection module.", "label": 1}
{"sent1": "Given these problems, we are motivated towards creating a synthetic user relevance feedback data, based on insights from query log analysis.", "sent2": "Despite its simplicity, it consistently and robustly improves the accuracy of existing highly accurate base models.", "label": 0}
{"sent1": "The graphs we use represent linguistic relations between words such as adjectival modification.", "sent2": "The MIMIC II database contains 1,237,686 clinical documents of various kinds.", "label": 0}
{"sent1": "These include diglossia, the use of an alternative alphabet (Roman), and code switching with foreign languages.", "sent2": "Arabic on social media has all the properties of any language on social media that make it tough for natural language processing, plus some specific problems.", "label": 1}
{"sent1": "We also present some preliminary word-level language identification experiments using this dataset.", "sent2": "This paper presents results from the first statistical dependency parser for Turkish.", "label": 0}
{"sent1": "Because of the multilingual authors (mountaineers, scientists) and the assumed multilingual readers, the texts contain numerous code-switching elements.", "sent2": "When building and annotating the corpus, we faced issues of language identification on the sentence and subsentential level.", "label": 1}
{"sent1": "Then, these objects of interest are processed in order to be labelled, and the related frames are thus annotated with the corresponding semantic content.", "sent2": "Moreover, a textual script is automatically generated with the video annotations.", "label": 1}
{"sent1": "In particular, concatenative compounding, in which the components are ?glued?", "sent2": "The evaluation on an independent test corpus of manually annotated full text articles shows a macroaverage F 1 measure of 0.74 with precision 0.68 and recall 0.81 on the task of identifying entities participating in relations.", "label": 0}
{"sent1": "We present an approach for providing partial supervision to a distantly supervised relation extractor using a small number of carefully selected examples.", "sent2": "Automatic detection of lexical entailment, or hypernym detection, is an important NLP task.", "label": 0}
{"sent1": "Most of the proposed solutions to this problem are based on non-convex formulations, and are thus prone to local minima.", "sent2": "However, distant supervision leads to a challenging multiple instance, multiple label learning problem.", "label": 1}
{"sent1": "We propose a novel method of jointly embedding entities and words into the same continuous vector space.", "sent2": "The embedding process attempts to preserve the relations between entities in the knowledge graph and the concurrences of words in the text corpus.", "label": 1}
{"sent1": "Second, we aggregate the aspect discourse trees and generate a graph.", "sent2": "We then modify the discourse trees such that every leaf node only contains the aspect words.", "label": 1}
{"sent1": "Most of existing methods for addressing this problem are context-based models which assume that domain synonymous phrases share similar co-occurrence contexts.", "sent2": "Clustering aspect-related phrases in terms of product?s property is a precursor process to aspect-level sentiment analysis which is a central task in sentiment analysis.", "label": 1}
{"sent1": "We demonstrate, that despite the inferior result using the standard evaluation metrics  for  parsers  like  UAS  or  LAS  on  standard  test  data,  our  system  achieves  comparable  results  when used in an application, such as the SemEval-2 #12 evaluation exercise PETE.", "sent2": "The choice of the right feature space for a given task is identified automatically by representing the optimal solution as a linear mixture of multiple kernel functions (MKL).", "label": 0}
{"sent1": "We used the C&C parser to build CCG dependency parses of the truth and hypothesis sentences.", "sent2": "We then used partial match heuristics to determine whether the system should predict entailment.", "label": 1}
{"sent1": "USFD2 identified temporal expressions successfully, and correctly classified their type in 90% of cases.", "sent2": "Determining the relation between an event and time expression in the same sentence was performed at 63% accuracy, the second highest score in this part of the challenge.", "label": 1}
{"sent1": "In the disambiguation stage, each induced cluster is scored according to the number of its vertices found in the context of the target word.", "sent2": "To select appropriate Kanji characters, an existing method requests the user to provide one or more related terms for a source word, which is time-consuming and expensive.", "label": 0}
{"sent1": "This system only uses topic features to cluster different word senses in their global context topic space.", "sent2": "We also demonstrate that an implementation of this algorithm is capable of learning auxiliary fronting in polar interrogatives (AFIPI) in English.", "label": 0}
{"sent1": "The last is an ensemble of these two systems.", "sent2": "Results of the formal run shows the second system is the best.", "label": 1}
{"sent1": "It reaches a performance of 61.6% unweighted average recall when discriminating between 5 classes (good to very poor).", "sent2": "In this paper we present a joint content selection and compression model for single-document summarization.", "label": 0}
{"sent1": "An appropriate set of labels for each connective can be found using information from their translations.", "sent2": "HMM-based models are developed for the alignment of words and phrases in bitext.", "label": 0}
{"sent1": "We extract constraints on preferences and dependencies among them, even when they are expressed indirectly, by exploiting discourse structure.", "sent2": "Our method relies on a study of 20 dialogues chosen at random from the Verbmobil corpus.", "label": 1}
{"sent1": "We illustrate the method with a tutoring system that adapts to student uncertainty over and above correctness.", "sent2": "Specifically, a plug-in architecture has been developed which allows components to be added to WordFreak for customized visualization, annotation specification, and automatic annotation, without re-compilation.", "label": 0}
{"sent1": "A spoken dialogue system for information navigation was implemented and the TTS was evaluated in terms of evoked user backchannels.", "sent2": "However, while these graph-based approaches perform effectively when the agent has perfect knowledge or perception of the environment (e.g., 84%), they perform rather poorly when the agent has imperfect perception of the environment (e.g., 45%).", "label": 0}
{"sent1": "The results of the study suggest that all four dimensions can be used as linguistic markers of all personality traits by both language communities.", "sent2": "The utterances are the turns within dialogue fragments that are presented as text transcripts to the workers of Amazon?s Mechanical Turk.", "label": 1}
{"sent1": "Finally, we constructed a semantic grammar and evaluated its coverage.", "sent2": "We asked a different set of subjects to follow these instructions to determine the usefulness and comprehensibility of individual instructions.", "label": 1}
{"sent1": "affect.", "sent2": "A wordchoice question was used to obtain sense-level annotations and to ensure data quality.", "label": 0}
{"sent1": "Distributional paraphrase generation is independent of parallel texts and syntactic parses, and hence is suitable also for resource-poor languages, but tends to erroneously rank antonyms, trend-contrasting, and polarity-dissimilar candidates as good paraphrases.", "sent2": "Paraphrases are useful for statistical machine translation (SMT) and natural language processing tasks.", "label": 1}
{"sent1": "In this paper, we use Arabic social media posts as stand-in for source language text, and determine loss in sentiment predictability when they are translated into English, manually and automatically.", "sent2": "In this paper, abstracted from a recent grant proposal, a new avenue for addressing both deficiencies and for inspiring new basic research on metaphor is investigated: namely, placing metaphor research within the ?Recognizing Textual Entailment?", "label": 0}
{"sent1": "In this paper, we improve such bigram based ILP summarization methods from different aspects.", "sent2": "First we use syntactic information to select more important bigrams.", "label": 1}
{"sent1": "We propose using zeroinflated models for dealing with this, and evaluate competing models on a Naive Bayes text classification task.", "sent2": "Another deficiency of standard models is due to the fact that most words never occur in a given document, resulting in large amounts of zero counts.", "label": 1}
{"sent1": "This is a very promising result given that our method does not require any hand-tagged text, such as SemCor.", "sent2": "Furthermore, we demonstrate that our method discovers appropriate predominant senses for words from two domainspecific corpora.", "label": 1}
{"sent1": "In order to alleviate the data sparseness in chunk-based translation, we take a stepwise back-off translation strategy.", "sent2": "Moreover, in order to obtain more semantically plausible translation results, we use bilingual verb-noun collocations; these are automatically extracted by using chunk alignment and a monolingual dependency parser.", "label": 1}
{"sent1": "Such sublexical units make it possible to expose the internal structure of words with multiple derivations to the grammar rules in a uniform manner.", "sent2": "This paper investigates the use of sublexical units as a solution to handling the complex morphology with productive derivational processes, in the development of a lexical functional grammar for Turkish.", "label": 1}
{"sent1": "Of these teams, 24 submitted final results.", "sent2": "We address the memory requirements by using only named entities as features.", "label": 0}
{"sent1": "In a brief survey, we put SPE in context with other system combination techniques and evaluate SPE vs. another simple system combination technique: using synthetic parallel data from TECTOMT to train a statistical MT system (SMT).", "sent2": "Specifically, based on 473 pairs of segment-final and segmentinitiating utterances, we find significant increases for segment-initial utterances in maximum pitch, average pitch, and average intensity, while segment-final utterances show significantly lower minimum pitch.", "label": 0}
{"sent1": "We use Markov chain Monte Carlo techniques for approximate inference in the model and perform slice sampling to learn its hyperparameters.", "sent2": "Humor generation is a very hard problem.", "label": 0}
{"sent1": "This information can be exploited as a powerful backoff strategy for word sense disambiguation given the zipfian distribution of word senses.", "sent2": "The bootstrapping technique gives a significant improvement to parsing accuracy, showing near state-of-theart performance with respect to other parsing approaches evaluated on the same data set.", "label": 0}
{"sent1": "Recently, Ott et al.", "sent2": "The rising influence of user-generated online reviews (Cone, 2011) has led to growing incentive for businesses to solicit and manufacture DECEPTIVE OPINION SPAM?fictitious reviews that have been deliberately written to sound authentic and deceive the reader.", "label": 1}
{"sent1": "In this paper, we address the problem of rumor detection in microblogs and explore the effectiveness of 3 categories of features: content-based, network-based, and microblog-specific memes for correctly identifying rumors.", "sent2": "Moreover, we show how these features are also effective in identifying disinformers, users who endorse a rumor and further help it to spread.", "label": 1}
{"sent1": "Thus, our approach requires only monolingual resources: a phoneme dictionary that lists words and their IPA representations.1 By adding a phoneme dictionary of a new language, we can readily build a transliteration system into any of the existing previous languages, without the expense of all-pairs data or computation.", "sent2": "We also propose a regularization framework for learning the interlingual representation, which accounts for language specific phonemic variability, and thus it can find better mappings between languages.", "label": 1}
{"sent1": "In previous work, it was established that performance drastically decreases when the coverage of a seed lexicon is small.", "sent2": "The results show that the Non-Viterbi alignment approach outperforms the other two approaches on F1 measure.", "label": 0}
{"sent1": "We also connect our analysis to social psychology theories of balance.", "sent2": "In contrast, by modeling both aspects of the EDT task simultaneously, we are able to learn using highly complex, non-local features.", "label": 0}
{"sent1": "We show that the usage of a domain-specific corpus is vital.", "sent2": "The categorizations are induced by a graph-based algorithm applied on a large unlabeled domain-specific corpus.", "label": 1}
{"sent1": "This greatly expands the applicability of the model across contexts.", "sent2": "Our hypothesis is that stylistic shifts that occur as a result of social processes are likely to display some consistency over time, and if we leverage this insight in our model,we will achieve a model that better captures inherent structure within speech.", "label": 1}
{"sent1": "We discuss previous works employing WSMs and present differences in the proposed approaches which include types of WSMs, corpora, preprocessing techniques, methods for determining compositionality, and evaluation testbeds.", "sent2": "This research focuses on determining semantic compositionality of word expressions using word space models (WSMs).", "label": 1}
{"sent1": "The main idea is to strengthen the views?", "sent2": "consistency for target data with source training data by identifying the correlations of domain-specific features from different domains.", "label": 1}
{"sent1": "This sampling scheme computes the exact conditional distribution for Gibbs sampling much more quickly than enumerating all possible latent variable assignments.", "sent2": "When applied to the problem of identity uncertainty, this approach results in a conditional probabilistic model that can reason about objects, combining the expressivity of recently introduced BLOG models with the predictive power of conditional training.", "label": 0}
{"sent1": "The algorithm collects the frequency of morphological categories of the given pattern on a unified scale in order to choose the stable categories and their values.", "sent2": "Our new regularization approaches make these efficient algorithms more flexible; we also show that these methods can be combined with informed priors.", "label": 0}
{"sent1": "Considerable volume of location data was imported in a knowledge base (KB) with entities of general importance used for semantic annotation, indexing, and retrieval of text.", "sent2": "Here we present work on using spatial knowledge in conjunction with information extraction (IE).", "label": 1}
{"sent1": "Instead of creating these resources manually, we propose to extract gazetteers from the World Wide Web, using Data Mining techniques.", "sent2": "However, since it only uses a linear  classifier  it  works 17-20 times faster  than other  state of the parsers, as for instance MaltParser or  Stanford Parser.", "label": 0}
{"sent1": "establishing its denotation with respect to the world or a model).", "sent2": "The latter aspect has so far been neglected.", "label": 1}
{"sent1": "This process evidenced the features needed in a computational lexicon to automatically perform the disambiguation task.", "sent2": "Our strategy to identify such verbs is to analyze the results of a corpus search and to rule out all the other possible uses of se.", "label": 1}
{"sent1": "Through all the classification process, a reduced dimensional vector representation obtained by Singular Value Decomposition (SVD) is used.", "sent2": "In order to combine the predictions generated by the multiclassifier, Bayesian voting is applied.", "label": 1}
{"sent1": "This system uses a corpus of 2,500 compounds annotated with WordNet senses and covering 139 different semantic relations.", "sent2": "This paper is situated in the context of AAC technology but the responses could be generalised for other communities affected by low digital literacy, low literacy levels and cognitive challenges.", "label": 0}
{"sent1": "These instances are then clustered using k?means where the number of clusters is discovered automatically using the Adapted Gap Statistic.", "sent2": "In these experiments SenseClusters did not use any information outside of the raw untagged text that was to be clustered, and no tuning of the system was performed using external corpora.", "label": 1}
{"sent1": "The induction algorithm is based on modeling the cooccurrences of two or more words using hypergraphs.", "sent2": "In addition, generative approaches provide advantages that may make them preferable to discriminative techniques such as Support Vector Machines under certain conditions.", "label": 0}
{"sent1": "task of Semeval 2007.", "sent2": "Our results show significant improvement over a majority class baseline as well as a more difficult baseline consisting of lexical n-grams.", "label": 0}
{"sent1": "In our system the different disambiguation methods are considered as experts that give a preference ranking for the senses a word can be assigned.", "sent2": "Gap-fill questions are fill-in-the-blank questions with multiple choices (one correct answer and three distractors) provided.", "label": 0}
{"sent1": "If it gives satisfaction with low Word Error Rate (WER) transcripts, we believe that a tighter integration of the IE and ASR modules can increase the IE performance in more difficult conditions.", "sent2": "More specifically this paper focuses on the robust extraction of Named Entities from speech input where a temporal mismatch between training and test corpora occurs.", "label": 1}
{"sent1": "We used the Weka ML workbench to facilitate experimenting with different ML algorithms.", "sent2": "The paper describes our system and supplies preliminary answers to the above questions.", "label": 1}
{"sent1": "The lexical sample sub-task also used syntactic category information given from a CCG-based parse to assist in verb disambiguation, while both WSD tasks also make use of more traditional features.", "sent2": "We demonstrate how a labeled corpus for the task can be automatically generated from a corpus of documents and accompanying abstracts.", "label": 0}
{"sent1": "The architecture uses multiple forms of syntactic, lexical, and semantic information to inform a classification-based approach that generates a different model for each machine learning algorithm that implements the classification.", "sent2": "When humans speak they often use grammatically incorrect sentences, which is a problem for grammar-based language processing methods, since they expect input that is valid for the grammar.", "label": 0}
{"sent1": "Our approach can significantly advance the state-of-the-art parsing accuracy on two widely used target treebanks (Penn Chinese Treebank 5.1 and 6.0) using the Chinese Dependency Treebank as the source treebank.", "sent2": "The improvements are respectively 1.37% and 1.10% with automatic part-of-speech tags.", "label": 1}
{"sent1": "Our parser integrates shallow parsing techniques with knowledge-based text retrieval to allow for robust processing and coordination of input modes.", "sent2": "Parsing relies on a two-layered approach: typical meta-expressions like those concerning search, newspaper types and dates are identified and excluded from the search string to be sent to the search engine.", "label": 1}
{"sent1": "We further argue for new perspectives to the performance evaluation of domain event extraction systems, considering a document-level, ?off-the-page?", "sent2": "When two vectors are similar, the two words corresponding to the vectors may have some implicit relationship with each other.", "label": 0}
{"sent1": "We identify five clusters of alignment patterns in which the children of a node in a decomposition tree are found and employ these five as nonterminal labels for the Hiero productions.", "sent2": "We therefore propose a topic similarity model to exploit topic information at the synchronous rule level for hierarchical phrase-based translation.", "label": 0}
{"sent1": "Our system uses a Map-Reduce-like approach to translation crowdsourcing where sentence translation is decomposed into the following smaller tasks: (a) translation of constituent phrases of the sentence; (b) validation of quality of the phrase translations; and (c) composition of complete sentence translations from phrase translations.", "sent2": "TransDoop incorporates quality control mechanisms and easy-to-use worker user interfaces designed to address issues with translation crowdsourcing.", "label": 1}
{"sent1": "Its database design permits a fast response time for all queries supported on realistic-size test beds.", "sent2": "The search engine offers a flexible query language allowing to find translation examples matching a combination of numerical and structural features associated to the calculation of the quality metrics.", "label": 1}
{"sent1": "Our model is based on a corpus of Reddit posts, collected across a diverse set of conversational topics and annotated via paid crowdsourcing.", "sent2": "Natural language conversation is widely regarded as a highly difficult problem, which is usually attacked with either rule-based or learning-based models.", "label": 0}
{"sent1": "Hence, sophisticated approximation techniques based on algorithms such as belief propagation and dual decomposition have been employed.", "sent2": "In this paper we discuss a model which combines the structure of the HMM and IBM Model 2.", "label": 0}
{"sent1": "One of the main drawbacks of these methods is that some of the generated abbreviations may not follow the conventional wisdom of Chinese.", "sent2": "To address this problem, we propose a novel neural network architecture to perform task.", "label": 1}
{"sent1": "Working with the Mechanical Turk API, we collected sample narrations, had other Turkers rate these samples and then granted access to full narration HITs depending on aggregate quality.", "sent2": "We obtained higher results (BLEU score of 0.8156) when compared to the state-of-art results.", "label": 0}
{"sent1": "Moreover, we show that our system can be trained on a pair of languages and test on a different pair of languages, obtaining a F-Measure of 77% for the classification of Chinese-English translations using a training corpus of Spanish-French.", "sent2": "Data sparsity is one of the main factors that make word sense disambiguation (WSD) difficult.", "label": 0}
{"sent1": "We experiment with a phrasal matching method in order to: i) build a system portable across languages, and ii) evaluate the contribution of lexical knowledge in isolation, without interaction with other inference mechanisms.", "sent2": "We claim that, in spite of the inherent difficulties of the task, phrase tables extracted from parallel data allow to capture both lexical relations between single words, and contextual information useful for inference.", "label": 1}
{"sent1": "geographic communities, we solve a multi-output regression problem between demographics and lexical frequencies.", "sent2": "In this paper, we develop a novel behavior-based assessment using human language on Facebook.", "label": 0}
{"sent1": "approaches), and compare them to more traditional (local) approaches.", "sent2": "We show that previous approaches for global disambiguation can be improved, but even then the local disambiguation provides a baseline which is very hard to beat.", "label": 1}
{"sent1": "As a result, effective high order features representing rich contexts are inconvenient to use.", "sent2": "For corpora building, GrawlTCQ outperforms the BootCaT tool, which is vastly used in the domain.", "label": 0}
{"sent1": "Furthermore, monolingual corpora are used to learn and filter the set of compound part candidates.", "sent2": "The method uses a bilingual corpus to learn the morphological operations required to split a compound into its parts.", "label": 1}
{"sent1": "This idea is not new, but despite several previous attempts there isn?t a commonly accepted measure to assess non-response.", "sent2": "There are several tasks where is preferable not responding than responding incorrectly.", "label": 1}
{"sent1": "Following Poon and Domingos (2009), we consider a semantic parsing setting where the goal is to (1) decompose the syntactic dependency tree of a sentence into fragments, (2) assign each of these fragments to a cluster of semantically equivalent syntactic structures, and (3) predict predicate-argument relations between the fragments.", "sent2": "We use hierarchical PitmanYor processes to model statistical dependencies between meaning representations of predicates and those of their arguments, as well as the clusters of their syntactic realizations.", "label": 1}
{"sent1": "Using several statistical measures, we show that our model is able to generalize and explain the data statistically significantly better than various baseline approaches.", "sent2": "Multi-Domain learning assumes that a single metadata attribute is used in order to divide the data into so-called domains.", "label": 0}
{"sent1": "The algorithm takes a self training approach driven by confidence estimation.", "sent2": "We also propose a new methodology to evaluate the ranking components of generate-and-rank paraphrase generators, which evaluates them across different combinations of weights for grammaticality, meaning preservation, and diversity.", "label": 0}
{"sent1": "opinions given to each aspect on their overall opinions.", "sent2": "The experimental results on 11 popular products in four domains demonstrate the effectiveness of our approach.", "label": 1}
{"sent1": "In a Wizard of Oz study, we evaluate the effects of out-of-domain utterances on cognitive load, driving performance, and usability.", "sent2": "However, an individual NP usually lacks adequate description information of its referred entity.", "label": 0}
{"sent1": "We collected situated utterances from drivers using our research system, Townsurfer, which is embedded in a real vehicle.", "sent2": "In this paper, we conduct a large-scale crowdsourcing experiment on guessing age and gender from tweets.", "label": 0}
{"sent1": "We hypothesize that over the course of four tutorial dialogue sessions, tutors adapt their strategies based on the personality of the student, and in particular to student introversion or extraversion.", "sent2": "This paper explores dialogue adaptation over repeated interactions within a taskoriented human tutorial dialogue corpus.", "label": 1}
{"sent1": "Increasingly, practitioners are using models with more complex structure?higher treewidth, larger fan-out, more features, and more data?rendering even approximate inference methods such as MCMC inefficient.", "sent2": "In this paper we propose an alternative MCMC sampling scheme in which transition probabilities are approximated by sampling from the set of relevant factors.", "label": 1}
{"sent1": "By considering the general inference representation provided by integer linear programs, we propose three exact inference theorems which allow us to re-use earlier solutions for certain instances, thereby completely avoiding possibly expensive calls to the inference procedure.", "sent2": "Distributional thesauri are now widely used in a large number of Natural Language Processing tasks.", "label": 0}
{"sent1": "The ARPA format for language models is extended to enable an efficient use of the max-backoff quantities required to compute the upper bound.", "sent2": "This allows us to build tractable variable-order HMMs.", "label": 1}
{"sent1": "Second, it minimizes the redundancy of the factors during training, improving accuracy over an independent approach.", "sent2": "In this way, a lemmatisation system can be trained and tested using any supervised tagging model.", "label": 0}
{"sent1": "Generally, due to the longdistance dependencies they induce, they lie beyond the expressivity of Probabilistic CFG, i.e., they cannot be directly reconstructed by a PCFG parser.", "sent2": "The model uses an Indian Buffet Process prior to learn the feature values used in the loglinear method, and is the first algorithm for learning phonological constraints without presupposing constraint structure.", "label": 0}
{"sent1": "(2009) who proposed to use clusters built over slightly coarsened French inflected forms.", "sent2": "We investigate the alternative method of building clusters over lemma/part-of-speech pairs, using a raw corpus automatically tagged and lemmatized.", "label": 1}
{"sent1": "Our comparison is through a case-study of digitizing an eighteenthcentury French novel for a new critical edition: the 1784 Lettres ta?", "sent2": "We compare four methods for transcribing early printed texts.", "label": 1}
{"sent1": "We explore sketch techniques, especially the CountMin Sketch, which approximates the frequency of a word pair in the corpus without explicitly storing the word pairs themselves.", "sent2": "In this paper, we address the challenges posed by large amounts of text data by exploiting the power of hashing in the context of streaming data.", "label": 1}
{"sent1": "We develop a framework for decisions made via in pipeline models, which addresses these difficulties, and presents and evaluates it in the context of bottom up dependency parsing for English.", "sent2": "The data set that supports this system is primarily built from mining a massive set of bilingual terms and sentences from across the web.", "label": 0}
{"sent1": "Evaluation on the datasets of CoNLL2005 SRL shared task shows that the novel hybrid convolution tree kernel outperforms the previous tree kernels.", "sent2": "We also combine our new hybrid tree kernel based method with the standard rich flat feature based method.", "label": 1}
{"sent1": "A merged model takes advantage of the recurring patterns within the hierarchy, and the clusters that exist in some sequences of observations, in order to increase the extraction accuracy.", "sent2": "Though data-driven in nature, emotion analysis based on latent semantic analysis still relies on some measure of expert knowledge in order to isolate the emotional keywords or keysets necessary to the construction of affective categories.", "label": 0}
{"sent1": "In this work we try to model such similarities observed in the consonant inventories, through a complex bipartite network.", "sent2": "Clearly, medical reasoning and decision-making need to be better understood.", "label": 0}
{"sent1": "We show that such a formulation allows for relatively simple and knowledge-lean compression models that do not require parallel corpora or largescale resources.", "sent2": "We present a holistic data-driven technique that generates natural-language descriptions for videos.", "label": 0}
{"sent1": "Since most successful methods of multi-document summarization are still largely extractive, in this paper, we explore just how well an extractive method can perform.", "sent2": "On the other hand, if we restrict the possible reorderings in an appropriate way, we obtain a polynomial-time search algorithm.", "label": 0}
{"sent1": "We formulate the problem as classifying decision-making units at two levels of granularity: dialogue acts and topic segments.", "sent2": "This corpus is composed of human-machine dialogues in the domain of hotel reservation and tourist information.", "label": 0}
{"sent1": "This algorithm was tested using a ?leaveone-out?", "sent2": "We test the validity of the acquired knowledge by means of an application to the problem of word sense disambiguation.", "label": 0}
{"sent1": "The contexts are the lexically-anchored semantic dependency relations that the NPs appear in.", "sent2": "We formally analyze and characterize the domain adaptation problem from a distributional view, and show that there are two distinct needs for adaptation, corresponding to the different distributions of instances and classification functions in the source and the target domains.", "label": 0}
{"sent1": "Theory of Longest Common Subsequence (LCS) originates from computer science and has been established as affine gap model in Bioinformatics.", "sent2": "We perform this developed LCS technique combined with linguistic criteria in MWE extraction.", "label": 1}
{"sent1": "We describe a design which encourages user efficiency and aids discovery of cheating.", "sent2": "Each noisy sentence/relation pair is presented to multiple turkers, who are asked whether the sentence expresses the relation.", "label": 1}
{"sent1": "We find that MTurk can be used to make test sets much cheaper than professionally-produced test sets.", "sent2": "We also extract the most frequent temporal expressions from a separate, larger subset, and note that most expressions concern parts of days or specific times.", "label": 0}
{"sent1": "To this aim workers have been hired for translation and validation tasks, through the CrowdFlower channel to Amazon Mechanical Turk.", "sent2": "Describing the main event of an image involves identifying the objects depicted and predicting the relationships between them.", "label": 0}
{"sent1": "Graded word sense method allows for labeling a word in more than one sense.", "sent2": "With our multilingual temporal tagger HeidelTime, we addressed task A, the extraction and normalization of temporal expressions for English and Spanish.", "label": 0}
{"sent1": "of SemEval-2013.", "sent2": "This means that dialogues are more efficient and that users are also more confident about the appointment that they have agreed with the system.", "label": 0}
{"sent1": "Our system achieves 1.8% accuracy higher than the stateof-the-part parser of Spitkovsky et al.", "sent2": "Therefore, one model can share translations and even derivations with other models.", "label": 0}
{"sent1": "Among submissions from 44 teams in a competition, our submissions stood first in both tasks on tweets, obtaining an F-score of 69.02 in the message-level task and 88.93 in the term-level task.", "sent2": "We define low resource settings as having only small amounts of parallel data available, which is the case for many language pairs.", "label": 0}
{"sent1": "The results of our experiments indicate that our method significantly outperforms the baseline method.", "sent2": "For each subtask, the collection of emotion-proviking event instances is used as labelled examples to train a classifier.", "label": 1}
{"sent1": "Constituency-based models often fail to capture generalizations that cannot be stated in structural terms, and dependency-based models employ a ?single-head?", "sent2": "By doing so, the common predictive structure shared by the multiple classification problems can be discovered, which can then be used to improve performance on the target problem.", "label": 0}
{"sent1": "In the past, the four tasks have been treated independently, using a wide variety of algorithms.", "sent2": "While for the most part the EBMT system of (Gough & Way, 2004b) outperforms any flavour of the phrasebased SMT systems constructed in our experiments, combining the data sets automatically induced by both Giza++ and their EBMT system leads to a hybrid system which improves on the EBMT system per se for French?English.", "label": 0}
{"sent1": "one sense to discover another one.", "sent2": "This confirms MT-based SA as a cheap and effective alternative to building a fully fledged SA system when dealing with under-resourced languages.", "label": 0}
{"sent1": "However, in 41% of these cases, the highest ranked relevant answer is not ranked in the top-10.", "sent2": "The starting-point is a system that retrieves a relevant answer for 73% of the test questions.", "label": 1}
{"sent1": "block bigram features.", "sent2": "a language model score) as well as binary features based on the block identities themselves, e.g.", "label": 1}
{"sent1": "Compared to existing sentence boundary determination approaches, our work offers three significant contributions.", "sent2": "In this paper, we use two similar German treebanks, Tu?Ba-D/Z and NeGra, and investigate the role that different annotation decisions play for parsing.", "label": 0}
{"sent1": "In this paper we present a state-of-the-art baseline semantic role labeling system based on Support Vector Machine classifiers.", "sent2": "Letter-substitution ciphers encode a document from a known or hypothesized language into an unknown writing system or an unknown encoding of a known writing system.", "label": 0}
{"sent1": "These methods are ineffective when question text contains very few individual words (e.g., named entities) that are indicative of the answer.", "sent2": "Text classification methods for tasks like factoid question answering typically use manually defined string matching rules or bag of words representations.", "label": 1}
{"sent1": "We describe our 13 summarization methods each from one of four summarization strategies.", "sent2": "(AfD) discussion is held to determine whether the article should be deleted.", "label": 0}
{"sent1": "The complete correspondence is a direct consequence of minimal assumptions about the semantic representations of basic syntactic categories (e.g., nouns are vectors), and CCG?s tight coupling of syntax and semantics.", "sent2": "We find that for about 3.5% of cases in the held-out corpus, we are able to predict a response, and among those, over half are either exact or at least reasonable substitutes for the actual response.", "label": 0}
{"sent1": "We evaluate the translation quality as well as the training time on a German-to-English translation task of TED and university lectures as well as on the news translation task translating from English to German.", "sent2": "We show their influence in the task of machine translation using continuous space language models based on restricted Boltzmann machines.", "label": 1}
{"sent1": "(DRP).", "sent2": "We evaluate the proposed method on transliterating English NEs to three different languages - Chinese, Russian and Hebrew.", "label": 0}
{"sent1": "In particular, we extend the idea of Baroni and Zamparelli (2010) and Guevara (2010) to use corpus-extracted examples of the target phrases for parameter estimation to the other models proposed in the literature, so that all models can be tested under the same training conditions.", "sent2": "We present an evaluation of alternative cDSMs under truly comparable conditions.", "label": 1}
{"sent1": "For noun-number and determiner correction, we apply a classification approach using rich lexical and syntactic features.", "sent2": "Then, we give the paraphrase lattice as an input to the lattice decoder.", "label": 0}
{"sent1": "It uses very few additional resources: a morphological analyzer and a list of 250 common uncountable nouns, along with the training data provided by the organizers.", "sent2": "The system is based on the rule-based approach.", "label": 1}
{"sent1": "We report on the scores attained and errors corrected and missed.", "sent2": "This paper presents the first probabilistic parsing results for French, using the recently released French Treebank.", "label": 0}
{"sent1": "Although the results on the shared task test set were poor, the approach may still be promising, as there are many aspects of the current implementation that could be optimised.", "sent2": "Unlike general purpose retrieval engines, FAQ retrieval engines have to address the lexical gap between the query and the usually short answer.", "label": 0}
{"sent1": "Error types covered by our system are article/determiner, preposition, and noun number agreement.", "sent2": "Automatically finding email messages that contain requests for action can provide valuable assistance to users who otherwise struggle to give appropriate attention to the actionable tasks in their inbox.", "label": 0}
{"sent1": "We examine the performance of lower dimensional approximations of transitive verb tensors on a sentence plausibility/selectional preference task.", "sent2": "However, instead of spending years of effort to create a large annotated corpus of Old Czech, we approximate it by a corpus of Modern Czech.", "label": 0}
{"sent1": "We combined up to nine different machine translation engines via system combination.", "sent2": "Comprehension tests pose questions based on short text passages to evaluate such understanding.", "label": 0}
{"sent1": "Relevant information is ubiquitous in web text, but extraction deems challenging.", "sent2": "FREEBASE contains entities and relation information but is highly incomplete.", "label": 1}
{"sent1": "The current version of MUSEEC provides the following summarization methods: (1) MUSE ?", "sent2": "or ?country western,?", "label": 0}
{"sent1": "Templates for English and Japanese accompany our software, and they are easy to understand, use and extend to cover other linguistic phenomena or languages.", "sent2": "Results show that even with our relatively small training corpus in a noisy domain, the joint task can be performed to attain 70% class labeling F 1 .", "label": 0}
{"sent1": "The system takes a set of carrier sentences as input, chooses a preposition in each sentence as the key, and then automatically generates distractors.", "sent2": "It personalizes item selection for the user in two ways.", "label": 1}
{"sent1": "There is a lot of evidence that self-explanation works well as a tutorial paradigm, Summative evaluations indicate that students are highly engaged in the tutoring sessions, and achieve learning outcomes equivalent to expert human tutors.", "sent2": "This virtual science tutor is unique in that it elicits self-explanations from students for various science phenomena by engaging them in spoken dialogs and guided by illustrations, animations and interactive simulations.", "label": 1}
{"sent1": "a task of growing clinical importance ?", "sent2": "is challenging, given extensive paraphrasing during retelling along with cascading automatic speech recognition (ASR) errors.", "label": 1}
{"sent1": "We find that human-addressed speech can be modeled using out-of-domain conversational speech transcripts, and that human-computer utterances can be modeled using single-user data: the resulting AD system outperforms a system trained only on matched in-domain data.", "sent2": "Over the last two decades, numerous algorithms have been developed that successfully capture something of the semantics of single words by looking at their distribution in text and comparing these distributions in a vector space model.", "label": 0}
{"sent1": "We also experiment with inserting text segmenters of various types between ASR and MT in a series of real-time translation experiments.", "sent2": "In order to improve machine translation (MT) performance, techniques that could be employed in real-time such as monotonic and partial translation retention are found to be of use.", "label": 1}
{"sent1": "This paper proposes a new lightweight feature-free approach to encode term informativeness in context by leveraging web knowledge.", "sent2": "Existing methods, mostly based on statistical information in corpora, do not actually measure informativeness of a term with regard to its semantic context.", "label": 1}
{"sent1": "For evaluation, we automatically translated RadLex ontology concepts from English into German.", "sent2": "The results show that inter-annotator agreement increases as the context of the verb under the annotation becomes increasingly specified, i.e.", "label": 0}
{"sent1": "A new style for sharing information is social media.", "sent2": "The rapid growth in IT in the last two decades has led to a growth in the amount of information available online.", "label": 1}
{"sent1": "This paper explores the hypothesis that simple statistical methods based on background data can help to filter unreliable training data and thus improve the precision of relation extractors.", "sent2": "Distant supervision approaches typically suffer from the problem of ambiguity when automatically labelling text, as well as the problem of incompleteness of background data to judge whether a mention is a true relation mention.", "label": 1}
{"sent1": "So far, no clinical trial has led to therapeutic approaches which achieve functional recovery in human patients.", "sent2": "In this paper, we describe a first prototype of an ontology-based information extraction system that automatically extracts relevant preclinical knowledge about spinal cord injury treatments from natural language text by recognizing participating entity classes and linking them to each other.", "label": 1}
{"sent1": "We construct meaning representation graphs for the given text and for each question-answer pair by merging the AMRs of comprising sentences using cross-sentential phenomena such as coreference and rhetorical structures.", "sent2": "For this task, we propose an approach using the Abstract Meaning Representation (AMR) formalism.", "label": 1}
{"sent1": "In this paper, we extend Eigenwords, spectral monolingual word embeddings based on canonical correlation analysis (CCA), to crosslingual settings with sentence-alignment.", "sent2": "The efficiency of these three classifications is investigated on two data sets.", "label": 0}
{"sent1": "word combinations such as, e.g., *give a suggestion or *make a walk.", "sent2": "This is because of the ?collocationality?", "label": 1}
{"sent1": "and ?give me a neutral word for greasy?", "sent2": "hate = love?", "label": 1}
{"sent1": "We exploit the compositionality based methods for the acquisition of synonymy relations and of indicators of these synonyms.", "sent2": "In our experiments, we saw an improvement of 0.77 Bleu points absolute in JP?EN.", "label": 0}
{"sent1": "Though that algorithm accomplished satisfying F-scores, the need to manually label training examples becomes a bottleneck to improve its coverage.", "sent2": "Herein we present a novel active learning solution to solve this challenging phenotype-mapping problem.", "label": 1}
{"sent1": "We evaluate Block-LDA in the yeast biology domain by jointly modeling PubMed R?", "sent2": "The goal of this research is to build a model to predict stock price movement using sentiments on social media.", "label": 0}
{"sent1": "We divide the task into independent steps which we approach as machine learning problems.", "sent2": "We define a wide array of features and in particular make extensive use of dependency parse graphs.", "label": 1}
{"sent1": "The OpenDMAP system and the rule set are available at bionlp.sourceforge.net.", "sent2": "First, we investigate how well the addressee of a dialogue act can be predicted based on gaze, utterance and conversational context features.", "label": 0}
{"sent1": "Detected events range from gene expression to protein localization, and cover a multitude of different entity types, including genes/proteins, binding sites, and locations.", "sent2": "Furthermore, our approach is capable of recognizing negation and the speculative character of extracted statements.", "label": 1}
{"sent1": "It consists of event trigger detector, event type classifier, and relation recognizer and event compositor.", "sent2": "In contrast to previous work we sought to combine the strengths of cognitive theories and simple learning algorithms.", "label": 0}
{"sent1": "In this paper, we present a detailed account of the challenges encountered during the construction of a machine learning framework for participation in this task.", "sent2": "The BioNLP?09 Shared Task on Event Extraction is a challenge which concerns the detection of bio-molecular events from text.", "label": 1}
{"sent1": "If the examples are pairs of user input and final system output, they are much more stable, but too coarse-grained to catch many errors.", "sent2": "In this paper, we propose a novel topic model based on incorporating dictionary definitions.", "label": 0}
{"sent1": "We demonstrate the benefits of TPTs for storing n-gram back-off language models and phrase tables for statistical machine translation.", "sent2": "(3) We provide two novel ways to extend the bimodal models to support three or more modalities.", "label": 0}
{"sent1": "We view this procedure as the first step in automatically acquiring (mostly) correct labeled data.", "sent2": "The best system is finally used to generate a definition for all Spanish synsets, which are currently ready for a manual revision.", "label": 0}
{"sent1": "A drawback of this approach is that it is extremely local: while decisions can be based on complex structures on the left, they can look only at a few words to the right.", "sent2": "Our submissions outperformed the official baseline, with our best system ranked above average, but the contribution of the semantic metrics was not conclusive.", "label": 0}
{"sent1": "Focusing on fewer but simpler examples trades off quantity against ambiguity; it attains 44.1% accuracy, using the standard linguisticallyinformed prior and batch training, beating state-of-the-art.", "sent2": "Leapfrog, our third heuristic, combines Less is More with Baby Steps by mixing their models of shorter sentences, then rapidly ramping up exposure to the full training set, driving up accuracy to 45.0%.", "label": 1}
{"sent1": "We evaluate our approach for the case of second-order dependency parsing and observe a tenfold increase in parsing speed, with no loss in accuracy, by performing inference over a small subset of the full factor graph.", "sent2": "Furthermore, the proposed approach has an important advantage in that it is language independent and linguistic theory neutral.", "label": 0}
{"sent1": "We show that it is always possible to obtain optimum parsing complexity with rank two.", "sent2": "Rather than creating and storing thousands of paraphrase examples, paraphrase templates have strong  representation capacity and can be used to generate many paraphrase examples.", "label": 0}
{"sent1": "Crucially, this web-derived lexicon does not require WordNet, part-of-speech taggers, or other language-dependent resources typical of sentiment analysis systems.", "sent2": "As a result, the lexicon is not limited to specific word classes ?", "label": 1}
{"sent1": "In this work, we propose to use convolution kernels for that task which identify meaningful fragments of sequences or trees by themselves.", "sent2": "As an algorithm for learning the second stage classifier, we employ a decision list learning method.", "label": 0}
{"sent1": "The method is simple and flexible with regard to domain and language, and takes into account the influence of aspect on sentiment polarity, an issue largely ignored in previous literature.", "sent2": "An intelligent thesaurus assists a writer with alternative choices of words and orders them by their suitability in the writing context.", "label": 0}
{"sent1": "In this paper, we present the first joint approach for bioevent extraction that obtains state-of-the-art results.", "sent2": "Some joint approaches have been proposed, but they still lag much behind in accuracy.", "label": 1}
{"sent1": "Second, all distortion is penalized linearly, even when appropriate reorderings are performed.", "sent2": "First, it does not estimate the future cost of known required moves, thus increasing search errors.", "label": 1}
{"sent1": "In the medical domain, we obtain a 1.9 BLEU improvement over a reranked baseline exploiting the same scoring function, corresponding to a 5.4 BLEU improvement over the original Moses baseline.", "sent2": "We show that if an indication of which phrases require rewriting is provided, our automatic rewriting procedure yields an additional improvement of 1.5 BLEU.", "label": 1}
{"sent1": "Our method leverages labeled data in the SwitchboardDAMSL and the Meeting Recorder Dialog Act database and applies simple domain adaptation techniques over a large amount of unlabeled email and forum data to address this problem.", "sent2": "We study the problem of predicting tense in Chinese conversations.", "label": 0}
{"sent1": "Existing methods incrementally expand the lexicon by greedily adding entries, considering a single training datapoint at a time.", "sent2": "We present methods to control the lexicon size when learning a Combinatory Categorial Grammar semantic parser.", "label": 1}
{"sent1": "It defines distributions over the novel relaxed hybrid tree structures which jointly represent both sentences and semantics.", "sent2": "Our state-of-the-art semantic role labeling system, while performing well on WSJ test data, shows significant performance degradation when applied to data from the Brown corpus.", "label": 0}
{"sent1": "They require setting additional hyperparameters, which can be problematic in unsupervised learning, so we investigate new methods for unsupervised model selection and system combination.", "sent2": "We instantiate these ideas for part-of-speech induction without tag dictionaries, improving over contrastive estimation as well as strong benchmarks from the PASCAL 2012 shared task.", "label": 1}
{"sent1": "Moreover, we develop a global constraint optimization inference process and use it to leverage an existing knowledge base also to enforce relational constraints among terms and thus improve the classifier predictions.", "sent2": "In this paper, rather than building a stationary hierarchical structure of terms and relations, we describe a system that, given two terms, determines the taxonomic relation between them using a machine learning-based approach that makes use of existing resources.", "label": 1}
{"sent1": "is-a relations; and (3) a graph algorithm that derives from scratch the integrated taxonomy structure of all the terms.", "sent2": "Experimental evaluation shows that the proposed method achieves improvement over the best known results with Japanese named entity extractors based on maximum entropy models.", "label": 0}
{"sent1": "Users may welcome a more general QA system for its capability to answer questions of various sources, integrated from existed specialized sub-QA engines.", "sent2": "Experiments show that these two methods are complementary and by being combined, they can provide useful clues as to how to improve a given grammar.", "label": 0}
{"sent1": "In this work, we develop an improved REQ classifier that could provide significant improvements in addressing this problem.", "sent2": "REQ forms a significant volume, as much as 6% of query traffic received by search engines.", "label": 1}
{"sent1": "We develop efficient inference algorithms using Collapsed Gibbs sampling for posterior inference, and give various evaluations and illustrations of the utility of our model on various document collections with promising results.", "sent2": "Finally we give a Metropolis-Hasting inference algorithm for a semi-supervised extension with decent results.", "label": 1}
{"sent1": "The models are trained using the maximum entropy principle.", "sent2": "In this paper we present an evaluation of new  techniques for automatically detecting emotions in text.", "label": 0}
{"sent1": "Central to our approach is the intuition that word meaning is represented as a probability distribution over a set of latent senses and is modulated by context.", "sent2": "Confidence measures for MT outputs include the rank-sum-based confidence measure (RSCM) for statistical machine translation (SMT) systems.", "label": 0}
{"sent1": "Common tasks in lexical semantics such as word relatedness or selectional preference can benefit from modeling such structure: Polysemous word usage is often governed by some common background metaphoric usage (e.g.", "sent2": "the senses of line or run), and likewise modeling the selectional preference of verbs relies on identifying commonalities shared by their typical arguments.", "label": 1}
{"sent1": "Next, a number of statistical measures ?", "sent2": "based on selectional preferences ?", "label": 1}
{"sent1": "The well known single and multi-stack decoding algorithms defined in the literature have been integrated within a new formalism which also defines a new family of stackbased decoders.", "sent2": "These decoders allows a tradeoff to be made between the advantages of using only one or multiple stacks.", "label": 1}
{"sent1": "The difficulty in using the perceptron for a phrase-structure parsing model is the need for an efficient decoder.", "sent2": "The CCG parser uses a phrase-structure parsing model and dynamic programming in the form of the Viterbi algorithm to find the highest scoring derivation.", "label": 1}
{"sent1": "The fully implemented model can achieve goals that do not match action effects, but that are rather entailed by them, which it does by reasoning about how to act: state-space planning is interwoven with theorem proving in such a way that a theorem prover uses the effects of actions as hypotheses.", "sent2": "The planner is able to model problematic conversational situations, including felicitous and infelicitous instances of bluffing, lying, sarcasm, and stating the obvious.", "label": 1}
{"sent1": "We will show significant improvements on the Chinese-English NIST task.", "sent2": "I present a novel approach to the determination of recurrent sound correspondences in bilingual wordlists.", "label": 0}
{"sent1": "We show that the implications of a predicate at an arbitrary depth of embedding about its complement clause depend on a globally determined notion of relative polarity.", "sent2": "Citing sentences that cite multiple papers are common in scientific writing.", "label": 0}
{"sent1": "In experiments on the Chinese-English FBIS data, our method was capable of producing translation results comparable to those of a state-of-the-art sentence aligner.", "sent2": "Automatic headline generation is a sub-task of document summarization with many reported applications.", "label": 0}
{"sent1": "Our system consists of several components that rely on machinelearning techniques and linguistic knowledge.", "sent2": "We submitted three versions of the system: these share several core elements but each version also includes additional components.", "label": 1}
{"sent1": "Such methods can be useful for studying language transfer, developing teaching materials tailored to students?", "sent2": "native language and forensic linguistics.", "label": 1}
{"sent1": "Efforts like the before mentioned have enabled researchers and analysts from various disciplines to semantically ?understand?", "sent2": "We view different patent classes and different patent text sections such as title, abstract, and claims, as separate translation tasks, and investigate the influence of such tasks on machine translation performance.", "label": 0}
{"sent1": "This study looks at the extent to which such physical co-presence effects have an impact on a child?s ability to deceive.", "sent2": "The automatic evaluation of a generated phrase is performed by producing n-grams and retrieving their frequencies from the World Wide Web (WWW).", "label": 0}
{"sent1": "However, identifying and reading all relevant reviews is a daunting task for a user.", "sent2": "It learns not only statistics of those domains but quantitative measures of domain differences and how those differences affect parsing accuracy.", "label": 0}
{"sent1": "Finding dependency structure can not only help find answer quickly but also allow users to trace back how the answer is concluded through user conversations.", "sent2": "In this paper, we introduce the task of sentence dependency tagging.", "label": 1}
{"sent1": "We jointly model the interplay between latent user intents that govern queries and unobserved entity types, leveraging observed signals from query formulations and document clicks.", "sent2": "When the induced constraints are combined with a fully unsupervised model, the resulting model challenges existing lightly supervised featurebased models as well as unsupervised models that use manually constructed declarative knowledge.", "label": 0}
{"sent1": "By fitting parameters to maximize the likelihood of the bilingual parallel data, the proposed model learns previously unseen sentiment words from the large bilingual parallel data and improves vocabulary coverage significantly.", "sent2": "In this paper, we propose a generative cross-lingual mixture model (CLMM) to leverage unlabeled bilingual parallel data.", "label": 1}
{"sent1": "Various textual and non-textual QA features are explored.", "sent2": "The training examples are sequences of sentences annotated with lambda-calculus meaning representations.", "label": 0}
{"sent1": "While low accuracies may be accepted for general purpose systems, it is critical in some fields such as religious affairs.", "sent2": "Our approach is described in the general framework of structured prediction, allowing future incorporation of additional features and constraints, and may extend to other formalisms as well.", "label": 0}
{"sent1": "Despite some common characteristics between MSA and Dialectal Arabic (DA), the significant differences between the two language varieties hinder such MSA specific systems from solving NER for Dialectal Arabic.", "sent2": "Deterministic parsing has emerged as an effective alternative for complex parsing algorithms which search the entire search space to get the best probable parse tree.", "label": 0}
{"sent1": "They provide valuable feedback to improve contact center processes and customer care, as well as, to enhance customer retention.", "sent2": "This paper describes a method for extracting salient features and identifying emotional emails in customer care.", "label": 1}
{"sent1": "AESOP also includes two novel components: a method for acquiring patient polarity verbs, which impart negative affect on their patients, and affect projection rules to propagate affect tags from surrounding words onto the characters in the story.", "sent2": "AESOP incorporates several existing sentiment analysis tools and lexicons to evaluate the effectiveness of current sentiment technology on this task.", "label": 1}
{"sent1": "In this paper, we show how we create a high-quality, moderate-sized emotion lexicon using Mechanical Turk.", "sent2": "The accuracy of matching verb pairs produced by distributional similarity is higher than using the synonym outputs of verbs from WordNet.", "label": 0}
{"sent1": "The bootstrapping approach learns extraction patterns for six classes of emotions.", "sent2": "WordNet Affect emotion words are used as seeds.", "label": 1}
{"sent1": "In the second model, ANEW (Affective Norm for English Words), a normative  database with affective terms, is employed.", "sent2": "Experiments show that a categorical model using NMF results in better performances for  SemEval and fairy tales, whereas a dimensional model performs better with ISEAR.", "label": 1}
{"sent1": "An EA system can be extremely useful in fields such as information retrieval and emotion-driven computer animation.", "sent2": "Initial results show that a more relaxed constraint of this form is capable of generating humor of deeper semantic content than wordplay riddles.", "label": 0}
{"sent1": "We set-up a comparison framework to study the effect of different summarisation algorithms of various compression rates in this task and compare the classification accuracy of summaries and documents for associating documents to classes.", "sent2": "We also propose a criterion for parameter selection on the basis of magnetization.", "label": 0}
{"sent1": "In order to capture arguing opinions in ideological stance taking, we construct an arguing lexicon automatically from a manually annotated corpus.", "sent2": "We build supervised systems employing sentiment and arguing opinions and their targets as features.", "label": 1}
{"sent1": "This process generates a very large number of features, many of which are highly correlated.", "sent2": "Both models combine lexical, syntactic, and prosodic information.", "label": 0}
{"sent1": "The corpus used for testing is the International Corpus of English, Great Britain (Nelson et al, 2002), which contains syntactically annotated speech of Great Britain.", "sent2": "The speakers are grouped into geographical regions based on place of birth.", "label": 1}
{"sent1": "Thus, the search for a CCG consists in large part in a search for the appropriate categories for the data-set?s lexical items.", "sent2": "We define an inventory of 32 relations, building on the word sense disambiguation task for prepositions and collapsing related senses across prepositions.", "label": 0}
{"sent1": "In this paper, we investigate the use of clustering methods for the task of grouping the text spans in a news article that refer to the same event.", "sent2": "The key idea is to cluster the sentences, using a novel distance metric that exploits regularities in the sequential structure of events within a document.", "label": 1}
{"sent1": "Extensions incorporated include an incremental specialization of property values for metonymic  references, local and global positions  reflecting group formations and implicature-based scope preferences to justify  unique identification of the intended  referent.", "sent2": "The approach is primarily  relevant for domains where abstract  formal objects are prominent, but some  of its features are also useful to extend  the expressive repertoire of reference  generation algorithms in other domains.", "label": 1}
{"sent1": "We found that LHs are even more advantageous in challenging conditions, such as having imbalanced and small training sets.", "sent2": "Our results motivate further research on the use of LHs for modeling the writing style of authors for related tasks, such as authorship verification and plagiarism detection.", "label": 1}
{"sent1": "Integrating work from psychology and computational linguistics, we develop and compare three approaches to detecting deceptive opinion spam, and ultimately develop a classifier that is nearly 90% accurate on our gold-standard opinion spam dataset.", "sent2": "To counteract the imprecision of such constraints, we compare several constraint selection algorithms that optimize classification accuracy on a tuning set.", "label": 0}
{"sent1": "The first one is a sentence-ranking method that linearly combines scores measured from different aspects including topic relevance, subjectivity, and sentence importance.", "sent2": "The second one is a graph-based method, which incorporates topic and sentiment information, as well as additional information about sentence-to-sentence relations extracted based on dialogue structure.", "label": 1}
{"sent1": "We then show how to compute a chart that represents, in finite space, the complete (possibly infinite) set of valid REs for a target object.", "sent2": "Finally, we propose a probability model that predicts how the listener will understand the RE, and show how to compute the most effective RE according to this model from the chart.", "label": 1}
{"sent1": "Results indicate that the crowd is able to provide reasonable and diverse templates within this methodology.", "sent2": "More work is necessary before elicited templates can be automatically plugged into the system.", "label": 1}
{"sent1": "Based on these contributions, we demonstrate a way to describe a pipeline such that all required software and resources can be automatically obtained, making it easy to share it with others, e.g.", "sent2": "SALAAM exploits multilingual evidence as a means of disambiguation.", "label": 0}
{"sent1": "These benefits help to increase development productivity and quality of HLT assets.", "sent2": "In this paper, we present our approach to the DSTC2 challenge.", "label": 0}
{"sent1": "The goal is not to define a new set of terms, but rather to provide a single web location where terms relevant for exchange among NLP tools are defined and provide a ?sameAs?", "sent2": "This paper describes a semantic role labeling system that uses features derived from different syntactic views, and combines them within a phrase-based chunking paradigm.", "label": 0}
{"sent1": "task.", "sent2": "We report results on a set of highly frequent source phrases, obtaining a significant improvement, specially with respect to adequacy, according to a rigorous process of manual evaluation.", "label": 1}
{"sent1": "However, many attitudes are conveyed implicitly, and benefactive/malefactive events are important for inferring implicit attitudes.", "sent2": "We also investigate a rule based method that uses hand crafted lists of terms derived from WordNet.", "label": 0}
{"sent1": "To the best of our knowledge, this online learning capability has never been provided by previous IMT systems.", "sent2": "According to empirical results, our system outperforms the results of conventional IMT systems.", "label": 1}
{"sent1": "English tasks show that our system is significantly better than the phrase-based model by up to +1.5/+0.5 BLEU scores.", "sent2": "This contrasts with previous approaches, which relied on hand-crafted cohesion metrics.", "label": 0}
{"sent1": "Successful transfer learning between languages suggests that the learned model is in fact independent of the underlying language.", "sent2": "We present an approach for automatically learning to solve algebra word problems.", "label": 0}
{"sent1": "We motivate this work from a psychological evidence that humans naturally have a tendency to point towards objects in the context or the environment when the name of an object is not known.", "sent2": "At each timestep, the decision of which softmax layer to use is adaptively made by an MLP which is conditioned on the context.", "label": 1}
{"sent1": "In particular, we suggest a scheme of slots that together make up a verb and show how each slot represents a subset of the morphosyntactic properties associated with the verb.", "sent2": "We also show how we can account for the tonal aspects of Yoru`ba?, in particular, the tone associated with the emphatic ending.", "label": 1}
{"sent1": "We use the RF-tagger (Schmid and Laws, 2008), which is particularly designed for the annotation of fine-grained tagsets (e.g.", "sent2": "including agreement information), and we restructure the 141 tags of the tagset proposed by Taljard et al (2008) in a way to fit the RF tagger.", "label": 1}
{"sent1": "We argue that the availability of such an online tool will facilitate the generation of in-depth annotated linguistic examples as part of linguistic research.", "sent2": "Using the translated portion of the Chinese treebank, our model is trained iteratively to maximize the marginal likelihood of training tree pairs, with alignments treated as latent variables.", "label": 0}
{"sent1": "OATS is motivated by the desire to query data in the knowledge base via IPA or native orthography, and for error checking of digitized data and conversion between transcription systems.", "sent2": "We report results on the provided development and test sets.", "label": 0}
{"sent1": "Its language allows the use of regular expressions and Generalized Restriction rules to define multi-tape transducers.", "sent2": "Both simultaneous and successive application of local constraints are possible.", "label": 1}
{"sent1": "However, in morphology-rich languages, in particular Semitic languages such as Hebrew and Arabic, the equivalents of such function words are usually written as morphemes attached as prefixes to other words.", "sent2": "The majority of these methods rely on the existence of function words as separate text units.", "label": 1}
{"sent1": "Here, we extend the LFG grammar acquisition approach to Arabic and the Penn Arabic Treebank (ATB) (Maamouri and Bies, 2004), adapting and extending the methodology of (Cahill and al., 2004) originally developed for English.", "sent2": "A number of papers have reported on methods for the automatic acquisition of large-scale, probabilistic LFG-based grammatical resources from treebanks for English (Cahill and al., 2002), (Cahill and al., 2004), German (Cahill and al., 2003), Chinese (Burke, 2004), (Guo and al., 2007), Spanish (O?Donovan, 2004), (Chrupala and van Genabith, 2006) and French (Schluter and van Genabith, 2008).", "label": 1}
{"sent1": "Either diagonal or full covariance.", "sent2": "Our method encompasses three tasks that have been previously handled separately: input segmentation, phoneme prediction, and sequence modeling.", "label": 0}
{"sent1": "We present a greedy document partitioning technique for the task.", "sent2": "In this paper, we show how the memory required for parallel LVM training can be reduced by partitioning the training corpus to minimize the number of unique words on any computational node.", "label": 1}
{"sent1": "refers to a fixed (remote) participant in a meeting.", "sent2": "where ?you?", "label": 1}
{"sent1": "tense, aspect, and person deixis, are a useful basis for automatic intentional discourse segmentation.", "sent2": "We present a novel algorithm and test our hypothesis on a set of intentionally segmented conversational monologues.", "label": 1}
{"sent1": "We evaluated our reranking approach on German and English phrase structure parsing tasks and compared it to various state-of-the-art reranking approaches such as the perceptron-based forest reranker.", "sent2": "As a consequence of this, machine translation from Scottish Gaelic to Irish has a great deal in common with the problem of normalizing pre-standard Irish texts, a problem with applications to lexicography and information retrieval.", "label": 0}
{"sent1": "To handle the large amount of data, our algorithm maintains approximate counts based on sketching algorithms.", "sent2": "We propose a system called FLAG to construct such graphs approximately from large data sets.", "label": 1}
{"sent1": "If a computer can reliably extract information from them, it will greatly benefit a variety of applications.", "sent2": "We propose to use HMMs to model text at the segment level, in which the extraction process consists of two steps: a segment retrieval step followed by an extraction step.", "label": 0}
{"sent1": "In order to address this issue, we developed a method which filters out nonscorable responses based on text similarity measures.", "sent2": "Since many automated proficiency scoring systems use fluency features such as speaking rate as one of the important features, students may engage in strategies designed to manipulate their speaking rate as measured by the system.", "label": 1}
{"sent1": "We hypothesize that such distractors should be particularly hard to distinguish from the correct answer.", "sent2": "Stubs on Wikipedia often lack comprehensive information.", "label": 0}
{"sent1": "Prior work mainly focuses on detecting corrections within sentences, which is at the level of words or phrases.", "sent2": "Second, we propose a novel way to utilize human rating processes in automated speech scoring.", "label": 0}
{"sent1": "Our work demonstrates that the addition of morphological, information theoretic, and language modeling features to a traditional readability baseline greatly benefits our performance.", "sent2": "(2013) on the Interagency Language Roundtable (ILR) scale.", "label": 1}
{"sent1": "An existing readability assessment tool developed for Italian was specialized at the level of training corpus and learning algorithm.", "sent2": "the corpora to be used for training, and the identification of the most effective features to determine sentence readability.", "label": 1}
{"sent1": "The dataset records purchases of AAC technology by the UK?s National Health Service between 2006 and 2012; giving information for each item on: make, model, price, year of purchase, and geographic area of purchase.", "sent2": "The dataset was designed to help answer open questions about the provision of AAC services in the UK; and the level of detail of the dataset is such that it can be used at the research level to provide context for researchers and to help validate (or not) assumptions about everyday AAC use.", "label": 1}
{"sent1": "We present a translation model which models derivations as a latent variable, in both training and decoding, and is fully discriminative and globally optimised.", "sent2": "We argue that a principle reason for this failure is not dealing with multiple, equivalent translations.", "label": 1}
{"sent1": "The pattern clusters are then used to construct features for training and classification of specific inter-nominal relationships.", "sent2": "We describe a translation model adaptation approach for conversational spoken language translation (CSLT), which encourages the use of contextually appropriate translation options from relevant training conversations.", "label": 0}
{"sent1": "We then present an algorithmic approach that jointly optimizes the temporal structure by coupling local classifiers that predict associations and temporal relations between pairs of temporal entities with global constraints.", "sent2": "We evaluate our system on two data sets for two sequence labeling tasks ?", "label": 0}
{"sent1": "We propose a joint inference model that leverages knowledge from predictors that optimize subtasks of opinion extraction, and seeks a globally optimal solution.", "sent2": "Experimental results demonstrate that our joint inference approach significantly outperforms traditional pipeline methods and baselines that tackle subtasks in isolation for the problem of opinion extraction.", "label": 1}
{"sent1": "In this paper, we propose a novel joint model that integrates recursive neural networks and conditional random fields into a unified framework for explicit aspect and opinion terms co-extraction.", "sent2": "Previous studies have shown that exploiting connections between aspect and opinion terms is promising for this task.", "label": 1}
{"sent1": "In this paper, we propose a novel approach based on emotion distribution learning in order to address the aforementioned issues.", "sent2": "Thanks to this important feature of Named Entities, we developed a multilingual super sense tagging system capable to distinguish between concepts and individuals.", "label": 0}
{"sent1": "We propose Item Response Theory (IRT) from psychometrics as an alternative means for gold-standard test-set generation and NLP system evaluation.", "sent2": "IRT is able to describe characteristics of individual items their difficulty and discriminating power - and can account for these characteristics in its estimation of human intelligence or ability for an NLP task.", "label": 1}
{"sent1": "While stateof-the-art methods provide efficient computation of word similarities via a low-dimensional matrix embedding, their motivation is often left unclear.", "sent2": "In this paper, we argue that word embedding can be naturally viewed as a ranking problem due to the ranking nature of the evaluation metrics.", "label": 1}
{"sent1": "The brain activity data were recorded using functional magnetic resonance imaging (fMRI) when subjects were viewing words.", "sent2": "First, we analysed the functional selectivity of different cortex areas by calculating the correlations between neural responses and several types of word representations, including skipgram word embeddings, visual semantic vectors, and primary visual features.", "label": 1}
{"sent1": "With this in mind, the SemEval-2014 Analysis of Clinical Text task aimed at assessing and improving current methods for identification and normalization of concepts occurring in clinical narrative.", "sent2": "This paper describes our approach in this task, which was based on a fully modular architecture for text mining.", "label": 1}
{"sent1": "This paper presents an integrated environment for annotating a treebank, called eBonsai.", "sent2": "eBonsai helps annotators to choose a correct syntactic structure of a sentence from outputs of a parser, allowing the annotators to retrieve similar sentences in the treebank for referring to their structures.", "label": 1}
{"sent1": "Much effort has been put in designing and evaluating dedicated word sense disambiguation (WSD) models, in particular with the Senseval series of workshops.", "sent2": "We have identified the user requirements as accurate ranking of phrase matches, domain independence, and reasonable response time.", "label": 0}
{"sent1": "It is found that for certain classes of words, using the POS information is more effective than using a combination of word and POS tag as the token.", "sent2": "In this paper, we investigate the suitability of a machine learning (ML) based system for resolving these tasks on a previously unexplored collection of Patient History and Physical Examination reports.", "label": 0}
{"sent1": "Since the candidate alignments are noisy, we develop a robust learning algorithm to learn the interlingual representation.", "sent2": "Prior work on training the IBM-3 translation model is based on suboptimal methods for computing Viterbi alignments.", "label": 0}
{"sent1": "As a kernel function, the Improved-Edit-Distance (IED) is used to calculate the similarity between two Chinese strings.", "sent2": "We empirically compare several settings for model learning, while we vary the use of features, source corpora for feature extraction, and disambiguated corpora.", "label": 0}
{"sent1": "However, little has been done in this field.", "sent2": "This study investigates the features that affect the placement (where to place a cue) of because for non-native speakers.", "label": 1}
{"sent1": "org.", "sent2": "Two groups were extremely inspired by the shared task and also provided gold-standard semantic representations for the seven texts, together with evaluation measures.", "label": 1}
{"sent1": "We describe the TEXTCAP system, detail the semantic triple representation it produces, illustrate step by step how TEXTCAP processes a short text, and use its results on unseen texts to discuss the amount of post-editing that might be realistically required.", "sent2": "Central to automatic summarization is the notion of similarity between sentences in text.", "label": 0}
{"sent1": "We also present an evaluation metric for the representation and use it to evaluate the performance of the TRIPS parser on the common task paragraphs.", "sent2": "We demonstrate the power of the new algorithm by evaluating on various sequence labeling tasks: Part-of-Speech tagging for multiple languages (including lowresource languages), with complete and incomplete dictionaries, and supertagging, a complex sequence labeling task, where the grammar size alone can grow to millions of entries.", "label": 0}
{"sent1": "But, conversely, (ii) difficult issues in metaphor understanding have hindered large-scale application, extensive empirical evaluation, and the handling of the true breadth of metaphor types and interactions with other language phenomena.", "sent2": "To illustrate, we extract research threads from citation graphs and construct timelines from news articles.", "label": 0}
{"sent1": "Most existing microblog search capabilities are focused on recent happenings and do not provide the ability to search and explore past events.", "sent2": "This paper proposes the problem of structured retrieval of historical event information over microblog archives.", "label": 1}
{"sent1": "Relying on these operators, a set of annotations is presented which are used to automatically annotate biographic texts.", "sent2": "A software application, plugged in the platformNavitext, is described that builds a calendar view of a biographic text.", "label": 1}
{"sent1": "More generally, ANAWIKI is a project that explores to what extend expert annotations can be substituted by a critical mass of non-expert judgements.", "sent2": "375 376 Chamberlain, Poesio, and Kruschwitz", "label": 1}
{"sent1": "The summaries of arbitrarily length are obtained by extraction using three different methods applied to the obtained segments.", "sent2": "A large vocabulary model based on a manually constructed morphological tagger is shown to give the lowest word error rate, while the unsupervised morphology discovery method Morfessor Baseline gives marginally weaker results.", "label": 0}
{"sent1": "Second, we create classifiers to categorize each medication mention with respect to six categories.", "sent2": "We demonstrate that this task benefits from a rich linguistic feature set, domain-specific semantic features produced by a weakly supervised semantic tagger, and balanced self-training.", "label": 1}
{"sent1": "We present a statement annotation scheme and examine its reliability by annotating around 1,500 pairs of statements.", "sent2": "This paper presents a framework to infer spatial knowledge from verbal semantic role representations.", "label": 0}
{"sent1": "The present work addresses paraphrases found between two different discourse types: specialized and lay texts.", "sent2": "We therefore built comparable corpora of specialized and lay texts in order to detect equivalent lay and specialized expressions.", "label": 1}
{"sent1": "To demonstrate our idea, we developed a system based on the proposed framework.", "sent2": "In this paper, we present an extensible crosslinguistic readability framework based on the use of parallel corpora to quickly create readability software for thousands of languages, including languages for which no linguists are available to define readability rules or for which documents with readability labels are lacking to train readability models.", "label": 1}
{"sent1": "The training process of feature-based summarization model usually requires a large amount of training data with high-quality reference summaries.", "sent2": "The model can also be combined with features used in previous work such as bag-of-words and n-grams.", "label": 0}
{"sent1": "We also report a comparison of our approach with that of (Munteanu and Marcu, 2005) using exactly the same corpora and show performance gain by using much lesser data.", "sent2": "I show that a measure of phonetic similarity based on multivalued features performs better than ?orthographic?", "label": 0}
{"sent1": "This classification tool is then inserted in a corpus compilation tool which is a text collection treatment chain realized through IBM UIMA system.", "sent2": "Starting from two specialized web documents collection in French and Japanese, this tool creates the corresponding corpus.", "label": 1}
{"sent1": "hand parses from the Penn Chinese Treebank.", "sent2": "While first proposed for English, the algorithm counts for its success on two characteristics that Chinese and English have in common.", "label": 1}
{"sent1": "The task of template \flling is cast as constrained parsing using the SLM.", "sent2": "The paper presents a data-driven approach to information extraction (viewed as template \flling) using the structured language model (SLM) as a statistical parser.", "label": 1}
{"sent1": "The goal of the corpus is to provide a large data resource for the development and evaluation of grammatical error correction systems.", "sent2": "In this paper, we propose and implement an effective technique to address this problem.", "label": 0}
{"sent1": "This problem area has seen a spike in interest in recent years as it can have an impact on educational applications tailored towards non-native speakers of a language, as well as authorship profiling.", "sent2": "Native Language Identification, or NLI, is the task of automatically classifying the L1 of a writer based solely on his or her essay written in another language.", "label": 1}
{"sent1": "Algorithms that model the argumentative structure seem to perform better than other algorithms.", "sent2": "Empirical results demonstrate that our model is effective in email and forum speech act recognition.", "label": 0}
{"sent1": "This paper proposes a methodological approach to temporally anchored relation extraction.", "sent2": "Each document of a particular genre was converted into a network of words with word collocations as edges.", "label": 0}
{"sent1": "PageRank is then used to weigh the words in the graph and score the candidate labels.", "sent2": "We introduce an intrinsic evaluation PARADIGM which measures the goodness of paraphrase collections that are represented using synchronous grammars.", "label": 0}
{"sent1": "First, we create a novel training source by semantically annotating a Korean corpus containing fine-grained morphological and syntactic information.", "sent2": "We then develop a supervised SRL model by leveraging morphological features of Korean that tend to correspond with semantic roles.", "label": 1}
{"sent1": "We score relational triples in the KB using these measures and select the top scoring relational triple to answer the question.", "sent2": "To handle the large amount of data, our algorithm maintains approximate counts based on sketching algorithms.", "label": 0}
{"sent1": "We analyze the performance of the Berkeley parser on OntoNotes WSJ and the English Web Treebank.", "sent2": "existing forms as a form of signaling novelty.", "label": 0}
{"sent1": "We examine the performance of three techniques on three treebanks (Negra, Tiger, and Tu?Ba-D/Z): (i) Markovization, (ii) lexicalization, and (iii) state splitting.", "sent2": "Particular attention is paid to constructing a large and reliable knowledge base for supporting inferences.", "label": 0}
{"sent1": "We propose a novel text normalization model based on learning edit operations from labeled data while incorporating features induced from unlabeled data via character-level neural text embeddings.", "sent2": "The text embeddings are generated using an Simple Recurrent Network.", "label": 1}
{"sent1": "We propose methods that transform word vectors into sparse (and optionally binary) vectors.", "sent2": "The corpus data has been used in several studies exploring different strategies for selecting facial displays for a synthetic talking head.", "label": 0}
{"sent1": "Our reduction is grounded on a new intermediate representation, ?head-ordered dependency trees,?", "sent2": "When the analyzer does not recognize a given token, we hit the problem of unknowns.", "label": 0}
{"sent1": "which yields a significant improvement over the best published result in the literature.", "sent2": "We present a new focus annotation effort designed to overcome this problem.", "label": 0}
{"sent1": "However, natural language exhibits syntactic properties that would naturally combine words to phrases.", "sent2": "To capture the variations found in this setting, we employ a distant supervision approach, modeling the task as multi-class text classification.", "label": 0}
{"sent1": "Instead, we use a convolutional neural network to predict the next word with the history of words of variable length.", "sent2": "To select appropriate Kanji characters, an existing method requests the user to provide one or more related terms for a source word, which is time-consuming and expensive.", "label": 0}
{"sent1": "The hallucinated phrase table is very noisy.", "sent2": "Our system is based on WebCrow, one of the most advanced systems for automatic crossword puzzle resolution.", "label": 0}
{"sent1": "Finally, we show that hybridizing these two approaches results in still more accurate generation systems.", "sent2": "Improved results are obtained by inverting a semantic parser that uses SMT methods to map sentences into meaning representations.", "label": 1}
{"sent1": "All graph-based algorithms rely on a graph that jointly represents labeled and unlabeled data points.", "sent2": "Graph-based semi-supervised learning has recently emerged as a promising approach to data-sparse learning problems in natural language processing.", "label": 1}
{"sent1": "Although it is widely assumed that QA technology provides more efficient access to information than IR systems, our experiments show that a simple IR baseline is quite competitive.", "sent2": "The framework is based on the notion of recall curves, which characterize the amount of relevant information contained within a fixed-length text segment.", "label": 1}
{"sent1": "The method is based on an incremental process driven by an association score featuring a minimal resources statistically aided linguistic approach.", "sent2": "We also introduce a linguistics-based lexical unit definition and use it to describe an evaluation protocol dedicated to the task.", "label": 1}
{"sent1": "Targeting a demonstrated potential improvement of almost 50% on some difficult TREC queries and their associated collections, we develop a suite of automatic techniques to re-write queries and study their characteristics.", "sent2": "We describe how the Data Contributors of MultiLing collected and generated a multilingual multi-document summarization corpus on 10 different languages: Arabic, Chinese, Czech, English, French, Greek, Hebrew, Hindi, Romanian and Spanish.", "label": 0}
{"sent1": "These combination methods operate on sentence, phrase and word level exploiting information from \u0004 -best lists, system scores and target-to-source phrase alignments.", "sent2": "The word-level combination provides the most robust gains but the best results on the development test sets (NIST MT05 and the newsgroup portion of GALE 2006 dry-run) were achieved by combining all three methods.", "label": 1}
{"sent1": "based on clusterings of similar, but supervised document collections (crossinstance tuning).", "sent2": "We formulate a hierarchical Bayesian model for jointly predicting bilingual streams of part-of-speech tags.", "label": 0}
{"sent1": "This approach can be used to specify complex dialogue behavior in a systematic way.", "sent2": "The information state approach, in contrast, allows system and user behavior to be specified as update rules, with preconditions and effects.", "label": 1}
{"sent1": "In this paper we present a methodology for numerically constructing confidence intervals for the expected cumulative reward for a learned policy.", "sent2": "Manually annotating data is expensive, however, and a new data set must be annotated for each domain.", "label": 0}
{"sent1": "Our assumption is that, during human machine conversation, a user?s eye gaze on the graphical display indicates salient entities on which the user?s attention is focused.", "sent2": "The specific domain information about the salient entities is likely to be the content of communication and therefore can be used to constrain speech hypotheses and help language understanding.", "label": 1}
{"sent1": "We adopt the Potts model for the probability model of the lexical network.", "sent2": "In the network, each node has one of the three orientation values and the neighboring nodes tend to have the same value.", "label": 1}
{"sent1": "While some early work used either rule-based methods or n-gram statistical models to determine the name language of origin, we use the discriminative classification maximum entropy model and view the task as a classification task.", "sent2": "We demonstrate the use of context features, namely, names of places, and unlabelled data for the detection of personal name language of origin.", "label": 1}
{"sent1": "We prove that our agreementbased joint model is more expressive than individual ranking models.", "sent2": "This algorithm guides the prediction of individual rankers by analyzing meta-relations between opinions, such as agreement and contrast.", "label": 1}
{"sent1": "Assuming that syllable plays a fundamental role in forming the non-standard tweet words, we choose syllable as the basic unit and extend the conventional noisy channel model by incorporating the syllables to represent the word-to-word transitions at both word and syllable levels.", "sent2": "However, to date, risk identification, the first step in the risk management cycle, has always been a manual activity with little to no intelligent software tool support.", "label": 0}
{"sent1": "We also create a new data set with newly added normalization annotation beyond the existing named entity labels.", "sent2": "This is the first data set with such annotation and we release it for research purpose.", "label": 1}
{"sent1": "In this paper, we equip the DCS framework with logical inference, by defining abstract denotations as an abstraction of the computing process of denotations in original DCS.", "sent2": "the problems of the recent TempEval challenges.", "label": 0}
{"sent1": "Unlike previous work, this method can be fed external lexical semantic relations to capture a wider class of rewriting rules.", "sent2": "It also does not assume preliminary syntactic parsing but is still able to provide a unified framework to capture syntactic structure and alignments between the two sentences.", "label": 1}
{"sent1": "Furthermore, our system is able to tag about 32K tokens per second.", "sent2": "Even with this simple tagging algorithm, our system shows comparable results against other state-of-the-art systems, and gives higher accuracies when evaluated on a mixture of the data.", "label": 1}
{"sent1": "We attempt to tease apart the effects that this simple but effective modification has on alignment precision and recall trade-offs, and how rare and common words are affected across several language pairs.", "sent2": "In this work we analyze a recently proposed agreement-constrained EM algorithm for unsupervised alignment models.", "label": 1}
{"sent1": "When translating into a segmented language, an extra step is required to desegment the output; previous studies have desegmented the 1-best output from the decoder.", "sent2": "Experimental results on the Robocup sportscasting corpora in both English and Korean indicate that our approach produces more accurate semantic alignments than existing methods and also produces competitive semantic parsers and improved language generators.", "label": 0}
{"sent1": "The phrase-level and sentence-level precision of the generated paraphrases are above 60% and 55%, respectively.", "sent2": "In addition, the contribution of each resource is evaluated, which indicates that all the exploited resources are useful for generating paraphrases of high quality.", "label": 1}
{"sent1": "In particular, we argue for the centrality of event coreference and therefore incorporate such a component based on topicality.", "sent2": "We demonstrate that a system for contradiction needs to make more fine-grained distinctions than the common systems for entailment.", "label": 1}
{"sent1": "A candidate is productive if it frequently leads to the discovery of other instances.", "sent2": "Intuitively, a candidate is popular if it was discovered many times by other instances in the hyponym pattern.", "label": 1}
{"sent1": "The proposed method makes it possible to use large corpora for training.", "sent2": "The evaluation is performed over newspaper corpora using different testing periods.", "label": 1}
{"sent1": "sentences) is very successful in generic summarization.", "sent2": "Next, all the combination pairs formed by a concept from the group of drugs (drug and substances) and the group of diseases (diseases and symptoms) are characterised through a set of 57 features.", "label": 0}
{"sent1": "The BRAE is trained in a way that minimizes the semantic distance of translation equivalents and maximizes the semantic distance of nontranslation pairs simultaneously.", "sent2": "of generating large numbers of output candidates which served as input to a ranking component.", "label": 0}
{"sent1": "Unfortunately, automatically obtained parallel data (which is available in relative abundance) tends to be quite noisy.", "sent2": "We explore at a macro-level firsthand accounts of domestic abuse from a substantial, balanced corpus of tweeted instances designated with these tags.", "label": 0}
{"sent1": "We compare unsupervised adaptation to supervised and pseudo supervised adaptation.", "sent2": "We explore unsupervised adaptation, where the source-language test corpus is combined with the corresponding hypotheses generated by the translation system to perform adaptation.", "label": 1}
{"sent1": "However, the sparse feature sets typically appearing in research evaluations are less attractive than standard dense features such as language and translation model probabilities: they often overfit, do not generalize, or require complex and slow feature extractors.", "sent2": "In this paper, we present an unsupervised information extraction system for short listings.", "label": 0}
{"sent1": "Formulating the reordering problem as a classification problem and using naive Bayes with feature selection, we achieve an improvement in the BLEU score over a lexicalized reordering model.", "sent2": "The proposed model is compact, fast and scalable to a large corpus.", "label": 1}
{"sent1": "from microblogging sites like Twitter, that correspond to key talking points or buzz around a particular topic or entity of interest.", "sent2": "In this paper we present the first steps in producing an automatically generated, readily consumable, technical survey.", "label": 0}
{"sent1": "Given a news article, we formulate the problem as two rank-then-extract tasks: (1) we find a set of indicative tweets and use them to assist the ranking of news sentences for extraction; (2) we extract top ranked tweets as a substitute of sentence extraction.", "sent2": "Different methods are proposed, based on a statistical translation model.", "label": 0}
{"sent1": "A dataset of pairwise judgments from humans is used to evaluate two methods, one based on clustering and another based on a hidden Markov model.", "sent2": "Our analysis suggests a five-point gap between system and median-human levels of agreement with a consensus annotation, of which half can be closed with bag of words representations and half requires more sophistication.", "label": 1}
{"sent1": "The choice of the right feature space for a given task is identified automatically by representing the optimal solution as a linear mixture of multiple kernel functions (MKL).", "sent2": "We treat authorship attribution as an anomaly detection problem where author regions are learned in feature space.", "label": 1}
{"sent1": "From a system evaluation perspective, pushing semantics into MT (b) is a necessity in order to complement the shallow methods currently used overcoming their limitations.", "sent2": "The parameters of the model are learned using a weakly supervised bootstrapping approach, without the need for manually tuned parameters or any other language expertise.", "label": 0}
{"sent1": "While high quality MT may increase productivity, post-editing poor translations can be a frustrating task which requires more effort than translating from scratch.", "sent2": "For this reason, estimating whether machine translations are of sufficient quality to be used for post-editing and finding means to reduce post-editing effort are an important field of study.", "label": 1}
{"sent1": "Controlled experiments using identical pre-processing, decoding, and weight tuning methods on standard system combination evaluation sets are presented.", "sent2": "This paper describes a systematic comparison of five well known hypothesis alignment algorithms for MT system combination via confusion network decoding.", "label": 1}
{"sent1": "Permutation parsers have been used to implement hierarchical re-ordering models (Galley and Manning, 2008) and to enforce inversion transduction grammar (ITG) constraints (Feng et al., 2010).", "sent2": "We present a number of theoretical results regarding the use of permutation parsers in PBSMT.", "label": 1}
{"sent1": "We address these issues by using Combinatory Categorial Grammar, or CCG, (Steedman, 2000), which has a much more flexible notion of constituency, thereby providing more labels for putative nonconstituent multiword translation phrases.", "sent2": "Structural information in language is important for obtaining a better understanding of a human communication (e.g., sentence segmentation, speaker turns, and topic segmentation).", "label": 0}
{"sent1": "We investigate the relation between color and concept, and color and emotion, reinforcing results from previous studies, as well as discovering new associations.", "sent2": "We also investigate cross-cultural differences in color-emotion associations between US and India-based annotators.", "label": 1}
{"sent1": "Applied to contiguous edit segments, our method achieves statistically significant improvements over a simple yet effective edit-distance baseline.", "sent2": "The approach is based on supervised machine learning using language model probabilities, string similarity measured over different representations of user edits, comparison of part-of-speech tags and named entities, and a set of adaptive features extracted from large amounts of unlabeled user edits.", "label": 1}
{"sent1": "In this study, phrase structure grammars and recurrent neural networks estimated both lexicalized and unlexicalized surprisal for words of independent sentences from narrative sources.", "sent2": "Finally, the results from our model more closely resemble human news summaries according to several metrics and are also preferred by human judges.", "label": 0}
{"sent1": "We use the Chinese Restaurant Process to automatically induce these frames from a massive amount of verb instances.", "sent2": "The small amount of high quality domain-specific terms is passed to the SMT system using the XML markup and the Fill-Up model methods, which produced a relative translation improvement up to 13% BLEU score points", "label": 0}
{"sent1": "We introduce novel features derived from semantic annotations based on FrameNet.", "sent2": "the current context for a word against a repository of contextual clues or glosses for each sense of each word.", "label": 0}
{"sent1": "The partially supervised nature of the problem leads us to define and approach it as the novel problem of partially supervised clustering.", "sent2": "linking together source mentions that refer to the same entity.", "label": 1}
{"sent1": "Using the overall density and precision of coherency in the corpus, the statistical estimation picks up appropriate polar atoms among candidates, without any manual tuning of the threshold values.", "sent2": "The experimental results show that the precision of polarity assignment with the automatically acquired lexicon was 94% on average, and our method is robust for corpora in diverse domains and for the size of the initial lexicon.", "label": 1}
{"sent1": "These  tweets were classified as to their habituality  status  using a bootstrapped, decision tree.", "sent2": "A corpus of more than  14 million tweets containing temporal duration  information  was  collected.", "label": 1}
{"sent1": "Events are complex linguistically and ontologically, so disambiguating their reference is challenging.", "sent2": "Interpreting news requires identifying its constituent events.", "label": 1}
{"sent1": "In this paper we develop a methodology that combines label propagation with constraint reasoning for temporal fact extraction.", "sent2": "Evaluations show that the model 1) matches a behavioral measure of semantics more closely, 2) can be used to predict corpus data for unseen words and 3) has predictive power that generalizes across brain imaging technologies and across subjects.", "label": 0}
{"sent1": "We propose a simple, efficient procedure in which part-of-speech tags are transferred from retrieval-result snippets to queries at training time.", "sent2": "Unlike previous work, our final model does not require any additional resources at run-time.", "label": 1}
{"sent1": "Yet many tasks focus on abstracts instead.", "sent2": "We take three schemes of different type and granularity (those based on section names, argumentative zones and conceptual structure of documents) and investigate their applicability to biomedical abstracts.", "label": 1}
{"sent1": "To move toward this objective, a method is proposed for reconstructing original semantic relationship graphs from projections, where each node and edge is mapped to the representative of its equivalence class, by determining the relationship argument combinations that represent real relationships.", "sent2": "The extraction of nested, semantically rich relationships of biological entities has recently gained popularity in the biomedical text mining community.", "label": 1}
{"sent1": "We also report encouraging correlations between the frequency of adverse drug reactions found by our system in unlabeled data and the frequency of documented adverse drug reactions.", "sent2": "We conclude that user comments pose a significant natural language processing challenge, but do contain useful extractable information which merits further exploration.", "label": 1}
{"sent1": "As an alternative, we propose two new models based on the BHMM in which sentence type is an observed variable which influences either emission or transition probabilities.", "sent2": "We first show that simply training a separate model for each sentence type decreases performance due to sparse data.", "label": 1}
{"sent1": "The emergence of domain languages is simulated using an empirically evaluated ACTR-based cognitive model of agents in a naming game played within communities.", "sent2": "Several community structures are examined (grids, trees, random graphs and small-world networks).", "label": 1}
{"sent1": "Unlike the McCarthy et al (2004) system, these methods can be used on relatively small target texts, without the need for a similarly-sensedistributed auxiliary text.", "sent2": "We perform an extensive evaluation using artificially generated thesaurus-sense-tagged data.", "label": 1}
{"sent1": "By formalizing memory capacity as beam-search in the parser, the model predicts gradience evident in human data.", "sent2": "To predict attachment behavior, the parser must be sensitive to the types of nominal intervenors that occur between a wh-filler and its head.", "label": 1}
{"sent1": "(1) they extract only relations that are mediated by verbs, and (2) they ignore context, thus extracting tuples that are not asserted as factual.", "sent2": "This paper presents OLLIE, a substantially improved Open IE system that addresses both these limitations.", "label": 1}
{"sent1": "We find that shallow approaches are as good as more computationally intensive alternatives with regards to two particular tests: (1) phrase similarity and (2) paraphrase detection.", "sent2": "This paper presents a semantic model for Chinese garden-path sentences.", "label": 0}
{"sent1": "The decoder iteratively generates new hypothesis corrections from current hypotheses and scores them based on features of grammatical correctness and fluency.", "sent2": "These features include scores from discriminative classifiers for specific error categories, such as articles and prepositions.", "label": 1}
{"sent1": "To this end, abstracts in evidence-based medicine can be labeled using a set of predefined medical categories, the socalled PICO criteria.", "sent2": "This requires efficient access to such evidence.", "label": 1}
{"sent1": "We use a large corpus of English learners?", "sent2": "Experimental analysis shows that our smoothing techniques improve coverage while keeping precision stable, and overall, that our top-performing model affects 9% of general web queries with 94% precision.", "label": 0}
{"sent1": "We show that Excitation is useful for extracting contradiction pairs (e.g., destroy cancer ?", "sent2": "prompt (Thomson and Wisowaty, 1999; Chu-Carroll and Carpenter, 1999; Gorin et al, 1997).", "label": 0}
{"sent1": "We show how one can use monolingual corpora, which are far more numerous and larger than bilingual corpora, to obtain paraphrases that rival in quality those derived directly from bilingual corpora.", "sent2": "While the former are regarded as a source of high-quality seed paraphrases, the latter are searched for paraphrases that match patterns learned from the seed paraphrases.", "label": 1}
{"sent1": "We present an empirically-based analysis of the semantic functions of discourse markers in dialogue.", "sent2": "By incorporating a mixture of labeled and unlabeled data, we are able to improve relation classification accuracy, reduce the need for annotated data, while still retaining the capacity to use labeled data to ensure that specific desired relations are learned.", "label": 0}
{"sent1": "While most annotation systems capture surface relationships, GLML captures the ?compositional history?", "sent2": "of the argument selection relative to the predicate.", "label": 1}
{"sent1": "This is especially true, as an author?s opinion is not always clearly marked.", "sent2": "One of the methods of the second set uses a classical technique in the field of artificial intelligence, the A* algorithm to obtain the suitable alignment.", "label": 0}
{"sent1": "the inferences they allow.", "sent2": "It combines standard ontological tools and formalisms with a formal semantic analysis and is hence more formalised and more detailed than existing lexical semantic resources like WordNet and FrameNet [Fellbaum, 1998, Baker et al, 1998].", "label": 1}
{"sent1": "This paper combines the two approaches and proposes an algorithm that provides a semantic order of terms based on a semantic relatedness measure.", "sent2": "This semantic order can be exploited by term weighting and term expansion methods.", "label": 1}
{"sent1": "We present ongoing work on two approaches to the automatic construction of ontologies from a flat database of records, and compare them to a manually constructed ontology.", "sent2": "views on the classes and relations of the domain at hand.", "label": 1}
{"sent1": "notion of presupposition in DRT.", "sent2": "Most existing approaches are either pipeline models of specific classifiers, usually subject to cascading errors, or joint structured models, more efficient but also more costly and more involved to train.", "label": 0}
{"sent1": "We then link them to existing, handcrafted ontologies, aligning them at the word-sense level.", "sent2": "Language comprehension, as with all other cases of the extraction of meaningful structure from perceptual input, takes places under noisy conditions.", "label": 0}
{"sent1": "The annotation scheme with a fully specified syntax and lexicon in the target English sentence yields a satisfactorily high agreement rate.", "sent2": "The Pearson correlation achieved is outperformed by other systems, due to the limitation of MT evaluation measures in the context of this task.", "label": 0}
{"sent1": "Detailed analysis shows that the joint method is able to choose such POS tags that are more helpful and discriminative from parsing viewpoint.", "sent2": "Experimental results on Chinese Penn Treebank 5 show that our joint models significantly improve the state-of-the-art parsing accuracy by about 1.5%.", "label": 1}
{"sent1": "By this new evaluation metric our algorithm achieves 60% error reduction on gold-standard input trees and 5% error reduction on state-ofthe-art machine-parsed input trees, when compared with the best previous work.", "sent2": "We find that our algorithm compares favorably with prior work on English using an existing evaluation metric, and also introduce and argue for a new dependency-based evaluation metric.", "label": 1}
{"sent1": "for perceptron with beam search (Collins and Roark, 2004).", "sent2": "We also propose several new update methods within this framework, among which the ?max-violation?", "label": 1}
{"sent1": "confidence that all relevant options have been presented (Demberg and Moore, 2006).", "sent2": "An evaluation in which participants rated dialogue transcripts showed that UMSR presents complex trade-offs understandably, provides users with a good overview of their options, and increases users?", "label": 1}
{"sent1": "The classification approach possesses other desirable characteristics, such as the ability to easily generalize beyond what was seen in training, the ability to train without human-annotated data, and the flexibility to adjust knowledge sources for individual error types.", "sent2": "Based on this analysis, we develop an algorithmic approach that combines the strengths of both methods.", "label": 1}
{"sent1": "Despite its simplicity, the system achieves competitive accuracies of 0.70?0.72 in detecting the sentiment of text messages.", "sent2": "Our approach extends standard clustering algorithms with cross-lingual mention and context similarity measures.", "label": 0}
{"sent1": "The dialogue manager and reference generation components then use situated references to explain the errors to the human users and provide solution strategies.", "sent2": "We explain dialogue management techniques for collaborative activities with humans, involving multiple concurrent tasks.", "label": 0}
{"sent1": "In this paper, we study the search logs of a public Swedish health portal to address the questions if health information seeking differs from other types of Internet search and if there is a potential for utilizing network analysis methods in combination with semantic annotation to gain insights into search behaviors.", "sent2": "Therefore, it is important that the portals are able to support this process as well as possible.", "label": 1}
{"sent1": "We report on findings from an analysis of language usage within a popular online discussion forum with participation of thousands of users spanning multiple years.", "sent2": "We find community norms of long time participants that are characterized by forum specific jargon and a style that is highly informal and shows familiarity with specific other participants and high emotional involvement in the discussion.", "label": 1}
{"sent1": "We extend past work in natural logic, which has focused on semantic containment and monotonicity, by incorporating both semantic exclusion and implicativity.", "sent2": "We propose a model of natural language inference which identifies valid inferences by their lexical and syntactic features, without full semantic interpretation.", "label": 1}
{"sent1": "Therefore, making use of generation resources promises some significant extensions in the kinds of annotation information that can be captured.", "sent2": "This task typically involves the learning of short range dependencies, which generally model the syntactic properties of a language and/or long range dependencies, which are semantic in nature.", "label": 0}
{"sent1": "To address this issue, in this paper we propose a novel method for normalizing and morphologically analyzing Japanese noisy text.", "sent2": "Finally, we feed the selected parses produced by each experiment to the full version of our semantic role labeler.", "label": 0}
{"sent1": "The integration of our domain-independent Spoken Dialogue System (SDS) framework into commercial products led to a major reengineering process.", "sent2": "Our work in this area started as a research project but when L2F joined TecnoVoz, a Portuguese national consortium including Academia and Industry partners, our focus shifted to real-time professional solutions.", "label": 1}
{"sent1": "Here we describe the methods we have developed to address this problem.", "sent2": "desired actions, then either the annotation is inaccurate or expensive retokenisation and reannotation will be required.", "label": 1}
{"sent1": "In contrast to earlier approaches to PPI extraction, the introduced alldependency-paths kernel has the capability to consider full, general dependency graphs.", "sent2": "The former is a deep-syntactic transfer-based system, the latter is a more-or-less standard statistical post-editing (SPE) applied on top of TECTOMT.", "label": 0}
{"sent1": "Various shallow features are extracted from these texts, and used to train statistical classifiers.", "sent2": "It occurs in tasks as diverse as name transliteration, spelling correction, pronunciation modeling and inflectional morphology.", "label": 0}
{"sent1": "This iterative annotation process is repeated until the estimated coverage reaches the desired level.", "sent2": "Unlike active learning approaches, our framework produces a named entity corpus that is free from the sampling bias introduced by the active strategy.", "label": 1}
{"sent1": "Furthermore, we were able to achieve 57.6% and 60.3% recall at 95% precision, and 58.9% and 49.1% precision at 90% recall.", "sent2": "Is it true that for each task there is a gain which roughly implies significance?", "label": 0}
{"sent1": "We evaluated performance of our NER on the standard JNLPBA-2004 data set.", "sent2": "The F-score on the test set has been improved from 73.14 to 73.78 after adding the protein names appearing in the training data to the POS tagger dictionary without any model retraining.", "label": 1}
{"sent1": "However, biomedical documents, especially full-length articles, often talk about entities across a number of species, in which case resolving species ambiguity becomes an indispensable part of TI.", "sent2": "This paper describes our rule-based and machine-learning based approaches to species disambiguation and demonstrates that performance of TI can be improved by over 20% if the correct species are known.", "label": 1}
{"sent1": "Previous approaches to resolving this problem have made use of a variety of knowledge sources including linguistic information (from the context in which the ambiguous term is used) and domain-specific resources (such as UMLS).", "sent2": "These ambiguities form a significant obstacle to the automatic processing of biomedical texts.", "label": 1}
{"sent1": "We train a CRF model to obtain a disfluency probability for each word.", "sent2": "We also automatically refine the syntactic categories given in our coarsely tagged input.", "label": 0}
{"sent1": "We also demonstrate how new sentiment word will benefit sentiment analysis.", "sent2": "The method is almost free of linguistic resources (except POS tags), and requires no elaborated linguistic rules.", "label": 1}
{"sent1": "We present experiments on five languages.", "sent2": "Despite its heuristic nature, the algorithm provides surprisingly competetive accuracies and running times against reference methods.", "label": 1}
{"sent1": ", then computing T ?", "sent2": "Existing knowledge-based question answering systems often rely on small annotated training data.", "label": 0}
{"sent1": "In this paper we present a feature transformation method named FFTM.", "sent2": "This method allows us to conduct experiments on a large dataset of unannotated data.", "label": 0}
{"sent1": "Examining these features individually, we show that we can uncover many of the same characteristics of agrammatic language that have been reported in studies using manual analysis.", "sent2": "Automatically identifying related specialist terms is a difficult and important task required to understand the lexical structure of language.", "label": 0}
{"sent1": "We propose a semi-supervised framework for generating a domain-specific sentiment lexicon and inferring sentiments at the segment level.", "sent2": "When a sentence s containing an unknown word u is to be tagged by a trained POS tagger, our algorithm collects from the web contexts that are partially similar to the context of u in s, which are then used to compute new tag assignment probabilities for u.", "label": 0}
{"sent1": "Based on these results, we explore the possibility of using annotation projection as a starting point for inexpensive data curation involving both experts and non-experts.", "sent2": "?X hit(s) Y ,?", "label": 0}
{"sent1": "Existing approaches are unable to capture subtle forms of context incongruity which lies at the heart of sarcasm.", "sent2": "We investigate an alternative paradigm that does not require labeled corpora, avoiding the domain dependence of ACEstyle algorithms, and allowing the use of corpora of any size.", "label": 0}
{"sent1": "We focus on a weakly supervised setting, in which only a small set of hashtags or phrases is labeled.", "sent2": "The factorization model allows us to determine which dimensions are important for a particular context, and adapt the dependency-based feature vector of the word accordingly.", "label": 0}
{"sent1": "This is an ideal application of NLP technologies, such as relation extraction, coreference resolution, and event detection.", "sent2": "We introduce a new and growing dataset, the Gun Violence Database, in order to facilitate the adaptation of current NLP technologies to the domain of gun violence, thus enabling better social science research on this important and under-resourced problem.", "label": 1}
{"sent1": "This information is particularly useful when the linguistic evidence is sparse, incomplete, or of dubious quality.", "sent2": "When considering a social media corpus, we often have access to structural information about how messages are flowing between people or organizations.", "label": 1}
{"sent1": "The comparative experiments on Support Vector Machines with such kernels on the CoNLL 2005 dataset show that very simple tree manipulations trigger automatic feature engineering that highly improves accuracy and efficiency in both phases.", "sent2": "In this paper, we study several tree kernel approaches for both boundary detection and argument classification.", "label": 1}
{"sent1": "In particular, Syntagmatic Kernels are defined by applying a Word Sequence Kernel to the local contexts of the words to be analyzed.", "sent2": "By accommodating a small number of vagueness quantifiers, we were able to extend our methodology to detecting vague sentences in Wikipedia articles.", "label": 0}
{"sent1": "We then use probabilistic planning to solve the MDP and generate a sentence that, with high probability, accomplishes the communicative goal.", "sent2": "We address appropriate user modeling in order to generate cooperative responses to each user in spoken dialogue systems.", "label": 0}
{"sent1": "The results show an unexploited opportunity of including prepositions and the relations they denote, e.g.", "sent2": "The experiments have been performed using an annotated extract of a corpus, consisting of prepositions surrounded by noun phrases, where the prepositions denote the relation we are trying disambiguate.", "label": 1}
{"sent1": "We use a system extending XQuery, the W3C-standard XML query language, with new axes that allow one to jump easily between different annotations of the same data.", "sent2": "This paper describes our approach to representing and querying multi-dimensional, possibly overlapping text annotations, as used in our question answering (QA) system.", "label": 1}
{"sent1": "pronouns with VP antecedents.", "sent2": "We extend the bound to sequence clustering, wherein classes represent longer context such as phrases.", "label": 0}
{"sent1": "We find that the proposed system is robust to disfluencies, so that a separate stage to elide disfluencies is not required.", "sent2": "events in 201112.", "label": 0}
{"sent1": "parsing, which makes parsing extremely fast.", "sent2": "The experiments show that the topic  features learned by LDA outperforms token features and more robust.", "label": 0}
{"sent1": "In this paper, we propose to use a lexicalized tree kernel based on the word embeddings created by a neural network model.", "sent2": "First, it is semantic based in that it takes as input a deep semantic representation rather than e.g., a sentence or a parse tree.", "label": 0}
{"sent1": "We first propose a new structure, termed augmented dependency path (ADP), which is composed of the shortest dependency path between two entities and the subtrees attached to the shortest path.", "sent2": "We propose to ?return the favor?", "label": 0}
{"sent1": "The approach further extends our prior work in that we also identify factual negated events.", "sent2": "(2012), which combines SVM cue classification with SVM-based ranking of syntactic constituents for scope resolution.", "label": 1}
{"sent1": "Following labeling, negated tokens are assigned to their respective cues using simple post-processing heuristics.", "sent2": "Models for scopes and events are created using lexical and syntactic features, together with a fine-grained set of labels that capture the scopal behavior of certain tokens.", "label": 1}
{"sent1": "The models are trained and tested using the dataset distributed with the *sem Shared Task 2012 on resolving the scope and focus of negation.", "sent2": "The system detects negation cues with 90.98% F1 measure (94.3% and 87.88% recall).", "label": 1}
{"sent1": "namely  the  SimpleTagger  library  in  the  MALLET machine learning toolkit.", "sent2": "We describe a nonparametric model and corresponding inference algorithm for learning Synchronous Context Free Grammar derivations for parallel text.", "label": 0}
{"sent1": "In this paper, we suggest a framework for evaluating inference-rule resources.", "sent2": "In this work we analyze a recently proposed agreement-constrained EM algorithm for unsupervised alignment models.", "label": 0}
{"sent1": "The model is formally a synchronous context-free grammar but is learned from a bitext without any syntactic information.", "sent2": "phrases that contain subphrases.", "label": 1}
{"sent1": "Finally, we point out problems with modeling the task in this way.", "sent2": "Comparable to the state-of-the-art system combination technique, joint decoding achieves an absolute improvement of 1.5 BLEU points over individual decoding.", "label": 0}
{"sent1": "We collect lexical resources for a multitude of semantic categories from a variety of biomedical domain sources.", "sent2": "We integrate string matching results into machine learning-based disambiguation through the use of a novel set of features that represent the distance of a given textual span to the closest match in each of a collection of lexical resources.", "label": 1}
{"sent1": "Model 2 by adding lexicalization and subcategorization.", "sent2": "Moreover, this algorithm can work on large grammars and datasets and infers correctly even from small samples.", "label": 0}
{"sent1": "The Hinoki treebank is a Redwoods-style treebank of Japanese dictionary definition sentences.", "sent2": "In this paper we present a quantitative and qualitative analysis of annotation in the Hinoki treebank of Japanese, and investigate a method of speeding annotation by using part-of-speech tags.", "label": 1}
{"sent1": "Following a Bayesian framework, the goal is finding the posterior distribution of the grammar given the relative frequencies of input-output pairs.", "sent2": "?ve alignment-based methods.", "label": 0}
{"sent1": "We show that the new technique can be intuitively understood as exploiting implicit negative evidence and is computationally efficient.", "sent2": "While some transport companies or repositories make some of this information accessible, it is not easy to find, and the majority of information about uncommon places can only be found in web free text such as blogs and forums.", "label": 0}
{"sent1": "We demonstrate that for certain field structured extraction tasks, such as classified advertisements and bibliographic citations, small amounts of prior knowledge can be used to learn effective models in a primarily unsupervised fashion.", "sent2": "The applicability of many current information extraction techniques is severely limited by the need for supervised training data.", "label": 1}
{"sent1": "These techniques have demonstrated the effectiveness and flexibility required of a commercial web search.", "sent2": "However, manually labeled training data (with multiple absolute grades) has become the bottleneck for training a quality ranking function, particularly for a new domain.", "label": 1}
{"sent1": "We apply the technique of pseudo relevance feedback to obtain expansion terms from definition clusters.", "sent2": "In this paper, we present in details our method in three main steps: 1) the document segmentation into sentences, 2) the removal of the sentences exempt of renaming act (false positives) using both a gene nomenclature and supervised machine learning (feature selection and SVM), 3) the linking of gene names by the target renaming relation in each sentence.", "label": 0}
{"sent1": "In this paper we present our approach of augmenting task-oriented dialogs with selected explanation dialogs to foster the humancomputer trust relationship in those kinds of situations.", "sent2": "IR views language as an open-ended set of mostly stable signs with which texts can be indexed and retrieved, focusing more on a text?s potential relevance than its potential meaning.", "label": 0}
{"sent1": "foreign language predicate-argument structures into a resource-rich language like English.", "sent2": "VSMs are models based on continuous word representations embedded in a vector space.", "label": 0}
{"sent1": "Current techniques for this task typically bootstrap a classifier based on a fixed seed set.", "sent2": "The system then iteratively suggests a series of candidate words, which the user can either accept or reject.", "label": 1}
{"sent1": "The tractability of the resulting POMDP can be preserved using a mechanism for dynamically constraining the action space based on prior knowledge over locally relevant dialogue structures.", "sent2": "Distributional semantics creates vectorspace representations that capture many forms of semantic similarity, but their relation to semantic entailment has been less clear.", "label": 0}
{"sent1": "We test our model on parsing the English Penn WSJ treebank using a re-ranking framework.", "sent2": "This technique allows us to efficiently test our model without needing a specialized parser, and to use the standard evaluation metric on the original Phrase Structure version of the treebank.", "label": 1}
{"sent1": "We formulate the objective function as the posterior probability of the training corpus according to a generative segmentation-translation model.", "sent2": "We tackle the previously unaddressed problem of unsupervised determination of the optimal morphological segmentation for statistical machine translation (SMT) and propose a segmentation metric that takes into account both sides of the SMT training corpus.", "label": 1}
{"sent1": "Our experimental syllabification method exhibited a reliable performance, and allowed for the acquisition of syllabic tokens from the corpus.", "sent2": "Consequently, the syllabic tokens were integrated in a tool for clinicians, a result which holds the potential of contributing to the current state of speech motor training methodologies.", "label": 1}
{"sent1": "In this paper we investigate a novel problem of discovering patterns based on emotion and the association of moods and affective lexicon usage in blogosphere, a representative for social media.", "sent2": "The definitions of two coreference scoring metrics?B 3 and CEAF?are underspecified with respect to predicted, as opposed to key (or gold) mentions.", "label": 0}
{"sent1": "In this paper, we propose a framework for figurative language use detection.", "sent2": "This framework is based on the idea of sense differentiation.", "label": 1}
{"sent1": "Being able to automatically identify, from a corpus of monolingual text, which word tokens are being used in a previously unseen sense has applications to machine translation and other tasks sensitive to lexical semantics.", "sent2": "We present a visual user interface supporting the investigation of a set of linguistic features discriminating between pass and fail ?English as a Second or Other Language?", "label": 0}
{"sent1": "We exploit document-level geotags to indirectly generate training instances for text classifiers for toponym resolution, and show that textual cues can be straightforwardly integrated with other commonly used ones.", "sent2": "Results are given for both 19th century texts pertaining to the American Civil War and 20th century newswire articles.", "label": 1}
{"sent1": "However, the relatively flat structure of the French Treebank does appear to have an adverse effect, and this is significantly improved by simple transformations of the French trees.", "sent2": "We propose a general approach for translating Chinese unknown words (UNK) for SMT.", "label": 0}
{"sent1": "Although recent approaches achieve satisfactory accuracy results, they typically suffer from at least one of the following issues: (1) the linking quality is highly sensitive to the amount of textual information; typically, long textual fragments are needed to capture the context of a mention, (2) the disambiguation uncertainty is not explicitly addressed and often only implicitly represented by the ranking of entities to which a mention could be linked, (3) complex, joint reasoning negatively affects the efficiency.", "sent2": "In experiments in the SemEval-2015 TimeLine task we show that our distantly supervised approach matches the state-of-the-art performance while joint inference further improves on it by 3.2 F-score points.", "label": 0}
{"sent1": "We draw upon ideas from the information seeking paradigm of Exploratory Search (ES) to enable an exploration process in which users begin with a vaguely defined information need and progressively sharpen their definition of extraction tasks as they identify relations of interest in the underlying data.", "sent2": "In this paper, we propose and demonstrate Exploratory Relation Extraction (ERE), a novel approach to identifying and extracting relations from large text corpora based on user-driven and data-guided incremental exploration.", "label": 1}
{"sent1": "respectively, then there is more likely a ?DirectorOf?", "sent2": "and ?FILM?", "label": 1}
{"sent1": "In this paper, we propose a novel constituent-based approach to argument labeling, which integrates the advantages of both linear tagging and subtree extraction.", "sent2": "In particular, the proposed approach unifies intra- and intersentence cases by treating the immediately preceding sentence as a special constituent.", "label": 1}
{"sent1": "For example, punctuation and entity tags in Wikipedia data define some word boundaries in a sentence.", "sent2": "Using a modified version of the Contenders Algorithm (Riggle, 2004b), we verify that Turbid Spreading makes typologically valid predictions about the types of harmony processes that may appear in natural language.", "label": 0}
{"sent1": "We also introduce a LWFG parser as a deductive system, used as an inference engine during LWFG induction.", "sent2": "An image and its caption convey different information, but are generated by the same underlying concepts.", "label": 0}
{"sent1": "Texts are parsed to obtain phrase-structures, and compared with texts to be analyzed.", "sent2": "Contrary to much previous work in stylometry, we focus on content words rather than function words.", "label": 1}
{"sent1": "One constructs a nearest-neighbor similarity graph over all trigrams of labeled and unlabeled data for propagating syntactic information, i.e., label distributions.", "sent2": "Our experiment results indicate that eye gaze provides a potential channel for automatically acquiring new words.", "label": 0}
{"sent1": "Overall this leads to a model which learns translations of entire sentences, while also learning their decomposition into smaller units (phrase-pairs) recursively, terminating at word translations.", "sent2": "Our experiments on Arabic, Urdu and Farsi to English demonstrate improvements over competitive baseline systems.", "label": 1}
{"sent1": "Our approach clusters candidate slot fillers to identify meaningful template slots.", "sent2": "We address the task of automatic discovery of information extraction template from a given text collection.", "label": 1}
{"sent1": "A neural network is a reasonable method to address these pitfalls.", "sent2": "Although the log-linear model achieves success in SMT, it still suffers from some limitations: (1) the features are required to be linear with respect to the model itself; (2) features cannot be further interpreted to reach their potential.", "label": 1}
{"sent1": "In particular, we train a Bayesian phrasal inversion transduction grammars for each domain separately.", "sent2": "The learned phrase tables are hierarchically combined as if they are drawn from a hierarchical Pitman-Yor process.", "label": 1}
{"sent1": "Free-text annotations are becoming increasingly abundant, due to the recent dramatic growth in semistructured, user-generated online content.", "sent2": "An example of such content is product reviews, which are often annotated by their authors with pros/cons keyphrases such as ?a real bargain?", "label": 1}
{"sent1": "In this paper we exploit the vast resource of images available on the web.", "sent2": "We create a database of pictures that are naturally embedded into news articles and propose to use their captions as a proxy for annotation keywords.", "label": 1}
{"sent1": "This method can extract long tail instances of semantic relations like causality from rare and complex expressions in a large JapaneseWeb corpus?", "sent2": "During inference of the probabilistic model, we use posterior expectation constraints to require that a minimum proportion of the dependencies we infer be instances of these rules.", "label": 0}
{"sent1": "a fundamental problem in aspect-based sentiment summarization (Hu and Liu, 2004a).", "sent2": "This system uses a corpus of 2,500 compounds annotated with WordNet senses and covering 139 different semantic relations.", "label": 0}
{"sent1": "We devise a gold-standard sense- and parse tree-annotated dataset based on the intersection of the Penn Treebank and SemCor, and experiment with different approaches to both semantic representation and disambiguation.", "sent2": "This paper shows that semantic classes help to obtain significant improvement in both parsing and PP attachment tasks.", "label": 1}
{"sent1": "Our classifier uses semantic smoothing kernels that can encode information from knowledge bases such as Wordnet, NELL and Freebase.com.", "sent2": "Our experiments on two spoken language corpora show that augmenting semantic information from these knowledge bases gives about 30% absolute improvement in task prediction over a parserbased method.", "label": 1}
{"sent1": "?test?", "sent2": "vs.", "label": 1}
{"sent1": "We examine issues in the different approaches, including linguistic irregularities, caption repetition, and data set overlap.", "sent2": "By combining key aspects of the ME and RNN methods, we achieve a new record performance over previously published results on the benchmark COCO dataset.", "label": 1}
{"sent1": "Based on a detailed example of a gesticulated circular trajectory, we present a data-driven approach that covers parts of the semantic reconstruction by making use of motion capturing (mocap) technology.", "sent2": "17 18 Bender and Goss-Grubbs", "label": 0}
{"sent1": "the strategy typically employed by existing search strategies ?", "sent2": "Due to the enormity of the search space, error analysis has indicated that it is often impossible to get to a desired embedded segment purely through binary segmentation that divides existing segmental rules in half ?", "label": 1}
{"sent1": "Bilingual terminals are special cases of bilingual constituents, where a vector represents either (1) a bilingual token?a token-totoken or ?word-to-word?", "sent2": "These features are applied to the Arabic, Chinese and English coreference resolution systems and their effectiveness is evaluated on data from the Automatic Content Extraction (ACE) task.", "label": 0}
{"sent1": "In our experiments, this method achieves comparable results with the standard model.", "sent2": "We present a light-weight tool, SPIED, to aid IE system developers in learning entities using patterns with bootstrapping, and visualizing the learned entities and patterns with explanations.", "label": 0}
{"sent1": "Nonetheless, our method performs robustly on both cases.", "sent2": "We show that English-French pairs of terms are highly transliterated in contrast to the EnglishChinese pairs.", "label": 1}
{"sent1": "In this paper, we propose Sentiment based Comparability Measures (SCM) to compare opinions in multilingual comparable articles without translating source/target into the same language.", "sent2": "An off-the-shelf implementation of the linear chain CRF model was used.", "label": 0}
{"sent1": "The algorithm ranks the candidate sentence pairs by means of a customized metric, which combines different similarity criteria.", "sent2": "Moreover, these words seem to show two different types of ambiguity: one depending on non-local context and another on right context.", "label": 0}
{"sent1": "Using these probabilities and corpus-based frequencies we calculate a plausibility measure for each generated reading given a dictionary entry, based on the naive Bayes model.", "sent2": "In response to a reading input, we calculate the plausibility of each dictionary entry corresponding to the reading and display a list of candidates for the user to choose from.", "label": 1}
{"sent1": "However, they do not indicate what kind of tools can be used by each module.", "sent2": "Nevertheless, we believe that certain tools widely used by the AI or NLU community are appropriate for NLG tasks.", "label": 1}
{"sent1": "It appears that the main reason for the drop in retrieval performance is that correct compounds and collocations are preserved by accurate segmenters, while they are broken up by less accurate (but reasonable) segmenters, to a surprising advantage.", "sent2": "Each paraphrase pair in PPDB contains a set of associated scores, including paraphrase probabilities derived from the bitext data and a variety of monolingual distributional similarity scores computed from the Google n-grams and the Annotated Gigaword corpus.", "label": 0}
{"sent1": "We learn a hierarchical classifier that is guided by a layered semantic hierarchy of answer types, and eventually classifies questions into finegrained classes.", "sent2": "We show accurate results on a large collection of free-form questions used in TREC 10.", "label": 1}
{"sent1": "However, it is unclear whether synchronous rewriting is a necessary feature.", "sent2": "However, there have been few attempts to explain skipping behavior with computational models, as most existing work has focused on predicting reading times (e.g., using surprisal).", "label": 0}
{"sent1": "Furthermore,  we  show  how  the  use  of  hard constraints and soft constraints helps  us  build  an  efficient  and  robust  hybrid  parser.", "sent2": "In the first stage, we train an SVM classifier to detect contradiction pattern pairs in a large web archive by exploiting the excitation polarity (Hashimoto et al., 2012) of the patterns.", "label": 0}
{"sent1": "This information, however, is not always a sufficient indicator of a topical shift, especially for certain genres.", "sent2": "This paper explores an additional source of information.", "label": 1}
{"sent1": "Even with second-order features or latent variables, which would make exact parsing considerably slower or NP-hard, BP needs only O(n3) time with a small constant factor.", "sent2": "As a parsing algorithm, BP is both asymptotically and empirically efficient.", "label": 1}
{"sent1": "neighborhood information to encourage similar tweets to have adjacent binary codes.", "sent2": "Second, we leverage the tweets?", "label": 1}
{"sent1": "We evaluate our embeddings using the word similarity measurement and show that our approach is significantly better in capturing the sense-level word similarities.", "sent2": "Results show that both methods reliably generate utterances that vary along the extraversion dimension, according to human judges.", "label": 0}
{"sent1": "We then extract skill connections between skills from the same person.", "sent2": "To well integrate various kinds of connections, we propose a joint prediction factor graph (JPFG) model to collectively infer personal skills with help of personal connection factor, skill connection factor, besides the normal textual attributes.", "label": 1}
{"sent1": "It is hard to determine which scheme is better because they reflect different views of dependency analysis.", "sent2": "For languages such as English, several constituent-to-dependency conversion schemes are proposed to construct corpora for dependency parsing.", "label": 1}
{"sent1": "This paper revisits an assumption that genre variation is continuous along multiple dimensions, and an early use of principal component analysis to find these dimensions.", "sent2": "Results on a very heterogeneous corpus of post1990s American English reveal four major dimensions, three of which echo those found in prior work and the fourth depending on features not used in the earlier study.", "label": 1}
{"sent1": "These lists are retrieved periodically by submitting multiple implicit queries derived from the pronounced words.", "sent2": "Each query is related to one of the topics identified in the conversation fragment preceding the recommendation, and is submitted to a search engine over the English Wikipedia.", "label": 1}
{"sent1": "Japan.", "sent2": "Correct stress placement is important in text-to-speech systems, in terms of both the overall accuracy and the naturalness of pronunciation.", "label": 0}
{"sent1": "However,  it  also  produces bad N-grams that  affect the language models' performance.", "sent2": "This  approach  boosts  N-gram  counts  and  generates  new  N-grams.", "label": 1}
{"sent1": "The second approach collects English MWEs from Princeton WordNet 3.0, translates the collection into Arabic using Google Translate, and utilizes different search engines to validate the output.", "sent2": "Modern statistical machine translation (SMT) systems usually use a linear combination of features to model the quality of each translation hypothesis.", "label": 0}
{"sent1": "The three components are responsible for the three distinct tasks of 1) generating observations or features, 2) training a statistical model based on the generated features, and 3) tagging unlabelled data with the model.", "sent2": "People vary widely in their temporal orientation?how often they emphasize the past, present, and future?and this affects their finances, health, and happiness.", "label": 0}
{"sent1": "The system uses an unsupervised approach based on rule-based opinion target detecting and unsupervised clustering techniques.", "sent2": "The system is open source and is freely available for download.", "label": 1}
{"sent1": "This work presents an application that shows how a set of heterogeneous automatic metrics can be used to evaluate a test bed of automatic translations.", "sent2": "This model allows easy integration of context-specific features.", "label": 0}
{"sent1": "This dataset is larger and more varied than previous REG datasets and allows us to study referring expressions in real-world scenes.", "sent2": "To date, the game has produced a dataset containing 130,525 expressions, referring to 96,654 distinct objects, in 19,894 photographs of natural scenes.", "label": 1}
{"sent1": "Recent works for extracting taxonomic relations from text focused on collecting lexical-syntactic patterns to extract the taxonomic relations by matching the patterns to text.", "sent2": "Taxonomies are the backbone of many structured, semantic knowledge resources.", "label": 1}
{"sent1": "We provide precise, empirical confirmation of previously hypothesised sources of recall loss in slot filling.", "sent2": "Named Entity Recognition (NER) is the task of identifying and classifying all proper nouns in a document as person names, organization names, location names, date & time expressions and miscellaneous.", "label": 0}
{"sent1": "While there have been attempts to overcome this limitation using Markov Logic Networks (MLNs), it remains challenging to perform joint inference in MLNs when the model encodes many high-dimensional sophisticated features such as those essential for event extraction.", "sent2": "We present an iterative technique to generate phrase tables for SMT, which is based on force-aligning the training data with a modified translation decoder.", "label": 0}
{"sent1": "idea, our joint model firstly combines two generative models, which are word-based hierarchical Dirichlet process model and character-based hidden Markov model, by simply multiplying their probabilities together.", "sent2": "We further show that we can use these paraphrases to generate surface patterns for relation extraction.", "label": 0}
{"sent1": "Our experiments demonstrate that morphemes improve overall performance of KWS systems.", "sent2": "Our system obtained an F-score of 11.03 on the official test set using the M2 evaluation method (the official evaluation method).", "label": 0}
{"sent1": "Free word order languages like Sanskrit pose more problems for constituency parses since the elements within a phrase are dislocated.", "sent2": "While the constituency trees mark the relations due to positions, the dependency relations mark the semantic dependencies.", "label": 1}
{"sent1": "Current research on uncertainty detection has mostly focused on the English language, in contrast, here we present the first machine learning algorithm that aims at identifying linguistic markers of uncertainty in Hungarian texts from two domains: Wikipedia and news media.", "sent2": "For instance, in information retrieval, it is of primary importance to distinguish among factual, negated and uncertain information.", "label": 1}
{"sent1": "The Bayesian framework provides a principled way to incorporate additional features such as cue phrases, a powerful indicator of discourse structure that has not been previously used in unsupervised segmentation systems.", "sent2": "This contrasts with previous approaches, which relied on hand-crafted cohesion metrics.", "label": 1}
{"sent1": "However, recently developed cross-lingually harmonized annotation schemes remove this obstacle and restore the abilities of syntactic annotation projection.", "sent2": "When humans speak they often use grammatically incorrect sentences, which is a problem for grammar-based language processing methods, since they expect input that is valid for the grammar.", "label": 0}
{"sent1": "Semantic patterns are useful for a variety of text understanding tasks, in particular for locating events in text for information extraction.", "sent2": "Linguistic research on multilingual societies has indicated that there is usually a preferred language for expression of emotion and sentiment (Dewaele, 2010).", "label": 0}
{"sent1": "Thus, opinion targets should be separated into entities and aspects before use because they represent very different things about opinions.", "sent2": "The paper then describes our data collection and annotation approach.", "label": 0}
{"sent1": ".", "sent2": ".", "label": 1}
{"sent1": "Certainly, a troll can be somebody who teases people to make them angry, or somebody who offends people, or somebody who wants to dominate any single discussion, or somebody who tries to manipulate people?s opinion (sometimes for money), etc.", "sent2": "Experimental results show that a combination RNNLM system outperforms all previous reported results on several standard G2P test sets.", "label": 0}
{"sent1": "Instead, we split a sentence at punctuation and impose parsing restrictions over its fragments.", "sent2": "Our grammar inducer is trained on the Wall Street Journal (WSJ) and achieves 59.5% accuracy out-of-domain (Brown sentences with 100 or fewer words), more than 6% higher than the previous best results.", "label": 1}
{"sent1": "In particular, we explore different ways of updating parameters given a training example.", "sent2": "We first discuss several challenges to error-driven discriminative approaches.", "label": 1}
{"sent1": "Thus, we have examined a method to estimate the state of a dialog user by capturing the user?s non-verbal behavior even when the user?s utterance is not observed.", "sent2": "To help these users before they give up, the system should know why they could not make an utterance.", "label": 1}
{"sent1": "We experimentally show that using the proposed framework incorporating all features outperforms previous work by 17%.", "sent2": "We propose a new method of selecting hypotheses for machine transliteration.", "label": 0}
{"sent1": "In this paper we investigate the applicability of part-of-speech tagging to typical Englishlanguage web search-engine queries and the potential value of these tags for improving search results.", "sent2": "Web-search queries are known to be short, but little else is known about their structure.", "label": 1}
{"sent1": "The SHERLOCK system, described herein, is a first-order learner that acquires over 30,000 Horn clauses from Web text.", "sent2": "SHERLOCK embodies several innovations, including a novel rule scoring function based on Statistical Relevance (Salmon et al, 1971) which is effective on ambiguous, noisy and incomplete Web extractions.", "label": 1}
{"sent1": "The main objective of our participation was to test RAMSES, an open source phrasebased decoder.", "sent2": "It has recently been shown that different NLP models can be effectively combined using dual decomposition.", "label": 0}
{"sent1": "We apply the information-retrieval metrics of precision and recall to evaluate the accuracy and coverage of our database with respect to a human-produced gold standard.", "sent2": "Thus, the research reported herein overlaps heavily with that of the machine-translation, lexicon-construction, and information-retrieval communities.", "label": 1}
{"sent1": "We also show that class-instance extraction can be significantly improved by adding semantic information in the form of instance-attribute edges derived from an independently developed knowledge base.", "sent2": "Within the research field of parsing with lexicalized grammars such as HPSG, recent developments have achieved efficient estimation of probabilistic models and high-speed parsing guided by probabilistic models.", "label": 0}
{"sent1": "In particular, the problems arising from student use of non-standard terminology appear to have negative consequences.", "sent2": "We describe an evaluation of an error recovery policy in the BEETLE II tutorial dialogue system and discuss how different types of interpretation problems affect learning gain and user satisfaction.", "label": 1}
{"sent1": "Our system uses daily newspaper articles to predict shifts in public opinion as reflected in prediction markets.", "sent2": "Most text simplification systems are based on hand-written rules (e.g., PEST (Carroll et al, 1999) and its module SYSTAR (Canning et al, 2000)), and therefore face limitations scaling and transferring across domains.", "label": 0}
{"sent1": "We provide results on three new test sets in Spanish, Farsi, and Russian.", "sent2": "Most previous approaches to syntactic parsing of Chinese rely on a preprocessing step of word segmentation, thereby assuming there was a clearly defined boundary between morphology and syntax in Chinese.", "label": 0}
{"sent1": "We evaluate performance on a newly gathered corpus of algebra word problems, demonstrating that the system can correctly answer almost 70% of the questions in the dataset.", "sent2": "We address the challenge of evaluating the emergent model with a qualitative visualization and an intrinsic conversation ordering task.", "label": 0}
{"sent1": "We have employed an HMM statistical framework for both speech recognition and synthesis which provides transformation mechanisms to adapt the synthesized voice in TTS (text-to-speech) using the recognized voice in ASR (automatic speech recognition).", "sent2": "As MT becomes increasingly desired for more and more language pairs and more and more domains, it becomes necessary to build test sets for each case.", "label": 0}
{"sent1": "Our function word model assumes that function words appear at the left periphery, and while this is true of languages such as English, it is not true universally.", "sent2": "This modification improves unsupervised word segmentation on the standard BernsteinRatner (1987) corpus of child-directed English by more than 4% token f-score compared to a model identical except that it does not special-case ?function words?, setting a new state-of-the-art of 92.4% token f-score.", "label": 1}
{"sent1": "By exploiting tag embeddings and tensorbased transformation, MMTNN has the ability to model complicated interactions between tags and context characters.", "sent2": "In this paper, we propose a novel neural network model for Chinese word segmentation called Max-Margin Tensor Neural Network (MMTNN).", "label": 1}
{"sent1": "In this paper, we address the problems of automatic identification of bilingual terminology using Wikipedia as a lexical resource, and its integration into an SMT system.", "sent2": "The automatic translation of domain-specific documents is often a hard task for generic Statistical Machine Translation (SMT) systems, which are not able to correctly translate the large number of terms encountered in the text.", "label": 1}
{"sent1": "Then, using a Phrase-Based Statistical Machine Translation model, we create a bilingual terminology with the extracted monolingual term lists.", "sent2": "In this paper, we apply a log-likelihood comparison method to extract monolingual terminology from the source and target sides of a parallel corpus.", "label": 1}
{"sent1": "Fortunately, there are currently several terminology management tools capable of assisting interpreters before and during an interpretation service.", "sent2": "They require this information prior to an interpretation and have it accessible during the interpreting service.", "label": 1}
{"sent1": "perception on the usefulness of automatic termlists.", "sent2": "We also investigate interpreters?", "label": 1}
{"sent1": "First, we use chunks to refine the set of word alignments typically used as a starting point in SMT systems.", "sent2": "Second, we extend an N -grambased SMT system with chunk tags to better account for long-distance reorderings.", "label": 1}
{"sent1": "It also provides a new perspective on ?quick-checking?", "sent2": "and related heuristics, which seems to confirm that forcing an early failure (as opposed to seeking an early guarantee of success) is in fact the best approach to use.", "label": 1}
{"sent1": "Each approach is based on a particular model for the patterns to be acquired, such as a predicate-argument structure or a dependency chain.", "sent2": "The algorithm we propose uses a word graph, along with optimization techniques such as decaying windows and pruning.", "label": 0}
{"sent1": "Experiment results have shown that a system that exploits the proposed method performs sufficiently and that holding multiple candidates for understanding results is effective.", "sent2": "Unlike conventional methods that use hand-crafted rules, the proposed method enables easy design of the discourse understanding process.", "label": 1}
{"sent1": "The main contribution of this research is in devising a divide-and-conquer strategy to alleviate the speech recognition errors.", "sent2": "This paper discusses the challenges and proposes a solution to performing information retrieval on the Web using Chinese natural language speech query.", "label": 1}
{"sent1": "We obtained reasonable classification accuracy for all dimensions.", "sent2": "Moreover, the models are automatically derived by decision tree learning using real dialogue data collected by the system.", "label": 1}
{"sent1": "Recent work on another aspect of multi-paragraph text, discourse markers, indicates it is time to consider where a discourse marker insertion algorithm fits in.", "sent2": "A  training  corpus  of  40,247  tokens  is  utilized  to  train  the  model.", "label": 0}
{"sent1": "We start from existing collocations to form lexical predicates (e.g., break ?)", "sent2": "We present SPred, a novel method for the creation of large repositories of semantic predicates.", "label": 1}
{"sent1": "We show that model summaries (1) are more abstractive and make use of more sentence aggregation, (2) do not contain as many topical caseframes as system summaries, and (3) cannot be reconstructed solely from the source text, but can be if texts from in-domain documents are added.", "sent2": "These results suggest that substantial improvements are unlikely to result from better optimizing centrality-based criteria, but rather more domain knowledge is needed.", "label": 1}
{"sent1": "Due to their extended notion of context, CRFs are able to take the global utterance context into account and are less constrained by local features than other realisers.", "sent2": "We empirically evaluate our approach in two tasks of link prediction and triple classification.", "label": 0}
{"sent1": "In this paper, we propose Two-Neighbor Orientation (TNO) model that jointly models the orientation decisions between anchors and two neighboring multi-unit chunks which may cross phrase or rule boundaries.", "sent2": "Our parser, which is simpler to implement than an upward-propagating best-first parser, is correct for a wide range of parser control strategies and maintains worst-case cubic time.", "label": 0}
{"sent1": "In this paper, we focus on further improving the performance of the reordering model (and thereby machine translation) by using a larger corpus of sentence aligned data for which manual word alignments are not available but automatic machine generated alignments are available.", "sent2": "Named entity recognition (NER) systems trained on newswire perform very badly when tested on Twitter.", "label": 0}
{"sent1": "Then, for each phrase pair extracted from the training data, we create a vector with features defined in the same way, and calculate its similarity score with the vector representing the dev set.", "sent2": "This profile might, for instance, be a vector with a dimensionality equal to the number of training subcorpora; each entry in the vector reflects the contribution of a particular subcorpus to all the phrase pairs that can be extracted from the dev set.", "label": 1}
{"sent1": "We then build and compare several classifiers that learn from the user?s responses to predict the relevance scores for new events.", "sent2": "Second, to obtain measures of utility, we build an environment that allows users to interact with the system by rating the analyzed content.", "label": 1}
{"sent1": "Given such pairs, we ask: which version attracts more retweets?", "sent2": "This turns out to be a more difficult task than predicting popular topics.", "label": 1}
{"sent1": "In addition, the content of tweets can be critical for distinguishing the role and importance of a user.", "sent2": "In this work, we explore Twitter user classification using context and content cues.", "label": 1}
{"sent1": "The proposed method is built on the principles of terminology extraction and distributional semantics.", "sent2": "It is realized as a regression task in a vector space model.", "label": 1}
{"sent1": "In contrast, this paper explores techniques for extracting terms fitting a broader definition: noun sequences specific to topics and not well-known to naive adults.", "sent2": "votes and perplexity of opinion language.", "label": 0}
{"sent1": "We are interested in whether adhering to writing principles is related to scientific quality, scientific domain or gender and whether these relations change over time.", "sent2": "Our results show (i) a clear relation between journal quality and scientific imprecision, i.e.", "label": 1}
{"sent1": "Our findings show that less granularity of the POS tagset leads to better tagging results.", "sent2": "But it is patently not reasonable if one?s task is to retrieve a short snippet of speech in a domain where WER?s can be as high as 50%; such would be the situation with teleconference speech, where one?s task is to find if and when a participant uttered a certain phrase.", "label": 0}
{"sent1": "We also design the first provably optimal dynamic oracle for constituency parsing, which runs in amortized O(1) time, compared to O(n3) oracles for standard dependency parsing.", "sent2": "We include an experimental evaluation that compares the two kinds of models independently of any MT system to investigate the possible potential of integrating a deep syntax language model into Hierarchical SMT systems.", "label": 0}
{"sent1": "However, when the corpus of tree/string pairs is small compared to the size of the vocabulary or the complexity of the grammar, word-alignments are unreliable.", "sent2": "scores to a Spearman correlation of ?", "label": 0}
{"sent1": "The network is designed to incorporate two signals: the similarity between conjuncts and the observation that replacing the whole coordination phrase with a conjunct tends to produce a coherent sentences.", "sent2": "The modeling makes use of several LSTM networks.", "label": 1}
{"sent1": "We apply the technique to learning of famous generative model, the dependency model with valence (Klein and Manning, 2004).", "sent2": "As the form of the subordinated verb depends heavily on the conjunction in the subordinated Spanish clause and the semantics of the main verb, we extracted this information from two treebanks and trained different classifiers on this data.", "label": 0}
{"sent1": "We explore two approaches for event status classification: (1) a feature-based SVM classifier augmented with a novel induced lexicon of future-oriented verbs, such as ?threatened?", "sent2": "We show that the temporal status of these events is difficult to classify because local tense and aspect cues are often lacking, time expressions are insufficient, and the linguistic contexts have rich semantic compositionality.", "label": 1}
{"sent1": "To address the lack of representation power, we propose NESTIE, which uses a nested representation to extract higher-order relations, and complex, interdependent assertions.", "sent2": "The experiments show that RCNN is very effective to improve the state-of-the-art dependency parsing on both English and Chinese datasets.", "label": 0}
{"sent1": "First, treebased position features are proposed to encode the relative positions of words in dependency trees and help enhance the word representations.", "sent2": "In this work, we offer a new perspective on utilizing syntactic information of dependency parse tree and present a position encoding convolutional neural network (PECNN) based on dependency parse tree for relation classification.", "label": 1}
{"sent1": "Our model explains human reading behavior as a tradeoff between precision of language understanding (encoding the input accurately) and economy of attention (fixating as few words as possible).", "sent2": "In this paper, we propose a novel approach that models both skipping and reading, using an unsupervised architecture that combines a neural attention with autoencoding, trained on raw text using reinforcement learning.", "label": 1}
{"sent1": "Specifically, we compare pitch accent identification at the syllable, vowel or word level as domains for analysis of acoustic indicators of accent.", "sent2": "A comparison to likelihood training demonstrates that expected BLEU is vastly more effective.", "label": 0}
{"sent1": "In a final step the ?seed?", "sent2": "clusters are combined with the results of the clustering algorithms.", "label": 1}
{"sent1": "We propose a loglinear model to compute the paraphrase likelihood of two patterns and exploit feature functions based on maximum likelihood estimation (MLE) and lexical weighting (LW).", "sent2": "Using the presented method, we extract over 1,000,000 pairs of paraphrase patterns from 2M bilingual sentence pairs, the precision of which exceeds 67%.", "label": 1}
{"sent1": "Each source of information is represented by kernel functions.", "sent2": "In particular, five basic kernel functions are linearly combined and weighted under different conditions.", "label": 1}
{"sent1": "Results from these classifiers served as features for a combined classifier.", "sent2": "Different classifiers were trained on the Mascara data set to determine which values for the context sizes n1, n2, and n3 yield the highest accuracy (n1 = 4, n2 = 3, and n3 = 7, determined with the leave-oneout method).", "label": 1}
{"sent1": "This way (i) effective structural relational patterns can be automatically learned with kernel machines; and (ii) structures are more invariant w.r.t.", "sent2": "different domains, thus fostering adaptability.", "label": 1}
{"sent1": "Second, we describe an efficient algorithm to perform inference and learning in this model.", "sent2": "Third, we apply our proposed method on two large datasets (108 tokens, 105 words types), and demonstrate that classes induced by our algorithm improve performance over Brown clustering on the task of semisupervised supersense tagging and named entity recognition.", "label": 1}
{"sent1": "However, common to most existing work, words are regarded as independent entities without any explicit relationship among morphologically related words being modeled.", "sent2": "As a result, rare and complex words are often poorly estimated, and all unknown words are represented in a rather crude way using only one or a few vectors.", "label": 1}
{"sent1": "This paper provides evidence that the addition of a vector disambiguation step prior to the actual composition would be beneficial to the whole process, producing better composite representations.", "sent2": "We introduce an LSTM model that hierarchically builds an embedding for a paragraph from embeddings for sentences and words, then decodes this embedding to reconstruct the original paragraph.", "label": 0}
{"sent1": "This work can be thought of as re-casting open domain information extraction: rather than growing a database of known facts, we smooth this data into a database in which any possible fact has membership with some confidence.", "sent2": "We evaluate our system predicting held out facts, achieving 74.2% accuracy and outperforming multiple baselines.", "label": 1}
{"sent1": "Up till now, however, most of the evaluation has been done on monolithic corpora such as the Penn Treebank, the Proposition Bank.", "sent2": "be ?", "label": 0}
{"sent1": "Further, we incorporate a large set of surface string variations for each entity by using anchor texts from the web that link to the entity.", "sent2": "On the other hand, topic modeling maps documents onto a low-dimensional topic space, by utilizing the global word collocation patterns in the same document.", "label": 0}
{"sent1": "However, previous work has failed to address the problem of false negative training examples mislabeled due to the incompleteness of knowledge bases.", "sent2": "Until recently, surface generation in dialogue systems has served the purpose of simply providing a backend to other areas of research.", "label": 0}
{"sent1": "Substantial gains have been demonstrated in previous works, which employ standard ngram language models.", "sent2": "We show how a large number of highly predictive features can be easily incorporated into the CRF, and demonstrate that even with only a few hundred word-aligned training sentences, our model improves over the current state-ofthe-art with alignment error rates of 5.29 and 25.8 for the two tasks respectively.", "label": 0}
{"sent1": "Streaming and sorting enables the algorithm to scale to much larger models by using a fixed amount of RAM and variable amount of disk.", "sent2": "We present an efficient algorithm to estimate large modified Kneser-Ney models including interpolation.", "label": 1}
{"sent1": "Thus, our approach is well-suited to the causal constraint of spoken conversations.", "sent2": "On an English-to-Iraqi CSLT task, the proposed approach gives significant improvements over a baseline system as measured by BLEU, TER, and NIST.", "label": 1}
{"sent1": "to refer linguistic expression which is commonly called ?metaphor?.", "sent2": "oped as a possible substitute to the Tarskian truth conditional semantics.", "label": 1}
{"sent1": "We demonstrate the application of statistical machine translation techniques to ?translate?", "sent2": "the phonemic representation of an English name, obtained by using an automatic text-to-speech system, to a sequence of initials and finals, commonly used subword units of pronunciation for Chinese.", "label": 1}
{"sent1": "The process is intended to be language-independent, and to provide human-readable generalizations of paradigms.", "sent2": "Our system extracts generalizations from inflection tables, representing the resulting paradigms in an abstract form.", "label": 1}
{"sent1": "We present an approach for translation into a compounding language that splits compounds into simple words for training and, due to an underspecified representation, allows for free merging of simple words into compounds after translation.", "sent2": "In contrast to previous approaches, we use features projected from the source language to predict compound mergings.", "label": 1}
{"sent1": "popular in many Web applications.", "sent2": "regions of the hypothesis to reveal a cloud of words simlar to the ?tag clouds?", "label": 1}
{"sent1": "Tag sets and color schemes can easily be adapted to the needs of specific annotation projects through configuration files.", "sent2": "Different text colors are used to indicate which words in a given sentence pair have already been aligned, and which ones still need to be aligned.", "label": 1}
{"sent1": "In this paper, we present image clustering as an example to illustrate how unsupervised learning can be improved by transferring knowledge from auxiliary heterogeneous data obtained from the social Web.", "sent2": "By letting multiple segmenters vote, our model improves segmentation consistently on the four different data sets from the second SIGHAN bakeoff.", "label": 0}
{"sent1": "This paper examines the case for a graded notion of word meaning in two experiments, one which uses WordNet senses in a graded fashion, contrasted with the ?winner takes all?", "sent2": "An evaluation using three different and independent data sets reveals promising results and indicate that the grammar of authors is a significant feature to enhance modern authorship attribution methods.", "label": 0}
{"sent1": "We also propose feature functions that naturally combine and weight these criteria, based on the training data.", "sent2": "This paper explores several criteria for generalizing semantic roles in FrameNet: role hierarchy, human-understandable descriptors of roles, semantic types of filler phrases, and mappings from FrameNet roles to thematic roles of VerbNet.", "label": 1}
{"sent1": "We evaluate our algorithm on PropBank10, achieving a precision of 56%, as opposed to 47% of a strong baseline.", "sent2": "The algorithm makes use of a fully unsupervised syntactic parser, using its output in order to detect clauses and gather candidate argument collocation statistics.", "label": 1}
{"sent1": "Most previously developed systems are CFG-based and make extensive use of a treepath feature, which suffers from data sparsity due to its use of explicit tree configurations.", "sent2": "This paper introduces three Temporal Correspondence Heuristics, that characterize regularities in parallel news streams, and shows how they may be used to generate high precision paraphrases for event relations.", "label": 0}
{"sent1": "First we propose to employ an iteratively trained target grammar parser to perform grammar formalism conversion, eliminating predefined heuristic rules as required in previous methods.", "sent2": "We begin by describing a graph propagation framework inspired by previous work on constructing polarity lexicons from lexical graphs (Kim and Hovy, 2004; Hu and Liu, 2004; Esuli and Sabastiani, 2009; BlairGoldensohn et al, 2008; Rao and Ravichandran, 2009).", "label": 0}
{"sent1": "A simple statistical machine translation method, word-by-word decoding, where not a parallel corpus but a bilingual lexicon is necessary, is adopted for the treebank translation.", "sent2": "Most work has formalized Named Entity Recognition as a sequential labeling problem, in which only local information is utilized for the label estimation, and thus a long named entity consisting of several morphemes tends to be wrongly recognized.", "label": 0}
{"sent1": "Such phenomena produce discontinuous constituents, which are not naturally modelled by projective phrase structure trees.", "sent2": "or ?no?", "label": 0}
{"sent1": "By representing textual documents as graph-of-words instead of historical n-gram bag-of-words, we extract more discriminative features that correspond to long-distance n-grams through frequent subgraph mining.", "sent2": "Moreover, by capitalizing on the concept of k-core, we reduce the graph representation to its densest part ?", "label": 1}
{"sent1": "However, the previous neural models cannot extract the complicated feature compositions as the traditional methods with discrete features.", "sent2": "Recently, neural network models for natural language processing tasks have been increasingly focused on for their ability of alleviating the burden of manual feature engineering.", "label": 1}
{"sent1": "Although a number of semi-supervised methods have been proposed, their effectiveness on NLP tasks is not always clear.", "sent2": "Using our proposed model, we observe improvements on two tasks, neural machine translation on the Europarl English to French parallel corpora and text summarization on the Gigaword dataset.", "label": 0}
{"sent1": "Error-correcting CRF training is much less resource intensive and has a much faster training time than a standardly formulated CRF, while decoding performance remains quite comparable.", "sent2": "This suggests that in principle it is feasible to align the parallel parse trees with somemodification of existing syntactic annotation guidelines.", "label": 0}
{"sent1": "This model is an extension of PCFG in which non-terminal symbols are augmented with latent variables.", "sent2": "This paper defines a generative probabilistic model of parse trees, which we call PCFG-LA.", "label": 1}
{"sent1": "is intuitively closer to ?four stars?", "sent2": "This involves the form interface on the Web, the XML DocBook encoding, and the XSL stylesheets used to present the catalogue either on the Web or in print.", "label": 0}
{"sent1": "We also propose a criterion for parameter selection on the basis of magnetization.", "sent2": "Given only a small number of seed words, the proposed method extracts semantic orientations with high accuracy in the experiments on English lexicon.", "label": 1}
{"sent1": "from one or more translation engines which could be substituted into our translation templates.", "sent2": "Based on the generation parse tree of the RBMT system and standard word alignment computation, we identify potential ?translation snippets?", "label": 1}
{"sent1": "The best modified SMT systems improve the translation of connectives without degrading BLEU scores.", "sent2": "Labeled connectives are then used into SMT systems either by modifying their phrase table, or by training them on labeled corpora.", "label": 1}
{"sent1": "However, it is largely unclear how these black-box techniques exactly capture word meaning.", "sent2": "Our research aims to extract information about medication use from veterinary discussion forums.", "label": 0}
{"sent1": "Using machine learning techniques, we investigate whether this tendency can be predicted from high-level dialogue features, such as backchannels, overlap and each participant?s proportion of talk.", "sent2": "The results indicate that these features are not predictive of a patient?s adherence to treatment or satisfaction with the communication, although they do have some association with symptoms.", "label": 1}
{"sent1": "Yet existing semantic grammars fail to do so.", "sent2": "Section 2 gives an overview of the structure of the dynamic morphological model, which is constructed through two complementary processes: a Morphological Process?section 3?and a Lexicographic Process?section 4.", "label": 0}
{"sent1": "We define a paraphrase probability that allows paraphrases extracted from a bilingual parallel corpus to be ranked using translation probabilities, and show how it can be refined to take contextual information into account.", "sent2": "Using alignment techniques from phrasebased statistical machine translation, we show how paraphrases in one language can be identified using a phrase in another language as a pivot.", "label": 1}
{"sent1": "The system incorporates a decision-tree classifier for 30 SCF types which tests for the presence of grammatical relations (GRs) in the output of a robust statistical parser.", "sent2": "We compare two types of statistical models for this task: a) local models, which predict a single class for an input; and b), sequential models, which align a sequence of classes to a sequence of input tokens.", "label": 0}
{"sent1": "Our method does not rely on complex linguistic resources, and apart from a hand coded system, we do not use any languagedependent tools.", "sent2": "The only information we use is automatically extracted from the documents, without human intervention.", "label": 1}
{"sent1": "A failure analysis points out factors that could contribute to improvements in both precision and recall, including pattern generalisation, pattern pruning, and term matching.", "sent2": "The experiments show that meronyms can be extracted using these patterns.", "label": 1}
{"sent1": "In this paper, we mimic a scanning process to extract biographical facts.", "sent2": "Verb roots are classified by the types of their radicals and the stems they generate.", "label": 0}
{"sent1": "The model is then used to classify the unknown Named Entities in the test set.", "sent2": "words which typically co-occur in certain syntactic positions with the members of that class.", "label": 1}
{"sent1": "Our work aims at providing useful insights into the the computational complexity of those problems.", "sent2": "We prove that while IBM Models 1-2 are conceptually and computationally simple, computations involving the higher (and more useful) models are hard.", "label": 1}
{"sent1": "To create the confusion network, we produce pairwise word alignments of the original machine translation hypotheses with an enhanced statistical alignment algorithm that explicitly models word reordering.", "sent2": "Similarly to the well-established ROVER approach of (Fiscus, 1997) for combining speech recognition hypotheses, the consensus translation is computed by voting on a confusion network.", "label": 1}
{"sent1": "The constraints are evaluated experimentally using data from the Prague Dependency Treebank and the Danish Dependency Treebank.", "sent2": "However, previous work on incremental NLG has not employed recent advances in statistical optimisation using machine learning.", "label": 0}
{"sent1": "We have explored statistical models that use different representational units for parsing.", "sent2": "called inflectional groups.", "label": 1}
{"sent1": "Starting from an existing baseline system we demonstrate that utilizing limited closed world knowledge can effectively eliminate ?dangerous?", "sent2": "or plainly wrong rules during the bootstrapping process.", "label": 1}
{"sent1": "We show the parameter estimation algorithm of this model.", "sent2": "The translation gives an intensional counterpart to previous extensional models.", "label": 0}
{"sent1": "Our model compares favorably with current state-of-the-art sequence labeling approaches.", "sent2": "Using official dataset for noun phrase (NP) chunking as a case study, the resulting optimizer converges to the same quality of solution over an order of magnitude faster than the structured sequential minimal optimization (structured SMO).", "label": 1}
{"sent1": "When integrated into the treebanking environment, the model brings a significant annotation speed-up with improved inter-annotator agreement.", "sent2": "Intuitively, with the appropriate treatment of MWEs, the results of an Information Retrieval (IR) system could be improved.", "label": 0}
{"sent1": "Parsers based on lexicalised grammar formalisms, such as TAG and CCG, can be made more efficient using supertagging, which for CCG is so effective that every derivation consistent with the supertagger output can be stored in a packed chart.", "sent2": "We describe QUEST, an open source framework for machine translation quality estimation.", "label": 0}
{"sent1": "One is to use these predicted implicit connectives as additional features in a supervised model.", "sent2": "The other is to perform implicit relation recognition based only on these predicted connectives.", "label": 1}
{"sent1": "This pragmatic approach is computationally efficient.", "sent2": "We participated in three language pairs, French?English, Russian?", "label": 0}
{"sent1": "We tackle the problem by introducing a re-parametrization in which the unknown distribution is distilled to a single scalar.", "sent2": "Second, a context-analysis step increases precision by including contextual information from the sentence in the extractions.", "label": 0}
{"sent1": "The annotated dataset contains about 1213 sentences which describe 612 images of the CLEF IAPR TC-12 Image Benchmark.", "sent2": "We have one participant system with two runs.", "label": 1}
{"sent1": "The goal of this task is to identify the dependency structure of Chinese sentences from the semantic view.", "sent2": "The selectors serve for the system to essentially learn the areas or concepts of WordNet that the sense of a target word should be a part of.", "label": 0}
{"sent1": "However, existing topic models generally cannot capture the latent topical structures in documents.", "sent2": "We evaluate the learned types by measuring their prediction accuracy for verb arguments in several domains.", "label": 0}
{"sent1": "This paper extends previous work to wordto-word selectional preferences by using webscale data.", "sent2": "By representing the model assumptions with a factor graph, we shed light on the optimization problems tackled in each method.", "label": 0}
{"sent1": "Then, by using both sets of examples, a support vector machine based classifier determined whether two terms (t1 and t2) were equivalent.", "sent2": "First, we automatically collected both positive examples (sets of equivalent term pairs) and negative examples (sets of inequivalent term pairs).", "label": 1}
{"sent1": "These words can be content words or proper nouns.", "sent2": "Experiments on three data sets for text categorization demonstrated that our method increases the accuracy for text categorization with a reasonable cost.", "label": 0}
{"sent1": "Also, there are tagging errors, multiple tags assigned in many cases, and some words have not been tagged.", "sent2": "We explore the performance of models with varying amounts of training data and find that with about 34,500 labeled tokens, we can outperform a reasonable baseline trained on over 99,000 tokens and achieve an accuracy of just over 80%.", "label": 0}
{"sent1": "Using the compositional translation method improved the results, but still shows some limits for MWTs of different syntactic structures.", "sent2": "We argue such sentences are semantically consistent with the query.", "label": 0}
{"sent1": "Consequently, novelties are rare in this small sub-field of term extraction.", "sent2": "Our model is novel in that it integrates information from separate sequential models, using global potentials that encourage the extracted event records to have desired properties.", "label": 0}
{"sent1": "We compare the performance of the new representation against the old one on a clustering task.", "sent2": "We end with a metric which is composed of weighted metrics at individual layers, which correlates very well with human judgment.", "label": 0}
{"sent1": "Of these, we have focused on two, i.e., equivalence and transition.", "sent2": "A pair of sentences in different newspaper articles on an event can have one of several relations.", "label": 1}
{"sent1": "The algorithm is informed by the results of two different summarization strategies and an offthe-shelf named entity recognition component.", "sent2": "Unlike conventional methods that use hand-crafted rules, the proposed method enables easy design of the discourse understanding process.", "label": 0}
{"sent1": "A context-sensitive clustering framework is then applied to obtain meaningful tuple clusters by examining their intrinsic and extrinsic similarities.", "sent2": "A certain number of these sentences are then selected as representatives according to their semantic similarity value with relation to the topic.", "label": 0}
{"sent1": "Cross language text categorization has attracted more and more attention for the organization of these heterogeneous document collections.", "sent2": "For many languages, a CFG is derived from a large-scale syntactically annotated corpus, and many parsing algorithms using CFGs have been proposed.", "label": 0}
{"sent1": "In this work, we consider embeddings for social media users and demonstrate that these can be used to identify users who behave similarly or to predict attributes of users.", "sent2": "These embeddings are used to identify similar words or make predictions about documents.", "label": 1}
{"sent1": "We build on their work by suggesting a more appropriate regularization for denoising autoencoders.", "sent2": "In contrast to previous works using pre-defined taskspecific features with fixed values, we dynamically extract representations of label distributions from both an in-domain corpus and an out-of-domain corpus.", "label": 0}
{"sent1": "In this paper, we show that linear mixture models can reliably improve translation quality in very heterogeneous training conditions, even if the mixtures do not use any domain knowledge and attempt to learn generic models rather than adapt them to the target domain.", "sent2": "This surprising finding opens new perspectives for using mixture models in machine translation beyond clear cut domain adaptation tasks.", "label": 1}
{"sent1": "The results show that lexical features such as word unigrams and character n-grams have more discriminative power in genre classification compared to features such as part-of-speech n-grams and text statistics.", "sent2": "In a second set of experiments, with the aim of learning from the neighbouring web pages, we investigated the performance of a semi-supervised graphbased model, which is a novel technique in genre classification.", "label": 1}
{"sent1": "Metrics over permutations exist (e.g., Kendal tau or Spearman Rho) and have been shown to be useful in earlier work.", "sent2": "However, none of the existing metrics over permutations groups word positions recursively into larger phrase-like blocks, which makes it difficult to account for long-distance reordering phenomena.", "label": 1}
{"sent1": "This leads to a kind of sparsity problem: candidate role-fillers for different senses of the verb end up being measured by the same ?yardstick?, the single prototypical role-filler.", "sent2": "The dependency annotation of Czech is done from plain text by automatic procedures.", "label": 0}
{"sent1": "Moreover, this architecture readily handles different segmentation tasks, such as morphological segmentation for Arabic and word segmentation for Chinese.", "sent2": "Specifically, we employ a randomized greedy algorithm that jointly predicts segmentations, POS tags and dependency trees.", "label": 1}
{"sent1": "We describe a new algorithm for incremental transition-based Combinatory Categorial Grammar parsing.", "sent2": "Part of speech taggers based on Hidden Markov Models rely on a series of hypotheses which make certain errors inevitable.", "label": 0}
{"sent1": "In addition, we incorporate semantic relatedness as additional features into the popular entity-based model of Barzilay and Lapata (2008).", "sent2": "First, in the unsupervised framework, we introduce semantic relatedness as an enrichment to the original graph-based model of Guinaudeau and Strube (2013).", "label": 1}
{"sent1": "However, newswire data, the primary source of existing coreference data, lack the richness necessary to truly solve coreference.", "sent2": "We present a new domain with denser references?quiz bowl questions?that is challenging and enjoyable to humans, and we use the quiz bowl community to develop a new coreference dataset, together with an annotation framework that can tag any text data with coreferences and named entities.", "label": 1}
{"sent1": "In this paper, we demonstrate the effectiveness of Abstract Meaning Representation (AMR) (Banarescu et al., 2013) to select high quality sets of entity ?collaborators?", "sent2": "to feed a simple similarity measure (Jaccard) to link entity mentions.", "label": 1}
{"sent1": "We compare it with two state-of-the-art systems and show that it can attain comparable quality when trained on a small dataset.", "sent2": "Its generalization capabilities also allow it to leverage much more data, leading to substantial quality improvements.", "label": 1}
{"sent1": "Our tensor-based approach rivals the best performing system on the CoNLL-2009 shared task.", "sent2": "The freshness of documents ranked for such queries is generally of critical importance.", "label": 0}
{"sent1": "It differs from recent related work by jointly performing word sense discrimination and embedding learning, by non-parametrically estimating the number of senses per word type, and by its efficiency and scalability.", "sent2": "We present an extension to the Skip-gram model that efficiently learns multiple embeddings per word type.", "label": 1}
{"sent1": "We address in this paper a lexical setting that allows for the straightforward incorporation of rich features and structural constraints.", "sent2": "We explore a lexical event ordering task, namely determining the likely temporal order of events based solely on the identity of their predicates and arguments.", "label": 1}
{"sent1": "We perform search by using an SMT decoder in forced decoding mode to produce a bag-ofwords representation of the target documents to be ranked.", "sent2": "In this paper, we present an attempt to turn this situation on its head: Instead of the retrieval aspect, we emphasize the translation component in CLIR.", "label": 1}
{"sent1": "In this paper, we provide solutions to each of these challenges and outline a new human evaluation methodology aimed specifically at assessment of segment-level metrics.", "sent2": "We discuss the differences between the datasets and how the algorithm uses them (e.g., for the Amazon dataset the algorithm makes use of structured information).", "label": 0}
{"sent1": "We learn weighted edit distance in a probabilistic finite state machine (pFSM) model, where state transitions correspond to edit operations.", "sent2": "Our proposed metric (SPEDE) computes probabilistic edit distance as predictions of translation quality.", "label": 1}
{"sent1": "The most successful regression methods had an RMSE of 0.86 and were trained with a feature set given by Correlation-based Feature Selection.", "sent2": "The Quality Estimation problem was addressed both as a regression task and as a discretised classification task, but the latter did not generalise well on the unseen testset.", "label": 1}
{"sent1": "We present a proof-of-concept study in the domain of Information Presentation (IP), where a learning agent faces the trade-off of whether to present information as soon as it is available (for high reactiveness) or else to wait until input ASR hypotheses are more reliable.", "sent2": "Results show that the agent learns to avoid long waiting times, fillers and self-corrections, by re-ordering content based on its confidence.", "label": 1}
{"sent1": "In this work, we formulate the optimization of the choices based on a unified criterion: Bayes risk, which is defined based on reward for correct information presentation and penalty for redundant turns.", "sent2": "The system also has several choices in generating responses or confirmations.", "label": 1}
{"sent1": "However, when we expand our attention to more analytic languages whose degree of pro-dropping is more free, CCG?s decomposition rule for dealing with gapping becomes incapable of parsing some patterns of intra-sentential ellipses in serial verb construction.", "sent2": "The high quality of the selected training data allows us to obtain very accurate translation outputs close to the top performing SMT systems.", "label": 0}
{"sent1": "Our solution is to exploit the sparsity of features, and express a model structure for each object by using a sparse graph.", "sent2": "We can thereby apply the junction tree algorithm, allowing for efficient exact inference on sparse graphs.", "label": 1}
{"sent1": "Compounds are handled by splitting them prior to training, and merging the parts after translation.", "sent2": "In this paper we present a model we refer to as Importance-Driven Turn-Bidding that treats turn-taking as a negotiative process.", "label": 0}
{"sent1": "The most challenging problem is to incorporate the semantic information in a theoretically sound and rigorous manner and to modify the standard interpretation of the VSM.", "sent2": "We investigate the impact of different levels of preprocessing settings on the SSA classification task.", "label": 0}
{"sent1": "The algorithm designed specifically to deal with imbalanced datasets for most types outperforms the standard classifier.", "sent2": "Statistical machine translation systems are usually trained on large amounts of bilingual text and monolingual text in the target language.", "label": 0}
{"sent1": "We convert the clusters into graphs, add smoothing/syntacticinformation-carrier vertices, and compute the similarity between phrases with a random walk-based measure, the commute time.", "sent2": "This paper presents a novel approach to lattice-based spoken document retrieval using statistical language models: a statistical model is estimated for each document, and probabilities derived from the document models are directly used to measure relevance.", "label": 0}
{"sent1": "This intuition is encoded as a distance-dependent CRP with a distance between two syntactic signatures indicating how likely they are to correspond to a single semantic role.", "sent2": "We propose a novel semantic parsing framework for question answering using a knowledge base.", "label": 0}
{"sent1": "We observe that in the assortative vowel communities the constituent nodes (read vowels) are largely uncorrelated in terms of their features indicating that they are formed based on the principle of maximal perceptual contrast.", "sent2": "Through this network we identify communities of vowels, which essentially reflect their patterns of co-occurrence across languages.", "label": 1}
{"sent1": "We evaluate their (combined) performance on various data sets.", "sent2": "However, earlier observations that the combination of features improves the overall accuracy could be replicated only partly.", "label": 1}
{"sent1": "First, we summarize our semantic logical-based approach which proved successful in the previous two challenges.", "sent2": "It is important to note that we developed this method when the standard (confusion network-based) system combination is ineffective such as in the case when the input is only two.", "label": 0}
{"sent1": "SLIM?s framework incorporates a range of resources that solve local entailment problems.", "sent2": "We compare two approaches to the problem of Textual Entailment: SLIM, a compositional approach modeling the task based on identifying relations in the entailment pair, and BoLI, a lexical matching algorithm.", "label": 1}
{"sent1": "However, these efforts have suffered from inadequate bag of words vector representations.", "sent2": "We show the effectiveness of this algorithm through experiments on largescale hyponymy-relation acquisition from Japanese Wikipedia and Web texts.", "label": 0}
{"sent1": "In order to cope with inevitable knowledge gaps, a cost function is used to measure the remaining ?distance?", "sent2": "Event schemas have important connections to early NLP research on frames and scripts, as well as modern applications like template extraction.", "label": 0}
{"sent1": "Motivated by theories of language transfer, NLI is the task of identifying a writer?s native language (L1) based on their writings in a second language (the L2).", "sent2": "An NLI system was applied to Chinese learner texts using topicindependent syntactic models to assess their accuracy.", "label": 1}
{"sent1": "This model ranks all candidate mentions based on scores which denote the degree of relevancy to target entities.", "sent2": "Furthermore, this graph based model could utilize reference pages of target entities.", "label": 1}
{"sent1": "The experiments were carried out using support vector machines as a classifier.", "sent2": "Each source of information is represented by a specific kernel function.", "label": 1}
{"sent1": "a word?s prior polarity) is a challenging task for sentiment analysis.", "sent2": "This paper investigates the effect of different explanatory variables on the performance of a phrase-based system for 110 European language pairs.", "label": 0}
{"sent1": "This is a two-fold process.", "sent2": "First, we propose rules for transforming a rhetorical structure theorybased discourse tree into a dependency-based discourse tree, which allows us to take a treetrimming approach to summarization.", "label": 1}
{"sent1": "To address this problem, we propose a hierarchical entity-based approach for structuralizing UGC in social media.", "sent2": "We firstly introduce the motivation of providing Chinese semantic dependency parsing task, and then describe the task in detail including data preparation, data format, task evaluation, and so on.", "label": 0}
{"sent1": "We tackle this problem in two ways: First, we build a coarse mapping from phrases to predicates using a knowledge base and a large text corpus.", "sent2": "Second, we use a bridging operation to generate additional predicates based on neighboring predicates.", "label": 1}
{"sent1": "For example, even simple phrases such as ?daughter?", "sent2": "This type of question has been traditionally addressed by qualitative studies in philology and literary theory.", "label": 0}
{"sent1": "We then use the generated target chains to provide constraints for word selection in document-level machine translation through the two proposed lexical chain based cohesion models.", "sent2": "We compute lexical chains for each source document to be translated and generate target lexical chains based on the computed source chains via maximum entropy classifiers.", "label": 1}
{"sent1": "We examine finitestate and SMT-based methods for these related tasks, and demonstrate that the tasks have different characteristics ?", "sent2": "This paper presents experiments on the use of machine translation output for technical translation.", "label": 0}
{"sent1": "The purpose of this paper is to generalise these ideas to tensor-based models, where relational words such as verbs and adjectives are represented by linear maps (higher order tensors) acting on a number of arguments (vectors).", "sent2": "We describe the creation of a new domain for the Methodius Natural Language Generation System, and an evaluation of Methodius?", "label": 0}
{"sent1": "The degree of two words having a specific relation can then be measured through simple linear algebraic operations.", "sent2": "Two ranking tables with different evaluation measures were calculated by the task organizers, every table with two baselines and six runs submitted by different teams.", "label": 0}
{"sent1": "The paper systematically introduces and describes all key elements of the bootstrapping procedure: (1) starting point or seed lexicon, (2) the confidence estimation and selection of new dimensions of the space, and (3) convergence.", "sent2": "Experimental results showed that the topdown method is more than 10 times faster than a method using the CYK algorithm.", "label": 0}
{"sent1": "Inside sentences, syntagmatic associations and paradigmatic associations can be used to characterize the relations between words or word pairs.", "sent2": "It is possible to compute such similarities based on the occurrences of words in actual sentences.", "label": 1}
{"sent1": "The traditional linguistic experiment methodwhich is used to exploremental lexicon has some disadvantages.", "sent2": "Mental lexicon plays a central role in human language competence and inspires the creation of new lexical resources.", "label": 1}
{"sent1": "In this paper, we propose a computational method based on bootstrapping and corpus statistics to automatically associate English words with senses.", "sent2": "We also apply our approach to the task of detecting the contextdependent sentiment of individual words and phrases within a message.", "label": 0}
{"sent1": "This paper presents the progress of an ongoing project on the construction of an e-dictionary of Chinese classifiers.", "sent2": "Learners often find that existing dictionaries either do not have classifiers as lexical entries, or give very brief explanations that are hardly helpful.", "label": 1}
{"sent1": "This paper describes how morphological knowledge is presently being introduced into the fr-LN through the implementation and lexicographic exploitation of a dynamic morphological model.", "sent2": "We propose two neural network architectures: one that handles standard two-way selectional preferences and one that is able to deal with multi-way selectional preferences.", "label": 0}
{"sent1": "Not every sentence is written strongly from a perspective.", "sent2": "To accomplish that, we present a novel representation of the temporal structure of a news article based on time intervals.", "label": 0}
{"sent1": "We apply this model to a large corpus of over 400000 words of written English, and evaluate the results using EVALB.", "sent2": "In this paper, we describe a simplified model of distributional analysis which uses heuristics to reduce the number of candidate constituents under consideration.", "label": 1}
{"sent1": "We also demonstrate that an implementation of this algorithm is capable of learning auxiliary fronting in polar interrogatives (AFIPI) in English.", "sent2": "We present a simple context-free grammatical inference algorithm, and prove that it is capable of learning an interesting subclass of context-free languages.", "label": 1}
{"sent1": "Although such features can improve model accuracy, they can also introduce hidden negative effects.", "sent2": "Approaches to such tasks often involve the use of maximum entropy-style models, where gazetteers usually appear as highly informative features in the model.", "label": 1}
{"sent1": "Acknowledgement Many thanks to Amit Dubey and Yuval Krymolowski, the other two organizers of the shared task, for discussions, converting treebanks, writing software and helping with the papers.2 1see http://ilps.science.uva.nl/?erikt/signll/conll/ 2Thanks also to Alexander Yeh for additional help with the paper reviews.", "sent2": "A particular example is presented that uses a specific graph representation of the logical contents of sentences.", "label": 0}
{"sent1": "Third, the problems have been filtered to remove a fraction that are easily solved by simple baselines, while remaining 84% solvable by humans.", "sent2": "Our results show that our approach achieves 80.0% F-Score accuracy compared to an F-Score of 66.7% produced by a state-of-the-art semantic parser on a dataset of input format specifications from the ACM International Collegiate Programming Contest (which were written in English for humans with no intention of providing support for automated processing).1", "label": 0}
{"sent1": "Our model outperforms previous work on a conditional language modeling task over a large corpus of naturalistic color descriptions.", "sent2": "We present herein an efficient algorithm for learning an L1 regularized logistic regression model with combination features.", "label": 0}
{"sent1": "Without the guide of explicit discourse connectives, the relation of sentence pairs are very hard to be inferred.", "sent2": "We present a model for detecting user disengagement during spoken dialogue interactions.", "label": 0}
{"sent1": "Flexible non-terminals have been proposed as a promising solution for this problem.", "sent2": "We explore here the relationship between protein/gene names and expressions used to characterize protein/gene function.", "label": 0}
{"sent1": "In this paper, we propose a novel approach to finding translations for oov words.", "sent2": "We induce a lexicon by constructing a graph on source language monolingual text and employ a graph propagation technique in order to find translations for all the source language phrases.", "label": 1}
{"sent1": "For a set of essays written by college graduates on a number of general topics, we show that the higher scoring essays tend to have higher percentages of both highly associated and dis-associated pairs, and lower percentages of mildly associated pairs of words.", "sent2": "We present a study of the relationship between quality of writing and word association profiles.", "label": 1}
{"sent1": "We view different patent classes and different patent text sections such as title, abstract, and claims, as separate translation tasks, and investigate the influence of such tasks on machine translation performance.", "sent2": "In this paper we analyze patents along the orthogonal dimensions of topic and textual structure.", "label": 1}
{"sent1": "This paper contradicts this claim and argues that the evolution of German case is driven by the need to optimize the cognitive effort and memory required for processing and interpretation.", "sent2": "the senses, of the words.", "label": 0}
{"sent1": "These rules are treated as discrete and independent events.", "sent2": "In this short paper, we propose a novel method to model rules as observed generation output of a compact hidden model, which leads to better generalization capability.", "label": 1}
{"sent1": "Our method is simpler in implementation.", "sent2": "Our methods make use of log likelihood ratios to estimate the strength of association between data tokens and text tokens.", "label": 0}
{"sent1": "that represents linguistic variation as a measure of unique template sequences across a collection of automatically generated documents.", "sent2": "The metrics for generated weather and biography texts fall within acceptable ranges.", "label": 1}
{"sent1": "However few work has focused on short text such as microblog post.", "sent2": "Entity linking in long text has been well studied in previous works.", "label": 1}
{"sent1": "We use a supervised clustering approach that learns the domain distance between data instances , and then cluster the data into better domains for MDL.", "sent2": "In this work, we propose an automatic domain partitioning approach that aims at providing better domain identities for MDL.", "label": 1}
{"sent1": "The specifically designed convolutional architecture encodes not only the semantic similarity of the translation pair, but also the context containing the phrase in the source language.", "sent2": "Therefore, our approach is able to capture context-dependent semantic similarities of translation pairs.", "label": 1}
{"sent1": "Our model is more direct than the usual pipeline approaches, and speeds up inference compared to joint models.", "sent2": "Such pairs are recursively provided to the classifier, so as to extract events involving other events as arguments.", "label": 1}
{"sent1": "It is now considered to be fundamental for many natural language processing tasks such as information retrieval, machine translation, information extraction and question answering.", "sent2": "The second approach uses an adapted Clique Partitioning technique to find the most weighted clique and expands this clique until all NE textual mentions are disambiguated.", "label": 0}
{"sent1": "We have built a rule based system using linguistic cues such as coordinating conjunct, subordinating conjunct etc.", "sent2": "To the best of our knowledge, not much work has been done on clause boundary identification for Hindi, which makes this task more important.", "label": 1}
{"sent1": "While showing large improvements over the top results from the previous year task (STS-2012), our best system ranks 21st out of total 88 participated in the STS2013 task.", "sent2": "We experiment with different structural representations derived from constituency and dependency trees.", "label": 1}
{"sent1": "Moreover, the approach does not require any manually coded resource (e.g.", "sent2": "We show this formulation of Shallow-n hierarchical phrasebased translation is comparable in translation quality to full Hiero-style decoding (without shallow rules) while at the same time being considerably faster.", "label": 0}
{"sent1": "Both the mention detection model and the novel entity tracking model can use arbitrary feature types, being able to integrate a wide array of lexical, syntactic and semantic features.", "sent2": "In addition, the mention detection model crucially uses feature streams derived from different named entity classifiers.", "label": 1}
{"sent1": "into them.", "sent2": "At the heart of our approach is a generative model of how documents are generated and how names are ?sprinkled?", "label": 1}
{"sent1": "However, scalability of such systems is a bottleneck due to the heavy cost of authoring and maintenance of rule sets and inevitable brittleness due to lack of coverage in the rule sets.", "sent2": "We use the word vectors to expand entity sets used for training classifiers in a bootstrapped pattern-based entity extraction system.", "label": 0}
{"sent1": "By pre-training the model on a large amount of automatically parsed data, and then fine-tuning on the manually annotated Treebank data, our parser achieves the highest F 1 score at 86.6% on Chinese Treebank 5.1, and a competitive F 1 score at 90.7% on English Treebank.", "sent2": "The second approach collects English MWEs from Princeton WordNet 3.0, translates the collection into Arabic using Google Translate, and utilizes different search engines to validate the output.", "label": 0}
{"sent1": "Whilst easily interpreted, the metric does not illustrate the cascading impact of errors, where the parser chooses an incorrect arc, and is subsequently forced to choose further incorrect arcs elsewhere in the parse.", "sent2": "We propose that suggestions can be extracted from the available opinionated text and put to several use cases.", "label": 0}
{"sent1": "Based on RCNN, we use a discriminative model to re-rank a k-best list of candidate dependency parsing trees.", "sent2": "Different with the original recursive neural network, we introduce the convolution and pooling layers, which can model a variety of compositions by the feature maps and choose the most informative compositions by the pooling layers.", "label": 1}
{"sent1": "Previous models rely heavily on richer syntactic information through lexicalizing rules, splitting categories, or memorizing long histories.", "sent2": "There are three measures based on clustering criterion functions, and another on the Gap Statistic.", "label": 0}
{"sent1": "We integrate these noisy indicators into a unified probabilistic framework using ideas from ensemble learning and graph-based semi-supervised learning.", "sent2": "This paper describes and evaluates a theoretically motivated method for removing unwanted meanings directly from the original query in vector models, with the same vector negation operator as used in quantum logic.", "label": 0}
{"sent1": "To disambiguate a collocation?s polarity, previous work always turned to investigate the polarities of its surrounding contexts, and then assigned the majority polarity to the collocation.", "sent2": "With the obtained relationship between the classes, we discuss a link between TM and linguistically-oriented semantics.", "label": 0}
{"sent1": "The contribution of this work is two-fold: We first construct a large corpus resource of comparable texts, including an evaluation set with manual predicate alignments.", "sent2": "Secondly, we present a novel approach for aligning predicates across comparable texts using graph-based clustering with Mincuts.", "label": 1}
{"sent1": "The results show that incorporation of the global context can improve over the use of the local context alone, depending on the types of metonymies addressed.", "sent2": "Our algorithm is tested on the data from the metonymy resolution task (Task 8) at SemEval 2007.", "label": 1}
{"sent1": "In this paper, we claim that it is imperative to utilize information from various textual scopes: verb co-occurrence within a sentence, verb cooccurrence within a document, as well as overall corpus statistics.", "sent2": "Recent work on multilingual WSD has shown that it is possible to leverage the annotation work done for WSD of one language (SL) for another (TL), by projecting Wordnet and sense marked corpus parameters of SL to TL.", "label": 0}
{"sent1": "Our system incorporates a linguistic parser/generator for LFG, a transfer component for parse reduction operating on packed parse forests, and a maximum-entropy model for stochastic output selection.", "sent2": "syntactic realization, we investigate how one can obtain semantically motivated verb classes by automatic means.", "label": 0}
{"sent1": "The MAP framework is general enough to include some previous model adaptation approaches, such as corpus mixing in Gildea (2001), for example.", "sent2": "This paper introduces a task of identifying and semantically classifying lexical expressions in running text.", "label": 0}
{"sent1": "We then carry out a set of experiments using a snapshot of the National Science Digital Library (NSDL) repository, and queries that only mention fields missing from the test data.", "sent2": "In modern machine translation practice, a statistical phrasal or hierarchical translation system usually relies on a huge set of translation rules extracted from bi-lingual training data.", "label": 0}
{"sent1": "This paper provides a method for the automatic detection and extraction of causal relations.", "sent2": "The impact of word alignment on MT quality is investigated, using a phrase-based MT system.", "label": 0}
{"sent1": "By dividing the task into two subtasks, i.e.", "sent2": "In this study, to tackle the problem, we take a two-phase named entity recognition method based on SVMs and dictionary; at the first phase, we try to identify each entity by a SVM classifier and post-process the identified entities by a simple dictionary look-up; at the second phase, we try to classify the semantic class of the identified entity by SVMs.", "label": 1}
{"sent1": "In this paper, we tackle the former problem by using a machine learning method to filter out false positives.", "sent2": "(2) low recall due to spelling variation.", "label": 1}
{"sent1": "Approximately 3400 terms are annotated and the model performs at about 74% F-score on cross-validation tests.", "sent2": "A detailed analysis based on empirical evidence shows the contribution of various feature sets to performance.", "label": 1}
{"sent1": "Many clinical applications require coded data to function appropriately, such as decision support and quality assurance applications.", "sent2": "To overcome this limitation, this paper proposes a method utilizing the perceptual groups of objects and n-ary relations among them.", "label": 0}
{"sent1": "The model?s usefulness is, however, limited by the computational complexity of estimating parameters at the phrase level.", "sent2": "We develop a semantic parsing framework based on semantic similarity for open domain question answering (QA).", "label": 0}
{"sent1": "This method relies on a Perceptron neural network classifier trained on comparable amounts of positive and negative samples of clinical notes previously categorized by human experts.", "sent2": "We present a machine learning based method for identifying patients diagnosed with congestive heart failure and other related conditions by automatically classifying clinical notes.", "label": 1}
{"sent1": "Learning is efficiently parallelized and line search is performed in each round when merging parameters across parallel jobs.", "sent2": "Experiments on the NIST Chinese-to-English Open MT task indicate significantly better translation results.", "label": 1}
{"sent1": "Automatic titling is an essential task for several applications: ?No Subject?", "sent2": "Recent literature in computational terminology has shown an increasing interest in identifying various semantic relationships between terms.", "label": 0}
{"sent1": "6.", "sent2": "It is shown that human labelers can perform this task with a high agreement (Fscore of .95).", "label": 0}
{"sent1": "The classifiers perform well in this challenging domain, identifying non-native writing with 95% accuracy (over a baseline of 67%).", "sent2": "We train classifiers to predict these attributes in computational linguistics papers.", "label": 1}
{"sent1": "Using the derived translation probabilities, we then calculate the expected word frequency of each word type in the target language.", "sent2": "Such a checker needs to interpret and generate sentences containing quantifiers and negation.", "label": 0}
{"sent1": "The paper then describes our data collection and annotation approach.", "sent2": "The paper first describes a human subjects pilot study that explores how individuals identify framing and informs the design of our technique.", "label": 1}
{"sent1": "By transferring knowledge from 1.2M+ images with category labels and 100,000+ images with captions, our method is able to create sentence descriptions of open-domain videos with large vocabularies.", "sent2": "Described video datasets are scarce, and most existing methods have been applied to toy domains with a small vocabulary of possible words.", "label": 1}
{"sent1": "We propose a model inspired by machine translation operating over a large parallel corpus of visual relations and linguistic descriptions.", "sent2": "This method is agnostic to the label set used, and the only manual annotations needed for training are grammatical error labels.", "label": 0}
{"sent1": "We propose to use the RPROP algorithm for optimizing a maximum expected BLEU objective and experimentally compare it to several other updating schemes.", "sent2": "The methods also provide a practical means of optimizing the system through component analysis and cost valuation.", "label": 0}
{"sent1": "We propose a much faster and simpler method that directly hallucinates translation rules for infrequent phrases based on phrases with similar continuous representations for which a translation is known.", "sent2": "To speed up the retrieval of similar phrases, we investigate approximated nearest neighbor search with redundant bit vectors which we find to be three times faster and significantly more accurate than locality sensitive hashing.", "label": 1}
{"sent1": "Translation models are built on top of combinations of these alignments.", "sent2": "Our approach explores the possibility of working with alignments at different levels of abstraction using different degrees of linguistic analysis from the lexical to the shallow syntactic level.", "label": 1}
{"sent1": "These indexes are used to select a minimal number of documents to be processed and to give indices when comparing question and sentence representations.", "sent2": "Class-instance label propagation algorithms have been successfully used to fuse information from multiple sources in order to enrich a set of unlabeled instances with class labels.", "label": 0}
{"sent1": "Then linguistic patterns and HTML structures are used to extract text fragments describing the term.", "sent2": "We focus on the generation of good candidates and compare two machine learning scenarios in order to establish an approach that produces high precision.", "label": 0}
{"sent1": "A computational procedure of matching an expression with a spatial scene should thus include detection of the interactional properties of the scene.", "sent2": "They can be determined through (1) retrieval of information about interactional properties of specific objects and (2) determining functionally relevant objectindependent perceptual properties of the scene.", "label": 1}
{"sent1": "A trivial dialogue phrase is defined as an expression used by a chatbot program as the answer of a user input.", "sent2": "It uses flexible semantic templates to specify semantic patterns.", "label": 0}
{"sent1": "In this paper, we propose a model to mine and organize temporal relations embedded in Chinese sentences.", "sent2": "Ensembling and unknown word replacement add another 2 BLEU which brings the NMT performance on low-resource machine translation close to a strong syntax based machine translation (SBMT) system, exceeding its performance on one language pair.", "label": 0}
{"sent1": "a fact that has gone practically unnoticed in the literature ?", "sent2": "These ambivalent phrases include relatively simple expressions like yesterday or last week, but also ?", "label": 1}
{"sent1": "It shows that puis is a marker of the Narration discourse relation, whereas un peu plus tard blocks Narration and licenses only a weaker discourse relation, that can be considered as a ?weak Narration?", "sent2": "involving only temporal succession.", "label": 1}
{"sent1": "On average-length Penn treebank sentences, our most detailed estimate reduces the total number of edges processed to less than 3% of that required by exhaustive parsing, and a simpler estimate, which requires less than a minute of precomputation, reduces the work to less than 5%.", "sent2": "Review mining and summarization has been a hot topic for the past decade.", "label": 0}
{"sent1": "We show that bitext word alignment and translation under the model can be performed with standard FSM operations involving these transducers.", "sent2": "To obtain high-quality parallel data, we introduce a crowdsourcing paradigm in which workers with only basic bilingual proficiency identify translations from an automatically extracted corpus of parallel microblog messages.", "label": 0}
{"sent1": "Moreover, the trace of the proofs provide answer justifications.", "sent2": "The results show that the prover boosts the performance of the QA system on TREC questions by 30%.", "label": 1}
{"sent1": "The inclusion of such detectors was motivated by the observation that more than 50% of definite descriptions (DDs) in an average corpus are discourse new (Poesio and Vieira, 1998), but whereas the inclusion of detectors for non-anaphoric pronouns in algorithms such as Lappin and Leass?", "sent2": "Our model with the gating mechanism effectively utilizes the character-level inputs for rare and out-ofvocabulary words and outperforms word-level language models on several English corpora.", "label": 0}
{"sent1": "The protein names in the biomedical literature show a high degree of morphological and syntactic variations, and various anaphoric expressions including null anaphors.", "sent2": "Thus, our approach is well-suited to the causal constraint of spoken conversations.", "label": 0}
{"sent1": "These focal entities often introduce new information in discourse.", "sent2": "We apply our techniques to the task of extracting contact records from faculty and student homepages, demonstrating a 53% error reduction over baseline approaches.", "label": 0}
{"sent1": "We proposed a few novel metrics, including precision and recall, that are further used to provide comparative results.", "sent2": "We introduce a novel tree representation, and use it to train predictive models with tree kernels using support vector machines.", "label": 0}
{"sent1": "A language-specific feature set was defined for Basque.", "sent2": "VSSP builds a CCG semantic parser respecting this correspondence; this semantic parser parses text into lambda calculus formulas that evaluate to vector space representations.", "label": 0}
{"sent1": "Then, one or more corresponding categories in another language are determined beforehand by comparing similarities between categories across languages.", "sent2": "In the proposed method, feature terms are first extracted from Web documents for each category in the source and the target languages.", "label": 1}
{"sent1": "The factors which contribute to the efficacy of Bayesian Inferencing on lexical relations are soft word sense disambiguation, parameter smoothing which ameliorates the data sparsity problem and estimation of joint probability over words which overcomes the deficiency of naive-bayes-like approaches.", "sent2": "Bayesian inference scheme for exploiting lexical relations for passage-scoring for QA .", "label": 1}
{"sent1": "In addition to the evaluation results, we analyze the relationships between key sentences and the features used in sentence extraction.", "sent2": "However, computing critical quantities in the gradient necessitates a novel dynamic program, which we also present here.", "label": 0}
{"sent1": "However, this work was lacking in two crucial ways.", "sent2": "Recent work has proposed the use of an extracted tree grammar as the basis for treebank analysis and search queries, in which queries are stated over the elementary trees, which are small chunks of syntactic structure.", "label": 1}
{"sent1": "These findings can be used to orient future research on ?off topic?", "sent2": "conversation, and help to  make sense of both previous coding schemes  and noisy data sets.", "label": 1}
{"sent1": "Language identification has traditionally been approached with character-level language models.", "sent2": "The task of identifying the language of text or utterances has a number of applications in natural language processing.", "label": 1}
{"sent1": "We compare four new data-to-text systems which were created by predominantly automatic techniques against six existing systems for the same domain which were created by predominantly manual techniques.", "sent2": "We evaluate the ten systems using intrinsic automatic metrics and human quality ratings.", "label": 1}
{"sent1": "in non trivial cases and we show that its properties lead us to the definition of a distance between entities.", "sent2": "Some particular classes of lexical paraphrases such as verb alteration and compound noun decomposition can be handled by a handful of general rules and lexical semantic knowledge.", "label": 0}
{"sent1": "Because geographic concepts are inherently vague our approach does not guarantee a distinguishing description.", "sent2": "Our algorithm enables fast multi-domain unknown word tagging, since, unlike previous work, it does not require a corpus from the new domain.", "label": 0}
{"sent1": "domain knowledge as it encounters them.", "sent2": "We address the problem that different users have different lexical knowledge about problem domains, so that automated dialogue systems need to adapt their generation choices online to the users?", "label": 1}
{"sent1": "The visualization displays a regularized training objective; it supports gradient ascent by optionally displaying gradients on the sliders and providing ?Step?", "sent2": "and ?Solve?", "label": 1}
{"sent1": "It was first offered at Columbia University during the 2013 spring semester, and will be offered at other institutions starting in the fall semester.", "sent2": "against two human grand champions.", "label": 1}
{"sent1": "knowledge-based and supervised machine learning.", "sent2": "To address the search challenge, we devise an iterative local search algorithm that stochastically explores reordering possibilities.", "label": 0}
{"sent1": "Lemmatization accuracy for the two languages reaches 97.87% and 96.30%, while full morphosyntactic tagging accuracy using a 600-tag tagset peaks at 87.72% and 85.56%, respectively.", "sent2": "We train models on Croatian text and evaluate them on samples of Croatian and Serbian from the SETimes corpus and the two Wikipedias.", "label": 1}
{"sent1": "PLTAG is a psycholinguistically-motivated formalism which extends the standard TAG operations with a prediction and verification mechanism and has experimental support as a model of syntactic processing difficulty.", "sent2": "Existing summarization algorithms fail to utilize trans-temporal characteristics among these component summaries.", "label": 0}
{"sent1": "Recognized entities play an important role in most of the system?s modules and provide another way to explore the data.", "sent2": "The improved system achieved an F-score of 65.39% in the Twitter message-level subtask for 2013 dataset (+ 9.08% of improvement) and 63.94% for 2014 dataset.", "label": 0}
{"sent1": "In this work, we propose a unified sentence scoring model which measures representativeness and diversity at the same time.", "sent2": "We present a machine learning approach to the problem of extracting roots of Hebrew words.", "label": 0}
{"sent1": "While there have been multiple proposals for dense representations of words, measuring similarity between short texts (sentences, snippets, paragraphs) requires combining these token level similarities.", "sent2": "Disambiguating named entities in naturallanguage text maps mentions of ambiguous names onto canonical entities like people or places, registered in a knowledge base such as DBpedia or YAGO.", "label": 0}
{"sent1": "We explore at a macro-level firsthand accounts of domestic abuse from a substantial, balanced corpus of tweeted instances designated with these tags.", "sent2": "This is the first study to take into account such a variety of linguistic factors and the first to empirically demonstrate that discourse relations are strongly associated with the perceived quality of text.", "label": 0}
{"sent1": "Continuous word-embeddings have been shown to capture most of these shades of similarity to some degree.", "sent2": "This work considers guiding word-embeddings with morphologically annotated data, a form of semisupervised learning, encouraging the vectors to encode a word?s morphology, i.e., words close in the embedded space share morphological features.", "label": 1}
{"sent1": "Stemming and data driven methods, however, are not suitable when data is sparse.", "sent2": "These traditional approaches lack generalization, take a large amount of human effort and are prone to error propagation and data sparsity problems.", "label": 0}
{"sent1": "The affix extraction algorithm uses only information from fluctation of frequencies, runs in linear time, and is free from thresholds and untransparent iterations.", "sent2": "In particular, when bilingual dictionaries are available the performance of the categorization gets close to that of monolingual text categorization.", "label": 0}
{"sent1": "Many of the over 200,000 protein entries in Swiss-Prot 49.1 lack annotations such as subcellular localization or function, but the vast majority have references to journal abstracts describing related research.", "sent2": "These abstracts represent a huge amount of information that could be used to generate annotations for proteins automatically.", "label": 1}
{"sent1": "The lexicon is then compared to a list of candidate gene mentions using various string transformations that can be applied and chained in a flexible order, followed by exact string matching or approximate string matching.", "sent2": "The system identifies human gene synonyms from online databases to generate an extensive synonym lexicon.", "label": 1}
{"sent1": "In addition, generative approaches provide advantages that may make them preferable to discriminative techniques such as Support Vector Machines under certain conditions.", "sent2": "We demonstrate that Hidden Markov Models are capable of accurately capturing the structure of such texts, and can achieve classification accuracy comparable to that of discriminative techniques.", "label": 1}
{"sent1": "We show that performance of trained keyphrase extractors approximates a classifier trained on articles labeled by multiple annotators, leading to higher average F1scores and better rankings of keyphrases.", "sent2": "Multilingual experiments show that it achieves high accuracy on the full range of punctuation marks across languages.", "label": 0}
{"sent1": "Due to the lack of explicitly annotated data, previous work is primarily rule-based and uses pre-trained temporal linking systems.", "sent2": "In this work, we propose a distantly supervised approach by heuristically aligning timelines with documents.", "label": 1}
{"sent1": "(converge on a predicted answer after ?listening?", "sent2": "It describes two sets of methods used to obtain the alignments needed.", "label": 0}
{"sent1": "We present a unified approach to semantic similarity that operates at multiple levels, all the way from comparing word senses to comparing text documents.", "sent2": "In the context of content selection for single document summarization of news, we examine the benefits of both the graph structure of text provided by discourse relations and the semantic sense of these relations.", "label": 0}
{"sent1": "We pinpoint some of the problems in obtaining full agreement, including annotation scheme vagueness for certain learner innovations, interface design issues, and difficult syntactic constructions.", "sent2": "To this end, we introduce a new method to quickly infer a multilingual alignment of words, using the co-occurrence of words in a massively parallel text (MPT) to simultaneously align a large number of languages.", "label": 0}
{"sent1": "A sample of tweets from each user is manually annotated in order to establish ground truth labels, and classifiers are trained to distinguish between optimistic and pessimistic users.", "sent2": "We analyze the online activity of a set of Twitter users in order to determine how well machine learning algorithms can detect a person?s outlook on life by reading their tweets.", "label": 1}
{"sent1": "Instead of access to data, they make available decision making procedures to enable predictions on new data.", "sent2": "The author or the generator of instructional texts must follow a number of principles to guarantee that the text is of any use.", "label": 0}
{"sent1": "We evaluate the performance of the learned model against a model learned only using the more conventional bottom-up token based rule induction, and demonstrate the superiority of our combined token based and rule segmentation induction method toward generating higher quality improvised responses, measured on fluency and rhyming criteria as judged by human evaluators.", "sent2": "We also propose a procedure to generate negative instances that affect the decision boundary of the model.", "label": 0}
{"sent1": "We further cast the model as a neural network and propose an unsupervised algorithm to jointly train word representations with co-compositionality.", "sent2": "The model achieves the best result to date (?", "label": 1}
{"sent1": "We find that we are able to distinguish the relevant classes and the correct order based primarily on the degree of modification of the adjectives.", "sent2": "On an English-to-Iraqi CSLT task, the proposed approach gives significant improvements over a baseline system as measured by BLEU, TER, and NIST.", "label": 0}
{"sent1": "By fixing this, we get new measures that improve performance over not just PMI but on other popular co-occurrence measures as well.", "sent2": "In support of this task, we introduce a novel technique for re-ranking paraphrases extracted from bilingual corpora.", "label": 0}
{"sent1": "We then develop a machine learner based on these, and show that this performs better than the individual parser metrics, approaching a lower bound on human performance.", "sent2": "In this paper we develop an automatic evaluation metric to estimate fluency alone, by examining the use of parser outputs as metrics, and show that they correlate with human judgements of generated text fluency.", "label": 1}
{"sent1": "For example, similar hand gestures tend to predict semantic similarity, so features that quantify gestural similarity can improve semantic tasks such as coreference resolution.", "sent2": "Then, a text expressing the probability problem is generated.", "label": 0}
{"sent1": "We make the discussion concrete by presenting results on the reputation system of Amazon.com.", "sent2": "We show that user feedback affects the pricing power of merchants and by measuring their pricing power we can infer the polarity and strength of the underlying feedback postings.", "label": 1}
{"sent1": "The data for this relation can be obtained from eXtended WordNet, a publicly available sensedisambiguated version of WordNet.", "sent2": "The idea derives from the observation that WordNet may be seen as a graph in which synsets are connected through the binary relation ?a term belonging to synset sk occurs in the gloss of synset si?, and on the hypothesis that this relation may be viewed as a transmitter of such semantic properties.", "label": 1}
{"sent1": "Each individual binarization considers only one monolingual projection of the grammar, entirely avoiding the constraints of synchronous binarization and allowing binarizations that are separately optimized for each stage.", "sent2": "We show that this resource, when used in conjunction with constraints, can efficiently identify transliteration pairs.", "label": 0}
{"sent1": "Given a particular sentence supervised approaches to Relation Extraction employed feature or kernel functions which usually have a single sentence in their scope.", "sent2": "Our results suggest that the averaged context DBN model and the Pair HMM achieve the highest accuracy given a large training set of positive examples.", "label": 0}
{"sent1": "To date, they have mostly been modeled in isolation.", "sent2": "and ?one sense per word  association.?", "label": 0}
{"sent1": "First, we show how we can reduce parsing times by restricting the number of tasks the parser will carry out, based on a generative model of rule applications.", "sent2": "Furthermore, using a product of experts (Hinton, 2002), we combine the model with a complementary logistic regression model based on state-of-the-art lexical overlap features.", "label": 0}
{"sent1": "For each task, nine additional languages are used as auxiliary languages to obtain the triangulated predictions.", "sent2": "We observe that NER label information can be used to correct alignment mistakes, and present a graphical model that performs bilingual NER tagging jointly with word alignment, by combining two monolingual tagging models with two unidirectional alignment models.", "label": 0}
{"sent1": "These algebras encode different granularities of relations and have different inferential properties.", "sent2": "Specifically, we compare three intervalbased algebras: Allen (1983) algebra, Bruce (1972) algebra, and the algebra derived from the TempEval-07 campaign.", "label": 1}
{"sent1": "Similar approximate inference techniques support efficient parameter estimation with hidden variables.", "sent2": "We use the decoder to conduct controlled experiments on a German-to-English translation task, to compare lexical phrase, syntax, and combined models, and to measure effects of various restrictions on nonisomorphism.", "label": 1}
{"sent1": "Labeled LDA outperforms SVMs by more than 3 to 1 when extracting tag-specific document snippets.", "sent2": "The paper focusses on a methodology for treebank conversion which consists in splitting the process in steps corresponding to the kinds of information that have to be converted, i.e.", "label": 0}
{"sent1": "In practice, the keyphrases of a document should not only be statistically important in the document, but also have a good coverage of the document.", "sent2": "We maintain a coverage vector to keep track of the attention history.", "label": 0}
{"sent1": "Given a set of locations as initial seeds, we retrieve from the web an extended set of locations and produce a map-like network which connects these locations using transport type edges.", "sent2": "Topic Model such as Latent Dirichlet Allocation(LDA) makes assumption that topic assignment of different words are conditionally independent.", "label": 0}
{"sent1": "Our expert performed best with uncertainty selection, but gained little from suggestions.", "sent2": "Our non-expert performed best with random selection and suggestions.", "label": 1}
{"sent1": "Our work capitalizes on the assumption that the distribution of words in the input and an informative summary of that input should be similar to each other.", "sent2": "Results on a large scale evaluation from the Text Analysis Conference show that input-summary comparisons are very effective for the evaluation of content selection.", "label": 1}
{"sent1": "Such a representation is well-suited for directional data.", "sent2": "The resulting dataset, obtained from a pipeline of different jobs routed to Amazon Mechanical Turk, contains more than 1,600 aligned pairs for each combination of texts-hypotheses in English, Italian and German.", "label": 0}
{"sent1": "In this paper, we demonstrate the necessity of a key concept, coherence, when assessing the topics and propose an effective method for its measurement.", "sent2": "We show that the proposed measure of coherence captures a different aspect of the topics than existing measures.", "label": 1}
{"sent1": "LFG corpus.", "sent2": "We extract functional descriptions from the frame-annotated LFG corpus, to derive general frame assignment rules that can be applied to new sentences.", "label": 1}
{"sent1": "The aim was to establish the validity of three well-known ordering constraints: given complements tend to occur before new complements, definite before indefinite, and pronoun before full noun phrase complements.", "sent2": "Frequencies of occurrences were derived for subject-first and object-first sentences from the German Negra corpus.", "label": 1}
{"sent1": "We have built a platform which allows us to compare syntactic parsers for a given language by splitting their results in elementary pieces, normalizing them, and comparing them with reference results.", "sent2": "The goal of this article is to present our work about a combination of several syntactic parsers to produce a more robust parser.", "label": 1}
{"sent1": "We demonstrate the wish detectors?", "sent2": "effectiveness on domains as diverse as consumer product reviews and online political discussions.", "label": 1}
{"sent1": "Problems include ambiguity and synonymy, the former allowing for erroneous groupings and the latter causing similarities between documents to go unnoticed.", "sent2": "We achieved a 41.13% F-score in detecting events of nine types in the Task 1 of the GE task, and a 52.67% F-score in identifying events across fifteen types in the core task of the EPI task.", "label": 0}
{"sent1": "The task uses the Scholastic Aptitude Test?s sentence completion format.", "sent2": "In addition, we evaluate the recognition accuracy of these gestures using a couple of popular gesture recognizers.", "label": 0}
{"sent1": "In this paper we present an unsupervised vocabulary adaptation method for morph-based speech recognition.", "sent2": "Modeling of foreign entity names is an important unsolved problem in morpheme-based modeling that is common in morphologically rich languages.", "label": 1}
{"sent1": "In recent works, when determining event types (trigger classification), most of the works are either pattern-only or feature-only.", "sent2": "However, although patterns cannot cover all representations of an event, it is still a very important feature.", "label": 1}
{"sent1": "Such word embeddings, however, cannot capture antonyms since they depend on the distributional hypothesis.", "sent2": "Word embeddings have shown to capture synonyms and analogies.", "label": 1}
{"sent1": "An analysis of user data from a real-time MT-based dialog system showed that generating correct verbal inflections is a key problem for this language pair.", "sent2": "The second is to identify at what level of the taxonomy to phrase the reference so that it unambiguously picks out only the intended referent, leaving all possible distractors in different branches of the taxonomy.", "label": 0}
{"sent1": "As opposed to other popular methods (e.g., MERT, MIRA, PRO), which involve randomness and require multiple runs to obtain a reliable result, APRO gives the same result on any run, given initial feature weights.", "sent2": "APRO follows the pairwise ranking approach of PRO (Hopkins and May, 2011), but instead of ranking a small sampled subset of pairs from the kbest list, APRO efficiently ranks all pairs.", "label": 1}
{"sent1": "In this paper, we study a parsing technique whose purpose is to improve the practical efficiency of RCL parsers.", "sent2": "to the computational study of written conversations; we interpret this notion as the gender makeup of an email thread, and show that some manifestations of power differ significantly between gender environments.", "label": 0}
{"sent1": "We begin to address this problem with a joint model of parsing and named entity recognition, based on a discriminative feature-based constituency parser.", "sent2": "We present an approach to training a joint syntactic and semantic parser that combines syntactic training information from CCGbank with semantic training information from a knowledge base via distant supervision.", "label": 0}
{"sent1": "The results are interesting from a dialogue perspective since they employ features that are present in the majority of spoken dialogue systems and can be obtained with little or no computational overhead.", "sent2": "The results are interesting from a machine learning perspective, since they show that the rule-based method performs significantly better than the memory-based method, because the former is better capable of representing interactions between features.", "label": 1}
{"sent1": "We acquired this way 750,000 typed Japanese contradiction pattern pairs with an estimated precision of 80%.", "sent2": "In this paper we describe the English Lexical Substitution task for SemEval.", "label": 0}
{"sent1": "or ?enjoy?, followed by an expression that describes an undesirable activity or state (e.g., ?taking exams?", "sent2": "or ?being ignored?).", "label": 1}
{"sent1": "This is a consequence of unreliable translation estimates and low coverage over source and target phrases.", "sent2": "This paper presents a method which alleviates this problem by exploiting multiple translations of the same source phrase.", "label": 1}
{"sent1": "To distinguish different types of sub-events, we propose a mixture-event-aspect model which models different sub-events into local and global aspects.", "sent2": "Distant supervision, which automatically creates training data, only works with relations that already populate a knowledge base (KB).", "label": 0}
{"sent1": "by a Bayesian framework which selects sentences to form a good summary.", "sent2": "Since MTeRater only assesses fluency, we build a meta-metric, MTeRaterPlus, that incorporates adequacy by combining MTeRater with other MT evaluation metrics and heuristics.", "label": 0}
{"sent1": "We tackle the problem with two approaches: methods that use local lexical information, such as the n-grams of a classical language model; and methods that evaluate global coherence, such as latent semantic analysis.", "sent2": "We evaluate these methods on a suite of practice SAT questions, and on a recently released sentence completion task based on data taken from five Conan Doyle novels.", "label": 1}
{"sent1": "We show the efficiency of these proposed algorithms for five NLP tagging tasks.", "sent2": "A new method for stopping AL based on stabilizing predictions is presented that addresses these needs.", "label": 0}
{"sent1": "We systematically model this cross-lingual sharing using typological features.", "sent2": "In our experiments, the model consistently outperforms a state-of-the-art multilingual parser.", "label": 1}
{"sent1": "At inference time, instead of only seeking the model which explains the monolingual data available for each language, we regularize the objective by introducing a soft constraint penalizing for disagreement in argument labeling on aligned sentences.", "sent2": "Specifically, we consider unsupervised induction of semantic roles from sentences annotated with automatically-predicted syntactic dependency representations and use a stateof-the-art generative Bayesian non-parametric model.", "label": 1}
{"sent1": "Generating candidate sentences corresponding to different possible coordination structures and comparing them with a language model is employed to help determine which coordination structure is best.", "sent2": "We show that our system is able to improve the quality of the state-of-the-art MT systems.", "label": 0}
{"sent1": "that are able to strongly correlate with manual ratings.", "sent2": "We call such expressions identifying descriptions.", "label": 0}
{"sent1": "We compare these techniques using an automated evaluation framework ROUGE, and determine the best.", "sent2": "According to the experimental results, we prove that the proposed method surpassed the results of conventional approaches and discriminated the target user?s states with an accuracy of more than 70%.", "label": 0}
{"sent1": "produced by off-the-shelf MT systems.", "sent2": "We present a human judgments dataset and an adapted metric for evaluation of Arabic machine translation.", "label": 0}
{"sent1": "These quotable phrases are memorable and succinct statements that people are likely to find useful outside of their original context.", "sent2": "This paper describes a simple yet novel method for constructing sets of 50-best parses based on a coarse-to-fine generative parser (Charniak, 2000).", "label": 0}
{"sent1": "We describe MapReduce implementations of two algorithms used to estimate the parameters for two word alignment models and one phrase-based translation model, all of which rely on maximum likelihood probability estimates.", "sent2": "On a 20-machine cluster, experimental results show that our solutions exhibit good scaling characteristics compared to a hypothetical, optimally-parallelized version of current state-of-the-art single-core tools.", "label": 1}
{"sent1": "The effectiveness of this approach is  demonstrated by evaluating its performance  on travel conversation data.", "sent2": "We employ probabilistic mixture  weights between models that can change dynamically on a segment-by-segment basis  depending on the characteristics of the source  segment.", "label": 1}
{"sent1": "In this paper, we demonstrate that optimizing segmentation for an existing segmentation standard does not always yield better MT performance.", "sent2": "We find that other factors such as segmentation consistency and granularity of Chinese ?words?", "label": 1}
{"sent1": "In these node rotations, the source binary tree instance is not considered.", "sent2": "Therefore, stronger constraints for word reordering can be obtained by imposing further constraints derived from the source tree on the ITG constraints.", "label": 1}
{"sent1": "Additionally, parallel and distributed computing techniques are exploited to make it scalable.", "sent2": "This paper presents a novel approach to categorize sentences in scientific abstracts into four sections, objective, methods, results, and conclusions.", "label": 0}
{"sent1": "In application to a hierarchical phrasebased system the simplest generalization allows its models of lexical selection and reordering to be conditioned on arbitrary attributes of the source sentence and its annotation.", "sent2": "We investigate translation modeling based on exponential estimates which generalize essential components of standard translation models.", "label": 1}
{"sent1": "Unlike previous approaches, this makes it possible to successfully integrate syntactic reordering with phrase-based SMT.", "sent2": "In decoding, the alternatives are scored based on the output word order, not the order of the input.", "label": 1}
{"sent1": "Using a robust rule-based dependency parser, we parse both the English source and the French translation candidates from the nbest list returned by our phrase-based system; we compute for each candidate a number of coupling features, that is, values that depend on the amount of alignment between edges in the source and target structures, and discriminatively train the weights of these coupling features.", "sent2": "Based on the structured perceptron, we propose a general framework of ?violation-fixing?", "label": 0}
{"sent1": "A verification step assures quality using a large background corpus.", "sent2": "Further improvement is reached through classifying the newly learnt elements on character level.", "label": 1}
{"sent1": "pairs of phrases.", "sent2": "Further results show that this form of co-training considerably outperforms self-training.", "label": 0}
{"sent1": "And, finally an aggregate topic classifier was built where reports are classified based on a single discriminative topic that is determined from the training dataset.", "sent2": "Previous studies have shown automatic evaluation metrics to be more reliable when compared against many human translations.", "label": 0}
{"sent1": "?ve technique of simplifying everything.", "sent2": "These are based upon previous approaches to the task and show that thresholding does not perform significantly differently to the more na?", "label": 1}
{"sent1": "The production scenario is exemplified by the Bulgarian verb as the morphologically richest and most problematic part-of-speech category.", "sent2": "The definition of the set of morphosyntactic specifications for verbs in the lexicon is described.", "label": 1}
{"sent1": "This helps reduce out-of-vocabulary (OOV) words.", "sent2": "A crucial step toward the goal of automatic extraction of propositional information from natural language text is the identification of semantic relations between constituents in sentences.", "label": 0}
{"sent1": "The resulting graph algorithm can be seen as a meta-algorithm in the sense that defining cost functions in different ways allows us to mimic ?", "sent2": "We characterize a class of indirect answers to yes/no questions, alternative answers, where information is given that is not directly asked about, but which might nonetheless address the underlying motivation for the question.", "label": 0}
{"sent1": "We therefore had to deviate from the generic code and make new design and implementation in many important cases.", "sent2": "Despite well-designed generic mechanisms of the system, it turned out that the task of generating Vietnamese posed non-trivial problems.", "label": 1}
{"sent1": "We also present our pilot case study, in which we took a particular type of paraphrasing that separates a relative clause from a sentence.", "sent2": "Their automatic disambiguation, i.e.", "label": 0}
{"sent1": "In this paper, we present a quantitative evaluation of various modules in our system, based on two criteria: first, the numbers of documents containing the correct answer and selected by the system; secondly, the number of answers found.", "sent2": "We describe the implementation steps required to scale high-order character language models to gigabytes of training data without pruning.", "label": 0}
{"sent1": "So, we established different criteria to compare them, based either on the words as class descriptors or on the thematic units.", "sent2": "To do that, we applied another clustering method, that only needs to know the number of classes to build, on the same subset of text segments and we reformulate our evaluation problem in comparing the two classifications.", "label": 1}
{"sent1": "\"genre\", and demonstrates, by complementing topic classification, that it can significantly improve retrieval of information.", "sent2": "Quantitative measurement of inter-language distance is a useful technique for studying diachronic and synchronic relations between languages.", "label": 0}
{"sent1": "In this paper, we try to work it out in another way: improving the quality of the comparable corpus from which the bilingual lexicon has to be extracted.", "sent2": "Previous work on bilingual lexicon extraction from comparable corpora aimed at finding a good representation for the usage patterns of source and target words and at comparing these patterns efficiently.", "label": 1}
{"sent1": "and ?biomedicine?", "sent2": "when porting NLP systems from one domain to another.", "label": 1}
{"sent1": "We propose a model-based feedback approach that learns Latent Dirichlet Allocation topic models on the top-ranked pseudo-relevant feedback, and we measure the semantic coherence of those topics.", "sent2": "More, the semantic coherence of the topics has never been considered in this field.", "label": 1}
{"sent1": "Although this separation makes tree-based decoding simple and efficient, its translation performance is usually limited by the number of parse trees offered by parser.", "sent2": "We introduce the DTRNN model which uses dependency trees to embed sentences into a vector space in order to retrieve images that are described by those sentences.", "label": 0}
{"sent1": "We propose and explore several methods for solving these challenges.", "sent2": "We then integrated an existing WSD tool and replaced the usual GF style lexicons, which give one target word per source word, by the WordNet based lexicons.", "label": 0}
{"sent1": "have only addressed discourse considerations via off-the-shelf coreference resolvers.", "sent2": "a generic paradigm for applied inference ?", "label": 1}
{"sent1": "In a recent bio-molecular event extraction task, state-of-the-art performance was achieved by systems building specifically on dependency representations of parser output.", "sent2": "The detailed analyses of sentence structure provided by parsers have been applied to address several information extraction tasks.", "label": 1}
{"sent1": "Each rule specifically examines the entities in one target interaction pair.", "sent2": "We also describe several ensemble methods that we employed for combining these base systems.", "label": 0}
{"sent1": "The search applies to the shift?reduce algorithm and the feature sets are extracted from the parser configuration.", "sent2": "The initial feature is limited to the first word in the input queue.", "label": 1}
{"sent1": "Unlike conventional co-training, the two processes in Co-STAR are applied to different source texts and training data.", "sent2": "We show the effectiveness of this algorithm through experiments on largescale hyponymy-relation acquisition from Japanese Wikipedia and Web texts.", "label": 1}
{"sent1": "This paper reports on three computational experiments designed to test whether this assumption is sound.", "sent2": "The results suggest that thematic consonants are predictable from the phonotactic probabilities of their active counterparts.", "label": 1}
{"sent1": "In the prototype, the mobile device serves as the locus of interaction, providing both a small touchscreen display, and speech input and output; while the TV screen features a larger, richer GUI.", "sent2": "We show how techniques from paraphrasing can be used to deal with these otherwise unknown source language phrases.", "label": 0}
{"sent1": "First, a very simple, randomized sentence-plangenerator (SPG) generates a potentially large list of possible sentence plans for a given text-plan input.", "sent2": "Second, the sentence-plan-ranker (SPR) ranks the list of output sentence plans, and then selects the top-ranked plan.", "label": 1}
{"sent1": "It achieves state-of-the-art performance on many natural language processing tasks and does not overtrain easily.", "sent2": "One such example, explored in this article, is the mention detection and recognition task in the Automatic Content Extraction project, with the goal of identifying named, nominal or pronominal references to real-world entities?mentions?", "label": 0}
{"sent1": "We found that coreference constraints on names improve the performance of the model from 92.6% to 97.0%.", "sent2": "Without the threshold tuning, the system showed 55.32 precision, 16.18 recall and 25.04 f-score.", "label": 0}
{"sent1": "measures, such as the Longest Common Subsequence Ratio (LCSR) or Dice?s coefficient.", "sent2": "I introduce a procedure for estimating semantic similarity of glosses that employs keyword selection and WordNet.", "label": 1}
{"sent1": "We are now considering an approach for computing sentence importance based on the concept of eigenvector centrality (prestige) that we call LexPageRank.", "sent2": "Centrality is typically defined in terms of the presence of particular important words or in terms of similarity to a centroid pseudo-sentence.", "label": 1}
{"sent1": "The edit detector achieves a misclassi\fcation rate on edited words of 2.2%.", "sent2": "We present a simple architecture for parsing transcribed speech in which an edited-word detector \frst removes such words from the sentence string, and then a standard statistical parser trained on transcribed speech parses the remaining words.", "label": 1}
{"sent1": "Furthermore, by the Kernel principle, SVMs can carry out training with smaller computational overhead independent of their dimensionality.", "sent2": "SVMs are known to achieve high generalization performance even with input data of high dimensional feature spaces.", "label": 1}
{"sent1": "In other words, the optimal strategy is expressed as a decision table specifying which action to take in each specific state.", "sent2": "It is therefore difficult to see whether there is any generality across states.", "label": 1}
{"sent1": "However, there are some cases where segmentation granularity contradicts the results of morphological analysis and the building units of NEs, so that extraction of some NEs are inherently impossible in this setting.", "sent2": "The connection between part-of-speech (POS) categories and morphological properties is well-documented in linguistics but underutilized in text processing systems.", "label": 0}
{"sent1": "The tool applies a series of automatic transformations to user documents to identify and remove the reading obstacles to comprehension.", "sent2": "This paper presents a novel method to learn to use formulas to solve simple arithmetic word problems.", "label": 0}
{"sent1": "At the text-level, constraints about textual adjacency and textual organization are integrated in a beam search in order to generate best discourse structures.", "sent2": "The recently introduced online confidence-weighted (CW) learning algorithm for binary classification performs well on many binary NLP tasks.", "label": 0}
{"sent1": "This problem is especially severe if the base classifier has already been finely tuned.", "sent2": "We evaluated our approach on a corpus of manually annotated data.", "label": 0}
{"sent1": "At the same time, high-quality automatic analysis is currently out of reach.", "sent2": "We thus propose to split the manual annotation in two phases: the simpler marking of lexical connectives and their relations, and the more difficult decisions on overall tree structure.", "label": 1}
{"sent1": "Our method is based on two steps.", "sent2": "In this paper, we describe a method of automatic sentence alignment for building extracts from abstracts in automatic summarization research.", "label": 1}
{"sent1": "This paper looks at treebank-training of generators, an alternative method for building statistical models for NLG from raw corpora, and two different ways of using treebank-trained models during generation.", "sent2": "On the downside, n-gram models are expensive to use as selection mechanisms and have a built-in bias towards shorter realisations.", "label": 1}
{"sent1": "We perform a cost-benefit analysis of the application of NLG techniques in the context of authoring cooking recipes in English and Hebrew.", "sent2": "Furthermore, we find that the parse features can lead to higher classification accuracies than traditional measures of syntactic complexity.", "label": 0}
{"sent1": "This is a strong assumption, since in  reality properties of objects may be perceived differently among people, due to a number of factors  including vagueness, knowledge discrepancies, and  limited perception capabilities.", "sent2": "Yet prior attempts to resolve opaque pairs using ontologies or distributional semantics hurt precision more than improved recall.", "label": 0}
{"sent1": "In addition, it models such aspects of child acquisition as ?fast mapping,?", "sent2": "The emergence of social media brings chances, but also challenges, to linguistic analysis.", "label": 0}
{"sent1": "To realize the logical forms, OpenCCG is used.", "sent2": "We propose the use of the word categories and embeddings induced from raw text as auxiliary features in dependency parsing.", "label": 0}
{"sent1": "Our approach leverages the vast resource of pictures available on the web and the fact that many of them are captioned.", "sent2": "In  this paper, we argue that reversing efficient  resources such as ours cannot in general be  achieved.", "label": 0}
{"sent1": "Recently, investigations of referential behaviours involved in situations in the real world have received increasing attention by researchers (Di Eugenio et al, 2000; Byron, 2005; van Deemter, 2007; Spanger et al, 2009).", "sent2": "We present a fast query-based multi-document summarizer called FastSum based solely on word-frequency features of clusters, documents and topics.", "label": 0}
{"sent1": "Processing these instructions is challenging?they posit goals to be achieved without specifying the steps required to complete them.", "sent2": "The learning strategy of conceptual vectors relies on a morphosyntaxic analysis of human usage dictionary definitions linked to vector propagation.", "label": 0}
{"sent1": "Conversion procedures fall out of our linguistic analysis of a newly available million-word hyper-text corpus.", "sent2": "Starting from raw bracketings of four common HTML tags (anchors, bold, italics and underlines), we refine approximate partial phrase boundaries to yield accurate parsing constraints.", "label": 1}
{"sent1": "In this approach the speech translation model consists of a single network where acoustic models (in the input) and the multilingual model (in the output) are embedded.", "sent2": "We propose to use definition clusters built from a combination of English lexical resources for query expansion.", "label": 0}
{"sent1": "Our method does not require any translated texts or token-level alignments.", "sent2": "We present an approach to multilingual grammar induction that exploits a phylogeny-structured model of parameter drift.", "label": 1}
{"sent1": "The rest of the words are subsequently mapped to these clusters.", "sent2": "The algorithm first identifies landmark clusters of words, serving as the cores of the induced POS categories.", "label": 1}
{"sent1": "Finally, we combine the retrieved data for all terms from the list to select or approximate the requested value.", "sent2": "The main contribution of this research is in devising a divide-and-conquer strategy to alleviate the speech recognition errors.", "label": 0}
{"sent1": "We also demonstrate that all the different types of part-whole relations can still be discovered, regardless of the type characterized by the initializing seeds.", "sent2": "Summarizing and analyzing Twitter content is an important and challenging task.", "label": 0}
{"sent1": "Carrying this further, we looked into the effect of using two assisting languages together on PRF.", "sent2": "This fact inspired us to study the effect of any source-assistant pair on MultiPRF performance from out of a set of languages with widely different characteristics, viz., Dutch, English, Finnish, French, German and Spanish.", "label": 1}
{"sent1": "decision making processes.", "sent2": "The NTU-MC is a parallel corpora of linguistically diverse languages (Arabic, English, Indonesian, Japanese, Korean, Mandarin Chinese, Thai and Vietnamese).", "label": 0}
{"sent1": "We expand features into a non-parametric, non-linear, and high-dimensional space.", "sent2": "We extend empirical Bayes reward training of model parameters to meta parameters of feature generation.", "label": 1}
{"sent1": "By varying separately three parameters (language, annotation scheme, and preprocessing information) and applying the same coreference resolution system, the strong bonds between system and corpus are demonstrated.", "sent2": "While the presence of conventional subjectivity keywords appears significant in the success of this technique, we are able to find the most domain-relevant keywords without sacrificing recall.", "label": 0}
{"sent1": "Next we consider several variants on A*, a classic exact search technique which to our knowledge has not been applied to more expressive grammar formalisms like CCG.", "sent2": "Our empirical evaluation using a manually annotated corpus in Japanese demonstrates that the proposed model achieved 0.758 in F-score, outperforming the two baseline models.", "label": 0}
{"sent1": "to dependency parsing of Arabic, a morphologically rich language.", "sent2": "Most approaches to relation extraction, the task of extracting ground facts from natural language text, are based on machine learning and thus starved by scarce training data.", "label": 0}
{"sent1": "In this paper, we present a greedy non-directional parsing algorithm which doesn?t need a fully connected parse and can learn from partial parses by utilizing available structural and syntactic information in them.", "sent2": "The projected target dependency parses are not always fully connected to be useful for training traditional dependency parsers.", "label": 1}
{"sent1": "Surprisingly, these results have not yet been broadly introduced into the computational linguistics community.", "sent2": "We look at one such problem that arises within universities on a daily basis but has attracted little attention in the literature, namely the problem of a searcher who is trying to identify a potential PhD supervisor, or, from the perspective of the university?s research office, to allocate a PhD application to a suitable supervisor.", "label": 0}
{"sent1": "We propose a simple approach for the extraction of such structures by taking the tree of event-argument relations and using it directly as the representation in a reranking dependency parser.", "sent2": "We describe in detail the motivation for the shared task, the acquisition of datasets, the evaluation methodology and the results of participating systems.", "label": 0}
{"sent1": "This paper presents efficient algorithmic and architectural solutions which have been tested within the Moses decoder, an open source toolkit for statistical machine translation.", "sent2": "Human speech is often ungrammatical and ill-formed, and there will frequently be a mismatch between training and test data.", "label": 0}
{"sent1": "The parameters are learned from a set of transliterated word pairs via the EM algorithm.", "sent2": "We propose a novel method which models language origins as latent classes.", "label": 1}
{"sent1": "Our approach models the generation process from the dictionary words to nonstandard tokens under a sequence labeling framework, where each letter in the dictionary word can be retained, removed, or substituted by other letters/digits.", "sent2": "To avoid the expensive and time consuming hand labeling process, we automatically collected a large set of noisy training pairs using a novel webbased approach and performed character-level alignment for model training.", "label": 1}
{"sent1": "We show how confidence ranges for state-of-the-art evaluation measures such as WER and TER can be computed accurately and efficiently without having to resort to Monte Carlo estimates.", "sent2": "Furthermore we argue that machine translation evaluations should be regarded as statistical processes, both for human and automatic evaluation.", "label": 1}
{"sent1": "We address this problem in a classification approach that includes features that model those two characteristics.", "sent2": "We show that the often-used frequency-based selection performs badly compared to maximum entropy feature selection, and that models with a few hundred well-picked features are competitive to models with no feature selection applied.", "label": 0}
{"sent1": ".", "sent2": ").", "label": 1}
{"sent1": "We treat idioms as semantic outliers, and the identification of a semantic shift as outlier detection.", "sent2": "Thus, this topic representation allows us to differentiate idioms from literals using local semantic contexts.", "label": 1}
{"sent1": "We present a representation for common sense spatial knowledge and an approach to extract it from 3D scene data.", "sent2": "The experiments show that considering inter-slot relations is crucial for generating a more coherent and compete slot set, resulting in a better spoken language understanding model, while enhancing the interpretability of semantic slots.", "label": 0}
{"sent1": "But both argumentation semantics and crosssentence syntax (such as coreference and tense rules) are very hard to formalize.", "sent2": "To solve the challenge of ordering a set of sentences into coherent order, existing approaches focus mostly on defining and using sophisticated features to capture the cross-sentence argumentation logic and syntactic relationships.", "label": 1}
{"sent1": "We present a linguistically accurate, large-scale morphological analyzer for Egyptian Arabic.", "sent2": "Evaluation of segment-level machine translation metrics is currently hampered by: (1) low inter-annotator agreement levels in human assessments; (2) lack of an effective mechanism for evaluation of translations of equal quality; and (3) lack of methods of significance testing improvements over a baseline.", "label": 0}
{"sent1": "The system consists of eight rules which target different relations based on linguistic insights.", "sent2": "Our rule-based system significantly outperforms a reimplementation of a previous rule-based system (Vieira and Poesio, 2000).", "label": 1}
{"sent1": "Visual display of the system?s response not only changes human behavior when interacting with devices, but also creates new research areas in SDSs.", "sent2": "Hand-crafted grammars inevitably lack coverage but many coverage failures are due to inadequacies of their lexicons.", "label": 0}
{"sent1": "The level of difficulty can be manipulated, and the sentence variations covered by the systems familiarize users with different expressions of the same meaning.", "sent2": "Two distinctly different activities, a translation game and a dialogue game are illustrated.", "label": 1}
{"sent1": "Such an automatic approach overcomes the problem of brittleness suffered in many existing methods and makes broad-coverage word sense disambiguation feasible in practice.", "sent2": "DKPro Keyphrases is a keyphrase extraction framework based on UIMA.", "label": 0}
{"sent1": "A few morphological analyzers of this language have been developed.", "sent2": "However, they give only inflectional analysis of the language.", "label": 1}
{"sent1": "It plays a key role in understanding natural language.", "sent2": "We introduce a new clustering method called Hierarchical Graph Factorization Clustering (HGFC) and extend it so that it is optimal for the task.", "label": 0}
{"sent1": "The tool incorporates a classical efficient algorithm for reranking the results by assigning weights to selected constructions and prioritizing the documents containing them.", "sent2": "Further, our classifier is able to learn the importance and quality of each topic within our corpus ?", "label": 0}
{"sent1": "For spatio-temporal information, however, other interaction paradigms may be better-suited.", "sent2": "In this work, we carry out stylistic segmentation of a well-known poem, The Waste Land by T.S.", "label": 0}
{"sent1": "Errors introduced during PDF-totext conversion or poorly formatted examples can make the task of automatically analyzing the data more difficult, so we aim to clean and normalize the examples in order to maximize accuracy during analysis.", "sent2": "The current release of the ODIN (Online Database of Interlinear Text) database contains over 150,000 linguistic examples, from nearly 1,500 languages, extracted from PDFs found on the web, representing a significant source of data for language research, particularly for low-resource languages.", "label": 1}
{"sent1": "We use training data from outof-domain corpora and adapt the system for biographies.", "sent2": "We present a French to English translation system for Wikipedia biography articles.", "label": 1}
{"sent1": "In this paper, we study three simple but effective task-independent regularization methods: (1) one is to average weights of different trained models to reduce the bias caused by the specific order of the training examples; (2) one is to add penalty term to the loss function; (3) and one is to randomly corrupt the data flow during training which is called dropout in the neural network.", "sent2": "All these models use global document-level information by sharing mention attributes, such as gender and number, across mentions in the same cluster.", "label": 0}
{"sent1": "Crucially, this algorithm avoids confusing the end user by preserving a consistent ordering of the query elements throughout the incremental query formulation process.", "sent2": "We attempt three ways of automatic construction to corroborate the effect of the directionality of dictionaries.", "label": 0}
{"sent1": "We formulate two measures that evaluate these paraphrase grammars using gold standard sentential paraphrases drawn from a monolingual parallel corpus.", "sent2": "Results on five Chinese-English NIST tasks show that our model improves the baseline system by 1.32 BLEU and 1.53 TER on average.", "label": 0}
{"sent1": "Although detailed accounts of the matching algorithms used in commercial systems can?t be found in the literature, it is widely believed that edit distance algorithms are used.", "sent2": "An important part of TM systems is the matching algorithm that determines what translations get retrieved from the bank of available translations to assist the human translator.", "label": 1}
{"sent1": "The analysis of one of our phonotactic grammars shows that interesting phonotactic constraints are learned.", "sent2": "For instance, unvoiced consonants are the most likely first consonants and liquids and glides are preferred as second consonants in two-consonantal onsets.", "label": 1}
{"sent1": "Extracting meaning from short text segments is difficult as there is little semantic redundancy between terms; hence methods based on shallow semantic analysis may fail to accurately estimate meaning.", "sent2": "Furthermore search queries lack explicit syntax often used to determine intent in question answering.", "label": 1}
{"sent1": "Using these features to score the collected translations, we are able to discriminate between acceptable and unacceptable translations.", "sent2": "We propose a set of features that model both the translations and the translators, such as country of residence, LM perplexity of the translation, edit rate from the other translations, and (optionally) calibration against professional translators.", "label": 1}
{"sent1": "We introduce a novel system combination framework in which hypotheses are encoded as a confusion forest, a packed forest representing alternative trees.", "sent2": "The state-of-the-art system combination method for machine translation (MT) is based on confusion networks constructed by aligning hypotheses with regard to word similarities.", "label": 1}
{"sent1": "Various models are proposed in recent literature to align the facts in the database to their mentions in the corpus.", "sent2": "In this paper, we discuss and critically analyse a popular alignment strategy called the ?at least one?", "label": 1}
{"sent1": "This approach can produce an ideal tradeoff between the in-vocaulary rate and out-of-vocabulary rate.", "sent2": "In addition, we proposed a confidence measure approach to combine the results of a dictionary-based and a subword-tagging-based segmentation.", "label": 1}
{"sent1": "This correspondence can be at multiple levels of granularity or resolutions.", "sent2": "In this paper, we introduce an approach to multi-resolution language grounding in the extremely challenging domain of professional soccer commentaries.", "label": 1}
{"sent1": "We present a freely available extension to the Enron corpus, with the gender of senders of 87% messages reliably identified.", "sent2": "Our parser integrates shallow parsing techniques with knowledge-based text retrieval to allow for robust processing and coordination of input modes.", "label": 0}
{"sent1": "When LDA is applied to tweet collections, it generally treats all aggregated tweets of a user as a single document.", "sent2": "Twitter-LDA, which assumes a single tweet consists of a single topic, has been proposed and has shown that it is superior in topic semantic coherence.", "label": 1}
{"sent1": "Second, it employs a chart parser which utilizes manually created syntax rules in addition to scores obtained after statistical processing during speech recognition.", "sent2": "At last, the performance of each component is enhanced.", "label": 0}
{"sent1": "First, we show how to reduce nonprojective dependency parsing to parsing with Linear Context-Free Rewriting Systems (LCFRS), by presenting a technique for extracting LCFRS from dependency treebanks.", "sent2": "For efficient parsing, the extracted grammars need to be transformed in order to minimize the number of nonterminal symbols per production.", "label": 1}
{"sent1": "In this work, we investigate several enhancements to analogical learning and test our implementation on translating medical terms.", "sent2": "discourse structure as a useful information source.", "label": 0}
{"sent1": "We compare the performance of both the alignment and terminology extraction module for three different language pairs (French-English, French-Italian and French-Dutch) and highlight languagepair specific problems (e.g.", "sent2": "This paper describes a set of experiments on two sub-tasks of Quality Estimation of Machine Translation (MT) output.", "label": 0}
{"sent1": "in psycholinguistics.", "sent2": "Such US models are now common in machine learning approaches to SDS, are trained on real dialogue data, and are related to theories of ?alignment?", "label": 1}
{"sent1": "Once possible errors have been detected, we examine each error candidate and hand-correct the corresponding PoS tag if necessary.", "sent2": "Overall, based on the three methods, we handcorrect the PoS tagging of 1,334 tokens (0.23% of the tokens) in the corpus.", "label": 1}
{"sent1": "Prior work has shown how to make use of a large text corpus to augment random walk inference over KBs.", "sent2": "We present two improvements to the use of such large corpora to augment KB inference.", "label": 1}
{"sent1": "We describe how duration information can be incorporated into an unsupervised Bayesian dependency parser whose only other source of information is the words themselves (without punctuation or parts of speech).", "sent2": "This paper explores the hypothesis that word duration can help with learning syntax.", "label": 1}
{"sent1": "We show that the algorithm provides models with the same accuracy as EM, but is an order of magnitude more efficient.", "sent2": "This paper describes experiments using the spectral algorithm.", "label": 1}
{"sent1": "The most suitable image is selected from this set using a graph-based algorithm which makes use of textual information from the metadata associated with each image and features extracted from the images themselves.", "sent2": "Candidate images for each topic are retrieved from the web by querying a search engine using the top n terms.", "label": 1}
{"sent1": "We test our methods using several corpora to quantitatively measure both the efficacy and scalability of our streaming approach.", "sent2": "In our study with the Dutch Spoken Corpus, syllabic inventories were obtained by means of automatic syllabification of the spoken language data.", "label": 0}
{"sent1": "We demonstrate that this model can be used as an exploratory tool for learning about these drugs from the Web by applying it to the task of extractive summarization.", "sent2": "Since a purely unsupervised topic model is unlikely to discover these specific factors of interest, we develop a novel method of incorporating prior knowledge by leveraging user generated tags as priors in our model.", "label": 1}
{"sent1": "We present a zero reference resolution model considering zero exophora and author/reader of a document.", "sent2": "This was developed independently of the semantic web.", "label": 0}
{"sent1": "This dataset provides rich collection of instances for the research on finding natural and relevant short responses to a given short text, and useful for both training and testing of conversation models.", "sent2": "This dataset consists of both naturally formed conversations, manually labeled data, and a large repository of candidate responses.", "label": 1}
{"sent1": "These explanations can help readers get easily comprehensible information of the discussed products and aspects.", "sent2": "The system provides only relevant context specific information.", "label": 0}
{"sent1": "A specific effort is also made on the detection of reactions to a particular event.", "sent2": "We consider the task of predicting lexical entailment using distributional vectors.", "label": 0}
{"sent1": "We demonstrate this in a text classification setting, assigning the tweet hashtag based on the rest of its text.", "sent2": "We use Gaussian Processes, a state-ofthe-art bayesian non-parametric model, with a novel periodic kernel.", "label": 1}
{"sent1": "We propose a new unsupervised, Markov Random Field-based model for SCF acquisition which is designed to address these problems.", "sent2": "We observed that none of the five aspects of readability are independent of each other, and hence by addressing the individual criterion of evaluation we aim to achieve automated appreciation of readability of summaries.", "label": 0}
{"sent1": "This is particularly problematic for training a tagger for modality because modality triggers are sparse for the overwhelming majority of sentences.", "sent2": "We seek to measure political candidates?", "label": 0}
{"sent1": "Some of our preliminary analyses suggest that hedges occur less frequently in scientific discourse than in popular text, a finding that contradicts prior assertions in the literature.", "sent2": "We hope that our initial work and data will encourage others to pursue this promising line of inquiry.", "label": 1}
{"sent1": "We first introduce a new regression model that uses a probabilistic finite state machine (pFSM) to compute weighted edit distance as predictions of translation quality.", "sent2": "We also propose a novel pushdown automaton extension of the pFSM model for modeling word swapping and cross alignments that cannot be captured by standard edit distance models.", "label": 1}
{"sent1": "notion of significance hold up in practical settings where future distributions are neither independent nor identically distributed, such as across domains?", "sent2": "Next, once significance levels are computed, how well does the standard i.i.d.", "label": 1}
{"sent1": "A variety of psychic, emotional as well as behavioral conditions can manifest at the same time.", "sent2": "In this paper, we address the issue of training very large CRFs, containing up to hundreds output labels and several billion features.", "label": 0}
{"sent1": "Robot systems are promising solutions but their value has to be acknowledged by the patients and the care personnel.", "sent2": "Due to the demographic changes, support by means of assistive systems will become inevitable for home care and in nursing homes.", "label": 1}
{"sent1": "Using this scoring function we achieve classification accuracy of 87% on Stanford Dataset and 88% on Mejaj dataset.", "sent2": "Using supervised machine learning approach, we achieve classification accuracy of 88% on Stanford dataset.", "label": 1}
{"sent1": "Then the test opinions are compared to both models and a decision and confidence measure are calculated.", "sent2": "We have found that the special structure of captions allows us to extract some names of people actually portrayed in the image quite reliably, using a simple syntactic analysis.", "label": 0}
{"sent1": "However, less attention has been given to the importance of selecting strong features to support learning a coreference model.", "sent2": "This paper describes a rather simple pairwise classification model for coreference resolution, developed with a well-designed set of features.", "label": 1}
{"sent1": "As the problem of automatic domain template creation is rather new, there is no well-defined procedure for the evaluation of the domain template quality.", "sent2": "We show that this methodology can be used for automatic domain template creation.", "label": 1}
{"sent1": "We examine if features used for syntactic parsing can be adapted for semantic parsing by creating similar semantic features based on the mapping between syntax and semantics.", "sent2": "We report experimental results on two real applications, an interpreter for coaching instructions in robotic soccer and a naturallanguage database interface.", "label": 1}
{"sent1": "A statistically significant increase in performance is obtained.", "sent2": "This paper focuses on the change of named entities over time and its influence on the performance of the named entity tagger.", "label": 0}
{"sent1": "In particular, attempts are being made to develop techniques for language pairs where the source and target languages are different, e.g.", "sent2": "(1) Are multi-domain learning improvements the result of ensemble learning effects?", "label": 0}
{"sent1": "We extracted different kinds of features (i.e.", "sent2": "However, the performance of these approaches depends entirely on the feature set used and the weighting of these features.", "label": 1}
{"sent1": "Identifying the correct expansion can be viewed as a Word Sense Disambiguation (WSD) problem.", "sent2": "This paper investigates SR in the context of unsupervised information extraction, where neither is available.", "label": 0}
{"sent1": "This encourages the model to group words that are a priori known to be semantically related into topics.", "sent2": "Crowdsourcing, while ideally reducing both costs and the need for domain experts, is no all-purpose tool.", "label": 0}
{"sent1": "Moreover, we show the optimality of Co-Simmate among other hop-(uk) variations, and integrate it with a matrix decomposition based method on singular graphs to attain higher efficiency.", "sent2": "))n 3 ) time.", "label": 1}
{"sent1": "In this work, we propose novel methods to automatically construct comprehensive topic hierarchies for given categories based on the structured Contents tables as well as corresponding unstructured text descriptions.", "sent2": "The articles with similar subjects are grouped together into Wikipedia categories.", "label": 1}
{"sent1": "We empirically demonstrate that the document-based approach obtains a much more complete time anchoring.", "sent2": "Moreover, this approach almost doubles the performance of the systems that participated in the task.", "label": 1}
{"sent1": "language to a ?recipient?", "sent2": "language as a result of contacts between communities speaking different languages.", "label": 1}
{"sent1": "Our proposed algorithm is mathematically sound and inherits convergence guarantees from EM.", "sent2": "We also describe an automatic SSA tagging system that exploits the annotated data.", "label": 0}
{"sent1": "To jointly consider word-to-word, word-toslot, and slot-to-slot relations, we use a random walk inference algorithm to combine the two knowledge graphs, guided by dependency grammars.", "sent2": "Traditional distributional semantic models extract word meaning representations from cooccurrence patterns of words in text corpora.", "label": 0}
{"sent1": "For the former, we propose a novel, ?soft?, F1 metric that incorporates similarity between extracted fillers and the gold truth, giving partial credit to different but similar values.", "sent2": "The subtask of aspect category detection obtains the best result when applying the Boosting method on the Maximum Entropy model, with the precision of 0.869 for Restaurants.", "label": 0}
{"sent1": "Recently, the flood of data from online social networks (OSN) offers a practical way to observe and analyze self-disclosure behavior at an unprecedented scale.", "sent2": "The challenge with such analysis is that OSN data come with no annotations, and it would be impossible to manually annotate the data for a quantitative analysis of self-disclosure.", "label": 1}
{"sent1": "We present an empirical evaluation method for quantifying the humanlikeness and relevance of the generated responses.", "sent2": "topics, sentiments and a knowledge graph.", "label": 1}
{"sent1": "We use various NLP algorithms in order to automatically analyze a large corpus of interview transcripts and construct a network of the industry members and their ?naming?", "sent2": "relations.", "label": 1}
{"sent1": "Behind the GUI is a set of Advanced Dialogue Tools (ADT) that generate complete SDS based on Business User Resources.", "sent2": "Taxonomies are the backbone of many structured, semantic knowledge resources.", "label": 0}
{"sent1": "The first translation service provides state-of-the-art text-to-text translations of Japanese as well as English conversational spoken language in the travel domain into 17 languages using statistical machine translation technologies trained automatically from a large-scale multilingual corpus.", "sent2": "The effect of these alternative models has not been previously studied.", "label": 0}
{"sent1": "Whilst the results on balanced corpora are promising, our chief motivation for the method is for application to domain specific text.", "sent2": "Amortized inference has been proposed as a way to accomplish this.", "label": 0}
{"sent1": "We formalize two particular types of DP algorithms under each of these frameworks: the Viterbi-style topological algorithms and the Dijkstra-style best-first algorithms.", "sent2": "Wherever relevant, we also discuss typical applications of these algorithms in Natural Language Processing.", "label": 1}
{"sent1": "In this work we take advantage of the morphological and syntactic idiosyncrasy of Hebrew noun compounds and employ it to extract such expressions from text corpora.", "sent2": "We show that relying on linguistic information dramatically improves the accuracy of compound extraction, reducing over one third of the errors compared with the best baseline.", "label": 1}
{"sent1": "We implemented a wide variety of previously suggested methods.", "sent2": "In the second step, matching is done in a novel way that calculates the chance of an accidental overlap of pivot words using the hypergeometric distribution.", "label": 1}
{"sent1": "Cross-language plagiarism occurs if a text is translated from a fragment written in a different language and no proper citation is provided.", "sent2": "Plagiarism, the unacknowledged reuse of text, does not end at language boundaries.", "label": 1}
{"sent1": "In this paper we present an approach to training a VDR Parsing Model without the extensive human supervision used in previous work.", "sent2": "Exploring this heterogeneous data by structured query languages is tedious and error-prone even for skilled users.", "label": 0}
{"sent1": "We introduce a dataset of 3D scenes annotated with natural language descriptions and learn from this data how to ground textual descriptions to physical objects.", "sent2": "The MASC infrastructure enables the incorporation of contributed annotations into a single, usable format that can then be analyzed as it is or ported to any of a variety of other formats.", "label": 0}
{"sent1": "Identifying topics or aspects of conversation and inferring sentiment in online course forum posts can enable instructor interventions to meet the needs of the students, rapidly address course-related issues, and increase student retention.", "sent2": "the task of automatically aligning data records with textual descriptions, such that data tokens are aligned with the word strings that describe them.", "label": 0}
{"sent1": "Using a rich set of shallow lexical, syntactic and structural features from the input text, our parser achieves, in linear time, 73.9% of professional annotators?", "sent2": "human agreement F-score.", "label": 1}
{"sent1": "The first finding means that genre should be made a factor in automated sense labelling of non-lexically marked discourse relations.", "sent2": "Our model assumes that coherent text implicitly favors certain types of discourse relation transitions.", "label": 0}
{"sent1": "We use several linguistically informed features, including polarity tags, Levin verb classes, length of verb phrases, modality, context, and lexical features.", "sent2": "In addition, we revisit past approaches using lexical pairs from unannotated text as features, explain some of their shortcomings and propose modifications.", "label": 1}
{"sent1": "The paper describes the Relational Structure as the common underlying representation of treebanks which is motivated by both theoretical and task-dependent considerations.", "sent2": "Then it presents a system for the annotation of the Relational Structure in treebanks, called Augmented Relational Structure, which allows for a systematic annotation of various components of linguistic knowledge crucial in several tasks.", "label": 1}
{"sent1": "Specifically, we set up three dimensions of user models: skill level to the system, knowledge level on the target domain and the degree of hastiness.", "sent2": "Moreover, we address appropriate user modeling in order to generate cooperative responses to each user.", "label": 1}
{"sent1": "Our work is focused on error detection in sentences with a language model based on syntactic tri-grams and bi-grams extracted from dependency trees generated from 90% of the English Wikipedia.", "sent2": "Empirical results show significant improvements in alignment quality as well as in translation performance over baselines in a large-scale ChineseEnglish translation task.", "label": 0}
{"sent1": "We find that the two models achieve similar levels of induction quality, while the HDP confers the advantage of automatically inducing a variable number of senses per word, as compared to manually fixing the number of senses a priori, as in LDA.", "sent2": "its main core ?", "label": 0}
{"sent1": "They enabled us to reveal a much better agreement between dense zones than between edges of synonymy graphs.", "sent2": "The comparison of raw paraphrases is sensitive to syntactic and morphological variation.", "label": 0}
{"sent1": "We reinterpret graph-based WSI as community detection, a well studied problem in network science.", "sent2": "The relations in the co-occurrence graph give rise to word communities, which distinguish senses.", "label": 1}
{"sent1": "For 1,000 documents retrieved, we improve mean precision by 25%.", "sent2": "For example, words such as good, beautiful , and wonderful are considered as positive words; whereas words such as bad, ugly, and sad are considered negative words.", "label": 0}
{"sent1": "Unlike most feature weight learning algorithms, we propose an unsupervised algorithm in the proposed framework to simultaneously optimize similarity and the keyword weights.", "sent2": "We obtain final BLEU scores of 19.35 (conditional probability model) and 19.00 (joint probability model) as compared to 14.30 for a baseline phrase-based system and 16.25 for a system which transliterates OOV words in the baseline system.", "label": 0}
{"sent1": "Two scenarios are considered: a scenario in which information about part-of-speech is available, and a scenario in which parsing relies only on word forms and distributional clusters.", "sent2": "Our approach is evaluated on data from 12 different languages.", "label": 1}
{"sent1": "These different context positions are then combined into one context vector and compared across languages.", "sent2": "the predecessors and successors.", "label": 1}
{"sent1": "At each stage, we evaluate the intermediate results manually, and tune the later stages accordingly.", "sent2": "Although the ideal length of summaries differs greatly from topic to topic on Twitter, previous work has only generated summaries of a pre-fixed length.", "label": 0}
{"sent1": "In this paper we explore three phrase alignment approaches to detect parallel phrase pairs embedded in comparable sentences: the standard phrase extraction algorithm, which relies on the Viterbi path; a phrase extraction approach that does not rely on the Viterbi path, but uses only lexical features; and a binary classifier that detects parallel phrase pairs when presented with a large collection of phrase pair candidates.", "sent2": "The ability to detect these phrases creates a valuable resource, especially for low-resource languages.", "label": 1}
{"sent1": "We present DAVID, a simple, lexical resource-based preference violation detector.", "sent2": "Under a lexicalist approach to semantics, a verb completely encodes its syntactic and semantic structures, along with the relevant syntax-tosemantics mapping; polysemy is typically attributed to the existence of different lexical entries.", "label": 0}
{"sent1": "In this paper we demonstrate that integrating qualitative information can bring significant performance improvements with negligible impact on system complexity.", "sent2": "the number of alignments), disregarding qualitative aspects (the importance of aligned terms).", "label": 1}
{"sent1": "In order to solve the problem, we have been building a large-scale Japanese syntactically annotated corpus.", "sent2": "The experiments also show that the reordering at the chunk-level performs better than at the POS-level.", "label": 0}
{"sent1": "However, the potential benefits of such data are yet to be fully realized due to the complexity and noise in the alignment between image content and text.", "sent2": "In this paper we propose a method for building frame-based corpus on the basis of domain knowledge provided by ontologies.", "label": 0}
{"sent1": "We also describe a new sampling algorithm called corpus sampling which allows us at training time to use BLEU instead of an approximation thereof.", "sent2": "Furthermore, combination of the proposed method and the JSCM gives further improvement, which outperforms state-of-the-art results in terms of top-1 accuracy.", "label": 0}
{"sent1": "This is motivated by the observation that N-best lists often show significant differences in feature distributions.", "sent2": "The idea is to reformulate the reranking problem as a Multitask Learning problem, where each N-best list corresponds to a distinct task.", "label": 1}
{"sent1": "However in theory, Winnow may not converge for nonseparable data.", "sent2": "The types of modifications that were made to the system are discussed.", "label": 0}
{"sent1": "Mostly, it makes topic distributions more coherent and more discriminative.", "sent2": "Experimental results on benchmark dataset empirically confirm this enhancement.", "label": 1}
{"sent1": "Our top-down parsing algorithm allows us to use the early update technique easily for the latent variable structured Perceptron algorithm with beam search, and solves the problem.", "sent2": "We present statistical parsing results that for the first time provide information about what sort of performance a user parsing Wikipedia text can expect.", "label": 0}
{"sent1": "These include the capability to: i) continuously learn and self-adapt to a stream of data coming from multiple translation jobs, ii) react to data diversity by exploiting human feedback, and iii) leverage data similarity by learning and transferring knowledge across domains.", "sent2": "The first type of data consists of category/answer pairs (?Types of vehicle?,?car?", "label": 0}
{"sent1": "State-of-the-art approaches address this issue by implicitly expanding the queries with additional words using statistical translation models.", "sent2": "We will use these word graph to provide an analysis of the search process.", "label": 0}
{"sent1": "The supervised approach directly learns semantic distances from users to propose meaningful task-specific taxonomies.", "sent2": "This paper explores techniques to quickly derive task-specific taxonomies supporting browsing in arbitrary document collections.", "label": 1}
{"sent1": "Second, these algorithms are traditionally evaluated in a balanced class label setting, although in practice many multidomain settings have domain-specific class label biases.", "sent2": "By tracking changes in contextual information, we predict and identify gradual and rapid changes in information content in response to in-game events.", "label": 0}
{"sent1": "Leveraging the Posterior Regularization framework, we develop an architecture for incorporating biases into representation learning.", "sent2": "We argue that because the task is computationally intractable in general, it is important for a representation learner to be able to incorporate expert knowledge during its search for helpful features.", "label": 1}
{"sent1": "The approach is based on the observation that natural language is remarkably unambiguous in the sense that only a tiny portion of the large number of possible parses of a natural language sentence are syntactically valid.", "sent2": "However, to the best of our knowledge, the NLG community has been less concerned with explicit voice selection.", "label": 0}
{"sent1": "definitions with an overall accuracy of 93.5%.", "sent2": "In this paper we show that the use of multiple dimensions in distinguishing and annotating semantic units supports a more accurate analysis of the meaning of discourse markers.", "label": 0}
{"sent1": "Our method is designed to select hypotheses which vary in trait value but do not significantly degrade in BLEU score.", "sent2": "Our results show that our theoretically motivated features achieve 66% accuracy, an improvement over a unigram baseline of an absolute 6%.", "label": 0}
{"sent1": "We introduce two rules: a BITG-style reordering glue rule and a simpler monotonic concatenation rule.", "sent2": "We use separate features for the new rules in our loglinear model allowing the decoder to directly optimize the feature weights.", "label": 1}
{"sent1": "The solver uses Soon et al (2001)?s classical resolution algorithm based on a pairwise classification of the mentions.", "sent2": "This paper presents an approach to the question whether it is possible to construct a parser based on ideas from case-based reasoning.", "label": 0}
{"sent1": "We use Entropy Guided Transformation Learning (ETL) and Decision Trees as the base learners, and, respectively, ETL Committee and Random Forest as ensemble algorithms.", "sent2": "Our system is evaluated on the closed track of the CoNLL 2011 shared task: Modeling Unrestricted Coreference in OntoNotes.", "label": 1}
{"sent1": "For coreference resolution, we apply SVM by exploiting multiple syntactic and semantic features.", "sent2": "We will show significant improvements on the Chinese-English NIST task.", "label": 0}
{"sent1": "The benefits of an incremental over a mention-pair architecture are: a drastic reduction of the number of candidate pairs, a means to overcome the problem of underspecified items in pairwise classification and the natural integration of global constraints such as transitivity.", "sent2": "We do not apply machine learning, instead the system uses an empirically derived salience measure based on the dependency labels of the true mentions.", "label": 1}
{"sent1": "Since the relatively small size of SALSA does not allow to estimate the semantic relatedness in the extracted argument-predicate pairs, we use a larger corpus for ranking.", "sent2": "In our approaches, we selected lexical and syntactic features based on n-grams of characters, words, Penn TreeBank (PTB) and Universal Parts Of Speech (POS) tagsets, and perplexity values of character of n-grams to build four different models.", "label": 0}
{"sent1": "English, and English?Russian.", "sent2": "I present a novel approach to the determination of recurrent sound correspondences in bilingual wordlists.", "label": 0}
{"sent1": "We develop parallel FDA for solving computational scalability problems caused by the abundance of training data for SMT models and LM models and still achieve SMT performance that is on par with using all of the training data or better.", "sent2": "We use feature decay algorithms (FDA) for fast deployment of accurate statistical machine translation systems taking only about half a day for each translation direction.", "label": 1}
{"sent1": "For the optional SMS evaluation dataset our overall average F-score was 58.82%.", "sent2": "Up to now, the transfer component used a traditional bilingual dictionary to seed the transfer pattern learning process and to provide fallback translations at runtime.", "label": 0}
{"sent1": "We formulate the first sub-problem as a supervised classification task, where we classify the potential keywords as real speculation keywords or not by using a diverse set of linguistic features that represent the contexts of the keywords.", "sent2": "In this paper we present the system we submitted to the WMT12 shared task on Quality Estimation.", "label": 0}
{"sent1": "The proposed method consists of two steps.", "sent2": "The first step is to assign the most similar and familiar word to each unfamiliar word based on their context vectors calculated from a large unannotated corpus.", "label": 1}
{"sent1": "We add phrase boundaries when these are missing, unify inconsistencies, and fix errors.", "sent2": "The SAIL-GRS system is based on a widely used approach originating from information retrieval and document indexing, the TF -IDF measure.", "label": 0}
{"sent1": "However, human perception of these traits is not perfectly aligned with reality.", "sent2": "MIRA based tuning methods have been widely used in statistical machine translation (SMT) system with a large number of features.", "label": 0}
{"sent1": "We perform the first human evaluation of concept dependency edges (to be published as open data), and the results verify the feasibility of automatic approaches for inferring concepts and their dependency relations.", "sent2": "Together, these factors contribute 75% to the variability of the performance of the system.", "label": 0}
{"sent1": "To tune interpolation weights, we apply Newton?s method to this convex problem and show that the derivatives can be computed efficiently in a batch process.", "sent2": "These findings are combined in new open-source interpolation tool, which is distributed with KenLM.", "label": 1}
{"sent1": "We intend for the probabilistic model to provide a probability distribution of verb-class associations, over known and unknown verbs, including polysemous words.", "sent2": "In our approach, training instances are obtained from an existing lexicon and/or from an annotated corpus, while the features, which represent syntactic frames, semantic similarity, and selectional preferences, are extracted from unannotated corpora.", "label": 1}
{"sent1": "We propose different methods through which word embeddings can be leveraged in a state-of-the-art supervised WSD system architecture, and perform a deep analysis of how different parameters affect performance.", "sent2": "However, this approach is prone to overfitting when the training is performed with scarce and noisy data.", "label": 0}
{"sent1": "Since our algorithm and cube pruning are both approximate, improvement can be used to increase speed or accuracy.", "sent2": "When tuned to attain the same accuracy, our algorithm is 4.0?7.7 times as fast as the Moses decoder with cube pruning.", "label": 1}
{"sent1": "Our approach is based on the analysis of the paths between two protein names in the dependency parse trees of the sentences.", "sent2": "We introduce a relation extraction method to identify the sentences in biomedical text that indicate an interaction among the protein names mentioned.", "label": 1}
{"sent1": "In common with other approaches to sequence modeling using perceptrons, and in contrast with comparable generative models, this model permits and transparently exploits arbitrary features of input strings.", "sent2": "Experiments show that imposing these constraints allows important gains in accuracy, with regard to the most probable alignments predicted by the model.", "label": 0}
{"sent1": "The full sentence translation hypotheses from multiple systems are additionally selected based on N-gram language models trained on word/word-POS mixed stream, which further improves the translation quality.", "sent2": "We measured timing and intra- and inter-annotator agreement for three types of subjective evaluation.", "label": 0}
{"sent1": "We investigate Gibbs Sampling (GS) and Variational Bayes (VB) estimators and show that VB converges faster than GS for this task and that VB significantly improves 1-to-1 tagging accuracy over EM.", "sent2": "Indeed, hillclimbing works reasonably well in practice but still fails to find the global optimum for between 2% and 12% of all sentence pairs and the probabilities can be several tens of orders of magnitude away from the Viterbi alignment.", "label": 0}
{"sent1": "This approach simultaneously addresses two tasks of coordination disambiguation: the detection of coordinate conjunctions and the scope disambiguation of coordinate structures.", "sent2": "By a ?domain theory?", "label": 0}
{"sent1": "One such language is Arabic, which: a) lacks a capitalization feature; and b) has relatively small knowledge bases, such as Wikipedia.", "sent2": "strategies, showing that using compositionality and avoiding synonyms correlates positively with task performance.", "label": 0}
{"sent1": "We also apply our approach to the famous Zodiac-408 cipher and obtain slightly better (and near to optimal) results than previously published.", "sent2": "Unlike the previous state-of-the-art approach that uses additional word lists to evaluate possible decipherments, our approach only uses a letterbased 6-gram language model.", "label": 1}
{"sent1": "The proposed approach uses Random Walks on a contextual similarity bipartite graph constructed from n-gram sequences on large unlabeled text corpus.", "sent2": "The proposed system is based on unsupervised learning of the normalization equivalences from unlabeled text.", "label": 1}
{"sent1": "2) Extend the chart decoder to incorporate features from the phrase-based path.", "sent2": "The work consists of two parts: 1) for each Hiero translation derivation, find its corresponding discontinuous phrase-based path.", "label": 1}
{"sent1": "Because variation across speakers is greater than variation across items, we also explore individual-level factors as predictors.", "sent2": "substantially improves recall and F1.", "label": 0}
{"sent1": "Metadata files are generated directly in the IMDI XML format from implicit information, and converted to tabular format using a similar procedure.", "sent2": "We consider SCFG-basedMT systems that get syntactic category labels from parsing both the source and target sides of parallel training data.", "label": 0}
{"sent1": "Considering  that  study  materials  are nowadays  very  much  accessible  through internet,  by accommodating  web  content  to anyhow  disabled  users  must  be  seen  as natural  thing.", "sent2": "Dyslexia  is  considered  as  an cognitive  impairment  arising  from  visual similarity  of  letters,  therefore  we  focus  on Czech  language  which  uses  special characters.", "label": 1}
{"sent1": "Participants were required to train their systems to discriminate between languages on a training and development set containing 20,000 sentences from each language (closed submission) and/or any other dataset (open submission).", "sent2": "One month later, a test set containing 1,000 unidentified instances per language was released for evaluation.", "label": 1}
{"sent1": "The performance of a tagger trained on the improved data set of 88% accuracy is significantly better than the baseline of 76%.", "sent2": "It can serve as a stepping stone for further improvement of resources for Macedonian.", "label": 1}
{"sent1": "We compiled NOAH?s Corpus of Swiss German Dialects consisting of various text genres, manually annotated with Part-ofSpeech tags.", "sent2": "As writing in Swiss German has become more and more popular in recent years, we would like to provide data to serve as a stepping stone to automatically process the dialects.", "label": 1}
{"sent1": "Taking advantage of the closeness of MSA and its dialects, one way to solve the problem of the lack of resources for dialects consists in exploiting available MSA resources and NLP tools in order to adapt them to process dialects.", "sent2": "We suggest using paraphrases to alleviate this problem, making this the first work to use paraphrases for FSD.", "label": 0}
{"sent1": "Telugu and Tamil belong to the Dravidian 2 language family.", "sent2": "are expressed in highly heterogeneous ways; but since the elements are textually annotated in existing datasets, SRL is technically applicable.", "label": 0}
{"sent1": "We also evaluate the classifier on dialect data from an additional data source.", "sent2": "Our best system achieves an accuracy of 89.1 % on the Arabic Online Commentary (AOC) dataset (Zaidan and Callison-Burch, 2011) using 10-fold stratified cross validation: a 1.3 % absolute accuracy improvement over the results published by (Zaidan and Callison-Burch, 2014).", "label": 1}
{"sent1": "It would be desirable to use this related dialog data to supplement the small corpus of well-matched dialog data.", "sent2": "perhaps pertaining to different semantic concepts, or from a different dialog system.", "label": 1}
{"sent1": "Recent success in using deep learning for speech research motivates the Deep Neural Network approach presented here.", "sent2": "Models of stylistic shift that focus on specific features are limited in terms of the contexts to which they can be applied if the goal of the analysis is to model socially motivated speech style accommodation.", "label": 0}
{"sent1": "and compare results for both.", "sent2": "We present a way to extract links from messages published on microblogging platforms and we classify them according to the language and possible relevance of their target in order to build a text corpus.", "label": 0}
{"sent1": "In order to become more practical, not only those fundamental techniques but also the techniques of portability and expansibility should be developed.", "sent2": "In our previous research, we demonstrated the portability of the speech recognition module to a developed portal spoken dialogue system.", "label": 1}
{"sent1": "By allowing a flexible order of operations across and within multiple NLP tasks, a CTF-TM can mitigate both cross-task and within-task error propagation.", "sent2": "Finally, CourseMIRROR presents the phrase summary to both instructors and students to help them understand the difficulties and misunderstandings encountered.", "label": 0}
{"sent1": "The two models are fused at the posterior level to produce a final output.", "sent2": "The approach proved successful, reaching rankings of 9th and 4th in the twitter sentiment analysis constrained and unconstrained scenario respectively, despite using only lexical features.", "label": 1}
{"sent1": "lines (turns) for modeling purposes.", "sent2": "Linguistic and textual cues are extracted from the characters?", "label": 1}
{"sent1": "This paper proposes a novel generative model (TransG) to address the issue of multiple relation semantics that a relation may have multiple meanings revealed by the entity pairs associated with the corresponding triples.", "sent2": "The new model can discover latent semantics for a relation and leverage a mixture of relationspecific component vectors to embed a fact triple.", "label": 1}
{"sent1": "The different types of analyses were evaluated using several datasets.", "sent2": "The number of these counters is up to 30 times less than the stream size which is a big memory and space gain.", "label": 0}
{"sent1": "Moreover, all the approaches in the literature thus far have been regular expression based.", "sent2": "Such systems alleviate the need for O(nC2) corpora, significantly.", "label": 0}
{"sent1": "by the term ?functor?", "sent2": "In this work, we propose an alternative way to address the word ambiguity and word mismatch problems by taking advantage of potentially rich semantic information drawn from other languages.", "label": 0}
{"sent1": "This confirms MT-based SA as a cheap and effective alternative to building a fully fledged SA system when dealing with under-resourced languages.", "sent2": "At the same time, documents at a wide range of reading levels are identified and even among the Top-10 search results one finds documents at the lower levels, supporting the potential usefulness of readability ranking for the web.", "label": 0}
{"sent1": "By this way, capturing spectral features from data is possible.", "sent2": "These trends generalize to the Brown corpus; awareness of data complexity may improve other parsing models and unsupervised algorithms.", "label": 0}
{"sent1": "This work presents a novel model for relation extraction from CQA data, which uses discourse of QnA pairs to predict relations between entities mentioned in question and answer sentences.", "sent2": "We present a novel statistical approach that can infer the distribution of a word?s likely acquisition age automatically from authentic texts collected from the Web.", "label": 0}
{"sent1": "However, the information about the authored and translated sides of the corpus is usually not preserved.", "sent2": "We propose a method for modelling how dialogue moves influence and are influenced by the agents?", "label": 0}
{"sent1": "The thesis will examine two main areas: modelling cohesive devices within sentences and modelling discourse relations (DRs) across sentences.", "sent2": "This paper presents an overview of a proposed thesis, exploring the difficulties around DMs in MT, with a focus on Chinese and English.", "label": 1}
{"sent1": "In MT, this is referred to as Quality Estimation (QE), an approach that uses machine learning techniques to predict the quality of unseen data, generalising from a few labelled data points.", "sent2": "Researchers have proven that the target-side monolingual data can greatly enhance the decoder model of NMT.", "label": 0}
{"sent1": "Categorizing large collection of documents requires hand-labeled training data, which is time consuming and needs human expertise.", "sent2": "Topic models are used to uncover underlying semantic and structure of document collections.", "label": 1}
{"sent1": "We present standards for the annotation of information status (old, mediated and new), and give guidelines for annotating information structure, i.e.", "sent2": "On the Penn Treebank, our parser reaches 94.26% unlabeled and 92.41% labeled attachment accuracy, which to our knowledge is the best accuracy on Stanford Dependencies to date.", "label": 0}
{"sent1": "To exploit this contextual feature, we propose the technique of temporal feature modification, which takes various sources of lexical change into account, including changes in term frequency, associative strength between terms and categories, and dynamic categorization systems.", "sent2": "We employ the concept-based optimization framework for topic summarization, and conduct both automatic and human evaluation regarding the summary quality.", "label": 0}
{"sent1": "We first present results suggesting that previous topic segmentation approaches are not appropriate for narrative text.", "sent2": "Experiments show that IMAM significantly outperforms state-of-the-art baselines.", "label": 0}
{"sent1": "Thus, we propose a method that combines opinion mining with graph analysis for the connections between users to identify the chronic critics.", "sent2": "Our experimental results show that the proposed method outperforms analysis based only on opinion mining techniques.", "label": 1}
{"sent1": "A tree kernel for selecting the subtrees which encodes argument structures is applied.", "sent2": "Experiments with Support Vector Machines on large data sets (i.e.", "label": 1}
{"sent1": "The  tool  accepts  preannotated corpora in TEI P5 format and  is able to export the corpus and lexicon in  TEI P5 as well.", "sent2": "The tool is implemented  using  the  LAMP  architecture  and  is  freely available for research purposes.", "label": 1}
{"sent1": "names, their gender and their normalized, linked form, including mentions of theistic beings (e.g., Gods?", "sent2": "To overcome this limitation, this paper proposes a method utilizing the perceptual groups of objects and n-ary relations among them.", "label": 0}
{"sent1": "We suggest that the distributional notion of ?characteristic context?", "sent2": "This paper illustrates the use of distributional techniques, as investigated in computational semantics, for supplying data from large-scale corpora to areas of the humanities which focus on the analysis of concepts.", "label": 1}
{"sent1": "We describe an approach that bridges this lexical gap by learning semantic relatedness using tensor representations.", "sent2": "Such knowledge can then be used by a topic model to discover more coherent aspects.", "label": 0}
{"sent1": "This paper considers the aspectual properties of discourse segments, meaning how they transpire in time.", "sent2": "Scripts representing common sense knowledge about stereotyped sequences of events have been shown to be a valuable resource for NLP applications.", "label": 0}
{"sent1": "The second method is an algorithm that computes the semantic similarity of two words using WordNet, which we use to find alternatives to words that are unknown to the grammar.", "sent2": "The motivation behind the approach is to automatically induce a compact feature representation for words and their relations, tailoring them to the task.", "label": 0}
{"sent1": "program in Computational Linguistics which was taught for the first time last semester.", "sent2": "In this paper we introduce the curriculum of a first semester B.A.", "label": 1}
{"sent1": "Instead, they typically cover a diverse assortment of topics tailored to the capabilities of the students and the interests of the instructor.", "sent2": "However, little content is shared across the introductory courses in this field.", "label": 1}
{"sent1": "class are presented.", "sent2": "The expanded document provides a more accurate estimation of the document model, thus improves retrieval accuracy.", "label": 0}
{"sent1": "This technology provides an opportunity for students to explore large-data issues in the context of a course organized around teams of graduate and undergraduate students, in which they tackle open research problems in the human language technologies.", "sent2": "We will keep in mind the complex nature of the task at hand, which emanates from the informal language applied in tweets and variety of humor types and styles.", "label": 0}
{"sent1": "Experiments show that any source word deletion model can improve a phrase-based system by at least 1.6 BLEU points and the most sophisticated model improves by nearly 2 BLEU points.", "sent2": "This paper also explores the impact of training data size and training data domain/genre on source word deletion.", "label": 1}
{"sent1": "In addition, different methods to train the model have been developed.", "sent2": "Since the structure of the CRFs can get complex, the inference can only be done approximately and the standard algorithms had to be adapted.", "label": 1}
{"sent1": "This paper explores this question by investigating the feasibility of mapping Stanford dependency parses to Hobbsian Logical Form, a practical, event-theoretic semantic representation, using only a set of deterministic rules.", "sent2": "The STD system described in this paper indexes word-level lattices produced by an LVCSR system using Weighted Finite State Transducers (WFSTs).", "label": 0}
{"sent1": "In this paper we analyze the qualities that contribute to the overall eventiveness of a predicate, that is, what makes a predicate an event.", "sent2": "We present results of the experimental implementation of the system in this paper.", "label": 0}
{"sent1": "At one extreme, in the fully unpruned case, it is neither fast nor accurate.", "sent2": "Shortest derivation parsing exhibits an unusual range of behaviors.", "label": 1}
{"sent1": "These new modules are added to a discriminative bootstrapping algorithm to realize topic feature generation, negative example selection and entity candidate pruning.", "sent2": "In this study, we model latent topics with LDA (Latent Dirichlet Allocation) in an unsupervised way.", "label": 1}
{"sent1": "The reason is that, while MT quality aspects are diverse, BLEU limits its scope to the lexical dimension.", "sent2": "In this work, we suggest using metrics which take into account linguistic features at more abstract levels.", "label": 1}
{"sent1": "A solution has been devised with Grammatical Framework (GF) to use language constructs and grammars as libraries that can be written once and reused in various applications.", "sent2": "In this paper, we describe our implementation of the Arabic numeral system, as an example of a bigger implementation of a grammar library for Arabic.", "label": 1}
{"sent1": "We have found wide disagreement among traditional dictionaries on the POS tag attributed to such words.", "sent2": "This work investigates text classification by format style, i.e.", "label": 0}
{"sent1": "For the BPC task, we introduce a more language specific set of definitions for the base phrase annotations.", "sent2": "The state-of-the-art methods for relation extraction are mostly based on statistical learning, and thus all have to deal with feature selection, which can significantly affect the classification performance.", "label": 0}
{"sent1": "Amharic is a Semitic language with rich and complex morphology.", "sent2": "The application of such a stemmer is in dictionary based cross language IR, where there is a need in the translation step, to look up terms in a machine readable dictionary (MRD).", "label": 1}
{"sent1": "Specifically, based on 473 pairs of segment-final and segmentinitiating utterances, we find significant increases for segment-initial utterances in maximum pitch, average pitch, and average intensity, while segment-final utterances show significantly lower minimum pitch.", "sent2": "We present an exploration of generative probabilistic models for multi-document summarization.", "label": 0}
{"sent1": "The concepts introduced here are applied in a system which integrates language and interpretation models into Stochastic Finite State Transducers (SFST).", "sent2": "This paper describes an interpretation and decision strategy that minimizes interpretation errors and perform dialogue actions which may not depend on the hypothesized concepts only, but also on confidence of what has been recognized.", "label": 1}
{"sent1": "of each technique, by comparing the similarity of the segmentation it derives to the original annotations in the corpus.", "sent2": "Quantitative evaluations demonstrate that the topics extracted by this model are substantially more than those obtained by Latent Dirichlet Allocation and the Author-Topic Model.", "label": 0}
{"sent1": "Each cluster level translation is considered as a bilingual concept, which generalizes words in bilingual clusters.", "sent2": "In particular, it is not clear whether, in planning a pointing gesture in conjunction with a description, an NLG system should seek to minimise the redundancy between them, e.g.", "label": 0}
{"sent1": "We show how these features correlate with a functional classification of tweets, thereby categorizing people?s writing styles based on their different intentions on Twitter.", "sent2": "An application programming interface, an I/O library, and graphical user interfaces are described.", "label": 0}
{"sent1": "Our evaluation illustrates that the summarizer reduces 2.50 characters per sentence on average; the reduction ratio is 6%.", "sent2": "A Naive Bayes learning algorithm learns associations between these features and relation membership categories.", "label": 0}
{"sent1": "into the supervised learning process.", "sent2": "Moreover, we propose a method to perform domain adaptation using the learnt word representations.", "label": 0}
{"sent1": "This paper examines the benefits of system combination for unsupervised WSD.", "sent2": "We investigate several voting- and arbiterbased combination strategies over a diverse pool of unsupervised WSD systems.", "label": 1}
{"sent1": "The key advantage of CCMC over existing methods is that it can obtain a globally optimal solution and can easily scale to large-scale matrices using Hazan?s algorithm.", "sent2": "We experiment with different machine learning approaches for automatic argumentation structure recognition on various levels of granularity of the scheme.", "label": 0}
{"sent1": "In some of these systems there is an option of assigning a sentiment value to a single sentence or a very short text.", "sent2": "Automated identification of diverse sentiment types can be beneficial for many NLP systems such as review summarization and public media analysis.", "label": 1}
{"sent1": "The key assumption behind many approaches is that translation is guided by the source and/or target language parse, employing rules extracted from the parse tree or performing tree transformations.", "sent2": "While it is generally accepted that many translation phenomena are correlated with linguistic structures, employing linguistic syntax for translation has proven a highly non-trivial task.", "label": 1}
{"sent1": "In this paper, we explore the potential of deep syntax language models providing an interesting comparison with the traditional string-based language model.", "sent2": "We include an experimental evaluation that compares the two kinds of models independently of any MT system to investigate the possible potential of integrating a deep syntax language model into Hierarchical SMT systems.", "label": 1}
{"sent1": "In some fields like image processing, many studies have shown the effectiveness of neural network-based transfer learning.", "sent2": "This module, which creates extraction patterns starting from a user?s narrative task description, allows rapid customization to new extraction tasks.", "label": 0}
{"sent1": "An experimental evaluation finds that our algorithm is able to segment the input two to three times more frequently than conventional methods in terms of number of words, while maintaining the same score of automatic evaluation.", "sent2": "1", "label": 1}
{"sent1": "From these experiments, we gain a better understanding of why self-training works for parsing.", "sent2": "Since improvements from selftraining are correlated with unknown bigrams and biheads but not unknown words, the benefit of self-training appears most influenced by seeing known words in new combinations.", "label": 1}
{"sent1": "Second, we combine this model with an extended notion of ?confidence score?", "sent2": "that combines speech recognition confidence with different kinds of semantic and pragmatic confidence, and argue that the resulting processing model can produce a more natural clarification and confirmation behaviour than that of current dialogue systems.", "label": 1}
{"sent1": "The latter consist of task creation and completion actions, collected from a wide variety of sources within the target environment.", "sent2": "feedback, we train a simplified ?Baby?", "label": 0}
{"sent1": "In addition, systems were tested in an intrinsic evaluation involving human judges.", "sent2": "The major novelty of our work is that we automatically learn commercial intents revealed from microblogs.", "label": 0}
{"sent1": "We also evaluated systems extrinsically by applying coreference resolution tools to the outputs and measuring the success of the tools.", "sent2": "In addition, systems were tested in an intrinsic evaluation involving human judges.", "label": 1}
{"sent1": "The parser achieves a precision of more than 68% on difficult test data, which is 23% more than the baseline obtained by randomly choosing one of the simplest analyses.", "sent2": "Remarkable is the fact that precision drops to 52% without lexicalization.", "label": 1}
{"sent1": "We look at the use of several sources of data, including parallel corpora, using English and Portuguese data from a corpus of Pediatrics, and examining how a second language can provide relevant cues for this tasks.", "sent2": "We report results obtained by a combination of statistical measures and linguistic information, and compare these to the reported in the literature.", "label": 1}
{"sent1": "Our research has shown that effective candidate selection leads to better performance as evaluation accounts for candidate coverage.", "sent2": "Our work also attests that many of existing features are also usable in unsupervised extraction.", "label": 1}
{"sent1": "We focus our study on Verb-Noun Constructions (VNC) that vary in their idiomaticity depending on context.", "sent2": "We address the problem of classifying multiword expression tokens in running text.", "label": 1}
{"sent1": "In addition, we implement three methods to integrate bilingual MWEs to Moses, the state-ofthe-art phrase-based machine translation system.", "sent2": "This paper presents a simple yet effective strategy to extract domain bilingual multiword expressions.", "label": 1}
{"sent1": "Our proposed method regards a compound noun (chunk) as a labeling unit, and first estimates the labels of all the chunks in a phrasal unit (bunsetsu) using a machine learning method.", "sent2": "In contrast, our system involves the user throughout the labeling process, using active learning to intelligently explore the space of similar words.", "label": 0}
{"sent1": "Recently, a few groups have proposed rulebased preprocessing methods to mitigate this problem (Xu et al, 2009; Hong et al, 2009).", "sent2": "However, SMT-based translation from an SVO language to an SOV language does not work well because their word orders are completely different.", "label": 1}
{"sent1": "This system has been in development at RWTH for the last two years and has been successfully applied in different machine translation evaluations.", "sent2": "However, to our knowledge, the meanings represented by WordNet have been only used for WSD at a very fine-grained sense level or at a very coarse-grained class level.", "label": 0}
{"sent1": "The competitive predictor assigns a probability per model weighted by the sequential performance.", "sent2": "We show the performance of C4.5, Bagging, and Ripper classifiers on several classes of instances such as nouns and pronouns, only nouns, only pronouns.", "label": 0}
{"sent1": "The basic three-pass framework includes building individual confusion networks (CNs), a super network, and a modified Minimum Bayes-risk (mConMBR) decoder.", "sent2": "We defined a kernel function, namely the Domain Kernel, that allowed us to plug ?external knowledge?", "label": 0}
{"sent1": "In the second part of the paper, we present supervised algorithms to address automatic discourse connective identification and discourse relation recognition.", "sent2": "Traditional approaches have focused on providing theoretical accounts for either the uncertainty or the complexity of spoken dialogue, but rarely considered the two issues simultaneously.", "label": 0}
{"sent1": "Using constrained resources, we participated in all nine language pairs, namely translating English to and from Czech, French, German, and Spanish as well as combining English translations from multiple languages.", "sent2": "Combination proceeds by aligning all pairs of system outputs then navigating the aligned outputs from left to right where each path is a candidate combination.", "label": 1}
{"sent1": "The incremental alignment scheme of (Karakos et.al, 2008) was used for confusion network generation.", "sent2": "The system order in the alignment of each sentence was learned using SVMs, following the work of (Karakos et.al, 2010).", "label": 1}
{"sent1": "All combinations were based on confusion network decoding.", "sent2": "Two experiments on parse reranking show that our method achieves comparable or even better performance than kernel methods and also improves the testing efficiency.", "label": 0}
{"sent1": "Current machine translation metrics do not adequately measure the reordering performance of translation systems.", "sent2": "We present a novel metric, the LRscore, which directly measures reordering success.", "label": 1}
{"sent1": "English).", "sent2": "Coordinations in the Penn Treebank are missing internal structure in many cases, do not include explicit marking of the conjuncts and contain various errors and inconsistencies.", "label": 0}
{"sent1": "In this paper, we propose a general framework based on Conditional Random Fields (CRFs) to detect the contexts and answers of questions from forum threads.", "sent2": "Extracting contexts and answers together with the questions will yield not only a coherent forum summary but also a valuable QA knowledge base.", "label": 1}
{"sent1": "We perform the evaluation on the data collected from Aspies Central forum, including 1,939 threads, 29,947 posts and 972 users.", "sent2": "We present a system that learns to follow navigational natural language directions.", "label": 0}
{"sent1": "The final vector representations of words are used in the LSTM language model which predicts the next word given all the preceding words.", "sent2": "This paper describes the development and evaluation of syllable-based Indian language Text-To-Speech (TTS) synthesis system (around festival TTS) with ORCA and NVDA, for Linux and Windows environments respectively.", "label": 0}
{"sent1": "The ITG constraint is also compatible with word alignments that are not covered by ITG parse trees.", "sent2": "Hence, the proposed method is robust to ITG parse errors compared to other alignment methods that directly use an ITG model.", "label": 1}
{"sent1": "We use a simple maximum entropy classifier to capture the two categories of argument relationships and test its performance on the Chinese Proposition Bank (CPB).", "sent2": "In particular, our method does not restrict words to be segmented only once, into a stem+affix form, as do many extant techniques.", "label": 0}
{"sent1": "We propose to use vector-space semantic models for selecting PPDB paraphrases that preserve the meaning of specific text fragments.", "sent2": "The result is a ?collapsed?", "label": 0}
{"sent1": "Essentially, the method works by sampling hierarchical structures with probability proportional to the likelihood with which they produce the input graph.", "sent2": "Commonly used implementations are inefficient for ambiguous languages, cannot accommodate left-recursive grammars, and require exponential space to represent parse trees for highly ambiguous input.", "label": 0}
{"sent1": "Specifically, we show that by augmenting direct-transfer systems with cross-lingual cluster features, the relative error of delexicalized dependency parsers, trained on English treebanks and transferred to foreign languages, can be reduced by up to 13%.", "sent2": "The paper aims to come up with a system that examines the degree of semantic equivalence between two sentences.", "label": 0}
{"sent1": "In this paradigm, the algorithm is initiated with a parser, such as one that was built based on a very limited amount of fully annotated training data.", "sent2": "systems identified and, if appropriate, replaced references to people in texts.", "label": 0}
{"sent1": "(ii) It employs neighborhood selection, a selection strategy that ensures coverage of both positive and negative links for selected markables.", "sent2": "exam scripts.", "label": 0}
{"sent1": "Our goal is to define a cheap and replicable data collection methodology that minimizes the manual work done by expert annotators, without resorting to preprocessing tools or already annotated monolingual datasets.", "sent2": "The results are interesting from a machine learning perspective, since they show that the rule-based method performs significantly better than the memory-based method, because the former is better capable of representing interactions between features.", "label": 0}
{"sent1": "In this paper, we take a new approach, based on research in cognitive linguistics that views metaphor as a method for transferring knowledge from a familiar, well-understood, or concrete domain to an unfamiliar, less understood, or more abstract domain.", "sent2": "When training a classifier, we would like the distribution of examples seen in training to be as similar as possible to the one seen in testing.", "label": 0}
{"sent1": "It helps to improve the extraction precision.", "sent2": "This work investigates to what degree speakers with different verbal intelligence may adapt to each other.", "label": 0}
{"sent1": "The context-aware constraints provide additional power to the CRF model and can guide semi-supervised learning when labeled data is limited.", "sent2": "We find that the unsupervised method we tried cannot be consistently applied to our data.", "label": 0}
{"sent1": "We build a semantic similarity graph to encode lexical semantic clue, and employ a convolutional neural model to capture contextual semantic clue.", "sent2": "We induce a lexicon by constructing a graph on source language monolingual text and employ a graph propagation technique in order to find translations for all the source language phrases.", "label": 0}
{"sent1": "There are two key challenges: (1) learning quality knowledge from reviews of diverse domains, and (2) making the model fault-tolerant to handle possibly wrong knowledge.", "sent2": "A novel approach is proposed to solve these problems.", "label": 1}
{"sent1": "We examine Arora et al.", "sent2": "?s anchor words algorithm for topic modeling and develop new, regularized algorithms that not only mathematically resemble Gaussian and Dirichlet priors but also improve the interpretability of topic models.", "label": 1}
{"sent1": "We use a maximum entropy classifier to predict translation errors by integrating word posterior probability feature and linguistic features.", "sent2": "We propose to incorporate two groups of linguistic features, which convey information from outside machine translation systems, into error detection: lexical and syntactic features.", "label": 1}
{"sent1": "We first develop an entity-aspect LDA model to simultaneously cluster both sentences and words into aspects.", "sent2": "We then apply frequent subtree pattern mining on the dependency parse trees of the clustered and labeled sentences to discover sentence patterns that well represent the aspects.", "label": 1}
{"sent1": "In this paper we present a method of using the hierarchy of labels to improve the classification accuracy.", "sent2": "However, genre classes are often organised into hierarchies, e.g., covering the subgenres of fiction.", "label": 1}
{"sent1": "Answers demonstrate the effectiveness of our method in terms of ROUGE scores.", "sent2": "We obtain significant improvements on Answer Selection and Dialogue Act Analysis without any feature engineering.", "label": 0}
{"sent1": "In order for these techniques to be more broadly applicable, they need to be extended to apply on weighted packed representations of ambiguous input.", "sent2": "Most of these tasks have been pursued in isolation with the classifier assuming unambiguous input.", "label": 1}
{"sent1": "In the process we evaluate data extracted from the description of a medieval city (Wolfenbu?ttel), transform and develop two methods of computing similarity between sentences based on WordNet.", "sent2": "Experiments are described that compare the pros and cons of the similarity measures and evaluate them.", "label": 1}
{"sent1": "First, the test collection derived from a transaction log corresponds well to the actual search experience of real users.", "sent2": "Many natural language processing (NLP) tools exhibit a decrease in performance when they are applied to data that is linguistically different from the corpus used during development.", "label": 0}
{"sent1": "The specialised language often associated with CH content introduces problems for automatic translation to support search applications.", "sent2": "Our experiments on two data sets in English and Korean show that the consideration of the factors results in performance improvement in keyword extraction from meeting transcripts.", "label": 0}
{"sent1": "The results show an agreement of 75% - 83%.", "sent2": "We validate this method by computing the agreement between the classification produced by the method and manually annotated classifications.", "label": 1}
{"sent1": "Types are specified as NE classes and Roles are integrated into NEs as attributes.", "sent2": "Concepts were classified as Types, while others were identified as being Roles.", "label": 1}
{"sent1": "The method is evaluated by integrating the extracted affixes into an existing learning-based biological term annotation system.", "sent2": "We propose an unsupervised method to automatically extract domain-specific prefixes and suffixes from biological corpora based on the use of PATRICIA tree.", "label": 1}
{"sent1": "Given a two-word noun compound, the participating system is asked to produce an explicitly ranked list of its free-form paraphrases.", "sent2": "Visual analytics techniques can offer new and unexpected insights and knowledge to the literary scholar.", "label": 0}
{"sent1": "Our approach is to build predictive models of concrete external variables, such as restaurant menu prices.", "sent2": "We make use of a dataset of menus and customer reviews for thousands of restaurants in several U.S. cities.", "label": 1}
{"sent1": "Until now, however, such conversion schemes have been created manually.", "sent2": "This unified representation plays a crucial role in cross-lingual syntactic transfer of multilingual dependency parsers.", "label": 1}
{"sent1": "The underlying problem is how to tag part-of-speech (POS) for the English words involved.", "sent2": "John G. Roberts, 2007 (Garner, 2010)", "label": 0}
{"sent1": "In this paper we show that we can build POS-taggers exceeding state-of-the-art bilingual methods by using simple hidden Markov models and a freely available and naturally growing resource, the Wiktionary.", "sent2": "The method can be applied to any language pair where the source language is unsegmented and the target language segmentation is known.", "label": 0}
{"sent1": "Although developed as part of a suite of tools aimed at providing question answering systems with information about both temporal and intensional relations among events, it can be used independently as an event extraction tool.", "sent2": "It is unique in that it is not limited to any pre-established list of relation types (events), nor is it restricted to a specific domain.", "label": 1}
{"sent1": "The models differ in terms of the mechanisms by which they integrate the two modalities.", "sent2": "An even more substantial improvement is obtained by combining the posterior probabilities of the two systems.", "label": 0}
{"sent1": "Using syntactic features, we are able to obtain significant improvements over a simple baseline of 23% F-measure absolute points.", "sent2": "Some of the challenges include: the often considerable imbalance in the distribution of positive and negative samples; changes in the documents over time; and effective training and quantification procedures for reporting results.", "label": 0}
{"sent1": "We propose a framework that simplifies the integration of independently existing NLP tools to build language-independent NLP systems capable of creating layered annotations.", "sent2": "The efficiency improvement of our method allows us to run experiments with vocabulary sizes of around 5,000 words, such as a non-parallel version of the VERBMOBIL corpus.", "label": 0}
{"sent1": "We focus on situations where word re-ordering is limited by syntax.", "sent2": "This work is concerned with the space of alignments searched by word alignment systems.", "label": 1}
{"sent1": "Both classifiers perform the best when conversational context and utterance features are combined with speaker?s gaze information.", "sent2": "We derive an efficient algorithm for learning the factorization, analyze its complexity, and provide proof of convergence.", "label": 0}
{"sent1": "In this paper we confront the task of deciding whether a given term has a positive connotation, or a negative connotation, or has no subjective connotation at all; this problem thus subsumes the problem of determining subjectivity and the problem of determining orientation.", "sent2": "is available, which is usually not the case.", "label": 1}
{"sent1": "Although each phrase consists of multiple words, the semantic orientation of the phrase is not a mere sum of the orientations of the component words.", "sent2": "Attention mechanism has enhanced stateof-the-art Neural Machine Translation (NMT) by jointly learning to align and translate.", "label": 0}
{"sent1": "The 58 runs were then collapsed into a single set of 7, 813 unique words.", "sent2": "We did 58 STEP runs on unique non-intersecting seed lists drawn from manually annotated list of positive and negative adjectives and evaluated the results against other manually annotated lists.", "label": 1}
{"sent1": "In our case, we have a KPMLresource (Nigel) and a CCG for English.", "sent2": "Symbolic resources for text synthesis and  text analysis are typically created and stored  separately.", "label": 1}
{"sent1": "While most previous work accesses web text through search engine hit counts, we created a Web Corpus by downloading web pages to create a topic-diverse collection of 10 billion words of English.", "sent2": "Web text has been successfully used as training data for many NLP applications.", "label": 1}
{"sent1": "Furthermore, we will show how some evaluation measures can be improved by the introduction of word-dependent substitution costs.", "sent2": "It is commonly used in informal settings such as social networking sites and is often with mixed with English.", "label": 0}
{"sent1": "We then explore the impact on performance of using ASR output as opposed to human transcription.", "sent2": "Examination of the effect of features shows that predicting top-level and predicting subtopic boundaries are two distinct tasks: (1) for predicting subtopic boundaries, the lexical cohesion-based approach alone can achieve competitive results, (2) for predicting top-level boundaries, the machine learning approach that combines lexical-cohesion and conversational features performs best, and (3) conversational cues, such as cue phrases and overlapping speech, are better indicators for the toplevel prediction task.", "label": 1}
{"sent1": "We compare evaluation results for these systems by human domain experts, human non-experts, and several automatic evaluation metrics, including NIST, BLEU, and ROUGE.", "sent2": "We consider the evaluation problem in Natural Language Generation (NLG) and present results for evaluating several NLG systems with similar functionality, including a knowledge-based generator and several statistical systems.", "label": 1}
{"sent1": "Detailed experiments on hand-annotated data show that our enhanced algorithm outperforms the baseline by 24.4%.", "sent2": "We adapt a word-sense disambiguation algorithm to our task and augment it with multiple seed set learners, a voting schema, and additional features like SuperTags and extrasentential context.", "label": 1}
{"sent1": "The predictions of the cross-validation study differed from the actual user ratings.", "sent2": "The production of color language is essential for grounded language generation.", "label": 0}
{"sent1": "Spoken language (speech-only) understanding systems have addressed this issue of lack of robustness of hand-crafted grammars by exploiting classification techniques to extract fillers of a frame representation.", "sent2": "However, handcrafted multimodal grammars can be brittle with respect to unexpected, erroneous, or disfluent inputs.", "label": 1}
{"sent1": "Our methods synthesize hidden Markov models (for underlying state) and topic models (to connect words to states).", "sent2": "Inferring demographic attributes of social media users is thus a critical step to improving the validity of such studies.", "label": 0}
{"sent1": "Events, time expressions, and temporal relations convey information about the time course of a patient?s clinical record that must be understood for many applications of interest.", "sent2": "Using the state-ofthe-art decoder Moses as the baseline, experiment results show that the shift-reduce algorithm can significantly improve both the accuracy and the speed on different test sets.", "label": 0}
{"sent1": "Previous research to identify pathological findings focused on simplistic approaches that recognize diseases or negated findings, but failed to establish a holistic approach.", "sent2": "Our discussions with radiologists revealed that anatomical entities with pathological findings are of particular interest when linking radiology text and images.", "label": 1}
{"sent1": "A medical expert inspects two thousand term pairs generated by two semantic spaces ?", "sent2": "We introduce a novel coreference resolution system that models entities and events jointly.", "label": 0}
{"sent1": "Importantly, however, our models use only the sentence containing the target phrase as input and are thus less dependent on a potentially inaccurate or incomplete model of discourse context.", "sent2": "In experiments on a subset of the Switchboard conversational speech corpus, our models thus far improve classification error rates from a previously published result of 29.1% to about 15%.", "label": 0}
{"sent1": "Experiments on an online breast cancer discussion forum dataset demonstrate a significant improvement in metaphor detection over the state-of-theart.", "sent2": "We conduct a large scale study and show significant improvement over existing state-ofthe-art approaches.", "label": 0}
{"sent1": "We show the limits of these point-based intrinsic evaluations.", "sent2": "We report on the TOR system that participated in the 2013 CoNLL shared task on grammatical correction.", "label": 0}
{"sent1": "Experiments on general and specific domains demonstrate that this framework can construct high-quality schemas with many event and argument role types, covering a high proportion of event types and argument roles in manually defined schemas.", "sent2": "We incorporate symbolic (e.g., Abstract Meaning Representation) and distributional semantics to detect and represent event structures and adopt a joint typing framework to simultaneously extract event types and argument roles and discover an event schema.", "label": 1}
{"sent1": "(2010)).", "sent2": "Instead of inducing this knowledge in the form of graphs, as in much of the previous work, in our method, distributed representations of event realizations are computed based on distributed representations of predicates and their arguments, and then these representations are used to predict prototypical event orderings.", "label": 1}
{"sent1": "Within an event, lexical weights capture the contribution of each word to the aligned path segment.", "sent2": "Our model encodes a map from natural language descriptions to paths, mediated by segmentation variables which break the language into a discrete set of events, and alignment variables which reorder those events.", "label": 1}
{"sent1": "We create a large dataset of gold-standard proposition entailment graphs, and provide a novel algorithm for automatically constructing them.", "sent2": "Our analysis shows that predicate entailment is extremely context-sensitive, and that current lexical-semantic resources do not capture many of the lexical inferences induced by proposition entailment.", "label": 1}
{"sent1": "This huge amount of spoken dialogue data has led to a need for fully automatic methods for selecting a subset of caller dialogues that are most likely to be useful for further system improvement, to be stored, transcribed and further analyzed.", "sent2": "We present two systems that select the most appropriate Spanish substitutes for a marked word in an English test sentence.", "label": 0}
{"sent1": "Experiments carried out on the TREC-2001 judged-answer collection show that the approach achieves a high level of performance (i.e.", "sent2": "Since improvements from selftraining are correlated with unknown bigrams and biheads but not unknown words, the benefit of self-training appears most influenced by seeing known words in new combinations.", "label": 0}
{"sent1": "The low-frequency variant performs even better, and the combinations is best.", "sent2": "This will further automate our knowledge acquisition system for non-technical users.", "label": 0}
{"sent1": "The system then uses a statistical hierarchical model of text production in order to drop non-important syntactic and discourse constituents so as to generate coherent, grammatical document compressions of arbitrary length.", "sent2": "Our compression system first automatically derives the syntactic structure of each sentence and the overall discourse structure of the text given as input.", "label": 1}
{"sent1": "The corpus of human created extracts is created from a newspaper corpus and used as a test set.", "sent2": "In particular, we explore the use of probabilistic decision tree within the clustering framework to account for the variation as well as regularity in human created summaries.", "label": 1}
{"sent1": "The first approach uses a boosting algorithm for ranking problems.", "sent2": "The second approach uses the voted perceptron algorithm.", "label": 1}
{"sent1": "The HMM and CRF hybrid model, which combines character-based model with word-based model in a directed graph, is adopted in system developing.", "sent2": "We present a probabilistic parsing model for German trained on the Negra treebank.", "label": 0}
{"sent1": "for structured natural language data.", "sent2": "This paper proposes the ?Hierarchical Directed Acyclic Graph (HDAG) Kernel?", "label": 1}
{"sent1": "Resulting inferences exceed the complexity of inferences undertaken in word sense disambiguation.", "sent2": "Our algorithm generalises over two levels of contextual similarity.", "label": 1}
{"sent1": "We present a statistical model for computing the probability of an alignment given a sentence pair.", "sent2": "We show significant improvements in translation quality of sentences from news domain, when compared to state-of-the-art reordering methods.", "label": 0}
{"sent1": "We propose an alternative model that uses sister-head dependencies instead of head-head dependencies.", "sent2": "aspect terms and aspect categories.", "label": 0}
{"sent1": "The N-best candidates are produced using a conditional random field (CRF) character-based tagger for word segmentation.", "sent2": "We present a general methodology for extracting multi-word expressions (of various types), along with their translations, from small parallel corpora.", "label": 0}
{"sent1": "We introduce new sampling techniques that take into account a notion of streaming discourse (current mentions depend on previous mentions).", "sent2": "For the sample to be representative it should represent a large number of entities whilst taking into account both temporal recency and distant references.", "label": 1}
{"sent1": "The interface allows the user to find supplementary information on selected difficult words.", "sent2": "We introduce an interactive interface that aims to help English as a Second Language (ESL) students overcome language related hindrances while reading a text.", "label": 1}
{"sent1": "The good performances achieved and the relative simplicity of both approaches make them reproducible baselines.", "sent2": "For this, we present several network visualizations based on activation clusters, first derivative saliency, and embedding space transformations, helping us automatically identify several subtle linguistics markers of politeness theories.", "label": 0}
{"sent1": "The task was designed to promote research on semantic inference over texts written in different languages, targeting at the same time a real application scenario.", "sent2": "Moreover, the models are automatically derived by decision tree learning using real dialogue data collected by the system.", "label": 0}
{"sent1": "For this we learn a binary classifier.", "sent2": "As only very little training data is provided, we describe a procedure for generating artificial unlabeled data from Wordnet and a corpus and approach the classification task as a semisupervised machine learning problem.", "label": 1}
{"sent1": "The assumption is that syntactic information are more robust than patterns when coping with length and complexity of the sentences.", "sent2": "Vi-xfst also keeps track of dependencies among the regular expressions at a very finegrained level.", "label": 0}
{"sent1": "An improvement of 17% 35% in the accuracy of verb WSD is obtained compared to the existing EM based approach.", "sent2": "On a general note, the work can be looked upon as contributing to the framework of unsupervised WSD through context aware expectation maximization.", "label": 1}
{"sent1": "We investigate active learning techniques to reduce the size of these datasets and thus annotation effort.", "sent2": "Experiments on a number of datasets show that with as little as 25% of the training instances it is possible to obtain similar or superior performance compared to that of the complete datasets.", "label": 1}
{"sent1": "In this paper, we develop a novel model called Evolutionary Hierarchical Dirichlet Process(EHDP) to capture the topic evolution pattern in timeline summarization.", "sent2": "POS-tagger for modern German on historical data from the Early Modern period (1650-1800).", "label": 0}
{"sent1": "Then by making use of the reconstruction error, we propose a unified scheme to determine which feature or example a classifier is most likely to benefit from having labeled.", "sent2": "Empirical results demonstrate the effectiveness of our proposed methods.", "label": 1}
{"sent1": "We present a system that can take a topic query as input and generate a survey of the topic by first selecting a set of relevant documents, and then selecting relevant sentences from those documents.", "sent2": "The second method is proposed to construct additional rules directly from the chart using inside and outside probabilities to determine the span of the rule and its non-terminals.", "label": 0}
{"sent1": "Applying accurate human ratings on a small set of responses can improve the whole scoring system?s performance while meeting cost and score-reporting time requirements.", "sent2": "Second, we propose a novel way to utilize human rating processes in automated speech scoring.", "label": 1}
{"sent1": "An empirical study is conducted on the tasks of graph-based knowledge base inference, and person named entity extraction from parsed text.", "sent2": "Traditional approaches to the task of ACE event extraction usually rely on sequential pipelines with multiple stages, which suffer from error propagation since event triggers and arguments are predicted in isolation by independent local classifiers.", "label": 0}
{"sent1": "a humanoid robot).", "sent2": "It is based on a Combinatory Categorial Grammar.", "label": 1}
{"sent1": "TransD has less parameters and has no matrix-vector multiplication operations, which makes it can be applied on large scale graphs.", "sent2": "In Experiments, we evaluate our model on two typical tasks including triplets classification and link prediction.", "label": 1}
{"sent1": "Thus, the method combines the benefits of both explicit and latent topic modelling approaches.", "sent2": "We show that on a crosslingual mate retrieval task, our model significantly outperforms LDA, LSI, and ESA, as well as a baseline that translates every word in a document into the target language.", "label": 1}
{"sent1": "To investigate the robustness of the approach, the system is tested on the three subcorpora of the BioScope corpus representing different text types.", "sent2": "The system combines several classifiers and works in two phases.", "label": 1}
{"sent1": "including discontiguous, many-to-many alignments?and produces competitive translation results.", "sent2": "The proposed method consists of three steps.", "label": 0}
{"sent1": "By representing the model assumptions with a factor graph, we shed light on the optimization problems tackled in each method.", "sent2": "We present a unified view of two state-of-theart non-projective dependency parsers, both approximate: the loopy belief propagation parser of Smith and Eisner (2008) and the relaxed linear program of Martins et al (2009).", "label": 1}
{"sent1": "Experimental results on a set of focused What ...?", "sent2": "This paper explores the large-scale acquisition of sense-tagged examples for Word Sense Disambiguation (WSD).", "label": 0}
{"sent1": "On the other hand, ontology screening systems should be able to take advantage of some popular techniques for WSD, which is supposed to decide the right sense where the target word is used in a specific context.", "sent2": "We present several examples regarding inconsistencies in ontologies with the aid of DAML+OIL notation(DAML+OIL, 2001), and propose that WSD can be one of the promising method to screen such as inconsistencies.", "label": 1}
{"sent1": "After extracting k-best derivations, we reestimate the translation model probabilities based on collected rule counts.", "sent2": "Instead, we model what makes timelines of fluents consistent by learning cross-fluent constraints, potentially spanning entities as well.", "label": 0}
{"sent1": "However, the conversational dialog distracts more from driving than the command-based.", "sent2": "Unlike traditional approaches, our method leverages the knowledge base in an early stage to prune the search space and thus simplifies the semantic matching problem.", "label": 0}
{"sent1": "V. Oswald was murdered at JFK after his assassin, K. F. Johns...?", "sent2": "E.g., the kill (Johns, Oswald) relation in: ?J.", "label": 1}
{"sent1": "This method is applied to preprocess the training data, and to collect statistics about verb movements.", "sent2": "meaning representations while generating the overall semantics.", "label": 0}
{"sent1": "It is often the case that literary works exist in more than one language, suggesting that, if properly aligned, they could be turned into useful resources for many practical applications, such as writing and language learning aids, translation studies, or data-based machine translation.", "sent2": "This paper provides a brief description related to the data of both tasks, the evaluation methodology, as well as an overview of participation and corresponding results.", "label": 0}
{"sent1": "Our tagger is designed as a combination of a linear model for discrete features and a feed-forward neural network that captures the non-linear interactions among the continuous features.", "sent2": "Results suggest that no single lexicon is best for every task and dataset and that the intrinsic evaluation of polarity lexicons is not a good performance indicator on a Sentiment Analysis task.", "label": 0}
{"sent1": "Word aligners that model the alignment matrix can express arbitrary alignments, but are difficult to decode.", "sent2": "We propose an alignment matrix model as a correction algorithm to an underlying sequencebased aligner.", "label": 1}
{"sent1": "35 teams participated in the task, submitting 88 runs.", "sent2": "Our model substantially outperforms a stateof-the-art semantic parsing baseline, yielding a 29% absolute improvement in accuracy.1", "label": 0}
{"sent1": "Despite this, the existing body of work is dominated by conservative methods with little (if any) attention paid to providing users with control over the behavior of stopping methods.", "sent2": "Code assignment is important for handling large amounts of electronic medical data in the modern hospital.", "label": 0}
{"sent1": "This work is inspired by a corpus of 1.3 million Twitter conversations, which will be made publicly available.", "sent2": "Social Media contain a multitude of user opinions which can be used to predict realworld phenomena in many domains including politics, finance and health.", "label": 0}
{"sent1": "Traditional machine translation (MT) systems treat LCS data as noise, or just as regular sentences.", "sent2": "?\u0000k ?meeting (We will have a meeting in 15 minutes)?.", "label": 1}
{"sent1": "Our experimental results show that feature clustering can aggressively reduce the dimensionality of feature space, while still maintaining state of the art sense disambiguation accuracy.", "sent2": "Thus, it can deal with both seen and unseen features in feature clustering process.", "label": 1}
{"sent1": "The new XML interface allows a visualization of predictions stemming from any kind of Machine Learning (ML) framework.", "sent2": "We adapted the widespread CMU Let?s Go corpus to demonstrate Witchcraft.", "label": 1}
{"sent1": "Morphologically rich languages are often short on training data or require much higher amounts of training data due to the increased size of their lexicon.", "sent2": "Incremental natural language understanding is the task of assigning semantic representations to successively larger prefixes of utterances.", "label": 0}
{"sent1": "In this paper, we propose methods to transform eojeol-based Korean treebanks into entity-based Korean treebanks.", "sent2": "A neural network is used to perform the projection and the probability estimation.", "label": 0}
{"sent1": "This paper introduces three Temporal Correspondence Heuristics, that characterize regularities in parallel news streams, and shows how they may be used to generate high precision paraphrases for event relations.", "sent2": "We encode the heuristics in a probabilistic graphical model to create the NEWSSPIKE algorithm for mining news streams.", "label": 1}
{"sent1": "We test our approach on the the Penn Treebank and the French Treebank.", "sent2": "The trend toward the growing multilinguality of the Internet requires text summarization techniques that work equally well in multiple languages.", "label": 0}
{"sent1": "The unified model decomposes into two classes of non-parametric Bayesian component models: a Dirichlet process mixture model for clustering, and a set of multinomial Dirichlet process models that perform bilingual alignment independently for each cluster.", "sent2": "The key idea is to assign a probability to each word pair to indicate how well they are aligned.", "label": 0}
{"sent1": "The features, source connectivity strength and target connectivity strength reflect the quality of projected alignments between the source and target phrases in the pivot phrase table.", "sent2": "In this paper, we present two language-independent features to improve the quality of phrase-pivot based SMT.", "label": 1}
{"sent1": "Previous approaches to D2W focused on the use of local and global statistics over the given text, Wikipedia articles and its link structures, to evaluate context compatibility among a list of probable candidates.", "sent2": "This finding suggests that global sequence classification of the relations in text can lead to better results, especially for implicit relations.", "label": 0}
{"sent1": "than a group.", "sent2": "In this work, we present an approach for multilingual portability of Spoken Language Understanding systems.", "label": 0}
{"sent1": "This approach allows an exact and compact description of mutations.", "sent2": "However, most of existing methods only focus on local text information and ignore the global user preference and product characteristics.", "label": 0}
{"sent1": "We present a statistical model for translation from Scottish Gaelic to Irish that we hope will facilitate communication between the two language communities, especially in social media.", "sent2": "In this paper, we investigate the problem of automatically predicting segment boundaries in spoken multiparty dialogue.", "label": 0}
{"sent1": "This paper presents a method that uses clustering to produce multiple ?sense-specific?", "sent2": "It was performed on a German and an English treebank using two different annotation schemes at the level of function-argument structure.", "label": 0}
{"sent1": "Our model aligns spans in a source sentence to nodes in a target parse tree.", "sent2": "Our empirical results corroborate theoretical results and show that an edge-based approach using levels of nodes provides an accurate and at the same time expressive means for capturing non-projective structures in natural language.", "label": 0}
{"sent1": "We apply error generation methods and train classifiers for detecting and correcting article errors in essays written by non-native English speakers; we show that training on data that contain errors produces higher accuracy when compared to a system that is trained on clean native data.", "sent2": "Error generation methods avoid expensive data annotation and create training data that resemble non-native data with errors.", "label": 1}
{"sent1": "Meanwhile, we propose a hierarchical attention mechanism for the bilingual LSTM network.", "sent2": "The sentence-level attention model learns which sentences of a document are more important for determining the overall sentiment while the word-level attention model learns which words in each sentence are decisive.", "label": 1}
{"sent1": "To understand in what respects NMT provides better translation quality than PBMT, we perform a detailed analysis of neural vs. phrase-based SMT outputs, leveraging high quality post-edits performed by professional translators on the IWSLT data.", "sent2": "In particular, at the IWSLT 2015 evaluation campaign, NMT outperformed well established state-ofthe-art PBMT systems on English-German, a language pair known to be particularly hard because of morphology and syntactic differences.", "label": 1}
{"sent1": "At each time during decoding, MEMDEC will read from this memory and write to this memory once, both with content-based addressing.", "sent2": "Second, the actions that we design are linguistically intuitive and capture the regularities in the mapping between the dependency structure and the AMR of a sentence.", "label": 0}
{"sent1": "Corpus development has been very expensive and time-consuming.", "sent2": "Lacking an explicit alignment between the text and the reference path makes it difficult to determine what portions of the language describe which aspects of the route.", "label": 0}
{"sent1": "In particular, Chinese performance improves by over 5% absolute F1 score.", "sent2": "We, therefore, augment the aligned corpus of the two languages, with the correspondence of English suffixes and semantic relations with Hindi suffixes and case markers.", "label": 0}
{"sent1": "Our experiments show that our method is comparable to Hashimoto et al.", "sent2": "We extend their framework and develop a minimally supervised method applicable to multiple languages.", "label": 1}
{"sent1": "Our feature set is a broad class of syntactic patterns, and to better capture the signal we extend the Bayesian Tree Substitution Grammar induction algorithm to a supervised mixture of latent grammars.", "sent2": "The automatic detection of causal relationships in text is important for natural language understanding.", "label": 0}
{"sent1": "A theory of grounding (Phillips, 2010) would suggest that cognitive limitations might cause languages to develop frequent constructions in such a way as to avoid processing costs.", "sent2": "In this paper, first, we explain the design of the challenge.", "label": 0}
{"sent1": "We evaluate our approach in the task of bilingual lexicon extraction (BLE) for a variety of language pairs.", "sent2": "We classify parenthetical translations into bilingual abbreviations, transliterations, and translations.", "label": 0}
{"sent1": "We also demonstrate a discrepancy in the performance of our model and human infants on an artificial-language task in which stress cues and transition-probability information are pitted against one another.", "sent2": "We establish PRO?s scalability and effectiveness by comparing it to MERT and MIRA and demonstrate parity on both phrase-based and syntax-based systems in a variety of language pairs, using large scale data scenarios.", "label": 0}
{"sent1": "To address this problem, we present two simple adaptation methods: the first method is based on the idea of using a shared feature representation when parsing multiple treebanks, and the second method on guided parsing where the output of one parser provides features for a second one.", "sent2": "To evaluate and analyze the adaptation methods, we train parsers on treebank pairs in four languages: German, Swedish, Italian, and English.", "label": 1}
{"sent1": "This improves search at the expense of memory.", "sent2": "Conversely, we show how to save memory by collapsing probability and backoff into a single value without changing sentence-level scores, at the expense of less accurate estimates for sentence fragments.", "label": 1}
{"sent1": "We observed four general types of coreferences in the corpus: sortal, pronominal, abbreviation and numerical.", "sent2": "Consumers increasingly rate, review and research products online (Jansen, 2010; Litvin et al, 2008).", "label": 0}
{"sent1": "Each entry in the thesaurus ?", "sent2": "While we find that co-training and word clusters produce the most promising results, there is little additive improvement when combining the two techniques, which suggests that in the absence of large grammatical discrepancies between the training and test domains, they address largely the same problem, that of unknown vocabulary, with word clusters being a somewhat more effective solution for it.", "label": 0}
{"sent1": "We contrast three types of adjectival modifiers ?", "sent2": "Adjectival modification, particularly by expressions that have been treated as higherorder modifiers in the formal semantics tradition, raises interesting challenges for semantic composition in distributional semantic models.", "label": 1}
{"sent1": "To maximize the utility of the injected knowledge, we deploy a learningbased multi-sieve approach and develop novel entity-based features.", "sent2": "In this paper, we propose a new contextdependent SMT model that is tightly coupled with a language model.", "label": 0}
{"sent1": "In this paper, we will address this weakness by using trees created from instances of Interlinear Glossed Text (IGT) to discover patterns of divergence between the languages.", "sent2": "We also introduce a novel metric to measure translation adequacy based on predicate-argument structure match using word alignments.", "label": 0}
{"sent1": "The results showed a precision of 70% and a recall of 81% for sentences containing the trigger phrases and a negative predictive value of 96% for sentences not containing any trigger phrases.", "sent2": "This translation was evaluated on a set of 436 manually classified sentences from Swedish health records.", "label": 1}
{"sent1": "The semantic descriptions of input utterances are usually defined ad-hoc with no ability to generalize beyond the target application domain or to learn from annotated corpora.", "sent2": "The approach we propose in this paper exploits machine learning of frame semantics, borrowing its theoretical model from computational linguistics.", "label": 1}
{"sent1": "The problem is partially solved either by introducing heuristics or by agreement constraints such that two directional word alignments agree with each other.", "sent2": "The network creation is implicit, as players collaboratively create links between words while they have fun.", "label": 0}
{"sent1": "The approach is evaluated in a series of ArabicEnglish and Chinese-English translation experiments.", "sent2": "The best models demonstrate significant improvements in BLEU and TER over the phrase-based baseline, as well as over the lexicalized BiLM by Niehues et al.", "label": 1}
{"sent1": "An alternative is to crawl the Web ourselves, which also allows us to remove duplicates and nearduplicates, navigational material, and a range of other kinds of non-linguistic matter.", "sent2": "We can also tokenize, lemmatise and part-of-speech tag the corpus, and load the data into a corpus query tool which supports sophisticated linguistic queries.", "label": 1}
{"sent1": "Our analysis reveals a weakness of HD models: their intrinsic focus on configurational information.", "sent2": "We conclude that the form-function separation ingrained in RR models makes them better suited for parsing nonconfigurational phenomena.", "label": 1}
{"sent1": "Our algorithm produces optimal k-best parses under the same conditions required for optimality in a 1-best A?", "sent2": "We show that LHs are particularly helpful for AA, because they provide useful information for uncovering, to some extent, the writing style of authors.", "label": 0}
{"sent1": "We show that our syntax-based model reaches an error reduction in KSPC of 12.4% on a Swedish corpus over a baseline using word frequencies.", "sent2": "We also show that bigrams are superior to all the other models.", "label": 1}
{"sent1": "We propose a novel method for improving word-based Chinese IR, which performs segmentation according to the tightness of phrases.", "sent2": "In combination, these extensions give a statistically significant improvement over a baseline distortion parameterization.", "label": 0}
{"sent1": "LXGram is grounded on the linguistic framework of Head-Driven Phrase Structure Grammar (HPSG).", "sent2": "We test the proposed procedure and the obtained knowledge base on the Recognizing Textual Entailment task using the data sets from the RTE-2 challenge for evaluation.", "label": 0}
{"sent1": "I propose and evaluate a novel unsupervised approach to MND that is motivated by the theory of narratology.", "sent2": "First, one context word representing a certain sense is chosen, and then the co-occurrence frequencies with two other context words, one of the same and one of another sense, are compared.", "label": 0}
{"sent1": "In this paper, a formalized representation of function word subcategorization is developed for parsing in an automatic manner.", "sent2": "Secondly, we use an IR-based indexing technique to speed up the time-consuming matching procedure of the EBMT system.", "label": 0}
{"sent1": "In this paper, we propose a novel study of capturing such long distance dependency by defining two principles of constructing skipedges for a skip-chain CRF: linking similar words and linking words having typed dependencies.", "sent2": "Holding non-co-located conversations while driving is dangerous (Horrey and Wickens, 2006; Strayer et al., 2006), much more so than conversations with physically present, ?situated?", "label": 0}
{"sent1": "User interface research suggests that it is easier to recognize a pattern than to compose it from scratch; therefore, interfaces for non-experts should show previews of syntactic relations.", "sent2": "What these previews should look like is an open question that we explored with a 400-participant Mechanical Turk experiment.", "label": 1}
{"sent1": "Time expressions are then parsed using an extended CYK+ algorithm, and converted to a normalized form by applying the operators recursively.", "sent2": "To address these challenges, we propose a collective inference method that simultaneously resolves a set of mentions.", "label": 0}
{"sent1": "We evaluate on a new corpus of 124 summaries of educational texts, and show that our new system outperforms the old method and several stateof-the-art non-proposition-based summarisers.", "sent2": "Robustness is a key requirement in spoken language understanding (SLU) systems.", "label": 0}
{"sent1": "Under our model, the probability of a class in a text block is a log-linear function of the classes in the previous block.", "sent2": "The study estimates categorical  model and dimensional model for the recognition of four affective states: Anger, Fear, Joy,  and Sadness that are common emotions in  three datasets: SemEval-2007 ?Affective  Text?, ISEAR (International Survey on Emotion Antecedents and Reactions), and children?s fairy tales.", "label": 0}
{"sent1": "This paper introduces a new task, called Open-Database Named-Entity Disambiguation (Open-DB NED), in which a system must be able to resolve named entities to symbols in an arbitrary database, without requiring labeled data for each new database.", "sent2": "We introduce two techniques for Open-DB NED, one based on distant supervision and the other based on domain adaptation.", "label": 1}
{"sent1": "Our results demonstrate that incorporating POS categorization yields substantial performance gains on morphological segmentation of Arabic.", "sent2": "Our model learns that words with common affixes are likely to be in the same syntactic category and uses learned syntactic categories to refine the segmentation boundaries of words.", "label": 1}
{"sent1": "Second, we present a self-learning clustering technique that effectively improves labeling accuracy in the test domain.", "sent2": "Latent models for opinion classification are studied.", "label": 0}
{"sent1": "To this purpose, we primarily rely on linguistic knowledge enriched with role frequency information collected from a training corpus.", "sent2": "An example for learning a grammar for noun compounds is given.", "label": 0}
{"sent1": "This assumption simplifies the computational modeling of semantic arguments, but it ignores the joint nature of natural language.", "sent2": "This framework integrates multiple MT systems?", "label": 0}
{"sent1": "Previous work showed that word lattices constructed from paraphrases are able to reduce out-ofvocabulary words and to express inputs in different ways for better translation quality.", "sent2": "To increase the model coverage, sourcelanguage paraphrases have been utilized to boost SMT system performance.", "label": 1}
{"sent1": "Unlike previous studies, we collect many alternative structures in a packed forest.", "sent2": "Our proposed method builds a simpler structure of MWUs than words using words as vertices of a dependency structure.", "label": 1}
{"sent1": "We show that the two WSD classifiers that were built for these experiments (English?", "sent2": "The geographical properties of words have recently begun to be exploited for geolocating documents based solely on their text, often in the context of social media and online content.", "label": 0}
{"sent1": "A new metric is also introduced to measure the effect of distortion in the translation hypotheses.", "sent2": "In practice however, the topics discovered by LDA do not always make sense to end users.", "label": 0}
{"sent1": "We present a Bayesian model which, unlike previous work, learns both categories and their features in a single process.", "sent2": "Our model employs particle filters, a sequential Monte Carlo method commonly used for approximate probabilistic inference in an incremental setting.", "label": 1}
{"sent1": "performance as they begin to segment words.", "sent2": "We propose a broader focus that includes designing models that display properties of infants?", "label": 1}
{"sent1": "strategy to generate labeled data for SWSD semiautomatically.", "sent2": "This paper describes a new approach for estimating term weights in a text classification task.", "label": 0}
{"sent1": "The first contribution of our work is the creation of a collection including a number of genuinely deceptive Amazon book reviews in collaboration with crime writer Jeremy Duns, who has devoted a great deal of effort in unmasking sock puppeting among his colleagues.", "sent2": "Identifying such deceptive reviews is not easy.", "label": 1}
{"sent1": "Our experiments show that a relative ranking is preferable to an absolute binary one and that the accuracy of identifying relative simplification depends on the initial reading level of the unsimplified version.", "sent2": "The approach is particularly successful in classifying the relative reading level of harder sentences.", "label": 1}
{"sent1": "We use Twitter for data collection and experimentation.", "sent2": "The main innovation of Soothsayer is that it not only uses idiolects, the language of one individual person, as its source of knowledge, but also sociolects, the language of the social circle around that person.", "label": 1}
{"sent1": "We show gains of up to 1.26 BLEU over the baseline and 1.04 over a domain adaptation benchmark.", "sent2": "There is now considerable evidence that the syntactic behaviors of some verbs can be predicted by their meanings, and many current theories posit that this is true for most if not all verbs.", "label": 0}
{"sent1": "Specifically, it exploits a series of natural language processing technologies, such as tweet normalization, named entity recognition, semantic role labeling, sentiment analysis, tweet classification, to extract useful information, i.e., named entities, events, opinions, etc., from a large volume of tweets.", "sent2": "Then, non-noisy tweets, together with the mined information, are indexed, on top of which two brand new scenarios are enabled, i.e., categorized browsing and advanced search, allowing users to effectively access either the tweets or fine-grained information they are interested in.", "label": 1}
{"sent1": "We examine word segmentation specifically, and explore the possibility that children might have generalpurpose chunking mechanisms to perform word segmentation.", "sent2": "During language acquisition, children learn to segment speech into phonemes, syllables, morphemes, and words.", "label": 1}
{"sent1": "In this study, we attempt to ascertain if there are measurable linguistic features of the consultations, and to investigate whether there is any relevant information about the communicative styles of the qualifying doctors that may predict satisfactory or non-satisfactory examination outcomes.", "sent2": "The doctors are internationally qualified and enrolled in a bridging course as preparation for their Australian Medical Council examination.", "label": 1}
{"sent1": "The co-occurrence network of consonants exhibits a high clustering coefficient.", "sent2": "We propose four novel synthesis models for these networks (each of which is a refinement of the earlier) so as to successively match with higher accuracy (a) the above mentioned topological properties as well as (b) the linguistic property of feature economy exhibited by the consonant inventories.", "label": 1}
{"sent1": "The algorithm is domainindependent and generates a representative set of informative and discriminative phrases that cover the entire event.", "sent2": "We evaluate this algorithm on a large collection of blog postings about different news events and report promising results.", "label": 1}
{"sent1": "We also investigate a rule based method that uses hand crafted lists of terms derived from WordNet.", "sent2": "We compare the performance of two approaches to this task: a Support Vector Machine (SVM) classifier and a Language Modeling (LM) approach.", "label": 1}
{"sent1": "Their manual improvement is a time consuming and complex task : identifying which resource is the true culprit for a given mistake is not always obvious, as well as finding the mistake and correcting it.", "sent2": "Thus, increasing the parser coverage and precision usually implies improving these two resources.", "label": 1}
{"sent1": "One possible way to overcome this problem is to summarize a scientific topic.", "sent2": "Quickly moving to a new area of research is painful for researchers due to the vast amount of scientific literature in each field of study.", "label": 1}
{"sent1": "The toolkit is efficient, accurate and currently supports a range of features including EM sequence alignment and several decoding techniques novel in the context of G2P.", "sent2": "Experimental results show that a combination RNNLM system outperforms all previous reported results on several standard G2P test sets.", "label": 1}
{"sent1": "As a starting point, a set of manually coded medical records were collected in order to code new medical records on the basis of this set of positive samples.", "sent2": "By combining existing large-scale knowledge resources (WordNet, Verbnet, the SURGE and HUGG realization grammars) and techniques from modern integrated software development environment (such as the Eclipse IDE), we obtain an efficient tool for the generation of logical forms, in domains where content is not available in the form of databases.", "label": 0}
{"sent1": "We employ stem as the atomic translation unit to alleviate data spareness.", "sent2": "As a consequence, our methodology can be applied to any language and proposes a solution to languagedependent Lexical Chainers.", "label": 0}
{"sent1": "As a result, MT systems tuned against semantic frame based MT evaluation metrics produce output that is more adequate.", "sent2": "In this way, our approach avoids the efforts of decoding the parse trees into the set of flat syntactic features.", "label": 0}
{"sent1": "The distributed representation is automatically learned from data and captures the correlations between POS tags.", "sent2": "In this paper, we propose a novel approach to unsupervised dependency parsing that uses a neural model to predict grammar rule probabilities based on distributed representation of POS tags.", "label": 1}
{"sent1": "The candidate senses for a feature correspond to sense clusters of its translations in a parallel corpus and the context used for disambiguation consists of the vector that contains the feature.", "sent2": "Instead of resorting to an external dictionary, we translate source vector features by using a cross-lingual Word Sense Disambiguation method.", "label": 1}
{"sent1": "Burst Information Networks (BINets).", "sent2": "We propose simple yet effective models to solve the problem based on a novel and promising representation of text streams ?", "label": 1}
{"sent1": "Specifically, we consider scenarios in which annotators explicitly mark sentences (or snippets) that support their overall document categorization, i.e., they provide rationales.", "sent2": "We also provide a new proof of nonregularity of simple OT grammars.", "label": 0}
{"sent1": "To address the coldstart issues commonly present in a collaborative \u0002ltering (CF) system, most existing crossdomain CF models require auxiliary rating data from another domain; nevertheless, under the cross-website scenario, such data is often unobtainable.", "sent2": "In this work, we investigate the possibility of cross-website transfer learning for tackling the cold-start problem.", "label": 1}
{"sent1": "Cross-language evidence shows that the model captures different aspects of linguistic properties for different languages due to the variance of syntactic complexity.", "sent2": "The output of this search process is the target word sequence associated to the optimal path.", "label": 0}
{"sent1": "LAMBADA is a collection of narrative passages sharing the characteristic that human subjects are able to guess their last word if they are exposed to the whole passage, but not if they only see the last sentence preceding the target word.", "sent2": "A detailed study of Sanskrit language reveals that its well-structured and finely organized grammar has affinity for automated translation systems.", "label": 0}
{"sent1": "The task contains a rich variety of challenging classification and extraction sub-tasks, making it well-suited for end-to-end models such as deep neural networks (DNNs).", "sent2": "Our NLP tools are available at: http:// github.com/aritter/twitter_nlp", "label": 0}
{"sent1": "We apply this to dependency parsing and tagging, where we use the hidden layer of the tagger network as a representation of the input tokens for the parser.", "sent2": "We evaluate performance on two opinion extraction tasks, and, in contrast to previous sequence labeling approaches to the task, explore the usefulness of segmentlevel syntactic parse features.", "label": 0}
{"sent1": "For this purpose, we augment the standard approach by a Word Sense Disambiguation process relying on a WordNet-based semantic similarity measure.", "sent2": "The aim of this process is to identify the translations that are more likely to give the best representation of words in the target language.", "label": 1}
{"sent1": "Third, we develop a human interpretable grammar that is competitive with a latent variable PCFG.", "sent2": "A manual error analysis of translated dialectal words shows that our system produces correct translations in 74% of the time for OOVs and 60% of the time for low frequency words.", "label": 0}
{"sent1": "Unfortunately, the latter goals exceed the ability of the traditional bag-of-word representation approach, and a richer, more structural representation is required.", "sent2": "Accordingly, learning algorithms must be created that can handle the structures observed in texts.", "label": 1}
{"sent1": "A spoiler is a comment that, when disclosed, would ruin a surprise or reveal an important plot detail.", "sent2": "We study automatic methods to detect comments and reviews that contain spoilers and apply them to reviews from the IMDB (Internet Movie Database) website.", "label": 1}
{"sent1": "The combination of these representations along the lines of compositional semantic principles exposes the underlying semantic relations in adjective-noun phrases.", "sent2": "We show that our compositional VSM outperforms simple pattern-based approaches by circumventing their inherent sparsity problems.", "label": 1}
{"sent1": "A thorough feature importance study is conducted to analyze how these three components contribute to the coreference results.", "sent2": "We exploit the Matrix Tree Theorem (Tutte, 1984) to derive an algorithm that efficiently sums the scores of all nonprojective trees in a sentence, permitting the definition of a conditional log-linear model over trees.", "label": 0}
{"sent1": "perception and interests.", "sent2": "users?", "label": 1}
{"sent1": "We propose a measure for cost-benefit analysis which measures the ?value for money?", "sent2": "earned in terms of accuracy by investing in annotation effort and lexicon building.", "label": 1}
{"sent1": "It can be applied across different machine translation paradigms and with arbitrary types of models.", "sent2": "We show its efficacy on a small German?English and a larger French?German translation task with both standard phrase-based and hierarchical phrase-based translation systems for a common set of models.", "label": 1}
{"sent1": "Methods used in this approach rank parts of a document based on the similarity to a presumably related document.", "sent2": "Ranks are then used to automatically construct the best anchor text for a link inside original document to the compared document.", "label": 1}
{"sent1": "Using vector representations, such an approach captures both distributional semantic similarities among words as well as the structural relations between them (encoded as the structure of the parse tree).", "sent2": "The key idea is to introduce a new type of transition that reorders top k elements in the memory module.", "label": 0}
{"sent1": "Toba has a complex system of causative suffixes, whose successive applications determinate the use of prefixes belonging different person marking prefix sets.", "sent2": "In order to yield semantics sensitive binary codes for tweet data, we design a binarized matrix factorization model and further improve it in two aspects.", "label": 0}
{"sent1": "These gains also translate to idiom detection in sentences, by simply using known word sense disambiguation algorithms to match phrases to their definitions.", "sent2": "In a set of Wiktionary definition example sentences, the more complete set of idioms boosts detection recall by over 28 percentage points.", "label": 1}
{"sent1": "We formulate the task as constrained optimization to induce the prototypical temporal structure of an event, integrating both visual and textual cues.", "sent2": "This annotation, using stand-off XML in NXT, can help establish standards for the annotation of information structure in discourse.", "label": 0}
{"sent1": "Instead, we propose a probabilistic model for taxonomy induction by jointly leveraging text and images.", "sent2": "used for writing the parser and rules of the grammar loaded into the parser.", "label": 0}
{"sent1": "We first conducted a crowdsourcing experiment and identified eighteen categories of physical causality for action verbs.", "sent2": "We examine word segmentation specifically, and explore the possibility that children might have generalpurpose chunking mechanisms to perform word segmentation.", "label": 0}
{"sent1": "Second, we show their usefulness, reporting on (a) inter-annotator agreement rate, (b) characteristic CFG rules in the corpora, and (c) parsing performance on them.", "sent2": "In addition, we explore methods to improve phrase structure parsing for learner English (achieving an F -measure of 0.878).", "label": 1}
{"sent1": "Our previous work has shown that standard clustering techniques succeed in inducing Levinstyle semantic classes from verb subcategorisation information.", "sent2": "We develop a novel training technique using a dependency oracle, in which all derivations are hidden.", "label": 0}
{"sent1": "In this paper, we analyze the reasons for this and propose a solution which consists in seeking predictions that maximize the expected benefit to the translator, rather than just trying to anticipate some amount of upcoming text.", "sent2": "Presence of OOV words and rare words in the input sentence prevents the system from finding longer phrasal matches and produces low quality translations due to less reliable language model estimates.", "label": 0}
{"sent1": "We used our techniques to generate natural language versions of computer-generated mathematical proofs, with good results on both a per-component and overall-output basis.", "sent2": "This problem requires jointly interpreting a question and an environment using background knowledge to select the correct answer.", "label": 0}
{"sent1": "The key component of the system is iterative query formulation and retrieval, in which one or more queries are automatically formulated from the user?s question, issued to the search engine, and the results accumulated to form the hit list.", "sent2": "Upon receiving these results, this paper suggests a practical design guideline for spoken dialogue systems.", "label": 0}
{"sent1": "This has particularly been a problem with WordNet which is widely used for word sense disambiguation (WSD).", "sent2": "The granularity of word senses in current general purpose sense inventories is often too fine-grained, with narrow sense distinctions that are irrelevant for many NLP applications.", "label": 1}
{"sent1": "On the other hand, human evaluation is a time consuming and expensive task.", "sent2": "Therefore some analysis of the generated output is needed in order to identify the main problems and to focus the research efforts.", "label": 1}
{"sent1": "The first, an unsupervised approach to Word Sense Discrimination, does not require any labelled training instances.", "sent2": "The annotation results were then analyzed via an ANOVA analysis, a logistic regression model and a log-linear model.", "label": 0}
{"sent1": "In a second analysis, we applied a soft cluster analysis to the collected targetresponse pairs.", "sent2": "We apply a unified reranking approach to both grapheme-to-phoneme conversion and machine transliteration demonstrating substantial accuracy improvements by utilizing heterogeneous transliterations and transcriptions of the input word.", "label": 0}
{"sent1": "Effective use of training data to estimate features and parameters is achieved by integrating a leaving-one-out method into the standard ME training algorithm.", "sent2": "The resulting ME models have orders of magnitude fewer parameters.", "label": 1}
{"sent1": "Most sequence labelling methods following a similar approach require the base classifier to make probabilistic predictions.", "sent2": "verbs that most likely will be beyond the state of the art for longer time.", "label": 0}
{"sent1": "In order to combine the predictions generated by the multiclassifier, Bayesian voting is applied.", "sent2": "Through all the classification process, a reduced dimension vector representation obtained by Singular Value Decomposition (SVD) is used for training and testing documents.", "label": 1}
{"sent1": "that provides targetlanguage equivalents for source-language segments.", "sent2": "One problem is that much of the work on discriminative methods conflates changes to the learning method with changes to the parameterization of the problem.", "label": 0}
{"sent1": "We find that this approach coupled with a simple grouping of most frequent morphemes and function words on both sides improve the BLEU score from the baseline of 0.0752 to 0.0913 with the small training data.", "sent2": "Morphological segmentation on the Turkish side also conflates the statistics from allomorphs so that sparseness can be alleviated to a certain extent.", "label": 1}
{"sent1": "We present in this paper exploratory results on learning to predict potential codeswitching points in Spanish-English.", "sent2": "Our extraction approach is inspired by a chunking approach, based on its strong past results on related tasks.", "label": 0}
{"sent1": "We present a new automatic and empirical measure of antonymy that combines corpus statistics with the structure of a published thesaurus.", "sent2": "We conclude by outlining current directions of research including specialized grammars and automatic detection of confusion.", "label": 0}
{"sent1": "The corpus targets 146 ambiguous idioms, and consists of 102,846 sentences, each of which is annotated with a literal/idiom label.", "sent2": "This paper reports on the corpus and the results of an idiom identification experiment using the corpus.", "label": 1}
{"sent1": "We show that though WSD systems trained with a large number of examples can obtain a high level of accuracy, they nevertheless suffer a substantial drop in accuracy when applied to a different domain.", "sent2": "To address this issue, we propose combining a domain adaptation technique using feature augmentation with active learning.", "label": 1}
{"sent1": "These interfaces allow students to experiment with different inputs and view corresponding output and inner workings of the systems.", "sent2": "Word Sense Induction (WSI) is the task of identifying the different senses (uses) of a target word in a given text.", "label": 0}
{"sent1": "We have built a number of visualizations depicting a hidden Markov model for partof-speech tagging and the operation of the Viterbi algorithm.", "sent2": "Our model leads to improved predictions of justices?", "label": 0}
{"sent1": "The methods were found to be almost equal in the accuracy measured by Spearman correlation between the grades given by the system and a human.", "sent2": "We compare evaluation results for these systems by human domain experts, human non-experts, and several automatic evaluation metrics, including NIST, BLEU, and ROUGE.", "label": 0}
{"sent1": "The paper presents the corpus that we use to develop the system and briefly, the developmental sequences.", "sent2": "By transferring knowledge from 1.2M+ images with category labels and 100,000+ images with captions, our method is able to create sentence descriptions of open-domain videos with large vocabularies.", "label": 0}
{"sent1": "We claim that the information status of a mention depends not only on the mention itself but also on other mentions in the vicinity and solve the task by collectively classifying the information status of all mentions.", "sent2": "We add a fine-grained information status layer to the Wall Street Journal portion of the OntoNotes corpus.", "label": 1}
{"sent1": "In the paper we present a 2 steps method for structuring items into descriptive properties.", "sent2": "While some sellers provide rich, structured descriptions of their items, a vast majority of them provide unstructured natural language descriptions.", "label": 1}
{"sent1": "This task can be modeled as a classification problem, provided that positive and negative examples are available for learning binary classifiers.", "sent2": "The named entity disambiguation task is to resolve the many-to-many correspondence between ambiguous names and the unique realworld entity.", "label": 1}
{"sent1": "To mitigate this cost, NLU researchers have considered two newly available sources of less expensive (but potentially lower quality) labeled data from distant supervision and crowd sourcing.", "sent2": "Classically, training relation extractors relies on high-quality, manually annotated training data, which can be expensive to obtain.", "label": 1}
{"sent1": "The model takes in coarse mention and type information and predicts argument roles for a given event template.", "sent2": "This approach is compared to the bilingual terminology provided by the Terminology as a Service (TaaS) platform.", "label": 0}
{"sent1": "Such an approach can, for example, learn likely event durations and the fact that start times should come before end times.", "sent2": "We evaluate intrinsically using held-out probability and perplexity, and find a substantial reduction in uncertainty brought by our spatial representation.", "label": 0}
{"sent1": "This work addresses the problem of PartOf-Speech tagging (initially for French but also for English) on noisy language usage from the popular social media services like Twitter, Facebook and forums.", "sent2": "We also consider the problem of modelling groups of related output variables, using a structured multi-task regularisation method.", "label": 0}
{"sent1": "Our models employ simple and efficient techniques based on n-gram Language modeling.", "sent2": "The Smoothed Partial Tree Kernel is applied, i.e.", "label": 0}
{"sent1": "On the latter task, the Profile HMM method outperforms average and minimum edit distance.", "sent2": "Given the success for these two tasks, we further discuss the potential applications of Profile HMMs to any task where consideration of a set of words is necessary.", "label": 1}
{"sent1": "Emotions and their acoustic correlates will be extracted from a persuasive dialog corpus and will be used to implement an emotionally intelligent dialog system; one that can recognize emotion, choose an optimal strategy for gaining rapport, and render a response that contains appropriate emotion, both lexically and auditory.", "sent2": "The experimental results show that predictive ability of SSHLDA is better than that of baselines, and SSHLDA can also achieve significant improvement over baselines for clustering on the FScore measure.", "label": 0}
{"sent1": "In this paper, we present a possible method of bridging the morpho-syntactic gap for EnglishKorean SMT.", "sent2": "In particular, the proposed method tries to transform a source sentence by inserting pseudo words, and by reordering the sentence in such a way that both sentences have a similar length and word order.", "label": 1}
{"sent1": "and surface realization (?how to say?)", "sent2": "by learning representations of individual characters, and their combinations into one or more lines as well as how these mutually reinforce and constrain each other.", "label": 1}
{"sent1": "Learners are trained to summarize document clusters based on various algorithms and reward functions and then evaluated using ROUGE.", "sent2": "We also show the effect of the training data on the performance of the system.", "label": 0}
{"sent1": "remove or retain.", "sent2": "We propose an innovative sentence compression method by considering every node in the constituent parse tree and deciding its status ?", "label": 1}
{"sent1": "This can be very expensive, especially when skilled annotators are required.", "sent2": "The performance of a tagger trained on the improved data set of 88% accuracy is significantly better than the baseline of 76%.", "label": 0}
{"sent1": "The XLE parser is a deep-parsing system that couples a Lexical Functional Grammar to a loglinear disambiguation component and provides much richer representations theory.", "sent2": "Our preliminary experiments show that this approach can supplement both the historical and the typological comparison of languages.", "label": 0}
{"sent1": "For the majority of tasks, we find that simple, unsupervised models perform better when n-gram frequencies are obtained from the web rather than from a large corpus.", "sent2": "Our tools give control of SDS application development to non-experts, who need only use a Graphical User Interface or GUI to develop state-of-the-art ?Information State Update?", "label": 0}
{"sent1": "We develop a dynamic program for extracting the so called oracle-best hypothesis from a hypergraph by viewing it as the problem of finding the most likely hypothesis under an n-gram language model trained from only the reference translations.", "sent2": "In this paper, we argue that the current AES systems can be further improved by taking into account the agreement between human and machine raters.", "label": 0}
{"sent1": "For these reasons, to improve automatic ontology translations, we first focus on identifying relevant unambiguous and domain-specific sentences from a large set of generic parallel corpora.", "sent2": "Then, we leverage Linked Open Data resources, such as DBPedia, to isolate ontologyspecific bilingual lexical knowledge.", "label": 1}
{"sent1": "is a particularly common source of humour.", "sent2": "In this paper we describe how traditional, language-agnostic WSD approaches can be adapted to ?disambiguate?", "label": 1}
{"sent1": "Given a pair of source-target domains, we propose an unsupervised method for learning domain-specific word representations that accurately capture the domainspecific aspects of word semantics.", "sent2": "First, we select a subset of frequent words that occur in both domains as pivots.", "label": 1}
{"sent1": "However, most existing semantic representation techniques cannot be used effectively for the representation of individual word senses.", "sent2": "There are a number of different estimators for Bayesian models, and it is useful to know what kinds of tasks each does well on.", "label": 0}
{"sent1": "We utilize meta-patterns of highfrequency words and content words in order to discover pattern candidates.", "sent2": "et al, 2002a).", "label": 0}
{"sent1": "Using these documents as reinforcement for query terms, BAYESUM is not afflicted by the paucity of information in short queries.", "sent2": "We show that approximate inference in BAYESUM is possible on large data sets and results in a stateof-the-art summarization system.", "label": 1}
{"sent1": "Much of this improvement, however, is based upon an ever-increasing number of features to be trained on (typically) the WSJ treebank data.", "sent2": "This has led to concern that such parsers may be too finely tuned to this corpus at the expense of portability to other genres.", "label": 1}
{"sent1": "Based on MOSES, our system is capable of translating German, French and Spanish into English.", "sent2": "The decoders accompanying these extensions typically exceed quadratic time complexity.", "label": 0}
{"sent1": "Phrase substitution is guided by several decision factors, a continuation of previous work within our group.", "sent2": "For the shared task, we have computed translations for six language pairs including English, German, French and Spanish.", "label": 1}
{"sent1": "In phrase-based SMT, the phrase table is the main tool in translation.", "sent2": "Connotation lexicons differ from much studied sentiment lexicons: the latter concerns words that express sentiment, while the former concerns words that evoke or associate with a specific polarity of sentiment.", "label": 0}
{"sent1": "We integrate the various pointwise decisions as latent variables in a single arc-level SVM classifier.", "sent2": "Because these classifiers overlap substantially in their filtering consequences, we propose to train them jointly, so that each classifier can focus on the gaps of the others.", "label": 1}
{"sent1": "We first collected bilingual data by performing automatic translations of monolingual texts.", "sent2": "We then propose a novel semi-supervised multitask learning method via Laplacian regularized logistic regression (SMTL-LLR) to further improve the review spam detection performance.", "label": 0}
{"sent1": "Spanish and English?Czech translation tasks, in which we employed our multiengine architecture to translate.", "sent2": "We also participated in the system combination task which was carried out by the MBR decoder and confusion network decoder.", "label": 1}
{"sent1": "Additionally, we contribute the first POS annotation guidelines for such text and release a new dataset of English language tweets annotated using these guidelines.", "sent2": "Tagging software, annotation guidelines, and large-scale word clusters are available at: http://www.ark.cs.cmu.edu/TweetNLP This paper describes release 0.3 of the ?CMU Twitter Part-of-Speech Tagger?", "label": 1}
{"sent1": "Edge scores are then combined into graph scores and used for reranking the topn analyses found by the unlexicalised parser.", "sent2": "The approach achieves significant improvements on WSJ and biomedical text over the unlexicalised baseline parser, which is originally trained on a subset of the Brown corpus.", "label": 1}
{"sent1": "Sentimental properties, including labels such as ?youthful?", "sent2": "In this paper, we study visual language, both literal and sentimental, that describes the overall appearance and style of virtual characters.", "label": 1}
{"sent1": "Verb roots are classified by the types of their radicals and the stems they generate.", "sent2": "Roots are moulded with morphosemantic and morphosyntactic patterns to generate stems modified for tense, voice, and mode, and affixed for different subject number, gender, and person.", "label": 1}
{"sent1": "Only few dialectal resources are available to date; moreover, most available acoustic data collections are transcribed without diacritics.", "sent2": "Automatic recognition of Arabic dialectal speech is a challenging task because Arabic dialects are essentially spoken varieties.", "label": 1}
{"sent1": "It is true especially for languages different from English, where the adopted learning management systems often do not support even the basic functionality of a language-oriented search and retrieval of learning objects.", "sent2": "As a case study, this paper demonstrates the application of the given ideas for e-learning materials in Czech.", "label": 1}
{"sent1": "One important dimension of ambiguity is the organism to which the entities belong: in order to disambiguate an ambiguous entity name (e.g.", "sent2": "Lexical Simplification consists in replacing complex words in a text with simpler alternatives.", "label": 0}
{"sent1": "The second part is the actual measurement, which has three steps.", "sent2": "In order to capture the property of such phrases, we introduce latent variables into the models.", "label": 0}
{"sent1": "That is, the translation is built by virtue of the joint action of both models.", "sent2": "The goal of integration is to make acoustic and translation models cooperate in the underlying decision problem.", "label": 1}
{"sent1": "The separation lets the linguist take advantage of the morphological features in order to reduce the number of dependency rules and to make them lexically selective.", "sent2": "The proposed interface extends Gaifman?s (1965) classical dependency rule formalism by separating lexical word forms and morphological categories from syntactic categories.", "label": 1}
{"sent1": "Then, it applies machine learning approaches to detect the scope and negated event for each negation cue identified in the first phase.", "sent2": "The first one is a word-based approach using word alignments.", "label": 0}
{"sent1": "We describe a rule-based system for detecting the presence of negations and delimitating their scope.", "sent2": "This scheme ignores many of the linguistic and semantic features contained in text documents.", "label": 0}
{"sent1": "It first makes use of an algorithm that detects negation cues, like no, not or nothing, and the words affected by them by traversing Minipar dependency structures.", "sent2": "We show that normal vectors of decision hyperplanes can be used for assessing reliability and internal cross-validation can be used for assessing stability of small sample data.", "label": 0}
{"sent1": "We also provide an evaluation of the impact of specific model parameters on the prediction of priming.", "sent2": "To the best of our knowledge, this is the first systematic evaluation of a wide range of DSM parameters in all possible combinations.", "label": 1}
{"sent1": "In this paper we characterise and analyse paths of items created by users of our online system.", "sent2": "We investigate whether measures of readability can be used to identify age-specific TV programs.", "label": 0}
{"sent1": "Features to capture how the relationship is described textually, as well as how central the relationship is in the sentence, are used in the learning process.", "sent2": "Algorithms for generating referring expressions  typically assume that an object in a scenary can be  identified through a set of commonly agreed  properties.", "label": 0}
{"sent1": "We investigate the effect of small sample size on the performance of a text categorization algorithm.", "sent2": "We show how to determine whether the dataset is large enough to train support vector machines.", "label": 1}
{"sent1": "partof).", "sent2": "Relation extraction in documents allows the detection of how entities being discussed in a document are related to one another (e.g.", "label": 1}
{"sent1": "It is proposed that changes to the noun phrase dependency parse will have a cascading effect down the NLP pipeline and in the end, improve machine translation output, even with a reduction in parser accuracy that the noun phrase structure might cause.", "sent2": "Our results indicate comparable and even better performance than current state of the art systems addressing the problem of sentence similarity.", "label": 0}
{"sent1": "First, we provide an extensive evaluation of individual indicators that rely on distributional or lexical information.", "sent2": "Then, we present a first evaluation of the combination of indicators of different types, considering both logical and numerical combinations schemes.", "label": 1}
{"sent1": "Often a language learner will find value in the ability to look up the meaning of an unknown word while reading an electronic document by clicking the word.", "sent2": "Highlighting words likely to be unknown to a reader is attractive due to drawing his or her attention to it and indicating that information is available.", "label": 1}
{"sent1": "Furthermore, we also explore a new representation in which roots and morphological features are represented as separate tokens instead of representing only words as tokens.", "sent2": "Using syntactic and contextual properties with the new representation provide an 7.6% relative improvement over the baseline.", "label": 1}
{"sent1": "To date I have defined a comprehensive set of social events and built a preliminary system that extracts social events from news articles.", "sent2": "Obtaining their training and test data for English?French, we carry out a number of experiments using the Pharaoh SMT Decoder.", "label": 0}
{"sent1": "However, one must be careful in how these resources are used, and noted writers such as George Orwell have argued that the use of canned phrases encourages sloppy thinking and results in poor communication.", "sent2": "Nonetheless, while Orwell prized home-made phrases over the readymade variety, there is a vibrant movement in modern art which shifts artistic creation from the production of novel artifacts to the clever reuse of readymades or objets trouv?s.", "label": 1}
{"sent1": "The system has been implemented for operation on an iPad.", "sent2": "The system has participated in tasks 2 and 13 of the SemEval-2007 competition, on word sense induction and Web people search, respectively, with mixed results.", "label": 0}
{"sent1": "We present a prototype implementation of the proposed  method, EdIt, that  can handle a broad range  of errors.", "sent2": "We compare several recent approaches, and find improvements from additional training data across the board; however, none outperform a simple n-gram model.", "label": 0}
{"sent1": "Nevertheless using a BCI-typewriter depending only on EEG responses will not be sufficiently accurate for single-trial operation in general, and existing systems utilize many-trial schemes to achieve accuracy at the cost of speed.", "sent2": "This paper presents an unsupervised approach for inferring verbs from nouns along with a new online resource PreDic (PREdicate DICtionary) that contains verbs inferred from nouns sharing similar concepts but not the root.", "label": 0}
{"sent1": "At a system level, Engkoo is an application platform that supports a multitude of NLP technologies such as cross language retrieval, alignment, sentence classification, and statistical machine translation.", "sent2": "Currently Engkoo is built for Chinese users who are learning English; however the technology itself is language independent and can be extended in the future.", "label": 1}
{"sent1": "BLAST can aid MT researchers and users in this process, by providing an easy-to-use graphical user interface.", "sent2": "We believe that error analysis, i.e., to identify and classify MT errors, should be an integral part of MT development, since it gives a qualitative view, which is not obtained by standard evaluation methods.", "label": 1}
{"sent1": "The determination of the significant sound correspondences which co-varied with cluster membership was carried out on a post hoc basis.", "sent2": "We use the Margin-Infused Relaxed Algorithm and Support Vector Machines for experiments on Arabic, Dari, English, and Pashto, and provide a detailed analysis of our results.", "label": 0}
{"sent1": "We first explore the two research questions empirically by reconstructing language family trees from English texts written by speakers of Asian languages.", "sent2": "In this paper, we address these research questions.", "label": 1}
{"sent1": "This paper describes a method for a contrastive automatic analysis of verbs in medical corpora, based on the semantic annotation of the verbs nominal co-occurents.", "sent2": "The corpora used are specialized in cardiology and distinguished according to their levels of expertise (high and low).", "label": 1}
{"sent1": "Yet while significant research has explored documentand passage-level reading difficulty, the special challenges involved in assessing aspects of readability for single sentences have received much less attention, particularly when considering the role of surrounding passages.", "sent2": "Second, the outputs of the three predictors are merged into sub-word sequences, which are further bracketed and labeled with POS tags by a fine-grained sub-word tagger.", "label": 0}
{"sent1": "This suggests that in principle it is feasible to align the parallel parse trees with somemodification of existing syntactic annotation guidelines.", "sent2": "Detecting levels of interest from speakers is a new problem in Spoken Dialog Understanding with significant impact on real world business applications.", "label": 0}
{"sent1": "We have implemented a sentence diagram editor that schoolchildren can use to practice morphology and syntax.", "sent2": "Question detection serves great purposes in the cQA question retrieval task.", "label": 0}
{"sent1": "Therefore, given their importance for various NLP tasks, we begin a study of discourse relations on microblogs by focusing on evidence relations.", "sent2": "Experiments from the ?20 Newsgroups?", "label": 0}
{"sent1": "We evaluate our method by improving the quality of noisy Spanish-Hebrew lexicons generated from two pivot English lexicons.", "sent2": "Semantic frames are a rich linguistic resource.", "label": 0}
{"sent1": "Our method correctly determines the matching words between two sentences using corresponding noun phrases.", "sent2": "As described in this paper, we propose a new automatic evaluation method for machine translation using noun-phrase chunking.", "label": 1}
{"sent1": "using heuristic matches between Wikipedia infobox attribute values and corresponding sentences to construct training data.", "sent2": "Like TextRunner, WOE?s extractor eschews lexicalized features and handles an unbounded set of semantic relations.", "label": 1}
{"sent1": "The performance of such systems is tightly bound to the quality of the underlying features.", "sent2": "Although this is our first non-optimized instantiation of the idea, our experiments show competitive performance with the Hiero baseline, exemplifying certain merits of this novel approach.", "label": 0}
{"sent1": "We compare SystemT?s approach against cascading grammars, both theoretically and with a thorough experimental evaluation.", "sent2": "These features were extracted from a 23M word WSJ corpus based on part-of-speech tags and phrasal chunks alone.", "label": 0}
{"sent1": "Our results provide evidence that the majority of novels in this time period do not fit two characterizations provided by literacy scholars.", "sent2": "We extract features from the social networks and examine their correlation with one another, as well as with metadata such as the novel?s setting.", "label": 1}
{"sent1": "We report results on Arabic-English word alignment and translation tasks.", "sent2": "We  estimate the degree of correlation by using comparable corpora based on  these assumptions: ?parallel word associations?", "label": 0}
{"sent1": "but uncertain in others (Was it acceptable?", "sent2": "We have developed an automated Japanese essay scoring system called Jess.", "label": 0}
{"sent1": "In this paper we present a model we refer to as Importance-Driven Turn-Bidding that treats turn-taking as a negotiative process.", "sent2": "This reliance results in restricted interactions that can lead to inefficient dialogues.", "label": 1}
{"sent1": "The approach is the first attempt to construct a continuous vector representation for expressions whose validity can be explicitly checked by their proximities to known sets of entity-pairs.", "sent2": "First, we determine the relevance of each source domain to the target domain for each relation type, using the consistency between the clustering given by the target domain labels and the clustering given by the predictors trained for the source domain.", "label": 0}
{"sent1": "As sense inventory we adopt BabelNet, a large multilingual semantic network built exploiting both WordNet and Wikipedia.", "sent2": "?ve Bayes methods and 2) Word Overlap methods, both of which rely on the extraction of syntactic features.", "label": 0}
{"sent1": "CRAG-2 makes use of OPENCCG and an over-generation and ranking approach, guided by a set of language models covering both personality and alignment.", "sent2": "We describe CRAG, which generates dialogues between pairs of agents, who are linguistically distinguishable, but able to align.", "label": 1}
{"sent1": "The results suggest that the model is able to extract coherent groups of satellite terms in corpora with varying size, content and structure.", "sent2": "The findings also confirm that language consists of a densely connected core (observed in dictionaries) and systematic, semantically coherent groups of terms at the edges of the lexicon.", "label": 1}
{"sent1": "In this paper, we show that training on the standard dataset does not generalize, because a unigram model may be tuned to topics in the comments and does not capture the distinguishing features of dialects.", "sent2": "Compared to the reordering constraint model, which requires the same training data as ours, our method achieved higher accuracy because of richer bilingual constraints.", "label": 0}
{"sent1": "However, it has also been demonstrated that currently available entailment rules are still far from being optimal.", "sent2": "Specifically, we develop three infinite tree models, each of which enforces different independence assumptions, and for each model we define a simple direct assignment sampling inference procedure.", "label": 0}
{"sent1": "However, most such applications have text embedded in the social network.", "sent2": "This is an important task for information extraction.", "label": 0}
{"sent1": "However, a considerable number of messages in Twitter with high retweet counts are actually mundane posts by celebrities that are of interest to themselves and possibly their followers.", "sent2": "Syntactic analysis of search queries is important for a variety of information-retrieval tasks; however, the lack of annotated data makes training query analysis models difficult.", "label": 0}
{"sent1": "By using a distributional similarity (DS) measure on corpora collected from a recipe domain, we get the most likely verbs for individual authors.", "sent2": "The accuracy of matching verb pairs produced by distributional similarity is higher than using the synonym outputs of verbs from WordNet.", "label": 1}
{"sent1": "Word sense disambiguation is performed on a disambiguation graph via a vertex centrality measure.", "sent2": "The sense inventory is generated by the MetaMap program.", "label": 1}
{"sent1": "This is an example of a more general problem where opinion is expressed using either sub- or supersets of expressive words found in newswire.", "sent2": "Once the multi-view video sequences are loaded into DALES, our software performs the detection, counting, and segmentation of the visual objects evolving in the provided video streams.", "label": 0}
{"sent1": "The parallel texts are processed in two phases, the sentence alignment phase and the word correspondence phase.", "sent2": "Our sentence alignment technique achieves a precision of 91.4% and a recall of 92.3%.", "label": 1}
{"sent1": "First, we use two bootstrapping algorithms that exploit extraction patterns to learn sets of subjective nouns.", "sent2": "Syntax, or sentence structure, could provide guidance to phrasebased systems, but the ?non-constituent?", "label": 0}
{"sent1": "The score of our method is a match for the best public score of this task.", "sent2": "In experiments, we solved 50 noun WSD problems in the Japanese Dictionary Task in SENSEVAL2.", "label": 1}
{"sent1": "Since the output of the taggers is noisy, there is a question of which newly labelled examples to add to the training set.", "sent2": "We investigate selecting examples by directly maximising tagger agreement on unlabelled data, a method which has been theoretically and empirically motivated in the co-training literature.", "label": 1}
{"sent1": "However, the performance of a statistical system can also depend heavily on the characteristics of the training data.", "sent2": "The experiments show that the performance in F -measure could drop from 98.2% to 85.6% when a length-based approach is trained by a technical manual and then tested on a general magazine.", "label": 0}
{"sent1": "The feature set was previously shown to work well in a supervised learning setting, using known English verb classes.", "sent2": "In moving to a scenario of verb class discovery, using clustering, we face the problem of having a large number of irrelevant features for a particular clustering task.", "label": 1}
{"sent1": "For FrameNet, the combined use of both collocation types achieves better performance for the individual classifiers: 70.3% versus 68.5%.", "sent2": "The experimental results point out that a strong prediction performance is achieved, especially for models based on the Gaussian Processes framework.", "label": 0}
{"sent1": "PhraseNet makes use of WordNet as an important knowledge source.", "sent2": "Notably, accuracy of all test/metric combinations for evaluation of English-to-Spanish are so low that there is not enough evidence to conclude they are any better than a random coin toss.", "label": 0}
{"sent1": "However, the use of unlabeled data via the basic EM algorithm often causes disastrous performance degradation instead of improving classification performance, resulting in poor classification performance on average.", "sent2": "In this study, we introduce a class distribution constraint into the iteration process of the EM algorithm.", "label": 1}
{"sent1": "In this paper, we describe a grammar error correction system which corrects grammatical errors at tree level directly.", "sent2": "Our method can be used as a purely monolingual dependency parser, requiring no human translations for the test data, thus making it applicable to a wide range of resource-poor languages.", "label": 0}
{"sent1": "In particular, we perform experiments with dependency-based contexts, and show that they produce markedly different embeddings.", "sent2": "The dependencybased embeddings are less topical and exhibit more functional similarity than the original skip-gram embeddings.", "label": 1}
{"sent1": "We used both dependency between words and dependency between sentences by constructing a nested tree, in which nodes in the document tree representing dependency between sentences were replaced by a sentence tree representing dependency between words.", "sent2": "Although the dependency between words has been used in most of these methods, the dependency between sentences, i.e., rhetorical structures, has not been exploited in such joint methods.", "label": 1}
{"sent1": "We describe an automatic question generator that uses semantic pattern recognition to create questions of varying depth and type for self-study or tutoring.", "sent2": "Throughout, we explore how linguistic considerations inform system design.", "label": 1}
{"sent1": "The first algorithm is exact and requires O(n 6 ) running time.", "sent2": "It extends Eisner?s cubic time parsing algorithm by using virtual dependency arcs to link deleted words.", "label": 1}
{"sent1": "We develop systems for generic and update summarization based on this idea.", "sent2": "about the world represented in the background.", "label": 1}
{"sent1": "The three models can compensate for each other?s weaknesses.", "sent2": "Contrary to the previous systems that depend on manually constructed linguistic knowledge, the proposed system can fully automatically acquire the linguistic knowledge from annotated corpora (e.g.", "label": 1}
{"sent1": "number of clusters based on the similarity of their contexts.", "sent2": "Experiments show that the accuracy of the extracted entities is improved by 6.7 to 28.2% depending on the domain.", "label": 0}
{"sent1": "Using partial match criteria, our system achieves an F-score of 81.3%.", "sent2": "Our system performs significantly better than dictionary-based systems.", "label": 1}
{"sent1": "Plausibility is estimated by using Web data, while the classification algorithm is instance-based.", "sent2": "The first system, SWAT-E, finds Spanish substitutions by first finding English substitutions in the English sentence and then translating these substitutions into Spanish using an English-Spanish dictionary.", "label": 0}
{"sent1": "The method is dynamic in the sense that the graph evolves over time to capture the evolution inherent to the participants salience.", "sent2": "This task has a strict relation with the task of automatic machine translation, but there are some differences: Cross-lingual lexical substitution targets one word at a time and the main goal is to find as many good translations as possible for the given target word.", "label": 0}
{"sent1": "We also provide successful results on learning of a toy case modeled on French vowel alternations, which have also been previously analyzed in terms of abstract URs.", "sent2": "This learner is successful on a test language provided by Tesar (2006) as a challenge for UR learning.", "label": 1}
{"sent1": "The former features are generated by a polynomial kernel encoding entity features whereas tree kernels are used to model dependencies amongst tagged candidate examples.", "sent2": "We use a lexicon based approach for discovering sentiments.", "label": 0}
{"sent1": "The proposed framework provides supporting algorithms and tools for automatically identifying and extracting unknown words from Web pages of given URLs.", "sent2": "Our main goal is to design and construct a Webbased system which allows a group of interested users to participate in constructing a Thai unknown-word open dictionary.", "label": 1}
{"sent1": "We propose a set of lexical knowledge for idiom recognition.", "sent2": "We start by addressing 1) and 2) using a neural network architecture.", "label": 0}
{"sent1": "(PDG), and proposes the ?Graph Branch Algorithm?", "sent2": "To bridge this gap, we introduce the task of entity salience: assigning a relevance score to each entity in a document.", "label": 0}
{"sent1": "The ultimate goal of this project is set to construct a cognitively sound and computationally effective character-grounded machine-understandable resource.", "sent2": "Philosophically, Chinese ideogram has its ontological status, but its applicability to the NLP task has not been expressed explicitly in terms of language resource.", "label": 1}
{"sent1": "Collins proposed Tree Kernel to calculate structural similarity.", "sent2": "This paper proposes an efficient method of sentence retrieval based on syntactic structure.", "label": 1}
{"sent1": "The statistical natural language parsers trained on text perform unreliably to encode non-local information on spoken language.", "sent2": "The shared task features machine transliteration of proper names from English to a set of languages.", "label": 0}
{"sent1": "The idea behind our method is to utilize certain layout structures and linguistic pattern.", "sent2": "We report two new approaches for building scoring models used by automated speech scoring systems.", "label": 0}
{"sent1": "Classifiers built on such data typically have a higher precision and a lower recall and tend to overproduce the NONE class.", "sent2": "dominates all other classes.", "label": 1}
{"sent1": "They were mainly based on N best rescoring approach.", "sent2": "The delay is consistent with the placement of each region on the processing pathway that starts in the visual cortex and moves to higher level regions.", "label": 0}
{"sent1": "A main role in the MT online adaptation process is played by the information extracted from source and post-edited sentences, which in turn depends on the quality of the word alignment between them.", "sent2": "In fact, this step is particularly crucial when the user corrects the MT output with words for which the system has no prior information.", "label": 1}
{"sent1": "We evaluated the performance of 15 novice translators translating technical English texts into German.", "sent2": "In this work, we will be using word graphs as an efficient interface between a phrase-based MT system and the IP engine.", "label": 0}
{"sent1": "Our method consists of two steps: it first selects VPC candidates on the basis of syntactic information and then selects genuine VPCs among them by exploiting new features like semantic and contextual ones.", "sent2": "Building machine translation (MT) test sets is a relatively expensive task.", "label": 0}
{"sent1": "In this paper we consider performance of such systems when we evaluate at the document level rather than on the lemma level.", "sent2": "We present an approach for providing partial supervision to a distantly supervised relation extractor using a small number of carefully selected examples.", "label": 0}
{"sent1": "We detail our approach, outline our implementation and provide an evaluation of the method for the language pair English/Brazilian-Portuguese.", "sent2": "The method operates by performing substitution on the original idiom with its literal meaning before translation, with a second substitution step replacing literal meanings with idioms following translation.", "label": 1}
{"sent1": "All literature-derived patterns are found?and new meaningful candidate patterns emerge?among the top-ranking trigrams for three association measures.", "sent2": "The proposed sense-based translation model enables the decoder to select appropriate translations for source words according to the inferred senses for these words using maximum entropy classifiers.", "label": 0}
{"sent1": "Based on this insight, we investigate the interaction between discourse connectives and the discourse relations and propose the criteria for selecting the discourse connectives that can be dropped independently of the context without changing the interpretation of the discourse.", "sent2": "Yet for many types of entities, such as restaurants and cult movies, relational databases exist that contain far more extensive information than Wikipedia.", "label": 0}
{"sent1": "In this paper we propose an algorithmic solution that involves a new representation for the knowledge required to address hard coreference problems, along with a constrained optimization framework that uses this knowledge in coreference decision making.", "sent2": "The effectiveness of this method was confirmed by comparing its effectiveness with that of a conventional Gaussian Mixture Model (GMM)-based and conventional NMFbased method.", "label": 0}
{"sent1": "Many believe that because women are seldom represented in film as strong leaders and thinkers, viewers associate weaker stereotypes with women.", "sent2": "The algorithms were originally developed to work with N -best lists of translations, and recently extended to lattices that encode many more hypotheses than typical N -best lists.", "label": 0}
{"sent1": "While many characteristics of translated text are more apparent in comparison to the original text, most of the prior research has focused on monolingual features of translated and original text.", "sent2": "Both types of syntactic features provide information which is complementary to tried-and-tested nonsyntactic features.", "label": 0}
{"sent1": "This is often measured by correlation with human judgment.", "sent2": "With the introduction of any new metric comes the question of just how well that metric mimics human assessment of translation quality.", "label": 1}
{"sent1": "Compared to syntactic constraints, our model is directly acquired from an aligned parallel corpus and does not require parsers.", "sent2": "Our model evaluates if a source span should be covered by translation rules during decoding, which is integrated into the translation system as soft constraints.", "label": 1}
{"sent1": "It can automatically transform a human-annotated corpus from one annotation guideline to another.", "sent2": "In this paper we first describe the technology of automatic annotation transformation, which is based on the annotation adaptation algorithm (Jiang et al., 2009).", "label": 1}
{"sent1": "Bo?rschinger et al.", "sent2": "Without forum specific features, we achieve an accuracy of 82%.", "label": 0}
{"sent1": "However, this introduces a challenging learning scenario where the relation expressed by a pair of entities found in a sentence is unknown.", "sent2": "is an efficient approach to scale RE to thousands of different relations.", "label": 1}
{"sent1": "As clusters are built, information flows between entity and event clusters through features that model semantic role dependencies.", "sent2": "Our iterative method cautiously constructs clusters of entity and event mentions using linear regression to model cluster merge operations.", "label": 1}
{"sent1": "By making a judgment about the general ambiguity of a term, a system is able to handle ambiguous and unambiguous cases differently, improving throughput and quality.", "sent2": "Conducted experiments for synonyms demonstrate that the presented methods can be extended to other semantic relations.", "label": 0}
{"sent1": "In this paper, we point out and analyze some critical factors in DS which have great impact on accuracy, including valid entity type detection, negative training examples construction and ensembles.", "sent2": "We propose an approach to handle these factors.", "label": 1}
{"sent1": "We identify opinion subgroups by partitioning the signed network representation or by clustering the vector space representation.", "sent2": "We opinion predictions to represent the discussion in one of two formal representations: signed attitude network or a space of attitude vectors.", "label": 1}
{"sent1": "An analysis revealed that 74.60% of the sentences in the WA corpus if segmented using an automated segmenter trained on the Penn Chinese Treebank (CTB) will contain conflicts with the gold WA annotations.", "sent2": "We use data from a virtual world game for automated learning of words and grammatical constructions and their meanings.", "label": 0}
{"sent1": "We present a general approach that exploits source-side contexts of foreign words to improve translation prediction accuracy.", "sent2": "In our work, we examine two types of opinion manipulation trolls: paid trolls that have been revealed from leaked ?reputation management contracts?", "label": 0}
{"sent1": "We introduce two tracking approaches which are fully applicable to true streaming environments.", "sent2": "When tracking 4.4 million topics against 52 million documents in constant time and space, we demonstrate that counter to expectations, simple single-pass clustering can outperform locality sensitive hashing for nearest neighbour search on streams.", "label": 1}
{"sent1": "To train our model on two non-overlapping datasets that each has only one-side tags, we transform a one-side tag into a set of bundled tags by considering all possible mappings at the missing side and derive an objective function based on ambiguous labelings.", "sent2": "This allows us to combine distributional similarity with symbolic logical inference in novel and effective ways.", "label": 0}
{"sent1": "When this is done, the system incurs the risk of translating components in non-consecutive positions, or in the wrong order.", "sent2": "Some topics appear to carry a ?focus marker?, indicating that they are particularly salient.", "label": 0}
{"sent1": "Therefore, there is increasing interest in methods to perform an adaptation of the translation model.", "sent2": "Using the implemented paraphraser and the obtained patterns, a paraphrasing experiment was conducted and the results were evaluated.", "label": 0}
{"sent1": "Our systems use n-code, an open source Statistical Machine Translation system based on bilingual n-grams.", "sent2": "I propose to build discriminative SMT models using both tree-to-string and tree-to-tree approaches.", "label": 0}
{"sent1": "arguments.", "sent2": "Experimental results obtained by adapting both the language and translation models show substantial gains over the baseline system.", "label": 0}
{"sent1": "Spelling normalization is applied to reduce out-of-vocabulary words in the corpus.", "sent2": "In addition we propose an unsupervised rule-based approach which can serve as a strong baseline for Open IE systems.", "label": 0}
{"sent1": "German we attempted to improve the translation tables with a combination of standard statistical word alignments and phrase-based word alignments.", "sent2": "For English?", "label": 1}
{"sent1": "The performance gain obtained for two typologically distinct languages shows the robustness of prosodic information for word segmentation.", "sent2": "The approach was tested on two different languages, English and Japanese, and the results show that boundary information helps word segmentation in both cases.", "label": 1}
{"sent1": "This yields significantly improved performance on documentlevel sentiment analysis in English and Spanish.", "sent2": "Previous work has transferred these annotations on a token-to-token basis, an approach that is sensitive to alignment errors and translation shifts.", "label": 0}
{"sent1": "In the third step, additional n-gram features are extracted from edit removed texts together with our newly induced in-between features to improve edited word detection.", "sent2": "Evaluation at development time showed considerably good results in a cross-validation experiment, with Kendall?s ?", "label": 0}
{"sent1": "The mismatch in the level of abstraction between the natural language representation and the regular expression representation make this a novel and challenging problem.", "sent2": "because the TG community has shown considerable hostility toward CL and everything it stands for over the past fifty years.", "label": 0}
{"sent1": "Yet, to create annotated linguistic resources from this data, we face the challenge of having to combine the judgements of a potentially large group of annotators.", "sent2": "In this work I introduce the task of multiple narrative disentanglement (MND), in which the aim is to tease these narratives apart by assigning passages from a text to the sub-narratives to which they belong.", "label": 0}
{"sent1": "The treebank is publicly available via the INESS treebanking environment, which also allows for the alignment of language pairs.", "sent2": "Thus it is an ideal time to consider the development of new experimental frameworks.", "label": 0}
{"sent1": "However, they are far from containing only interesting semantic relations.", "sent2": "Distributional thesauri are now widely used in a large number of Natural Language Processing tasks.", "label": 1}
{"sent1": "While a variety of semi-supervised methods exist for training from incomplete data, there are open questions regarding what types of training data should be used and how much is necessary.", "sent2": "Code assignment is important for handling large amounts of electronic medical data in the modern hospital.", "label": 0}
{"sent1": "While significant progress has been made in this area for text sources and for English audio sources, little work has been done in automatic segmentation of other languages using both text and acoustic information.", "sent2": "Automatic topic segmentation, separation of a discourse stream into its constituent stories or topics, is a necessary preprocessing step for applications such as information retrieval, anaphora resolution, and summarization.", "label": 1}
{"sent1": "The paper consists of two major components.", "sent2": "Since each component model of our mixture model is expressed using a one-dimensional Gaussian-type function, the proposed kernel has an advantage in computational time.", "label": 0}
{"sent1": "Although the speech recognition performance degraded steadily, the system did not fail catastrophically.", "sent2": "It offers a wide range of state-of-the-art keyphrase experiments approaches.", "label": 0}
{"sent1": "The top ranking entry suggested by the algorithm is retinal diseases.", "sent2": "In this paper, we revisit annotation projection and show that the previously reported results are mainly spoiled by the flaws of evaluation with incompatible annotation schemes.", "label": 0}
{"sent1": "Human reasoning is the primary method for extracting, synthesizing, and interpreting the results contained in the literature, yet the rate at which publications are produced is exponential.", "sent2": "With the advent of digital, full-text publication and increasing computational power, automated techniques for knowledge discovery and synthesis are being developed to assist humans in making sense of growing literature databases.", "label": 1}
{"sent1": "The model itself is not extremely novel, but herein we introduce a new procedure to determine oracle labels so as to maximize Kendall?s ?", "sent2": ".", "label": 1}
{"sent1": "This paper proposes to evaluate translations with distributed representations of words and sentences.", "sent2": "It interfaces an active learning algorithm which is complemented by the NLP pipeline to provide a rich feature selection.", "label": 0}
{"sent1": "N-gram language model and three discriminatively trained ?neural?", "sent2": "This method generates 50-best lists that are of substantially higher quality than previously obtainable.", "label": 0}
{"sent1": "Most systems are however 1) highly-engineered, 2) English-specific, and 3) only tested on the same genre they were trained on.", "sent2": "We use this metric to explore the variability in human opinion about optimal policy decisions, and to automatically evaluate several learned policies in our example domain.", "label": 0}
{"sent1": "Apache Hadoop is a freely available environment for running distributed applications on a computer cluster.", "sent2": "Error analysis in addition shows which types of phenomena cause trouble in the POS-tagging of Northern Sotho.", "label": 0}
{"sent1": "One advantage of metaembeddings is the increased vocabulary coverage.", "sent2": "We also find that ?contentword negators?, not widely employed in previous work, play an important role in determining expression-level polarity.", "label": 0}
{"sent1": "Experiment results reveal the language universal and specific properties encoded in various word representation.", "sent2": "Additionally, strong evidence supports the utility of word form, especially for inflectional languages.", "label": 1}
{"sent1": "that represent a canonical version of the text shared between the documents.", "sent2": "We demonstrate that LOBBYBACK accurately reconstructs model legislation and apply it to a dataset of over 550k bills.", "label": 1}
{"sent1": "We propose a tagging model using Wsabie, a discriminative embeddingbased model with rank-based learning.", "sent2": "This dictionary achieved a syntactic coverage of 98% and a semantic coverage of 78%.", "label": 0}
{"sent1": "Here we alleviate this problem by empowering a relation extraction method with additional evidence from Wikipedia.", "sent2": "Compared to several standard?", "label": 0}
{"sent1": "A comparison of independent phrase-based translation models interpolation for each available training corpora were tested, giving an improvement of 0.4 BLEU points over the baseline.", "sent2": "Experiment results show that all three models can achieve significant improvements over the baseline.", "label": 0}
{"sent1": "We consider both a mostly-unsupervised approach, co-training, in which two parsers are iteratively re-trained on each other?s output; and a semi-supervised approach, corrected co-training, in which a human corrects each parser?s output before adding it to the training data.", "sent2": "This paper investigates bootstrapping for statistical parsers to reduce their reliance on manually annotated training data.", "label": 1}
{"sent1": "The algorithm works by first using a large corpus to find semantic neighbors of the unknown word, which we accomplish by combining latent semantic analysis with part-of-speech information.", "sent2": "Children with autism spectrum disorder often exhibit idiosyncratic patterns of behaviors and interests.", "label": 0}
{"sent1": "This paper provides initial perplexity results on both CallHome Arabic and on Penn Treebank Wall Street Journal articles.", "sent2": "Significantly, FLMs with GPB can produce bigrams with significantly lower perplexity, sometimes lower than highly-optimized baseline trigrams.", "label": 1}
{"sent1": "The work described here demonstrates that substantial savings in this effort can be obtained by actively selecting examples to be labeled using confidence scores from the BoosTexter classifier.", "sent2": "The saving in class labeling effort is evaluated on two different spoken language system domains in terms both of the number of utterances to be labeled and the length of the labeled utterances in phones.", "label": 1}
{"sent1": "The greatest difficulty during the translation process is to generate the correct Quechua verb form in subordinated clauses.", "sent2": "Despite Chinese word segmentation being a specific case, MMTNN can be easily generalized and applied to other sequence labeling tasks.", "label": 0}
{"sent1": "The structures may have more complexity due to their coordination structure or attachment rules.", "sent2": "The main objective of our participation was to test RAMSES, an open source phrasebased decoder.", "label": 0}
{"sent1": "We propose a framework where only POS tags and unlabeled dependency parse trees are necessary, and linguistic knowledge on structural difference can be encoded in the form of reordering rules.", "sent2": "We show significant improvements in translation quality of sentences from news domain, when compared to state-of-the-art reordering methods.", "label": 1}
{"sent1": "We present a general definition of feature spaces based on a graphic representation of relation instances, and explore three different representations of relation instances and features of different complexities within this framework.", "sent2": "In this paper, we systematically explore a large space of features for relation extraction and evaluate the effectiveness of different feature subspaces.", "label": 1}
{"sent1": "Experiments suggest that this leads to a reduction in grammar size by a factor of 2.", "sent2": "Moreover, the approach does not require any manually coded resource (e.g.", "label": 0}
{"sent1": "Using unsupervised part-of-speech tagging as our case study, we discuss the reasons that render this evaluation paradigm unsuitable for the evaluation of unsupervised learning methods.", "sent2": "In this paper, we propose a new method for identifying participants?", "label": 0}
{"sent1": "The algorithm then iteratively bootstraps from these translations to learn more pairs and more translations.", "sent2": "Specifically, we propose a non-parametric Bayesian model for learning phonological markedness constraints directly from the distribution of input-output mappings in an Optimality Theory (OT) setting.", "label": 0}
{"sent1": "using contrastive estimation for estimation of the parameters.", "sent2": "To overcome this, we extend standard within sentence joint inference to inference across multiple sentences.", "label": 0}
{"sent1": "The first step is an implementation of latent Dirichlet alocation that produces a set of topics with probabilities for each topic to be associated with a word in a sentence.", "sent2": "Answering precise questions requires applying Natural Language techniques in order to locate the answers inside retrieved documents.", "label": 0}
{"sent1": "In this paper we present a novel unsupervised method for extracting domainspecific lexical variants given a large volume of text.", "sent2": "We demonstrate the utility of this method by applying it to normalize text messages found in the online social media service, Twitter, into their most likely standard English versions.", "label": 1}
{"sent1": "Our results show that integrating a second translation model with only non-hierarchical phrases extracted from the automatically generated bitexts is a reasonable approach.", "sent2": "Historically, unsupervised learning techniques have lacked a principled technique for selecting the number of unseen components.", "label": 0}
{"sent1": "most efficient approaches for language understanding are statistical.", "sent2": "Recent years?", "label": 1}
{"sent1": "In this paper, the fundamental components of the Vithea system are presented, with particular emphasis on the speech recognition module.", "sent2": "Experiment results show that the proposed Structural Topic Model can effectively discover topical structures in text, and the identified structures significantly improve the performance of tasks such as sentence annotation and sentence ordering.", "label": 0}
{"sent1": "Results indicate that people can provide substantial keystroke savings by providing word completion or prediction, but that the savings are not as high as n-gram language models.", "sent2": "Interestingly, the language model and human predictions are complementary in certain key ways ?", "label": 1}
{"sent1": "This paper argues that the AAC design and implementation process needs to identify and address personal data use problems.", "sent2": "Accordingly, this paper explores personal data management problems and proposes responses.", "label": 1}
{"sent1": "Using Huffman codes derived from a character n-gram model, we investigate both synchronous (fixed latency highlighting) and asynchronous (self-paced using long versus short press) scanning.", "sent2": "Additionally, we look at methods that allow for scanning past a target and returning to it versus methods that remove unselected items from consideration.", "label": 1}
{"sent1": "A participatory design approach was followed in the development of the integrated system to ensure that the expectations of visually challenged people are met.", "sent2": "Given that India is a multilingual country (22 official languages), a uniform framework for an integrated text-to-speech synthesis systems with screen readers across six Indian languages are developed, which can be easily extended to other languages as well.", "label": 1}
{"sent1": "The character n-gram based models showed considerable improvement over the word based models.", "sent2": "This paper describes the features used and experiments to increase the recall of Named Entity Recognition Systems which is also language independent.", "label": 1}
{"sent1": "We examine different formulations of the classification task which considerably influence performance.", "sent2": "The results demonstrate that classifier combination is an effective technique of improving system performance: experiments over a large annotated corpus of fine-grained entity types exhibit a 10% relative reduction in F-measure error.", "label": 0}
{"sent1": "We investigate the effect of including demographic information on performance in a variety of text-classification tasks.", "sent2": "In this article, we present a hierarchical generative probabilistic model of topical phrases.", "label": 0}
{"sent1": "Sarcasm detection has been a challenging research problem, and its importance for NLP applications such as review summarization, dialog systems and sentiment analysis is well recognized.", "sent2": "We show empirically that our approach can generate complex sentences with a speed that generally matches or surpasses the state of the art.", "label": 0}
{"sent1": "The only requirement is that the learned embeddings should be compatible within each individual fact.", "sent2": "or ?startup?).", "label": 0}
{"sent1": "We rederive all the steps of KN smoothing to operate on count distributions instead of integral counts, and apply it to two tasks where KN smoothing was not applicable before: one in language model adaptation, and the other in word alignment.", "sent2": "(2) The coverage of the extracted paraphrase patterns is high, which is above 84%.", "label": 0}
{"sent1": "The number of errors tagging these words corresponds to a quarter of the total errors made by a VLMCbased tagger.", "sent2": "However, in Historical Portuguese, two words show a high degree of ambiguity: que and a.", "label": 1}
{"sent1": "Instead, we introduce a Compositional Vector Grammar (CVG), which combines PCFGs with a syntactically untied recursive neural network that learns syntactico-semantic, compositional vector representations.", "sent2": "The CVG improves the PCFG of the Stanford Parser by 3.8% to obtain an F1 score of 90.4%.", "label": 1}
{"sent1": "In this model, the probabilities of parse trees are defined with only the probabilities of selecting lexical entries.", "sent2": "The proposed model is very simple, and experiments revealed that the implemented parser runs around four times faster than the previous model and that the proposed model has a high accuracy comparable to that of the previous model for probabilistic HPSG, which is defined over phrase structures.", "label": 1}
{"sent1": "The supervised component is Collins?", "sent2": "We investigate the effect of corpus size in combining supervised and unsupervised learning for two types of attachment decisions: relative clause attachment and prepositional phrase attachment.", "label": 1}
{"sent1": "Among them the most frequent construction type is ?Modifier + Postposition + Head?.", "sent2": "In other cases, they are translated into varied syntactic constructs.", "label": 1}
{"sent1": "The joint nature provides crucial benefits by allowing situated cues, such as the set of visible objects, to directly influence learning.", "sent2": "This paper proposes the use of local histograms (LH) over character n-grams for authorship attribution (AA).", "label": 0}
{"sent1": "We also propose to average parameters in training.", "sent2": "Our experimental results on semantic relation classification show that both phrase categories and task-specific weighting significantly improve the prediction accuracy of the model.", "label": 1}
{"sent1": "Then, using the annotated corpus, we investigated the causal relation instances from some viewpoints.", "sent2": "Because of its nature as an online community, it contains more updated knowledge than other places.", "label": 0}
{"sent1": "We show the performance of C4.5, Bagging, and Ripper classifiers on several classes of instances such as nouns and pronouns, only nouns, only pronouns.", "sent2": "This decoder extends recent approaches for discriminative character transduction by allowing for a list of known target-language words, an important resource for transliteration.", "label": 0}
{"sent1": "In this paper, we generalize distant supervision to complex knowledge extraction, by proposing the first approach to learn a semantic parser for extracting nested event structures without annotated examples, using only a database of such complex events and unannotated text.", "sent2": "Separately, there have been active pursuits in leveraging databases for distant supervision in information extraction, yet such methods are often limited to binary relations and none can handle nested events.", "label": 1}
{"sent1": "To accomplish this, we infer ideological cues from a corpus of political writings annotated with known ideologies.", "sent2": "ideological positioning from their speeches.", "label": 1}
{"sent1": "As expected the relative performance of left-to-right and rightto-left strategies proved to be highly language dependent.", "sent2": "Our experimental evaluation was extensive, based on 272 different language pairs, and gave the surprising result that for most of the language pairs, it was better decode from right-to-left than from left-to-right.", "label": 1}
{"sent1": "For the constrained condition of both the aspect term extraction and aspect term polarity tasks, we take a supervised machine learning approach using a combination of lexical, syntactic, and baseline sentiment features.", "sent2": "This paper describes the systems submitted by the University of San Francisco (USF) to Semeval-2014 Task 4, Aspect Based Sentiment Analysis (ABSA), which provides labeled data in two domains, laptops and restaurants.", "label": 1}
{"sent1": "We have defined an algorithm that, given a task-based corpus situated in a virtual world, which contains human instructor?s speech acts and the user?s responses as physical actions, generates a virtual instructor that robustly helps a user achieve a given task in the virtual world.", "sent2": "The system has been implemented for operation on an iPad.", "label": 0}
{"sent1": "To alleviate the problem, we have investigated the effectiveness of automatic context selection by applying feature selection methods explored mainly for text categorization.", "sent2": "Our experiments on synonym acquisition have shown that while keeping or sometimes increasing the performance, we can drastically reduce the unique contexts up to 10% of the original size.", "label": 1}
{"sent1": "weights are computed from the topical similarity between the utterances, evaluated using probabilistic latent semantic analysis (PLSA), and from word overlap.", "sent2": "In the challenge, UNITOR system achieves good results, even considering that no manual feature engineering is performed and no manually coded resources are employed.", "label": 0}
{"sent1": "the size of a language model to improve its performance.", "sent2": "Experimental results show that the multi-target one requires less amount of memory.", "label": 0}
{"sent1": "Then through a series of crowdsourcing experiments conducted on the Crowdflower platform, we successfully collected both overall semantic transparency and constituent semantic transparency data for each of them.", "sent2": "We then train a language model on tag sequences in otherwise unlabeled target data and rank labeled source data by perplexity per word of tag sequences from less similar to most similar to the target.", "label": 0}
{"sent1": "No Chinese corpus is available by now with all different types of sentences annotated with their main functionalities in terms of modality, speech act or event.", "sent2": "This paper describes a Chinese corpus with all the information annotated.", "label": 1}
{"sent1": "We approach this combination of challenges by investigating feature selection in order to reduce the large number of features to those that are discriminative.", "sent2": "We examine the performance of five feature selection methods on two sentiment analysis data sets from different domains, each with different ratios of class imbalance.", "label": 1}
{"sent1": "This has given rise to a new wave of research to develop algorithms for emotion detection and extraction on social data.", "sent2": "We release the first annotated data set for exploring this task, and discuss how our approach may be extended to other applications.", "label": 0}
{"sent1": "As well as considering the predominant  sentiments expressed in individual posts, we analyze sequences of sentiments in online discussions.", "sent2": "In this work, we  study sentiments expressed on online medical forums.", "label": 1}
{"sent1": "Hence, the English Wikipedia is used to bootstrap the NEs for other languages.", "sent2": "The cluster information and the term co-occurrences are considered in extracting the NEs from non-English languages.", "label": 1}
{"sent1": "We experiment this model on two highly related and agglutinative languages namely Tamil and Telugu, and compare our results with the state of the art Morfessor system.", "sent2": "We show that, knowledge of morph length has a positive impact and provides competitive results in terms of overall performance.", "label": 1}
{"sent1": "The corpora, from the conference organization domain, are built using the multilingual ontology concept labels as seeds for crawling relevant documents from the web through a search engine.", "sent2": "Using ontologies allows a better coverage of the domain.", "label": 1}
{"sent1": "The use of graphical schemes for helping text comprehension is recommended in education manuals.", "sent2": "This study explores the relation between text readability and the visual conceptual schemes which aim to make the text more clear for these specific target readers.", "label": 1}
{"sent1": "Human computation games have been widely used in recent years to acquire human knowledge and use it to solve problems which are infeasible to solve by machine intelligence.", "sent2": "Our game aims at annotating sentiments of a collection of text documents and simultaneously constructing a highly discriminative lexicon of positive and negative phrases.", "label": 1}
{"sent1": "We describe the principles and implementation of the platform.", "sent2": "The network creation is implicit, as players collaboratively create links between words while they have fun.", "label": 1}
{"sent1": "Particular, we focus on encoding user feedback in taxonomy construction process to handle task-specification rising from a given document collection.", "sent2": "In this paper, we investigate both automatic and interactive techniques to derive taxonomies from scratch for arbitrary document collections.", "label": 1}
{"sent1": "Some recent studies attempted to train multi-prototype word embeddings through clustering context window features of the word.", "sent2": "To address this problem, it is necessary to build multi embedding vectors to represent different meanings of a word respectively.", "label": 1}
{"sent1": "In this framework, we utilise knowledge derived from ratings on feedback summaries by extracting the most relevant features using Principal Component Regression (PCR) analysis.", "sent2": "We present a novel approach to student feedback generation, which simultaneously takes into account the preferences of lecturers and students when determining the content to be conveyed in a feedback summary.", "label": 1}
{"sent1": "In addition we found that stochastic generation performs better if applied at the word level than at an original-sentence level (?template-based?)", "sent2": "in terms of email coherence, sentence fluency, naturalness, and preference.", "label": 1}
{"sent1": "The key feature of the visualisation is that it brings geographic, phylogenetic, and linguistic data together into a single image, allowing a new visual perspective on linguistic typology.", "sent2": "This paper presents a novel way of visualising relationships between languages.", "label": 1}
{"sent1": "exam scripts.", "sent2": "We present a visual user interface supporting the investigation of a set of linguistic features discriminating between pass and fail ?English as a Second or Other Language?", "label": 1}
{"sent1": "Instead of using word lists or abstract grammatical characteristics to infer (phylogenetic) relationships, we use multilingual alignments of words in sentences to establish measures of language similarity.", "sent2": "The Visual Dependency Representation (VDR) is an explicit model of the spatial relationships between objects in an image.", "label": 0}
{"sent1": "For visualization and data exploration purposes, we used an implementation of the Fruchterman-Reingold algorithm, a version of force directed graph layout.", "sent2": "The results show that the proposed models successfully learn how perspectives are reflected in word usage and can identify the perspective of a document with high accuracy.", "label": 0}
{"sent1": "We utilize Wikipedia to automatically construct a corpus of biographical sentences and TDT4 to construct a corpus of non-biographical sentences.", "sent2": "Motivated in part by this concern, we present a learning-based named entity recognizer that does not rely on manually-constructed gazetteers, using Bengali as our representative resource-scarce, morphologicallyrich language.", "label": 0}
{"sent1": "if they are not based on any languagespecific knowledge.", "sent2": "We compare the results of machine learning experiments using different feature sets to predict the annotated emotions.", "label": 0}
{"sent1": "The resulting relational model of the domain can be extended by specifying additional relational features in a declarative way using a logic programming language.", "sent2": "This declarative approach offers a flexible way of experimentation and a way to insert domain knowledge.", "label": 1}
{"sent1": "We provide preliminary results on a subset of the Corel image database which has three to five keywords per image.", "sent2": "A re-scoring strategy is proposed that makes it feasible to capture more long-distance dependencies in the natural language.", "label": 0}
{"sent1": "In this paper, we address the full task of Chinese temporal tagging (extraction and normalization) by developing Chinese HeidelTime resources.", "sent2": "We thus propose a Senseval-3 lexical sample activity where the training data is collected via Open Mind Word Expert.", "label": 0}
{"sent1": "The system then extracts facts that match the predefined ontology.", "sent2": "Many existing knowledge bases (KBs), including Freebase, Yago, and NELL, rely on a fixed ontology, given as an input to the system, which defines the data to be cataloged in the KB, i.e., a hierarchy of categories and relations between them.", "label": 1}
{"sent1": "Previous attempts to use collocations (short sequences of adjacent words) in topic models have either relied on a pipeline approach, restricted attention to bigrams, or resulted in models whose inference does not scale to large corpora.", "sent2": "The summarizer does not use any expensive NLP techniques such as parsing, tagging of names or even part of speech information.", "label": 0}
{"sent1": "Integrating these different annotation types within an interoperable environment allows us to study the correlations between different types of discourse and report on the new insights that this allows us to discover.", "sent2": "Then, we train another CRF model using the result of the first phase.", "label": 0}
{"sent1": "The architecture defines common data structures and interfaces to support interoperability of individual processing components working together in a UIMA application.", "sent2": "The components exchange data by sharing common type systems?schemata of data type structures?which extend a generic, top-level type system built into UIMA.", "label": 1}
{"sent1": "We have found that the special structure of captions allows us to extract some names of people actually portrayed in the image quite reliably, using a simple syntactic analysis.", "sent2": "We have been able to build a directory of face images of individuals from this collection.", "label": 1}
{"sent1": "In particular, we present our methodology for reliably annotating antecedents of such anaphoric nouns and the challenges we faced in doing so.", "sent2": "We examine the feasibility of annotating such anaphoric nouns using crowdsourcing.", "label": 1}
{"sent1": "Since different models are obtained for each subject it becomes hard to perform an analysis on the group level.", "sent2": "We introduce a new algorithm for Bayesian multi-task learning which imposes a coupling between single-subject models.", "label": 1}
{"sent1": "We focus on the rule component and a qualitative and quantitative evaluation.", "sent2": "Semantic networks have been used successfully to explain access to the mental lexicon.", "label": 0}
{"sent1": "Part of the corpus are detailed interaction logs that consistently cover the search for sources as well as the creation of documents.", "sent2": "This will allow for in-depth analyses of how text is composed if a writer is at liberty to reuse texts from a third party?a setting which has not been studied so far.", "label": 1}
{"sent1": "We also introduce a novel sense pruning mechanism for WordNet-based similarity measures, which improves their performance in the first phase.", "sent2": "The newly introduced method compares favorably to existing methods in all configurations tested.", "label": 0}
{"sent1": "Results suggest that no single lexicon is best for every task and dataset and that the intrinsic evaluation of polarity lexicons is not a good performance indicator on a Sentiment Analysis task.", "sent2": "The qwn-ppv method allows to easily create quality polarity lexicons whenever no domain-based annotated corpora are available for a given language.", "label": 1}
{"sent1": "In this paper, we show that semi-supervised Viterbi-EM can be used to extend the lexicon of a generative CCG parser.", "sent2": "By learning complex lexical entries for low-frequency and unseen words from unlabeled data, we obtain improvements over our supervised model for both indomain (WSJ) and out-of-domain (questions and Wikipedia) data.", "label": 1}
{"sent1": "The DDIExtraction 2013 challenge poses the task of detecting drugdrug interactions and further categorizing them into one of the four relation classes.", "sent2": "I report on the translation quality of a machine translation (MT) system where both techniques are implemented.", "label": 0}
{"sent1": "Tools like openDMAP and TEES are used to extract semantic concepts from the corpus.", "sent2": "The best F-score that we got for DrugDrug Interaction (DDI) detection is 50% and 61% and the best F-score for DDI detection and classification is 34% and 48% for test and development data respectively.", "label": 1}
{"sent1": "Corpus based  approaches have been used for deriving feature vectors of concrete nouns, to model the  brain activity associated with that noun.", "sent2": "Different studies have been conducted for  predicting human brain activity associated  with the semantics of nouns.", "label": 1}
{"sent1": "In this paper we propose a set of methods to extract a word-emotion lexicon automatically from an emotion labelled corpus of tweets.", "sent2": "In order to handle the subtree extraction problem, we investigate a new class of submodular maximization problem, and a new algorithm that has the approximation ratio 12(1 ?", "label": 0}
{"sent1": "We use a pipeline approach, in which preprocessing, unrelated documents discarding, Chinese personal name extension and document clustering are performed separately.", "sent2": "Multi-category bootstrapping algorithms were developed to reduce semantic drift.", "label": 0}
{"sent1": "The key point of  Clustering is the similarity measure of  context, which depends upon the features  selection and representation.", "sent2": "This is an example of a more general problem where opinion is expressed using either sub- or supersets of expressive words found in newswire.", "label": 0}
{"sent1": "the query we expand it using encyclopedic knowledge in Wikipedia.", "sent2": "The expanded query is linked with its associated documents through spreading activation in a graph that represents words and their grammatical connections in these documents.", "label": 1}
{"sent1": "In this paper, we present a text generation method called rewriting that edits existing human-authored narratives to change their theme without changing the underlying story.", "sent2": "We apply the approach to math word problems, where it might help students stay more engaged by quickly transforming all of their homework assignments to the theme of their favorite movie without changing the math concepts that are being taught.", "label": 1}
{"sent1": "The annotation is based on the scheme of the W3C Emotion Markup Language.", "sent2": "Thus, we first present a dataset we built using SINA city news.", "label": 1}
{"sent1": "However, most of existing methods only focus on local text information and ignore the global user preference and product characteristics.", "sent2": "Our algorithm produces optimal k-best parses under the same conditions required for optimality in a 1-best A?", "label": 0}
{"sent1": "However, one of the remaining challenges is to model long texts in document-level sentiment classification under a recurrent architecture because of the deficiency of the memory unit.", "sent2": "Argumentation in a scientific article is composed of unexpressed and explicit statements of old and new knowledge combined into a logically coherent textual argument.", "label": 0}
{"sent1": "We apply the framework to sentence sentiment analysis, augmenting a DNN with massive linguistic constraints on discourse and polarity structures.", "sent2": "In natural language understanding (NLU), a user utterance can be labeled differently depending on the domain or application (e.g., weather vs. calendar).", "label": 0}
{"sent1": "This results in a very sparse vector space, requiring a mechanism for inferring missing knowledge.", "sent2": "The result is particularly interesting in the case of the fast greedy parser (Malt), since improving its accuracy without significantly compromising speed is relevant for large scale applications such as parsing the web.", "label": 0}
{"sent1": "Experiments on the new task and previous data sets show significant improvement of our model over baselines and other traditional latent variable models.", "sent2": "In this paper we address the problems of: identifying Arabizi in text and converting it to Arabic characters.", "label": 0}
{"sent1": "We present a new neural network architecture which 1) learns word embeddings that better capture the semantics of words by incorporating both local and global document context, and 2) accounts for homonymy and polysemy by learning multiple embeddings per word.", "sent2": "We introduce a new dataset with human judgments on pairs of words in sentential context, and evaluate our model on it, showing that our model outperforms competitive baselines and other neural language models.", "label": 1}
{"sent1": "We compare the alignment results by Turkers to that by experts, and incorporate the alignments in a semi-supervised word alignment tool to improve the quality of the labels.", "sent2": "We evaluate the method on two languages that rarely serve as a material for automatic splitting systems: English and Russian.", "label": 0}
{"sent1": "The ranking model is automatically derived from word aligned parallel data with a syntactic parser for source language based on both lexical and syntactical features.", "sent2": "In this work, we further extend this line of exploration and propose a novel but simple approach, which utilizes a ranking model based on word order precedence in the target language to reposition nodes in the syntactic parse tree of a source sentence.", "label": 1}
{"sent1": "For each group of languages, the classifier uses a different kind and combination of knowledge-poor features: token or character n-grams and ?white lists?", "sent2": "of tokens.", "label": 1}
{"sent1": "Language groups are predicted using a generative classifier with 99.99% accuracy on the five target groups.", "sent2": "Agent-based models of language evolution have received a lot of attention in the last two decades.", "label": 0}
{"sent1": "More specifically, from an off-site post, we ask human commanders (C) to perform an exploratory task in collaboration with a remotely located human robot-navigator (Rn) who controls the navigation of, but cannot see the physical robot (R).", "sent2": "We impose network bandwidth restrictions in two mission scenarios comparable to real circumstances by varying the availability of sensor, image, and video signals to Rn, in effect limiting the human Rn to function as an automation stand-in.", "label": 1}
{"sent1": "or ?animal??)", "sent2": "In this paper, we propose the idea of ?granularityaware?", "label": 1}
{"sent1": "In particular, we propose a novel entity-mention detection algorithm that might help identify nominal mentions in an unknown language.", "sent2": "We posit that there is a latent mapping of the question-answer meaning representation graph onto the text meaning representation graph that explains the answer.", "label": 0}
{"sent1": "and a variety of error models and algorithms, including proposed improvements of our own.", "sent2": "Special reference is made to on-line three-way composition of the input, the error model and the language model.", "label": 1}
{"sent1": "In order to produce proper alignments, we show that factors must satisfy a number of constraints such as orthogonality.", "sent2": "We then propose an algorithm for orthogonal non-negative matrix factorisation, based on a probabilistic model of the alignment data, and apply it to word alignment.", "label": 1}
{"sent1": "We participate in the ?closed challenge?", "sent2": "While these approaches have proven to be effective they have the disadvantage of being targeted to a particular language.", "label": 0}
{"sent1": "For many reasons, it is highly desirable to accurately estimate the confidence the system has in the correctness of each extracted field.", "sent2": "The information extraction system we evaluate is based on a linear-chain conditional random field (CRF), a probabilistic model which has performed well on information extraction tasks because of its ability to capture arbitrary, overlapping features of the input in a Markov model.", "label": 1}
{"sent1": "The toolkit has been designed using the principle of on-demand computation and offers a large range of widely used algorithms.", "sent2": "To prove the superior efficiency of the toolkit, we compare the implementation to that of other publically available toolkits.", "label": 1}
{"sent1": "We present a nearly-automated approach for deriving such hierarchies, by converting the lexical hierarchy WordNet into a format that reflects the contents of a target information collection.", "sent2": "When translating among languages that differ substantially in word order, machine translation (MT) systems benefit from syntactic preordering?an approach that uses features from a syntactic parse to permute source words into a target-language-like order.", "label": 0}
{"sent1": "While significant progress has been made in this area for text sources and for English audio sources, little work has been done in automatic, acoustic feature-based segmentation of other languages.", "sent2": "In this paper, we focus on prosody-based topic segmentation of Mandarin Chinese.", "label": 1}
{"sent1": "Our results show that augmenting a stateof-the-art SMT system with paraphrases leads to significantly improved coverage and translation quality.", "sent2": "We show how techniques from paraphrasing can be used to deal with these otherwise unknown source language phrases.", "label": 1}
{"sent1": "In this paper, we compare several existing approaches to approximating the nearestneighbour search for distributional similarity.", "sent2": "We investigate the trade-off between efficiency and accuracy, and find that SASH (Houle and Sakuma, 2005) provides the best balance.", "label": 1}
{"sent1": "To capture the association and order of two textual segments (eg, sentences), we define four criteria, chronology, topical-closeness, precedence, and succession.", "sent2": "A key challenge of designing coherent semantic ontology for spoken language understanding is to consider inter-slot relations.", "label": 0}
{"sent1": "Our grammars automatically learn the kinds of linguistic distinctions exhibited in previous work on manual tree annotation.", "sent2": "On the other hand, our grammars are much more compact and substantially more accurate than previous work on automatic annotation.", "label": 1}
{"sent1": "We also introduce a simple trick to transfer information about distant entities by embedding label information into non-entity labels.", "sent2": "We further use algorithms for Sentiment Analysis in order to add a psychological dimension to the edges in the network.", "label": 0}
{"sent1": "One such example, explored in this article, is the mention detection and recognition task in the Automatic Content Extraction project, with the goal of identifying named, nominal or pronominal references to real-world entities?mentions?", "sent2": "The solver core is a mention classifier that uses Soon et al.", "label": 0}
{"sent1": "We propose to use HMMs to model text at the segment level, in which the extraction process consists of two steps: a segment retrieval step followed by an extraction step.", "sent2": "This modelling might cause undesired redundancy in extraction in the sense that more than one filler is identified and extracted.", "label": 1}
{"sent1": "is achieved when the full-text representation is combined with the automatically extracted keywords.", "sent2": "as measured by micro-averaged F-measure on a standard text categorization collection ?", "label": 1}
{"sent1": "Part-of-speech tagging is a crucial preliminary process in many natural language processing applications.", "sent2": "We study substitute vectors to solve the part-of-speech ambiguity problem in an unsupervised setting.", "label": 1}
{"sent1": "The importance are detected using linguistic clues.", "sent2": "The proposed method uses three types of term importance: necessary, optional, and unnecessary.", "label": 1}
{"sent1": "Second, a topic summary should not be similar to any other topic summary (we refer to this problem as redundancy between summaries).", "sent2": "First, each topic summary should not contain any redundancy (we refer to this problem as redundancy within a summary).", "label": 1}
{"sent1": "Our system identifies these semantic relations in Japanese Web texts using a combination of lexical, syntactic, and semantic information and evaluate our system against gold standard data that was manually constructed for this task.", "sent2": "Our system targets a set of semantic relations that have been inspired by CST but that have been generalized and broadened to facilitate application to mixed fact and opinion data from the Internet.", "label": 1}
{"sent1": "One aim is to examine if distributionally similar terms can be in fact equated with ?semantically similar?", "sent2": "We analyzed the details of aWeb-derived distributional data of Japanese nominal terms with two aims.", "label": 1}
{"sent1": "Using Wikipedia articles as a target corpus, our approach is based on surface level text matching between formulas and text, as well as patterns that represent relationships between them.", "sent2": "The results showed the potential of our approach for formulas and text coreference mining.", "label": 1}
{"sent1": "This motivates us to develop an alignment-based framework for unsupervised dependency parsing.", "sent2": "The framework (which will be made publicly available) is flexible, modular and easy to extend.", "label": 1}
{"sent1": "Previous approaches have been designed for particular natural languages or specific meaning representations; here we present a more general method.", "sent2": "The similarity of pairs of sentences was rated on a 0-5 scale (low to high similarity) by human judges using Amazon Mechanical Turk, with high Pearson correlation scores, around 90%.", "label": 0}
{"sent1": "During inference of the probabilistic model, we use posterior expectation constraints to require that a minimum proportion of the dependencies we infer be instances of these rules.", "sent2": "Two knowledge bases, GRISP and Wikipedia, are then exploited for producing a last set of lexical/semantic features.", "label": 0}
{"sent1": "The two methods differ in the data they use for learning the hash functions - the first method uses a set of names in a given language/script whereas the second uses a set of bilingual names.", "sent2": "The key idea behind our methods is to learn hash functions that map similar names to similar (and compact) binary codewords.", "label": 1}
{"sent1": "It first computes multiple typed functionality scores, representing functionality of the relation phrase when its arguments are constrained to specific types.", "sent2": "We present the LEIBNIZ system that overcomes these challenges by exploiting the synergy between the Web corpus and freelyavailable knowledge resources such as Freebase.", "label": 1}
{"sent1": "Applied to a new dataset of geotagged microblogs, our model recovers coherent topics and their regional variants, while identifying geographic areas of linguistic consistency.", "sent2": "relation.", "label": 0}
{"sent1": "Empirically the LP relaxation is very often tight: for many languages, exact solutions are achieved on over 98% of test sentences.", "sent2": "These clusters can then be analysed in terms of the possible Dialogue Acts that they might represent.", "label": 0}
{"sent1": "Inference in these models is kept tractable through dual decomposition.", "sent2": "The second model captures correlations between events, while the third model ensures consistency between arguments of the same event.", "label": 1}
{"sent1": "In this paper, we present the task of parsing user forum threads to determine the labelled dependencies between posts.", "sent2": "Three methods, including a dependency parsing approach, are proposed to jointly classify the links (relationships) between posts and the dialogue act (type) of each link.", "label": 1}
{"sent1": "Given a set of N -best lists produced from S input sentences, this algorithm finds a linear model that is globally optimal with respect to this set.", "sent2": "We find that this algorithm is polynomial in N and in the size of the model, but exponential in S. We present extensions of this work that let us scale to reasonably large tuning sets (e.g., one thousand sentences), by either searching only promising regions of the parameter space, or by using a variant of LP-MERT that relies on a beam-search approximation.", "label": 1}
{"sent1": "This task differs from the named entity task in that the information we are interested in is a subset of the named entities in the message, and consequently, the need to pick the correct subset makes the problem more difficult.", "sent2": "In this paper we address the problem of extracting key pieces of information from voicemail messages, such as the identity and phone number of the caller.", "label": 1}
{"sent1": "It is well known that hand-crafted systems with a large set of heuristic rules are difficult to maintain, and corpus-based statistical approaches are expected to be more robust and require less human intervention.", "sent2": "Several statistical approaches have been reported in the literature.", "label": 1}
{"sent1": "We contrast our approach to other approaches used for shallow?parsing (i.e.", "sent2": "In order to perform robustly for fragmental speech input and erroneous output of an automatic speech recognition (ASR), the system should selectively use N-best hypotheses of ASR and contextual information.", "label": 0}
{"sent1": "Such larger structures are not only desirable for a deeper syntactic analysis.", "sent2": "They also constitute a necessary prerequisite for assigning function-argument structure.", "label": 1}
{"sent1": "speech recognition errors as well as with ?normal?", "sent2": "Graph-based and transition-based approaches to dependency parsing adopt very different views of the problem, each view having its own strengths and limitations.", "label": 0}
{"sent1": "The training data for the second system is generated with the use of the rule-based system, thus avoiding the need for manual tagging.", "sent2": "Approaches have evolved from text classification to structured output prediction, including collective classification and sequence labeling.", "label": 0}
{"sent1": "Methods for vowel restoration in previous work involving morphological analysis concentrated on a single language and relied on a parsed corpus that is difficult to create for many Semitic languages.", "sent2": "Thus we design a graph-based algorithm to automatically identify triggers based on personalized PageRank and Affinity Propagation for a given (query, filler) pair and then label the slot type based on the identified triggers.", "label": 0}
{"sent1": "parameters.", "sent2": "We propose two new probabilistic models based on the innerouter segmentations and use EM algorithms for estimating the models?", "label": 1}
{"sent1": "In contrast to the well known back-off n-gram language models, the neural network approach attempts to overcome the data sparseness problem by performing the estimation in a continuous space.", "sent2": "We demonstrate the feasibility of recovering implicit arguments with a supervised classification model.", "label": 0}
{"sent1": "We focus on modeling references to people, both because news often revolve around people and because existing natural language tools for named entity identification are reliable.", "sent2": "To control for these confounding factors, we take advantage of the surprising fact that there are many pairs of tweets containing the same url and written by the same user but employing different wording.", "label": 0}
{"sent1": "For example, when the complete system is presented with ?The bird dove to the rock,?", "sent2": "For the task of question answering (QA) over Freebase on the WEBQUESTIONS dataset (Berant et al., 2013), we found that 85% of all questions (in the training set) can be directly answered via a single binary relation.", "label": 0}
{"sent1": "In this paper, we propose a fast and easy-toimplement dual coordinate descent algorithm for SSVMs.", "sent2": "While there exists evidence showing that linear Structural Support Vector Machine (SSVM) algorithm performs better than structured Perceptron, the SSVM algorithm is still less frequently chosen in the NLP community because of its relatively slow training speed.", "label": 1}
{"sent1": "Finally, we employ dual decomposition techniques to produce consistent syntactic and predicate-argument structures while searching over a large space of syntactic configurations.", "sent2": "We combine statistical knowledge with well known features in a Support Vector Machine pronoun resolution classifier.", "label": 0}
{"sent1": "We define an inventory of 32 relations, building on the word sense disambiguation task for prepositions and collapsing related senses across prepositions.", "sent2": "The experimental results on Wikipedia and ACE data have confirmed that backgroundknowledge-based topics generated from the Wikipedia relation repository can significantly improve the performance over the state-of-theart relation detection approaches.", "label": 0}
{"sent1": "Existing state-of-the-art approaches mainly rely on learning from human annotated equations.", "sent2": "In this paper, we demonstrate that it is possible to efficiently mine algebra problems and their numerical solutions with little to no manual effort.", "label": 1}
{"sent1": "In this application the generative model first draws a latent summary sentence from a background language model, and then subsequently draws the observed sentence conditioned on this latent summary.", "sent2": "We formulate a variational auto-encoder for inference in this model and apply it to the task of compressing sentences.", "label": 1}
{"sent1": "especially when constructing long texts.", "sent2": "Teachers report that it is feasible to integrate into their curriculum.", "label": 0}
{"sent1": "Second, we systematically explore the correlations between automatic evaluation metrics and human judgments of meaning preservation and grammaticality in the compression task, and analyze the impact of the linguistic units used and precision versus recall measures on the quality of the metrics.", "sent2": "Some applications such as Information Extraction from biological documents benefit from word dependency analysis even without phrase labels.", "label": 0}
{"sent1": "First, one context word representing a certain sense is chosen, and then the co-occurrence frequencies with two other context words, one of the same and one of another sense, are compared.", "sent2": "This paper is devoted to describe the process that we have followed to automatically identify the set of separators from a corpus only annotated with Part-of-Speech (POS) tags.", "label": 0}
{"sent1": "This project applies a rule-based method to solve the acronym recognition task and compares and evaluates the results of different machine learning algorithms on the same task.", "sent2": "The method proposed is based on the approach that acronym-definition pairs follow a set of patterns and other regularities that can be usefully applied for the acronym identification task.", "label": 1}
{"sent1": "functions, we have partially implemented the detection of emotions, etc.", "sent2": "To partially automate the directors?", "label": 1}
{"sent1": "These features were extracted from a 23M word WSJ corpus based on part-of-speech tags and phrasal chunks alone.", "sent2": "We constructed several decision tree classifiers trained on this data.", "label": 1}
{"sent1": "Based on this observation, we propose a hybrid method for translation selection that combines disambiguation of a source word sense and selection of a target word.", "sent2": "In this paper we present a graph-based approach to question answering.", "label": 0}
{"sent1": "Performance was evaluated by distorting the system?s arguments (generated from a BN) and feeding them to the system for interpretation.", "sent2": "We introduce a novel coreference resolution system that models entities and events jointly.", "label": 0}
{"sent1": "We report results for training and testing an automatic classifier to label the information provider?s utterances in spoken human-computer and human-human dialogues with DATE (Dialogue Act Tagging for Evaluation) dialogue act tags.", "sent2": "In this work, we examine whether it is possible to fully automate the tagging task with the goal of enabling rapid creation of corpora for evaluating spoken dialogue systems and comparing them to human-human dialogues.", "label": 1}
{"sent1": "Type-token generalization was applied, but also reduced performance.", "sent2": "However, few of the methods pay attention to non-entity words and clicked websites in queries, which also help conveying user intent.", "label": 0}
{"sent1": "The focus of this paper is to show that two essential techniques ?", "sent2": "This is largely due to the fact that an individual event can be expressed by several sentences.", "label": 0}
{"sent1": "Here we present such a parser, which avoids some of the limitations of other discriminative parsers.", "sent2": "(3) The extracted paraphrase patterns can be classified into 5 types, which are useful in various applications.", "label": 0}
{"sent1": "The approach improves on previous work which either loses efficiency by unpacking the parse forest before extracting weighted GRs, or places extra constraints on which nodes can be packed, leading to less compact forests.", "sent2": "to be computed directly from the forest.", "label": 1}
{"sent1": "One step towards obtaining these representations is event extraction - the identification of event triggers and arguments in text.", "sent2": "With previous approaches mainly focusing on classifying events into a small set of predefined types, we analyze unsupervised techniques for complex event extraction.", "label": 1}
{"sent1": "Then a novel multi-sentence compression algorithm is used to fuse the extracted events, generating a headline for the document.", "sent2": "Given an input document, the system identifies a key event chain by extracting a set of structural events that describe them.", "label": 1}
{"sent1": "We also introduce a new transfer learning technique based on pretraining of hidden-unit CRFs (HUCRFs).", "sent2": "Traditionally, automated triage of papers is performed using lexical (unigram, bigram, and sometimes trigram) features.", "label": 0}
{"sent1": "We describe a text-to-text generation scenario that poses challenging research questions, and delivers practical outcomes that are useful in the first case to our own community and potentially much more widely.", "sent2": "The aim is to use tools and techniques developed in computational linguistics to help people writing about computational linguistics.", "label": 1}
{"sent1": "We show that, with some modifications, the first type of model can be improved and made to approximate the output of the second, even though the latter is more informative.", "sent2": "We compare two types of statistical models for this task: a) local models, which predict a single class for an input; and b), sequential models, which align a sequence of classes to a sequence of input tokens.", "label": 1}
{"sent1": "In our approach, we first train hidden Markov models (HMMs) of dialogue-act sequences associated with each overall rating.", "sent2": "This paper proposes a novel approach for predicting user satisfaction transitions during a dialogue only from the ratings given to entire dialogues, with the aim of reducing the cost of creating reference ratings for utterances/dialogue-acts that have been necessary in conventional approaches.", "label": 1}
{"sent1": "POTs embody a principled approach to leverage the dependencies among domain concepts and incorporate corroborating or conflicting dialog observations in the form of interpreted user utterances across dialog turns.", "sent2": "We tailor standard inference algorithms to the POT framework to efficiently compute the user intentions in terms of m-best most probable explanations.", "label": 1}
{"sent1": "In this paper, we attempt to tackle this problem by employing a semi-supervised method for discourse relation classification.", "sent2": "Instead of directly incorporating a Senseval-style WSD system, we redefine the WSD task to match the exact same phrasal translation disambiguation task faced by phrase-based SMT systems.", "label": 0}
{"sent1": "Our investigation concentrates on the association between discourse relations and properties of the referring expressions that appear in the related sentences.", "sent2": "The properties of interest include coreference information, grammatical role, information status and syntactic form of referring expressions.", "label": 1}
{"sent1": "a  relation  that  connects  the  parts  of  a  discontinuous  discourse  segment  ?", "sent2": "This  study investigates  the  use of  Same  ?", "label": 1}
{"sent1": "We show that while there is a large degree of ambiguity in temporal explicit discourse connectives, overall connectives are mostly unambiguous and allow high-accuracy prediction of discourse relation type.", "sent2": "We present a corpus study of local discourse relations based on the Penn Discourse Tree Bank, a large manually annotated corpus of explicitly or implicitly realized relations.", "label": 1}
{"sent1": "Here we explore van der Sandt?s theory along the line of this formal framework.", "sent2": "In recent years, we have proposed a typetheoretic rebuilding of DRT that allows Montague?s semantics to be combined with discourse dynamics.", "label": 1}
{"sent1": "Learning from simulated younger users leads to a policy which is close to one of the dialogue strategies of the underlying SDS, while the simulated older users allow us to learn more flexible dialogue strategies that accommodate mixed initiative.", "sent2": "We used a few basic rules that were executed automatically to create the consensus.", "label": 0}
{"sent1": "Evaluation results are given both in terms of statistics of generated user behaviour and the quality of policies trained with different simulators.", "sent2": "Compared to a handcrafted simulator, the trained system provides a much better fit to corpus data and evaluations suggest that this better fit should result in improved dialogue performance.", "label": 1}
{"sent1": "We present two methods to apply the predicted connectives to implicit discourse relation recognition.", "sent2": "In this paper, we use language models to predict the discourse connectives between the arguments pair.", "label": 1}
{"sent1": "Lexical cohesion ?", "sent2": "However, after giving a suitably flexible presentation of OT, we show carefully how to treat comprehension under recent variants of OT in which grammars can be compiled into finite-state transducers.", "label": 0}
{"sent1": "Their approach is limited to small training sets of a few thousand sentences and a similar number of sparse features.", "sent2": "Recent work by Cherry (2013) has shown that directly optimizing phrase-based reordering models towards BLEU can lead to significant gains.", "label": 1}
{"sent1": "Moreover, our method adopts a pattern-learning strategy for semantic item grouping.", "sent2": "All clauses can then produce interacted effects in a unified framework and can jointly resolve all ambiguities.", "label": 1}
{"sent1": "We argue that people?s emotional reactions immediately reflect the occurring of real-world events and should be important for event detection.", "sent2": "had to be identified.", "label": 0}
{"sent1": "This enables our model to capture longrange dependencies between words and to better handle constructs such as verbobject and subject-verb-object relations.", "sent2": "We show several procedures that enable evaluating the quality of a translated sentence more appropriately than using conventional methods.", "label": 0}
{"sent1": "However, the classical approach is based on a quadratic time algorithm with 80% coverage.", "sent2": "There are several NLP systems whose accuracy depends crucially on finding misspellings fast.", "label": 1}
{"sent1": "We apply the model to an experiment about candidate biographies, recovering intuitive features of voters?", "sent2": "decisions and revealing a penalty for lawyers and a bonus for military service.", "label": 1}
{"sent1": "At the task of producing generic DUC-style summaries, HIERSUM yields state-of-the-art ROUGE performance and in pairwise user evaluation strongly outperforms Toutanova et al (2007)?s state-of-the-art discriminative system.", "sent2": "We also explore HIERSUM?s capacity to produce multiple ?topical summaries?", "label": 1}
{"sent1": "Our empirical study on both synthetic data sets and real world data sets demonstrates the efficacy of COPYNET.", "sent2": "COPYNET can nicely integrate the regular way of word generation in the decoder with the new copying mechanism which can choose subsequences in the input sequence and put them at proper places in the output sequence.", "label": 1}
{"sent1": "However, several applications encounter scenarios where models need to transfer/adapt across domains when the label sets vary both in terms of count of labels as well as their connotations.", "sent2": "This paper presents first-of-its-kind transfer learning algorithm for cross-domain classification with multiple source domains and disparate label sets.", "label": 1}
{"sent1": "We solve this problem by exploiting existing morphological resources that can enumerate a word?s component morphemes.", "sent2": "The groups using it include such major Figure 1: Screenshot of ?Minna no Hon?yaku?NGOs as Amnesty International Japan site (http://trans- )and Democracy Now!", "label": 0}
{"sent1": "In this paper, we introduce a simpler and more effective approach, making the NMT model capable of open-vocabulary translation by encoding rare and unknown words as sequences of subword units.", "sent2": "Previous work addresses the translation of out-of-vocabulary words by backing off to a dictionary.", "label": 1}
{"sent1": "We view semantic role assignment as an optimization problem in a bipartite graph and answer extraction as an instance of graph matching.", "sent2": "We present a framework for word alignment based on log-linear models.", "label": 0}
{"sent1": "We use sparse features to address reordering, which is often considered a weak point of phrase-based translation.", "sent2": "Experimenting with different mathematical objects for text representation is an important step of building text classification models.", "label": 0}
{"sent1": "The model jointly induces word and morpheme alignments using an EM algorithm.", "sent2": "We evaluated our model on Turkish-English parallel data.", "label": 1}
{"sent1": "We propose a multi-faceted event recognition approach, which identifies documents about an event using event phrases as well as defining characteristics of the event.", "sent2": "Identifying documents that describe a specific type of event is challenging due to the high complexity and variety of event descriptions.", "label": 1}
{"sent1": "We use a CRF to train a model to predict when a sequence of words is a member of a given class and use this to label our language model training data.", "sent2": "However, evaluating such resources has turned out to be a non-trivial task, slowing progress in the field.", "label": 0}
{"sent1": "We present KELP, a Java framework that supports the implementation of both kernel-based learning algorithms and kernel functions over generic data representation, e.g.", "sent2": "Kernel-based learning algorithms have been shown to achieve state-of-the-art results in many Natural Language Processing (NLP) tasks.", "label": 1}
{"sent1": "We model wide variety of features and show an alternative way to capture knowledge base information using embeddings.", "sent2": "We conduct an extensive study over 37, 000 manually annotated queries and report performance of 90.92 F 1 independent of the query length.", "label": 1}
{"sent1": "The goal of this research is to give a formal account of language coordination in dialogue, and semantic coordination in particular.", "sent2": "Extensive knowledge bases of entailment rules between predicates are crucial for applied semantic inference.", "label": 0}
{"sent1": "linguistic?behaviours?investigated.?", "sent2": "?This?paper?", "label": 1}
{"sent1": "The structures that we are inducing are very similar to the conceptual structures that are used in Frame Semantics (such as FrameNet).", "sent2": "Those structures are called messages and they were previously used in the context of a multi-document summarization system of evolving events.", "label": 1}
{"sent1": "Furthermore, our observations indicate that this parameter might bear a correlation with the period of existence of the language families under investigation.", "sent2": "The experiments with this model parameter indicates that the choice of consonants among the languages within a family are far more preferential than it is across the families.", "label": 1}
{"sent1": "The multidimensional organisation of the taxonomy reflects that there are various aspects that dialogue participants have to deal with simultaneously during a dialogue.", "sent2": "Besides performing some underlying task, a participant also has to pay attention to various aspects of the communication process itself, including social conventions.", "label": 1}
{"sent1": "The system generates seed candidates through local, cross-language edit likelihood and then bootstraps to make broad predictions across both languages, optimizing combined contextual, word-shape and alignment models.", "sent2": "Natural language parsing has to be accurate and quick.", "label": 0}
{"sent1": "However, a single model cannot deal with mixture of words with different origins, such as ?get?", "sent2": "We demonstrate the frequency and productivity of these sequences in social media such as Twitter.", "label": 0}
{"sent1": "Annotation guidelines were developed, consistent with existing time-related annotation guidelines for TimeML.", "sent2": "We annotated 310 abstracts from PubMed.", "label": 1}
{"sent1": "Our approach largely decomposes questions using their syntactic structure, recognizing independent questions embedded in clauses, as well as coordinations and exemplifying phrases.", "sent2": "Additionally, we identify elements specific to disease-related consumer health questions, such as the focus disease and background information.", "label": 1}
{"sent1": "We obtained an improvement of 40% over the baseline with unweighted average F 1 -measure using B-CUBED, MUC, and CEAF metrics.", "sent2": "We adopt several competitive methods as comparisons and perform extensive experiments.", "label": 0}
{"sent1": "In this work we introduce a novel generic distributional similarity scheme under which the power of probabilistic models can be leveraged to effectively model joint contexts.", "sent2": "We present a novel, discriminative sample selection strategy that preferentially selects batches of candidate sentences with constructs that lead to erroneous translations on a held-out development set.", "label": 0}
{"sent1": "For instance, a patient problem list from a clinical document can be derived from individual problem mentions within the clinical document once these mentions are mapped to a standard vocabulary.", "sent2": "In order to develop and evaluate accurate document-level inference engines for this task, a patient problem list could be generated using a standard vocabulary.", "label": 1}
{"sent1": "sentiment polarity relations extracted from the unlabeled target domain data.", "sent2": "The similarities between target domain and different source domains are also incorporated into the adaptation process.", "label": 1}
{"sent1": "perspective: y probably dislikes x, (3) effect: something bad happened to y, (4) value: y is something valuable, and (5) mental state: y is distressed by the event.", "sent2": "and y as a ?victim?, (2) entities?", "label": 1}
{"sent1": "Thus, domain adaptation for sentiment classification algorithms are highly desirable to reduce the domain discrepancy and manual labeling costs.", "sent2": "Due to the mismatch among different domains, a sentiment classifier trained in one domain may not work well when directly applied to other domains.", "label": 1}
{"sent1": "Our work makes the following contributions.", "sent2": "Compared with sentence-wise FA, dependency-wise PA gives us more flexibility in task selection and avoids wasting time on annotating trivial tasks in a sentence.", "label": 1}
{"sent1": "SCQA consist of twin convolutional neural networks with shared parameters and a contrastive loss function joining them.", "sent2": "to find the semantic similarity between the current and the archived questions.", "label": 1}
{"sent1": "We formulate the problem as a reranking task and integrate different similarity measures under the learning to rank framework.", "sent2": "Our model admits an efficient variational meanfield inference algorithm which can be parallelized and run on large snippet collections.", "label": 0}
{"sent1": "Unfortunately, the size of the tensors can make their use impractical in large-scale implementations.", "sent2": "This motivates a more structured approach, using a process of attachment to form constituents from their distributional components.", "label": 0}
{"sent1": "the relaxed hybrid tree model by introducing our constrained semantic forests.", "sent2": "These relations are provided by the Stanford Parser 1 .", "label": 0}
{"sent1": "Still, it is desirable to be able to identify rhetorical questions, as it is relevant for many NLP tasks, including information extraction and text summarization.", "sent2": "Minimum Error Rate Training (MERT) and Minimum Bayes-Risk (MBR) decoding are used in most current state-of-theart Statistical Machine Translation (SMT) systems.", "label": 0}
{"sent1": "This in turn leads to an optimistic upper bound on algorithm performance.", "sent2": "To address these drawbacks, we propose the use of lexical categories to create more realistic pseudowords, and evaluate the results of different variations of this idea against the standard approach.", "label": 1}
{"sent1": "We capture visual properties such as color, texture, shape, and orientation by computing low-level image features, and measure the contribution of each type of visual feature towards the accuracy of the model.", "sent2": "This makes possible the use of the approach in domains where several hundreds of millions words of texts are available.", "label": 0}
{"sent1": "We show that this knowledge, automatically mined from web-scale text corpora, enhances the triplet selection algorithm by providing it contextual information and leads to a four-fold increase in activity identification.", "sent2": "One of the difficulties in using Folksonomies in computational systems is tag ambiguity: tags with multiple meanings.", "label": 0}
{"sent1": "This requires the user to go through the images first, in order to reveal the semantic relationship between the different nodes.", "sent2": "Classic exploratory data analysis methods, such as agglomerative hierarchical clustering, only provide a means of obtaining a tree-structured partitioning of the data.", "label": 1}
{"sent1": "It was developed to ease every step in engineering rule-based applications.", "sent2": "This demonstration gives an overview of the UIMA Ruta Workbench, which provides a development environment and tooling for the rule language.", "label": 1}
{"sent1": "The system architecture is extensible and handles realtime behaviors.", "sent2": "The system supports multiple activities, including discussing the weather, playing cards, telling stories, exercise coaching and video conferencing.", "label": 1}
{"sent1": "We investigate a largely unsupervised approach to learning interpretable, domain-specific entity types from unlabeled text.", "sent2": "We cast multi-sentence compression as a structured prediction problem.", "label": 0}
{"sent1": "LSH accounts for neighbor candidate pruning, while ITQ provides an efficient and effective reranking over the neighbor pool captured by LSH.", "sent2": "Many NLP tasks need accurate knowledge for semantic inference.", "label": 0}
{"sent1": "This paper proposes a new annotation process with a mechanism to force annotators to label connected graphs.", "sent2": "It generates 10 times more relations per document than the TimeBank, and our TimeBank-Dense corpus is larger than all current corpora.", "label": 1}
{"sent1": "This points to an underlying ambiguity rather than random errors.", "sent2": "Moreover, a quantitative analysis of tag confusions reveals that the majority of disagreements are due to linguistically debatable cases rather than annotation errors.", "label": 1}
{"sent1": "A detailed study of Sanskrit language reveals that its well-structured and finely organized grammar has affinity for automated translation systems.", "sent2": "Developing a Machine Translation system for ancient languages is much more fascinating and challenging task.", "label": 1}
{"sent1": "In this paper, we propose a new algorithm for Persian language.", "sent2": "Many algorithms have been proposed for stemming.", "label": 1}
{"sent1": "The system makes use of the different contextual information of the words along with the variety of features that are helpful in predicting the various named entity (NE) classes.", "sent2": "We consider semi-supervised learning of information extraction methods, especially for extracting instances of noun categories (e.g., ?athlete,?", "label": 0}
{"sent1": "In this paper, to reduce this human effort, we use the World Wide Web to extract related terms for source words.", "sent2": "Further, it does not answer the question of ?Can better accuracy be achieved if a user is willing to pay additional money??", "label": 0}
{"sent1": "In such a case, training set selection can reduce the size of the translation model.", "sent2": "However, training corpora sometimes include both target task matched and unmatched sentences.", "label": 1}
{"sent1": "Reordered and generalized rules are the most significant in our approach.", "sent2": "It supports several different measures for automatically determining the number of clusters in which a collection of contexts should be grouped.", "label": 0}
{"sent1": "Finally, we demonstrate that, on balanced training and test sets, we can distinguish turnunit final words from other words at ?", "sent2": "Additionally, SEERLAB performed particularly well in generating the top 5 keyphrases with an F-score that ranked third.", "label": 0}
{"sent1": "work.", "sent2": "We present a novel approach to Data-Oriented Parsing (DOP).", "label": 0}
{"sent1": "A common approach is to define a generative model and maximize the probability of the hidden structure given the observed data.", "sent2": "Unsupervised learning of linguistic structure is a difficult problem.", "label": 1}
{"sent1": "This paper focuses on techniques related to the latter efforts.", "sent2": "We have developed a very simple n-gram counting method that reduces the size of data sets dramatically, as much as 90%, and is applicable independent of specific dev and test data.", "label": 1}
{"sent1": "tasks defined as sections of the International Patent Classification versus ?random?", "sent2": "In this paper, we utilize Wikipedia as an open knowledge base to improve multilingual NER systems.", "label": 0}
{"sent1": "During training, we allow the decoder to generate new phrases on-the-fly and increment the maximum phrase length in each iteration.", "sent2": "In this paper, we bound the test set perplexity of two popular language models ?", "label": 0}
{"sent1": "We present a novel open-source toolkit for quantitative tasks in historical linguistics that offers these features.", "sent2": "Additionally, we compare the maximum a-posteriori decision rule and the minimum Bayes risk decision rule.", "label": 0}
{"sent1": "As such, people no loger remain mere spectators to the events that happen in the world, but become part of them, commenting on their developments and the entities involved, sharing their opinions and distributing related content.", "sent2": "This may especially be the case with multiple redundant texts on the same topic.", "label": 0}
{"sent1": "The loss function can be seen as a (generative) alternative to maximum likelihood estimation with an interesting information-theoretic interpretation, and it is statistically consistent.", "sent2": "It is substantially faster than maximum (conditional) likelihood estimation of conditional random fields (Lafferty et al, 2001; an order of magnitude or more).", "label": 1}
{"sent1": "DKPro WSD abstracts the WSD process in such a way that test corpora, sense inventories, and algorithms can be freely swapped.", "sent2": "Our dynamic parser can achieve accuracies comparable or even superior to parsers using a full set of features, while computing fewer than 30% of the feature templates.", "label": 0}
{"sent1": "Thus, the contents can be incomplete at the initial stage and become solid gradually as being utilized.", "sent2": "Surprisingly, this simple method yields fairly good results.", "label": 0}
{"sent1": "To acquire these noun-verb pairs, we use asares, a machine learning technique that automatically infers extraction patterns from examples and counter-examples of realization noun-verb pairs.", "sent2": "We focus on verbs that convey a meaning of realization.", "label": 1}
{"sent1": "in domainspecific corpora, and to detect the semantic relations they involve between their main terms.", "sent2": "Our aim is therefore to mine ?defining expressions?", "label": 1}
{"sent1": "We also apply the information radius to calculating similarities between words using a full dependency syntactic feature space, and introduce a method for similarity recalculation during clustering as a fast approximation of the high-dimensional feature space.", "sent2": "Finally, we show that 69-79% of the words in the clusters we discover are useful for thesaurus construction.", "label": 1}
{"sent1": "Specific words have been imported into multiple countries simultaneously, if they are influential across cultures.", "sent2": "The pronunciation of a source word is similar in different languages.", "label": 1}
{"sent1": "Exploiting HeidelTime?s strict separation between source code and languagedependent parts, we tuned HeidelTime?s existing English resources and developed new Spanish resources.", "sent2": "For both languages, we achieved the best results among all participants for task A, the combination of extraction and normalization.", "label": 1}
{"sent1": "We propose a multipass, coarse-to-fine approach in which the language model complexity is incrementally introduced.", "sent2": "The intersection of tree transducer-based translation models with n-gram language models results in huge dynamic programs for machine translation decoding.", "label": 1}
{"sent1": "This paper shows that the transliteration problem can be formulated as a constrained optimization problem and thus take into account contextual dependencies and constraints among character bi-grams in the two strings.", "sent2": "Such an approach can, for example, learn likely event durations and the fact that start times should come before end times.", "label": 0}
{"sent1": "By developing a graph-based and a transition-based dependency parser, we show that a beam-search decoder is a competitive choice for both methods.", "sent2": "For computers, things are different, however.", "label": 0}
{"sent1": "We show that our question classifier can achieve the state of the art performance in the standard UIUC question dataset.", "sent2": "We employ Laplacian Eigenmaps (LE) to project the latent topic distributions into low-dimensional semantic representations while preserving the intrinsic local geometric structure.", "label": 0}
{"sent1": "In the empirical approach, on the other hand, we re-parse a sentence with a target error corrected and observe errors corrected together.", "sent2": "In the descriptive approach, we define some combinations of error patterns and extract them from given errors.", "label": 1}
{"sent1": "One approach to this task is supervised classification.", "sent2": "Named entity disambiguation concerns linking a potentially ambiguous mention of named entity in text to an unambiguous identifier in a standard database.", "label": 1}
{"sent1": "We address this problem using nonparametric Bayesian modeling, specifically adaptor grammars (Johnson et al, 2006).", "sent2": "In contrast, human feedback has a positive and statistically significant, but lower, impact on precision and recall.", "label": 0}
{"sent1": "that also supports cubic-time decoding.", "sent2": "By simply pruning non-scope-3 rules from a GHKM-extracted grammar, we obtain better translation performance than synchronous binarization.", "label": 1}
{"sent1": "Firstly, a discourse scheme with discourse constraints on polarity was defined empirically based on Rhetorical Structure Theory (RST).", "sent2": "These matrices are then compared to give distances between languages.", "label": 0}
{"sent1": "Given the collection of time-stamped web documents related to the evolving news, ETTS aims to return news evolution along the timeline, consisting of individual but correlated summaries on each date.", "sent2": "ETTS greatly facilitates fast news browsing and knowledge comprehension, and hence is a necessity.", "label": 1}
{"sent1": "Experiments show that it achieves an \u0000 -measure of 0.879 and outperforms other methods.", "sent2": "Cross-lingual word embeddings are used for cross-lingual information retrieval or domain adaptations.", "label": 0}
{"sent1": "Given the novelty of this kind of data, it is crucial to get a better understanding of how questions in social Q&A sites can be automatically analysed and retrieved.", "sent2": "In this paper, we propose a method to support learners in the information seeking process which consists in answering their questions by retrieving question paraphrases and their corresponding answers from social Q&A sites.", "label": 1}
{"sent1": "Though subject-verb agreement is generally viewed to be syntactic in nature, a perusal of relevant examples discussed in the theoretical linguistics literature (Kathol, 1999; Pollard and Sag, 1994) points toward the heterogeneous nature of English agreement.", "sent2": "Compared to writing grammar rules, our method is more robust and allows incorporating information from diverse sources in realization.", "label": 1}
{"sent1": "The ability of an ICALL system to diagnose and provide feedback on the meaning conveyed by a learner response depends on how well it can deal with the response variation allowed by an activity.", "sent2": "We focus on short-answer reading comprehension questions which have a clearly defined target response but the learner may convey the meaning of the target in multiple ways.", "label": 1}
{"sent1": "The features which contributed the most to high translation quality were training data sub-sampling methods, document-specific models, as well as rule-based morphological normalization for Russian.", "sent2": "This paper describes a novel approach for the automatic generation and evaluation of a trivial dialogue phrases database.", "label": 0}
{"sent1": "Therefore the paper does not present a multi-engine system combination.", "sent2": "In particular, it requires assimilating information from multiple knowledge sources to recognize the intended message of the graphic, just as recognizing intention in text does.", "label": 0}
{"sent1": "Both hierarchical and phrase-based SMT systems are applied.", "sent2": "This sentiment information is very useful in various aspects for business and governments.", "label": 0}
{"sent1": "Sentences and the on-the-fly ontology are represented in probabilistic logic.", "sent2": "For inference, we use probabilistic logic frameworks like Markov Logic Networks (MLN) and Probabilistic Soft Logic (PSL).", "label": 1}
{"sent1": "Dynamic programming is used to search the upper bound.", "sent2": "Research accomplishment is usually measured by considering all citations with equal importance, thus ignoring the wide variety of purposes an article is being cited for.", "label": 0}
{"sent1": "MTurk workers are more successful in annotating some languages than others and are not evenly distributed around the world or among the world?s languages.", "sent2": "We carry out a user study using a real time web based personal news filtering system, and collect extensive multiple forms of evidence, including explicit and implicit user feedback.", "label": 0}
{"sent1": "On a large-scale ChineseEnglish translation task, we obtain statistically significant improvements of +1.5 B???", "sent2": "The impact of the features typically is evaluated using reference corpora containing graded reading material.", "label": 0}
{"sent1": "We use Mechanical Turk annotations to train an Opinion Mining System to classify Spanish consumer comments.", "sent2": "We design three different Human Intelligence Task (HIT) strategies and report high inter-annotator agreement between non-experts and expert annotators.", "label": 1}
{"sent1": "Recent studies have found that while there are suggestive connections between topic models and the way humans interpret data, these two often disagree.", "sent2": "In this paper, we explore this disagreement from the perspective of the learning process rather than the output.", "label": 1}
{"sent1": "While results are largely inconclusive, we identify important obstacles encountered, lessons learned, related work, and interesting ideas for future investigation.", "sent2": "However, many phrase pairs do not encode any relevant context, which means that the translation event encoded in that phrase pair is led by smaller translation events that are independent from each other, and can be found on smaller phrase pairs, with little or no loss in translation accuracy.", "label": 0}
{"sent1": "In order to measure the effectiveness of the clarification strategies, we compute concept precisions for two different mentions of the concept in the dialog: first mentions and final values after clarifications and similar strategies, and compare this to a rulebased system on the same task.", "sent2": "We investigate the relationship between dialog length and task completion.", "label": 1}
{"sent1": "We train a dialog simulator that combines traits of human behavior such as cooperativeness and context with domain-related aspects via the Expectation-Maximization algorithm.", "sent2": "component of user simulation includes a User Model representing userspecific features.", "label": 1}
{"sent1": "We report a novel experiment where similar technology is applied to the important, challenging domain of biomedicine.", "sent2": "We define a measure for the observable amount of paradigmatic modifiability of terms and, subsequently, test it on bigram, trigram and quadgram noun phrases extracted from a 104-million-word biomedical text corpus.", "label": 0}
{"sent1": "This shared task has witnessed enthusiastic participation of 31 teams from all over the world, with diversity of participation for a given system and wide coverage for a given language pair (more than a dozen participants per language pair).", "sent2": "Diverse transliteration methodologies are represented adequately in the shared task for a given language pair, thus underscoring the fact that the workshop may truly indicate the state of the art in machine transliteration in these language pairs.", "label": 1}
{"sent1": "NEs are to be recognized from the text and transliterated accordingly into the target language in order to ensure the quality of MT.", "sent2": "Such NEs are crucial in deciding the quality of MT.", "label": 1}
{"sent1": "A contribution of this work is that the models and classifiers are learned in a completely unsupervised manner.", "sent2": "Using our system we were able to get quite accurate transliteration models.", "label": 1}
{"sent1": "We next present a principled approach to visualization which highlights the similarities and differences between two sets of documents ?", "sent2": "Our experiments confirm that in movies that fail the test, women are in fact portrayed as less-central and less-important characters.", "label": 0}
{"sent1": "We only participated in the standard run, which is a direct orthographical mapping (DOP) between two languages without using any intermediate phonemic mapping.", "sent2": "We propose a new two-step conditional random field (CRF) model for DOP machine transliteration, in which the first CRF segments a source word into chunks and the second CRF maps the chunks to a word in the target language.", "label": 1}
{"sent1": "We discuss and analyze results from the Senseval-3 English, Chinese, and Multilingual Lexical Sample data sets.", "sent2": "The HKUST word sense disambiguation systems benefit from a new nonlinear Kernel Principal Component Analysis (KPCA) based disambiguation technique.", "label": 1}
{"sent1": "The system is based on a multicomponent architecture.", "sent2": "It consists of one classifier with two components.", "label": 1}
{"sent1": "We show that the first heuristic obtains a precision and recall of .58 and .35 respectively in the all words task while the second obtains .80 and .25.", "sent2": "This patterns are matched against the disambiguation contexts.", "label": 1}
{"sent1": "?ve Bayes on word tokens and Maximum Entropy on local syntactic and semantic features.", "sent2": "We hypothesize that since word co-occurrences are governed by syntactic properties of a language, the network has much constrained topology than that predicted by the previously proposed growth model.", "label": 0}
{"sent1": "For the translation and sense subtask of the multilingual lexical sample task, the English sense given for the target word was also used as an additional knowledge source.", "sent2": "The knowledge sources used were partof-speech of neighboring words, single words in the surrounding context, local collocations, and syntactic relations.", "label": 1}
{"sent1": "We evaluate on both the SENSEVAL-2 and SENSEVAL-3 English allwords data.", "sent2": "We also release a new dataset of human-authored rewrites of math word problems in several themes.", "label": 0}
{"sent1": "The user can issue translation requests from Arabic, Chinese or Spanish into English.", "sent2": "This paper describes a multi-lingual phrase-based Statistical Machine Translation system accessible by means of a Web page.", "label": 1}
{"sent1": "(ISU) dialogue system to exhibit reinforcement learning of dialogue strategies, and also has a fragmentary clarification feature.", "sent2": "In this paper, we address this issue by incorporating user- and product- level information into a neural network approach for document level sentiment classification.", "label": 0}
{"sent1": "LEM is fully unsupervised and does not require annotated data for training.", "sent2": "In this paper we propose a simple and yet effective Bayesian model, called Latent Event Model (LEM), to extract structured representation of events from social media.", "label": 1}
{"sent1": "(Zhou Yongkang)?", "sent2": "The system combination weights were tuned using a graph based expected BLEU as the objective function while incrementally expanding the networks to bi-gram and 5-gram contexts.", "label": 0}
{"sent1": "We implement this approach for Old Spanish.", "sent2": "Existing approaches consider only a small subset of the possible combinations, due to statistical and computational efficiency considerations.", "label": 0}
{"sent1": "Hana et al, 2004; Feldman and Hana, 2010).", "sent2": "We use a traditional supervised tagger.", "label": 1}
{"sent1": "POS-tagger for modern German on historical data from the Early Modern period (1650-1800).", "sent2": "The paper gives an overview of CTS for those that are unfamiliar and establishes its place in the Digital Humanities research.", "label": 0}
{"sent1": "In essence eResearch is all about cyberstructure and being connected in ways that might change how we perceive scientific creation.", "sent2": "The present work advocates open access to scientific data for linguists and language experts working within the Humanities.", "label": 1}
{"sent1": "Digital metadata descriptions play an important role in this endeavour.", "sent2": "Cultural heritage institutions are making their digital content available and searchable online.", "label": 1}
{"sent1": "They are regarded as linguistically na?", "sent2": "?ve, but estimating them from any amount of text, large or small, is straightforward.", "label": 1}
{"sent1": "In this paper, we present an approach which is capable of jointly learning a policy for following natural language commands such as ?Pick up the tire pallet,?", "sent2": "as well as a mapping between specific phrases in the language and aspects of the external world; for example the mapping between the words ?the tire pallet?", "label": 1}
{"sent1": "Predicting possible responses automatically by mining a corpus of dialogues is a novel contribution to the literature on whole utterance-based methods in AAC.", "sent2": "Finally we compare our approach to a state-of-the-art chatbot, and show (not surprisingly) that a system like ours, tuned for a particular style of conversation, outperforms one that is not.", "label": 1}
{"sent1": "We apply wellknown regression techniques to a large corpus of freely available financial reports, constructing regression models of volatility for the period following a report.", "sent2": "Experimental results demonstrate that our algorithm leads to an absolute improvement of 25% over standard transliteration approaches.", "label": 0}
{"sent1": "Our taxonomy has been prepared by analysing a corpus of tutorial dialogues on mathematical theorem proving.", "sent2": "We also detail an annotation experiment in which we apply the taxonomy and discuss idiosyncrasies in the data which influence the decisions in the dialogue move classification.", "label": 1}
{"sent1": "The unlabeled data is parsed by a dependency parser trained on labeled source domain data.", "sent2": "We extract constraints on preferences and dependencies among them, even when they are expressed indirectly, by exploiting discourse structure.", "label": 0}
{"sent1": "NER classifiers usually lose accuracy in the domain transfer due to the different data distribution between the source and the target domains.", "sent2": "The detection of OOV regions in the output of a LVCSR system is typically addressed as a binary classification task, where each region is independently classified using local information.", "label": 0}
{"sent1": "Based on time and money extraction, we identify sentences that represent statements on revenue using support vector classification.", "sent2": "We present an efficient information extraction chain to automate this complex natural language processing task and show results for the identification part.", "label": 1}
{"sent1": "This paper investigates how costly such redundancy is for a lexicalised grammar such as CCG.", "sent2": "We also show that better accuracy is achieved by using both methods than by using only the first.", "label": 0}
{"sent1": "Semantic Fields are determined by a set  of highly semantically associated terms  with high tag co-occurrences in the image corpus and in different corpora and  lexica such as WordNet and Wikipedia.", "sent2": "and a variety of error models and algorithms, including proposed improvements of our own.", "label": 0}
{"sent1": "We show that this resource, when used in conjunction with constraints, can efficiently identify transliteration pairs.", "sent2": "We compare these to the usual verb?argument paraphrase test using corpus statistics, and frequencies obtained by scraping the Google search engine interface.", "label": 0}
{"sent1": "In this paper, we argue that the fault lies with using generic finite-state libraries, and not with the formalisms themselves.", "sent2": "We present an open-source implementation that capitalises on the characteristics of CG rule application to improve execution time.", "label": 1}
{"sent1": "We propose a gradient based optimization algorithm to efficiently learn the model parameters.", "sent2": "In our approach, we first train hidden Markov models (HMMs) of dialogue-act sequences associated with each overall rating.", "label": 0}
{"sent1": "?s model; (2) We compare a model encoded using only shallow RST-style discourse relations, against the one encoded using the complete set of RST-style discourse relations.", "sent2": "Our approach achieves up to 93% precision and 71% recall.", "label": 0}
{"sent1": "We report results on a large Arabic-English system and a medium-sized Urdu-English system.", "sent2": "Our proposed approach significantly improves the performance of competitive phrasebased systems, leading to consistent improvements between 1 and 4 BLEU points on standard evaluation sets.", "label": 1}
{"sent1": "For current MT quality estimation (QE) systems, additional complexity comes from the difficulty to model user and domain changes.", "sent2": "We handle this task as both a regression and a classification modeling problem and explore several combinations of syntactic and semantic features.", "label": 0}
{"sent1": "We evaluate our model on its ability to simulate similarity judgments and concept categorization.", "sent2": "On both tasks, our approach outperforms baselines and related models.", "label": 1}
{"sent1": "Experimental results show that these modifications improve parsing performance significantly.", "sent2": "It is a preliminary implementation.", "label": 0}
{"sent1": "We utilized SubcatLMF to standardize lexicons with largescale SCF information: the English VerbNet and two German lexicons, i.e., a subset of IMSlex and GermaNet verbs.", "sent2": "This work is part of an ongoing project for an information extraction system in the field of maritime Search And Rescue (SAR).", "label": 0}
{"sent1": "We found that both text type and topic domain play a role in text prediction quality.", "sent2": "The best performing training corpus was a set of medical pages from Wikipedia.", "label": 1}
{"sent1": "In particular, we analyze spelling errors in the assignee field of patents granted by the United States Patent & Trademark Office.", "sent2": "While recent research engages in specialized models and algorithms to improve the effectiveness of patent retrieval, we bring another aspect into focus: the detection and exploitation of patent inconsistencies.", "label": 1}
{"sent1": "Our LMF model captures lexical information at a fine-grained level by employing a large number of Data Categories from ISOCat and is designed to be directly extensible by new languages and resources.", "sent2": "This approach yields improvements on intrinsic word similarity evaluations, and also in the downstream task of part-of-speech tagging.", "label": 0}
{"sent1": "We evaluate the performance of our algorithm on multiple semantic relations expressed using ?verb?, ?noun?, and ?verb prep?", "sent2": "We propose a minimally supervised bootstrapping algorithm that uses a single seed and a recursive lexico-syntactic pattern to learn the arguments and the supertypes of a diverse set of semantic relations from the Web.", "label": 1}
{"sent1": "trees that can be decomposed into at most two planar graphs ?", "sent2": "We present a model based on Bayesian surprise which provides an intuitive way to identify surprising information from a summarization input with respect to a background corpus.", "label": 0}
{"sent1": "We also report preliminary experiments using an ?on-the-fly?", "sent2": "Experimental results show a significant and consistent BLEU improvement of approximately 1 point for all conditions.", "label": 1}
{"sent1": "This allows non-joinable elements to share bits, resulting in a smaller vector size.", "sent2": "In a simulation, we show that focusing on challenging responses can achieve a larger scoring performance improvement than simply applying human scoring on the same number of randomly selected responses.", "label": 0}
{"sent1": "Many supervised WSD systems have been built, but the effort of creating the training corpus - annotated sense marked corpora - has always been a matter of concern.", "sent2": "Our approach incorporates general domain knowledge which we encode as First Order Logic rules and automatically combine with a topic model developed specifically for the relation extraction task.", "label": 0}
{"sent1": "The monolingual system is based on a modification of the graph based state of the art algorithm In-Degree.", "sent2": "In this paper we present a system that combines evidence from a monolingual WSD system together with that from a multilingual WSD system to yield state of the art performance on standard All-Words data sets.", "label": 1}
{"sent1": "Both approaches rely on the existence of a handcrafted generator, which limits their scalability to new domains.", "sent2": "Most previous work on trainable language generation has focused on two paradigms: (a) using a statistical model to rank a set of generated utterances, or (b) using statistics to inform the generation decision process.", "label": 1}
{"sent1": "A key feature in our approach is the reliance on a story planner which we acquire automatically by recording events, their participants, and their precedence relationships in a training corpus.", "sent2": "Contrary to previous work our system does not follow a generate-and-rank architecture.", "label": 1}
{"sent1": "We show that implicit arguments are pervasive for these predicates, adding 65% to the coverage of NomBank.", "sent2": "We describe our preliminary work evaluating the feasibility of using crowdsourcing to generate simplifications for these documents.", "label": 0}
{"sent1": "We call this a paraphrase lattice.", "sent2": "Then, we give the paraphrase lattice as an input to the lattice decoder.", "label": 1}
{"sent1": "This paper presents a joint model to predict the selection of hierarchical rules.", "sent2": "Previous work mainly focused on the selection of either the source side of a hierarchical rule or the target side of a hierarchical rule rather than considering both of them simultaneously.", "label": 1}
{"sent1": "We propose to use a structure named reordering graph, which represents all phrase segmentations of a sentence pair, to learn lexicalized reordering models efficiently.", "sent2": "Additionally, we argue that this can be performed using schemata, as represented by word-pair co-occurrences, and demonstrate its use in statistical summary sentence generation.", "label": 0}
{"sent1": "Our approach is especially useful for queries that contain multiple types of concepts.", "sent2": "This paper describes the HULTECH team participation in Task 3 of SemEval-2014.", "label": 0}
{"sent1": "However, such approaches have severely suffered from the errors in Chinese phoneme-to-grapheme conversion.", "sent2": "0.41) BLEU points across 7 language pairs.", "label": 0}
{"sent1": "This typically involves heuristic search procedures and calibrating multiple arbitrary thresholds.", "sent2": "We present a simple approach that uses no thresholds other than those involved in standard application of ?2 significance testing.", "label": 1}
{"sent1": "We experiment with two non-parametric priors, the Dirichlet and Pitman-Yor processes, on the Wall Street Journal dataset using a parallelized implementation of an iHMM inference algorithm.", "sent2": "We evaluate the results with a variety of clustering evaluation metrics and achieve equivalent or better performances than previously reported.", "label": 1}
{"sent1": "This paper describes a novel approach for automatically detecting and down-weighing certain parts of the training corpus by assigning a weight to each sentence in the training bitext so as to optimize a discriminative objective function on a designated tuning set.", "sent2": "This way, the proposed method can limit the negative effects of low quality training data, and can adapt the translation model to the domain of interest.", "label": 1}
{"sent1": "Moreover, morphologically rich languages such as Korean present an even bigger challenge, since optimal token boundaries for machine translation in these languages are often unclear.", "sent2": "AutoExtend achieves state-of-the-art performance on word similarity and word sense disambiguation tasks.", "label": 0}
{"sent1": "We present a novel randomised language model which uses an online perfect hash function to efficiently deal with unbounded text streams.", "sent2": "However, being batch-based they are unsuitable for modelling an unbounded stream of language whilst maintaining a constant error rate.", "label": 1}
{"sent1": "This allows the method to access valuable information encoded in a lexical resource, such as a thesaurus, while still being able to effectively handle domainspecific terms and named entities.", "sent2": "Although it uses a knowledge source, the method is not vocabularylimited: if the target word is not in the thesaurus, the method falls back gracefully on the word?s co-occurrence information.", "label": 1}
{"sent1": "Despite its simplicity, the quality of such cosine similarity measure is usually domain dependent and decided by the choice of the termweighting function.", "sent2": "People rarely articulate explicitly what a native speaker of a language is already assumed to know.", "label": 0}
{"sent1": "Accurate measurement of semantic similarity between words is essential for various tasks such as, document clustering, information retrieval, and synonym extraction.", "sent2": "Our system outperforms existing pattern scoring algorithms for extracting drug-andtreatment entities from four medical forums.", "label": 0}
{"sent1": "We run a series of off-theshelf parsers on the corpus to evaluate how well state-of-the-art parsing technology is able to recover such dependencies.", "sent2": "This is the first time that self-training with small labeled datasets is applied successfully to these tasks.", "label": 0}
{"sent1": "In this paper we present a metastudy comparing various semantic measures and their correlation with human judgments.", "sent2": "We focus our attention on the task of ranking textual inferences and show substantially improved results on a recently investigated question answering data set.", "label": 0}
{"sent1": "The system has been evaluated on a wide variety of texts from closed domains, producing full and accurate parsing, semantics and anaphora resolution for all sentences.", "sent2": "Using the Mechanical Turk we created a gold standard sample in which each sentence was tagged by 3 annotators, obtaining F-scores of 0.78 on the product reviews dataset and 0.83 on the Twitter dataset.", "label": 0}
{"sent1": "We introduce the notion of instructional compound, which is a complex structure that articulates instructions with various discourse elements.", "sent2": "The improvement of the translation results is demonstrated on a German-English corpus.", "label": 0}
{"sent1": "However, the local context of an ambiguous word can give important clues to which of its senses was intended.", "sent2": "Due to the big skew in the sense distribution of many words (Yarowsky and Florian, 2002), the First Sense heuristic for WSD is often hard to beat.", "label": 1}
{"sent1": "In this paper we describe a method of automatically deriving fine-grained, domain-specific semantic classes of arguments while simultaneously clustering verbs into semantically meaningful groups: the first step in verb sense induction.", "sent2": "Verbs are clustered into groups that share semantic elements of meaning as they exhibit similar syntactic behavior.", "label": 0}
{"sent1": "In order to respond appropriately to simple-seeming questions such as ?Is going for a walk good for me?", "sent2": "We have focused our work mainly around the filtering of false positives, creating a high-precision extraction method.", "label": 0}
{"sent1": "In this paper, we refine the semantics of concession substantially and offer a formal description of concessive relations and the associated inferences drawn by the reader, utilizing basic notions from Hobbs?s logic, including the distinction between causes and causal complexes (Hobbs, 2005).", "sent2": "The PDTB 2.0 manual describes the hierarchical set of senses used in the annotation and offers rough semantic descriptions of each label.", "label": 1}
{"sent1": "Focusing here on causal coherence relations, we propose a lexical resource that holds both lexicographic and corpusstatistic information on German connectives.", "sent2": "The primary source of information for this step is the connectives provided by a language for, more or less explicitly, signaling the relations.", "label": 1}
{"sent1": "Currently, we present a topic-sensitive version of our method and hypothesize that it can outperform a competitive baseline, which compares the similarity of each sentence to the input question via IDF-weighted word overlap.", "sent2": "In our experiments, the method achieves a TRDR score that is significantly higher than that of the baseline.", "label": 1}
{"sent1": "In this paper we present a system to search directly the audio recordings by key phrases.", "sent2": "We evaluate a wizard-of-oz spoken dialogue system that adapts to multiple user affective states in real-time: user disengagement and uncertainty.", "label": 0}
{"sent1": "In order to tackle this specific condition, we introduce two refinements to a well-known query expansion technique.", "sent2": "In this paper we propose a query expansion technique which performs well even if a user notifies just a relevant document and a non-relevant document.", "label": 1}
{"sent1": "We present a new model of text segmentation based on ideas from multilabel classification.", "sent2": "We find varying choices for the optimum classifier, feature set and training strategy depending on the task and dataset.", "label": 0}
{"sent1": "Since discrete spoken commands are ill-suited to such tasks, our interface exploits a large set of continuous acousticphonetic parameters like pitch, loudness, vowel quality, etc.", "sent2": "We present a novel voice-based humancomputer interface designed to enable individuals with motor impairments to use vocal parameters for continuous control tasks.", "label": 1}
{"sent1": "In spoken dialogue interfaces, users often make utterances before the query is completely generated in their mind; thus input queries are often vague or fragmental.", "sent2": "This paper addresses a dialogue strategy to clarify and constrain the queries for speech-driven document retrieval systems.", "label": 1}
{"sent1": "We propose a novel binarization method utilizing rich information learnt from training corpus.", "sent2": "Experimental results not only show that different binarizations have great impacts on parsing efficiency, but also confirm that our learnt binarization outperforms other existing methods.", "label": 1}
{"sent1": "To induce word features, we make use of contextual, morphologic and orthographic properties of the words.", "sent2": "This study proposes a new dependency DAG parsing approach which uses a dynamic oracle within a shift-reduce transitionbased parsing framework.", "label": 0}
{"sent1": "Earlier Rule based approaches are employed to detect Empty heads for Hindi language but statistical learning for automatic prediction is not explored.", "sent2": "In this approach we used a technique of introducing complex labels into the data to predict Empty categories in sentences.", "label": 1}
{"sent1": "To evaluate the consistency between two argument structures, we also formulate a log-linear model to compute the probability of aligning two arguments.", "sent2": "Our model prefers the bilingual SRL result that is not only reasonable on each side of bitext, but also has more consistent argument structures between two sides.", "label": 1}
{"sent1": "An extended definition of MANNER is proposed, including restrictions on the sorts of concepts that can be part of its domain and range.", "sent2": "We present experimental results demonstrating that SCISSOR produces more accurate semantic representations than several previous approaches.", "label": 0}
{"sent1": "Using English grammar textbooks, we compiled a syntactic sense dictionary comprising common tense syntactic forms and semantic senses for each.", "sent2": "We annotated thousands of BNC sentences using the defined senses.", "label": 1}
{"sent1": "Using integer linear programming we compress this graph to a new tree, which we then linearize.", "sent2": "Given a group of related sentences, we align their dependency trees and build a dependency graph.", "label": 1}
{"sent1": "For our English-language system, at various miss rates we eliminate 97% of false alarms on inputs from other Latin-alphabet languages.", "sent2": "The diverse nature of input noise leads us to pursue a multi-faceted approach to robustness.", "label": 1}
{"sent1": "NEG-FINDER exploits unsupervised term clustering to generate multiple negative categories during bootstrapping.", "sent2": "Our algorithm effectively removes the necessity of manual intervention and formulation of negative categories, with performance closely approaching that obtained using negative categories defined by a domain expert.", "label": 1}
{"sent1": "Motivated by the fact that both documents and words can be represented by a mixture of semantic topics, we propose to decompose traditional random walk into multiple random walks specific to various topics.", "sent2": "Existing graph-based ranking methods for keyphrase extraction compute a single importance score for each word via a single random walk.", "label": 1}
{"sent1": "Both of these elements are learned jointly using the EM algorithm.", "sent2": "We propose a multiple-document summarization system with user interaction.", "label": 0}
{"sent1": "By pointing out where these methods fail and what any desired model should consider, we propose two novel extensions of the models that not only use lexical information but also exploit finer level conversation structure in a principled way.", "sent2": "We show how the existing topic segmentation models (i.e., Lexical Chain Segmenter (LCSeg) and Latent Dirichlet Allocation (LDA)) which are solely based on lexical information, can be applied to emails.", "label": 1}
{"sent1": "Our experimental results on the RST Discourse Treebank corpus and Penn Discourse Treebank indicate that the proposed method brings a significant improvement in classification accuracy and macro-average F-score when small training datasets are used.", "sent2": "DT-RNNs outperform other recursive and recurrent neural networks, kernelized CCA and a bag-of-words baseline on the tasks of finding an image that fits a sentence description and vice versa.", "label": 0}
{"sent1": "In general, when translating a given sentence, one or more conditions should be satisfied to maintain a high translation quality.", "sent2": "In EnglishJapanese translation, for example, prepositions and infinitives must be appropriately translated.", "label": 1}
{"sent1": "The present work addresses three limitations of previous work.", "sent2": "These context features serve as important indicators of language changes that are otherwise difficult to capture using text data by itself.", "label": 0}
{"sent1": "We argue redundant information in a SMT system may not only delay the computations but also affect the quality of the outputs.", "sent2": "This paper proposes an approach to reduce the model size by filtering out the less probable entries based on compatible data in an intermediate language, a novel use of triangulation, without sacrificing the translation quality.", "label": 1}
{"sent1": "entails ?We doubt the epidemic spread quickly via fleas?.", "sent2": "Here, we present the first algorithm for the challenging lexical-semantics problem of learning linguistic constructions that, like ?doubt?, are downward entailing (DE).", "label": 1}
{"sent1": "We then develop a system that takes implicit argumentation into account, improving overall performance by nearly 5%.", "sent2": "Our results indicate that the degree of implicit argumentation varies widely across nominals, making automated detection of implicit argumentation an important step for nominal SRL.", "label": 1}
{"sent1": "We consider two methods for hypothesizing these degradations, the best of which is constructed using factored phrasebased statistical machine translation.", "sent2": "We show that this approach is able to significantly improve upon a state-of-the-art baseline technique in an evaluation on held-out speech.", "label": 1}
{"sent1": "We present a light-weight rule-based approach to producing Modern Standard Arabic (MSA) paraphrases of dialectal Arabic out-of-vocabulary (OOV) words and low frequency words.", "sent2": "This paper is about improving the quality of Arabic-English statistical machine translation (SMT) on dialectal Arabic text using morphological knowledge.", "label": 1}
{"sent1": "Here we automatically construct a corpus of Hiberno-English (English as spoken in Ireland) using a variety of methods: filtering by national domain, filtering by orthographic conventions, and bootstrapping from a set of Irelandspecific terms (slang, place names, organisations).", "sent2": "We evaluate the national specificity of the resulting corpora by measuring the incidence of topical terms, and several grammatical constructions that are particular to Hiberno-English.", "label": 1}
{"sent1": "These rules are sensitive to the dialect area, so that the dialects of more than 300 towns are covered.", "sent2": "In this paper, we apply the concept of pretraining to hidden-unit conditional random fields (HUCRFs) to enable learning on unlabeled data.", "label": 0}
{"sent1": "The candidate compressions are annotated with human judgements for grammaticality and meaning preservation.", "sent2": "We present a new dataset that contains candidate extractive and abstractive compressions of source sentences.", "label": 1}
{"sent1": "While this scenario of use is one of the strongest contenders for real-world applications of referring expression generation, existing data sets still only embody very simple stimulus scenes.", "sent2": "Careful quality control is necessary for crowdsourcing to work well.", "label": 0}
{"sent1": "We build a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%).", "sent2": "However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research.", "label": 1}
{"sent1": "It drastically shortens the complete development cycle, and offers a new design experience.", "sent2": "Orange Dialogue Design Studio (ODDS), our design tool, allows developers to design several alternatives and compare their relative performances.", "label": 1}
{"sent1": "This model provides a polysemy index for each noun which (a), accurately distinguishes between polysemy and homonymy; (b), supports the analysis that polysemy can be grounded in the frequency of the meaning shifts shown by nouns; and (c), improves a regression model that predicts when the ?one-sense-per-discourse?", "sent2": "We present a first step towards such a model, based on WordNet augmented with ontological classes provided by CoreLex.", "label": 1}
{"sent1": "by reflexive matching.", "sent2": "Twenty semantic classes are evaluated against the corresponding full ontologies, i.e.", "label": 1}
{"sent1": "The resulting joint nonterminals often lead to needlessly large label sets that are not optimized for an MT scenario.", "sent2": "This paper presents a method of iteratively coarsening a label set for a particular language pair and training corpus.", "label": 1}
{"sent1": "In this paper, we investigate how different types of perceived helpfulness might influence the utility of features for automatic prediction.", "sent2": "The CCG parser obtains an F-score of 81.9% on labelled dependencies, against an upper bound of 84.8%.", "label": 0}
{"sent1": "The resulting DLFs are fed into the OpenCCG realizer for n-best realization, using a pruning strategy that encourages lexical diversity.", "sent2": "We demonstrate the applicability of tiered clustering, highlighting particular cases where modeling shared structure is beneficial and where it can be detrimental.", "label": 0}
{"sent1": "In this paper, we present the implementation and evaluation of a signaturebased machine-learning technique to predict events from full texts of infectious disease documents.", "sent2": "Building on technical advances from the BioNLP 2009 Shared Task Challenge, the 2011 challenge sets forth to generalize techniques to other complex biological event extraction tasks.", "label": 1}
{"sent1": "This paper tackles the problem of stability in ISR.", "sent2": "The wide availability of parallel text and accurate parsers in English has opened up the possibility of grammar induction through partial transfer across bitext.", "label": 0}
{"sent1": "In order to account for non-local binding phenomena, as in raising and ECM cases, we employ flexible composition, constrained by a subject intervention constraint between the two components of the anaphor?s lexical entry.", "sent2": "The analysis also allows a parallel treatment of reflexives and reciprocals, which is desirable because their behavior is very similar.", "label": 1}
{"sent1": "The proposed analysis provides features that signal the presence of a negation in the semantics and that specify its scope.", "sent2": "is language identification (language ID) of written text.", "label": 0}
{"sent1": "We will exemplify the differences and similarities by looking at several phenomena.", "sent2": "There are striking similarities between the frameworks that make them comparable in many respects.", "label": 1}
{"sent1": "Extrinsic evaluation on a document clustering task reveals a significant improvement when using seed information, even over other models that use seed information na?", "sent2": "We evaluate the method using a query log from Baidu1, a Chinese search engine.", "label": 0}
{"sent1": "We extracted various features from the LTAG derivation trees and trained a discriminative decision list model to predict semantic roles.", "sent2": "Sentence compression has attracted much interest in recent years, but most sentence compressors are extractive, i.e., they only delete words.", "label": 0}
{"sent1": "We present a method for learning models of verb argument patterns directly from unannotated text.", "sent2": "Determining the semantic roles of a verb?s dependents is an important step in natural language understanding.", "label": 1}
{"sent1": "RSCM can be applied to non-SMT systems but does not always work well on them.", "sent2": "We overcome this through a ?mostly-automated?", "label": 0}
{"sent1": "Then, we show that clustering these sequences can effectively disentangle the threads of conversation.", "sent2": "All three strategies were implemented for our English?German system submitted to the WMT10 shared task.", "label": 0}
{"sent1": "The supervised learning system is based on lexical features and bagged decision trees.", "sent2": "Two systems from the University of Minnesota, Duluth participated in various SENSEVAL-3 lexical sample tasks.", "label": 1}
{"sent1": "The results show that the system does best when stemming is used and glosses are expanded.", "sent2": "However, it appears that the evidence for word-senses ,accumulated through WordNet, in the form of glosses, are quite sparse.", "label": 1}
{"sent1": "For the open test we only used the utf-8 code knowledge for discrimination among Latin characters, Arabic numbers and all other characters.", "sent2": "We participated the close and open tests for all the four corpora.", "label": 1}
{"sent1": "Head words are represented as feature vectors with several hundred features.", "sent2": "In this work, we train a classifier that is able to predict which encipherment method has been used to generate a given ciphertext.", "label": 0}
{"sent1": ".", "sent2": "Unlike the previous state-of-the-art approach that uses additional word lists to evaluate possible decipherments, our approach only uses a letterbased 6-gram language model.", "label": 0}
{"sent1": "(TSR trees).", "sent2": "Users were able to make quicker and more informed decisions when presented with the summary as compared to the full album review.", "label": 0}
{"sent1": "We compare representatives of two principal approaches to computing phonetic similarity: manually-designed metrics, and learning algorithms.", "sent2": "This baseline model has been improved and expanded for this year?s competition in several respects.", "label": 0}
{"sent1": "although we cannot identify which form of context (bigram, trigram, etc.)", "sent2": "We likewise find evidence for the superiority of measures which incorporate a sensitivity to phonological context, realized in the form of n-grams?", "label": 1}
{"sent1": "If we can represent the models as distributions, then the similarity is basically the similarity of distributions.", "sent2": "To determine how close two language models (e.g., n-grams models) are, we can use several distance measures.", "label": 1}
{"sent1": "Such a parser would employ a partial analysis of the input sentence to select a (nearly) complete syntax tree and then adapt this tree to the input sentence.", "sent2": "These experimental results also reveal a tendency toward metaphor usage in personal topics and certain emotional contexts.", "label": 0}
{"sent1": "Unlike the more traditional string-based measures, this measure tries to reflect ?deeper?", "sent2": "This paper outlines a measure of language similarity based on structural similarity of surface syntactic dependency trees.", "label": 1}
{"sent1": "Our scores were very close to the highest level.", "sent2": "We further extend the parametric model to non-parametric model which not only simplifies the problem of model selection but also brings improved performance.", "label": 0}
{"sent1": "We have shown that even simple features like point-wise mutual information are useful for word-alignment task in English-Hindi parallel corpora.", "sent2": "Experiments on a Chinese corpus are conducted to compare our algorithm with the standard HMM-based POS tagging and the POS tagging software ICTCLAS3.0.", "label": 0}
{"sent1": "In this paper we propose to semi-automatically detect MWE candidates in texts using some error mining techniques and validating them using a combination of the World Wide Web as a corpus and some statistical measures.", "sent2": "Syriac is an under-resourced Semitic language for which there are no available language tools such as morphological analyzers.", "label": 0}
{"sent1": "the confidence interval.", "sent2": "We construct a new QA dataset with over 5,000 logical form-question pairs, associated with answers from the knowledge base, and show that datasets constructed in this way enable finegrained analyses of QA systems.", "label": 0}
{"sent1": "Our findings are compared to the theoretical models and based on this we deduce which models best describe learning and forgetting in our automotive environment.", "sent2": "The resulting models are used to develop an adaptive help system for a speech dialogue system.", "label": 1}
{"sent1": "Conventional Hiero-style SCFG rules will also be extracted in the same framework.", "sent2": "We use directed graphical models (DGMs) to automatically detect decision discussions in multi-party dialogue.", "label": 0}
{"sent1": "However, we show that the nature of these resources is significantly different from the ?free-text?", "sent2": "First, each topic summary should not contain any redundancy (we refer to this problem as redundancy within a summary).", "label": 0}
{"sent1": "Our models abstract contents of individual posts of threads using latent categories, learned jointly with the binary intervention prediction problem.", "sent2": "English) into a form more closely resembling the source language, and then by using standard alignment methods to align the transformed bitext.", "label": 0}
{"sent1": "After training, our system can be used to find definitions of terms that are not covered by encyclopedias.", "sent2": "The system outperforms a comparable publicly available system, as well as a previously published form of our system.", "label": 1}
{"sent1": "However, citances might not accurately represent the content of the cited article, as they often fail to capture the context of the reported findings and can be affected by epistemic value drift.", "sent2": "To this end, we propose a rankbased approach that utilizes listwise learning to rank algorithms for learning a rating model, where the agreement between the human and machine raters is directly incorporated into the loss function.", "label": 0}
{"sent1": "We instead aim to generate socially-informed timelines that contain both news article summaries and selected user comments.", "sent2": "Existing timeline generation systems for complex events consider only information from traditional media, ignoring the rich social context provided by user-generated content that reveals representative public interests or insightful opinions.", "label": 1}
{"sent1": "We introduce Conditional Random Fields (CRFs) to pitch accent prediction task in order to incorporate these factors efficiently in a sequence model.", "sent2": "In this paper we investigate probabilistic, contextual, and phonological factors that influence pitch accent placement in natural, conversational speech in a sequence labeling setting.", "label": 1}
{"sent1": "The objective can be optimized using the Expectation-Maximization algorithm while maintaining the discriminative nature of CRFs.", "sent2": "On the revised annotations, the F1 score increases to 0.2505.", "label": 0}
{"sent1": "Topic signatures can be useful in a number of Natural Language Processing (NLP) applications, such as Word Sense Disambiguation (WSD) and Text Summarisation.", "sent2": "Given a particular concept, or word sense, a topic signature is a set of words that tend to co-occur with it.", "label": 1}
{"sent1": "Boosting, the method in question, combines the moderately accurate hypotheses of several classifiers to form a highly accurate one.", "sent2": "Further improvements were obtained when a small annotated Korean corpus was combined with the Japanese training corpus, confirming that efficient crosslingual transfer learning can be achieved without expensive linguistic resources.", "label": 0}
{"sent1": "The new information incorporated in the model is acquired through the use of a wide-coverage parser.", "sent2": "The trigram HMM can be extended with global contextual information, without making the model infeasible, by incorporating the context separately from the POS tags.", "label": 1}
{"sent1": "The study focusses on a set of transcribed pages from 1530-1531 originally hand written in a mixture of Latin and Middle Scots.", "sent2": "We apply a text analytic tool to the corpus, providing deep semantic annotation and making the text amenable to linking to web-resources.", "label": 1}
{"sent1": "Based on all the information gathered we have devised an automatic syllabification algorithm which has a 99% accuracy on the words in the dictionary.", "sent2": "Furthermore, we have approached the syllabic complexities, the sonority patterns present in the syllable?s constituents and the degree in which the Sonority Sequencing Principle (SSP) holds for this language.", "label": 1}
{"sent1": "These new tags generated in this step are semantic-related, which can provide a good start for splitting.", "sent2": "Secondly, a knowledge-based criterion is used to supervise the hierarchical splitting of these semantic-related tags, which can alleviate overfitting.", "label": 1}
{"sent1": "Current state-of-theart approaches usually require annotated data and relevant linguistic knowledge which may not be available for all languages.", "sent2": "This paper introduces a new method for identifying named-entity (NE) transliterations within bilingual corpora.", "label": 1}
{"sent1": "We show that the AL technique which performs best depends on how cost is measured.", "sent2": "A key concern in building syntax-based machine translation systems is how to improve coverage by incorporating more traditional phrase-based SMT phrase pairs that do not correspond to syntactic constituents.", "label": 0}
{"sent1": "Our experimental evaluation over thousands of real questions indicates that indeed it is beneficial to personalize satisfaction predictions when sufficient prior user history exists, significantly improving accuracy over a ?one-size-fits-all?", "sent2": "prediction model.", "label": 1}
{"sent1": "This achieves an f -score of 84.3% on a standard test set of biomedical abstracts from the Genia corpus.", "sent2": "By adding some limited closed-world knowledge for confidence estimation of learned rules to the usual seed data, the precision of relation extraction can be considerably improved.", "label": 0}
{"sent1": "semantic properties is a less-explored area with greater challenges.", "sent2": "Also related to lower translation quality is the need to employ multiple explicit discourse connectives (because, but, etc.", "label": 0}
{"sent1": "We create two bilingual pronunciation dictionaries for the language pairs German-Dutch and GermanEnglish.", "sent2": "For these tasks, it is useful to know which connectives can signal the same coherence relations.", "label": 0}
{"sent1": "These have mostly been tried on European language pairs.", "sent2": "We have compared four approaches using this method.", "label": 1}
{"sent1": "Several phrase-based translation models are built out from these alignments.", "sent2": "In experiments, our proposed model obtained significant improvements compare to baseline models that use Support Vector Machines.", "label": 0}
{"sent1": "We present results with the EuroParl task in the direction Spanish to English and results from the evaluation of the shared task ?Exploiting Parallel Texts for Statistical Machine Translation?", "sent2": "(ACL Workshop on Parallel Texts 2005).", "label": 1}
{"sent1": "Appearances of concepts are considered as genes, each one encoding the type of reference used.", "sent2": "Three genetic operators are used: classic crossover and mutation, plus a specific operator dealing with aggregation.", "label": 1}
{"sent1": "We propose an approximated joint decoding method by reranking the N-best segmenter output, based POS tagging information.", "sent2": "We perform extensive experiments including hypothesis test and real task evaluation.", "label": 0}
{"sent1": "Yet in practice, all implemented constraint-oriented parsing strategies still need to discriminate between ?important?", "sent2": "In some societies, internet users have to create information morphs (e.g.", "label": 0}
{"sent1": "We automatically acquire English sense examples using an English-Chinese bilingual dictionary, Chinese monolingual corpora and Chinese-English machine translation software.", "sent2": "Hence, automatic selection of high quality parses created by unsupervised parsers is an important problem.", "label": 0}
{"sent1": "The structure of the graph and distances between vertices can be utilized to define metrics for identification of semantic relations.", "sent2": "The vertices of the graph are lexical items (words), their connection follows the syntactic structure of a sentence.", "label": 1}
{"sent1": "For semantic dependency parsing, we explore use of global features.", "sent2": "Pictorial communication systems convert natural language text into pictures to assist people with limited literacy.", "label": 0}
{"sent1": "This paper proposes a more general strategy which leverages two distincts semantic levels, one that encapsulates the foundations of the domain considered, and one that specifically accounts for the overall affective fabric of the language.", "sent2": "This makes it vulnerable to any discrepancy between the ensuing taxonomy of affective states and the underlying domain of discourse.", "label": 1}
{"sent1": "Sponsored by the DARPA TIDES project, NIST launched a new text summarization evaluation effort, called DUC, in 2001 with follow-on workshops in 2002 and 2003.", "sent2": "One critical problem remains how to handle the unavoidable variability in human judgments at the core of all the evaluations.", "label": 1}
{"sent1": "Perspectives range from the word level to sentence fragments to sequences of sentences; the networks operate only on word-embedding representations of text.", "sent2": "The parallel hierarchy enables our model to compare the passage, question, and answer from a variety of trainable perspectives, as opposed to using a manually designed, rigid feature set.", "label": 1}
{"sent1": "We extend the breadth of inferences afforded by natural logic to include relational entailment (e.g., buy ?", "sent2": "own) and meronymy (e.g., a person born in a city is born the city?s country).", "label": 1}
{"sent1": "While CRFs model source identification as a sequence tagging task, AutoSlog learns extraction patterns.", "sent2": "Our results show that the combination of these two methods performs better than either one alone.", "label": 1}
{"sent1": "In this work, we propose a series of deep learning models to address passage answer selection.", "sent2": "To this aim, the present article deals with the problem of sentiment detection in three different languages - French, German and Spanish - using three distinct Machine Translation (MT) systems - Bing, Google and Moses.", "label": 0}
{"sent1": "In this paper we explore tables as a semi-structured formalism that provides a balanced compromise to this tradeoff.", "sent2": "This paper presents observations on our experience with an annotation scheme that was used in the training of a state-of-the-art noun phrase semantic interpretation system.", "label": 0}
{"sent1": "In this work we propose a data-driven approach based on neural networks and continuous sentence features.", "sent2": "We develop a general framework for single-document summarization composed of a hierarchical document encoder and an attention-based extractor.", "label": 1}
{"sent1": "Furthermore, words with special functions (such as negation and transition) are distinguished and the dissimilarities of words with opposite sentiment are magnified.", "sent2": "An interesting case study on negation expression processing shows a promising potential of the architecture dealing with complex sentiment phrases.", "label": 1}
{"sent1": "Furthermore, when comparing to other sentiment analysis methods, the accuracy of our method was also better than LDA and JST based methods by 6.43% and 6.07%.", "sent2": "We describe the development of PASTAWeb, a WWWbased interface to the extraction output of PASTA, an IE system that extracts protein structure information from MEDLINE abstracts.", "label": 0}
{"sent1": "We propose two models, Tag Guided RNN (TGRNN for short) which chooses a composition function according to the part-ofspeech tag of a phrase, and Tag Embedded RNN/RNTN (TE-RNN/RNTN for short) which learns tag embeddings and then combines tag and word embeddings together.", "sent2": "Although a variety of composition functions have been proposed, the syntactic information has not been fully encoded in the composition process.", "label": 1}
{"sent1": "We describe an efficient optimization algorithm to learn the parameters of our model, based on the Frank-Wolfe algorithm.", "sent2": "The official results of the task show that our approach yields an F-score of 0.80 for DDI detection and an F-score of 0.65 for DDI detection and classification.", "label": 0}
{"sent1": "However, we show that the scores produced by such models can be aggregated to define powerful entity-level features between clusters of mentions.", "sent2": "Using these features, we train an entity-centric coreference system that learns an effective policy for building up coreference chains incrementally.", "label": 1}
{"sent1": "However, we report results that the integrated system performs as good as a pipelined system that decomposes the problem into a few smaller subtasks.", "sent2": "Data sparsity might be an important issue as a result of a large number of classes and relatively moderate training data size.", "label": 1}
{"sent1": "An experimental result revealed that de-romanization, which is reverse operation of romanization, is crucial for JnJk task.", "sent2": "In EnJa task, it is shown that mora is the best alignment unit for Japanese language.", "label": 1}
{"sent1": "OntoNotes also provides additional layers of integrated annotation, capturing additional shallow semantic structure.", "sent2": "The Discriminative Word Lexicon (DWL) is a maximum-entropy model that predicts the target word probability given the source sentence words.", "label": 0}
{"sent1": "Our system is evaluated on the CoNLL2012 Shared Task closed track, which comprises three languages: Arabic, Chinese and English.", "sent2": "We apply the same system to all languages, except for minor adaptations on some language dependent features, like static lists of pronouns.", "label": 1}
{"sent1": "The corpus contains edit, add before, split, merge, add after, move and other error types.", "sent2": "The winning tagger  was  thereafter  applied  to annotate  a  570,247 token corpus.", "label": 0}
{"sent1": "Specifically, we utilize the parse trees directly as a structured feature and apply kernel functions to this feature, as well as other normal features, to learn the resolution classifier.", "sent2": "In this way, our approach avoids the efforts of decoding the parse trees into the set of flat syntactic features.", "label": 1}
{"sent1": "In this paper, we focus on addressing the limitations caused by the imperfect mapping results and study how to further improve the retrieval performance of the concept-based ranking methods.", "sent2": "In particular, we apply axiomatic approaches and propose two weighting regularization methods that adjust the weighting based on the relations among the concepts.", "label": 1}
{"sent1": "The framework subsumes issues such as differential compositional as well as noncompositional behavior of phrasal consituents, and circumvents some problems of data sparsity by design.", "sent2": "Experimental results on the task of predicting semantic textual similarity do, however, not show a systematic difference between singleprototype and multi-prototype models.", "label": 0}
{"sent1": "We propose a novel approach that integrates the distributional representation of multiple sub-sets of the MWP?s words.", "sent2": "We assume a latent distribution over sub-sets of the MWP, and estimate it relative to a downstream prediction task.", "label": 1}
{"sent1": "The network uses Dynamic k-Max Pooling, a global pooling operation over linear sequences.", "sent2": "The network handles input sentences of varying length and induces a feature graph over the sentence that is capable of explicitly capturing short and long-range relations.", "label": 1}
{"sent1": "using latent semantic indexing, word co-occurrences or synonym relations using a word ontology have been shown not very effective.", "sent2": "In particular, when to extend the similarity function external prior knowledge is used, e.g.", "label": 1}
{"sent1": "A compositional-semantics procedure is then used to map the augmented parse tree into a final meaning representation.", "sent2": "It first uses an integrated statistical parser to produce a semantically augmented parse tree, in which each non-terminal node has both a syntactic and a semantic label.", "label": 1}
{"sent1": "Both are surprisingly good indicators of the processing difficulty of garden-path sentences.", "sent2": "Our results indicate that, despite their simplicity, our contributions yield a statistically-significant improvement of 33% (relative) over a strong distantly-supervised system.", "label": 0}
{"sent1": "However, this test involves as few as 80 questions, prompting questions regarding the statistical significance of reported results.", "sent2": "However, the task often suffers from errors propagating from upstream entity linkers to downstream relation extractors.", "label": 0}
{"sent1": "Our tests focus on the identification of cognates ?", "sent2": "The parameters of the model are automatically learned from training data that consists of word pairs known to be similar.", "label": 1}
{"sent1": "The model provides measures of a term?s re-occurrence rate and withindocument burstiness.", "sent2": "We examine the utility of speech and lexical features for predicting student emotions in computerhuman spoken tutoring dialogues.", "label": 0}
{"sent1": "These two tasks are interleaved in an incremental parsing-based dialog model.", "sent2": "In this paper, we present an approach to developing resources for a low-resource language, taking advantage of the fact that it is closely related to languages with more resources.", "label": 0}
{"sent1": "Our work places sense induction in a Bayesian context by modeling the contexts of the ambiguous word as samples from a multinomial distribution over senses which are in turn characterized as distributions over words.", "sent2": "The Bayesian framework provides a principled way to incorporate a wide range of features beyond lexical cooccurrences and to systematically assess their utility on the sense induction task.", "label": 1}
{"sent1": "We build novel types of networks in which links between characters are different types of social events.", "sent2": "We present a network analysis of a literary text, Alice in Wonderland.", "label": 1}
{"sent1": "We report the results of an initial study into the predictive power of surface syntactic statistics for the task; we use fluency assessments done for the purpose of evaluating machine translation.", "sent2": "Targeting a demonstrated potential improvement of almost 50% on some difficult TREC queries and their associated collections, we develop a suite of automatic techniques to re-write queries and study their characteristics.", "label": 0}
{"sent1": "While EM frequently fails to find good models for the tasks to which it is set, in this case it works quite well.", "sent2": "In all three cases, we outperform state-of-the-art systems either quantitatively or statistically significantly.", "label": 0}
{"sent1": "The number of retrieved relevant documents is optimized with respect to the number of queries submitted.", "sent2": "In this paper we present a hybrid statistical machine translation (SMT)-example-based MT (EBMT) system that shows significant improvement over both SMT and EBMT baseline systems.", "label": 0}
{"sent1": "This can be very useful for cross-lingual information retrieval and the preparation of multi-lingual lexical resources.", "sent2": "This makes the task more challenging, as the frequent pronunciation errors of non-native speakers may weaken the phonetic and phonotactic distinction between English responses and non-English responses.", "label": 0}
{"sent1": "The resulting model correctly resolves 81% of ambiguities left unresolved by an initial handcrafted baseline.", "sent2": "We illustrate with a case study building maximum entropy models over abductive interpretations in a referential communication task.", "label": 1}
{"sent1": "Our work aims to reduce the annotation effort involved in creating resources for semantic role labeling via semi-supervised learning.", "sent2": "Our algorithm augments a small number of manually labeled instances with unlabeled examples whose roles are inferred automatically via annotation projection.", "label": 1}
{"sent1": "Both methods exploit multiple hypotheses from ASR, in the form of word confusion networks, in order to achieve tighter coupling between ASR and query parsing and improved accuracy of the query parser.", "sent2": "In order to improve the robustness of the query parser to noise in the ASR output, in this paper, we investigate two different methods to query parsing.", "label": 1}
{"sent1": "The user?s familiarity with the company?s profile is assumed.", "sent2": "Therefore, automatic speech recognition (ASR) is a promising modality for such assistive devices.", "label": 0}
{"sent1": "We outline our recommendations about how any evaluation, manual or automatic, should be used to find statistically significant differences between summarization systems.", "sent2": "In this work, we use a ?cluster and label?", "label": 0}
{"sent1": "We find that combining lexical, syntactic, and language model-related features with the output of a state-of-the-art disfluency identification system improves overall word-level identification of these and other errors.", "sent2": "We emphasize false start regions, which are often missed in current disfluency identification approaches as they lack lexical or structural similarity to the speech immediately following.", "label": 1}
{"sent1": "Existing models of discourse semantics in principle generate all interpretations of discourse fragments and carry these until contradicted, and thus the dissonance criteria in humour cannot be met.", "sent2": "Results show that our strategy overcomes the proposed baselines and achieves adequate to moderate results when compared to other systems.", "label": 0}
{"sent1": "It introduces reordering rules, and motivates them linguistically.", "sent2": "This paper applies syntactic reordering to English-to-Arabic translation.", "label": 1}
{"sent1": "The second step is to identify communities within the graph, where each community corresponds to an abstractive sentence to be generated.", "sent2": "), general computer-mediated communication and human-computer interaction, increase in the friendliness of natural language interfaces, educational and edutainment systems.", "label": 0}
{"sent1": "LyriCloud is a word-level language ?browser?", "sent2": "An important part of TM systems is the matching algorithm that determines what translations get retrieved from the bank of available translations to assist the human translator.", "label": 0}
{"sent1": "Most text simplification systems are based on hand-written rules (e.g., PEST (Carroll et al, 1999) and its module SYSTAR (Canning et al, 2000)), and therefore face limitations scaling and transferring across domains.", "sent2": "In this work, we investigate the potential of Simple Wikipedia to assist automatic text simplification by building a statistical classification system that discriminates simple English from ordinary English.", "label": 1}
{"sent1": "triggers more community attention and consequently more content contribution.", "sent2": "Our main innovations are (i) the usage of outputs from NLP tools, viz.", "label": 0}
{"sent1": "For second order grandparent models, our method considers, or scores, no more than 6?13% of the second order edges of the full model.", "sent2": "This yields up to an eightfold parsing speedup, while providing the same empirical accuracy and certificates of optimality as working with the full LP relaxation.", "label": 1}
{"sent1": "To the best of our knowledge, this work is the first to both (i) develop a domain adaptation algorithm for the coreference resolution problem and (ii) have the above features as an ensemble method.", "sent2": "As training and test data we used two text collections of different genre: Europarl and CLUVI.", "label": 0}
{"sent1": "Our key observation is that multiple forms of weak supervision can be combined to train an accurate semantic parser: semantic supervision from a knowledge base, and syntactic supervision from dependencyparsed sentences.", "sent2": "We present a method for training a semantic parser using only a knowledge base and an unlabeled text corpus, without any individually annotated sentences.", "label": 1}
{"sent1": "Our focus is to improve the speech recognition performance of low-resource languages by leveraging the language model statistics from resource-rich languages.", "sent2": "The most challenging work of cross-lingual language modeling is to solve the syntactic discrepancies between the source and target languages.", "label": 1}
{"sent1": "A commonly-adopted framework generates structured review summaries with aspects and opinions.", "sent2": "Discovering and summarizing opinions from online reviews is an important and challenging task.", "label": 1}
{"sent1": "In the second stage, we introduce Comparative LexRank, a novel random walk formulation to score sentences and pairs of sentences from opposite viewpoints based on both their representativeness of the collection as well as their contrastiveness with each other.", "sent2": "Experimental results show that the proposed approach can generate informative summaries of viewpoints in opinionated text.", "label": 1}
{"sent1": "Our research explores whether current NLP technology can be used to automatically produce plot unit representations for narrative text.", "sent2": "We create a system called AESOP that exploits a variety of existing resources to identify affect states and applies ?projection rules?", "label": 1}
{"sent1": "We then describe an analysis of the distribution of PECO elements throughout the relevant documents and propose a language modeling approach that uses these distributions as a weighting strategy.", "sent2": "In this work, we first present the construction of a large test collection extracted from systematic literature reviews.", "label": 1}
{"sent1": "In our model, each X nonterminal in a SCFG rule is decorated with a real-valued feature vector computed based on its distribution of latent syntactic categories.", "sent2": "We also test combinations of ROUGE variants and find that they considerably improve the accuracy of automatic prediction.", "label": 0}
{"sent1": "The algorithm uses a similarity graph to encourage similar ngrams to have similar POS tags.", "sent2": "We also duplicate three state-of-the-art name translation mining methods and use two existing name translation gazetteers to compare with our approach.", "label": 0}
{"sent1": "We investigate limitations associated with previous methods, and propose a novel approach based on dynamic conditional random fields.", "sent2": "running 80 times faster than MBR in experiments with 1000-best lists.", "label": 0}
{"sent1": "In this paper, we present a novel method which integrates graph structures of two subtasks into one using virtual nodes, and performs joint training and decoding in the factorized state space.", "sent2": "Experimental evaluations on CoNLL 2000 shallow parsing data set and Fourth SIGHAN Bakeoff CTB POS tagging data set demonstrate the superiority of our method over cross-product, pipeline and candidate reranking approaches.", "label": 1}
{"sent1": "This modification significantly improves unsupervised POS tagging performance across several measures on five data sets for four languages.", "sent2": "We also show that simply using different hyperparameter values for content and function word states in a standard HMM (which we call HMM+) is surprisingly effective.", "label": 1}
{"sent1": "Common techniques for alleviating these problems, such as filtering low-frequency words, are successful in enhancing model quality, but exhibit failure trends similar to models trained on unprocessed OCR output in the case of LDA.", "sent2": "As expected, experimental results show that performance declines as word error rates increase.", "label": 1}
{"sent1": "We explore two variants to create these projections: Oriented Principal Component Analysis (OPCA) and Coupled Probabilistic Latent Semantic Analysis (CPLSA).", "sent2": "We use discriminative training to create a projection of documents from multiple languages into a single translingual vector space.", "label": 1}
{"sent1": "We apply our approach to storing the full Google Web1T n-gram set and all 1-to-5 grams of the Gigaword newswire corpus.", "sent2": "Both types of syntactic features provide information which is complementary to tried-and-tested nonsyntactic features.", "label": 0}
{"sent1": "As we target lesser-known languages, we try to focus on non-English posts by filtering out English text.", "sent2": "Using mature open-source software from the NLP research field, a spell checker (aspell) and a language identification system (langid.py), our case study and our benchmarks give an insight into the linguistic structure of the considered services.", "label": 1}
{"sent1": "The approach we follow relies on patterns that convey lexical, syntactic and semantic information, automatically learned from largescale corpora.", "sent2": "In this paper we discuss the impact of varying several parameters during pattern learning and matching in the Question Generation task.", "label": 1}
{"sent1": "Given that reversible models also use features that are specific to parsing or generation, there is the possibility that the model is trained to rely on these directional features.", "sent2": "If this is true, the premise that preferences are shared between parse disambiguation and fluency ranking does not hold.", "label": 1}
{"sent1": "Although it is not the first time that SMT inspires a QA system, it is the first approach that uses a full Machine Translation system for generating answers.", "sent2": "during lectures or interviews.", "label": 0}
{"sent1": "We describe our initial experiences with a corpus consisting of descriptions for video segments crafted from TREC video data.", "sent2": "In this paper, we propose a novel approach to learning topic representation for parallel data using a neural network architecture, where abundant topical contexts are embedded via topic relevant monolingual data.", "label": 0}
{"sent1": "In addition, since PropBank was designed on a verb-by-verb basis, the argument labels Arg2 - Arg5 get used for very diverse argument roles with inconsistent training instances.", "sent2": "However, because this training data is taken from the WSJ, the resulting machine learning models tend to overfit on idiosyncrasies of that text?s style, and do not port well to other genres.", "label": 1}
{"sent1": "We present a series of experiments designed to investigate the source of this lack of portability.", "sent2": "As part of our work, we introduce the NUS Corpus of Learner English (NUCLE), a fully annotated one million words corpus of learner English available for research purposes.", "label": 0}
{"sent1": "In addition, we used word category information of a Chinese thesaurus as features for verb disambiguation.", "sent2": "The features used were neighboring words and their part-of-speech, as well as single words in the context, and other syntactic features based on shallow parsing.", "label": 1}
{"sent1": "The second system, an enhancement to the first, incorporates cosine similarity using unigram features.", "sent2": "The first system scores candidates based on how frequently their local contexts match that of the marked word.", "label": 1}
{"sent1": "ReNoun then generalizes from this seed set to produce a much larger set of extractions that are then scored.", "sent2": "ReNoun creates a seed set of training data by using specialized patterns and requiring that the facts mention an attribute in the ontology.", "label": 1}
{"sent1": "This system uses a combination of Na?", "sent2": "Our first entry, for Task 5: Multilingual Chinese-English Lexical Sample Task, is a supervised system that decides the most appropriate English translation of a Chinese target word.", "label": 1}
{"sent1": "We implemented an unsupervised na?", "sent2": "Mohammad and Hirst (2006a) proposed a way to determine the strength of association between a sense or concept and co-occurring words?the distributional profile of a concept (DPC)?without the use of manually annotated data.", "label": 1}
{"sent1": "latent tree is NP-hard in general, for the case of projective trees we find that it can be found using bilexical parsing algorithms.", "sent2": "Moreover, pseudo grammars increase the diversity of base models; therefore, together with all other models, further improve system combination.", "label": 0}
{"sent1": "This approach learns role assignment in filler-gap constructions in a manner consistent with current developmental findings and is extremely robust to initialization variance.", "sent2": "Specifically, this model, trained on part-of-speech tags, represents the preferred locations of semantic roles relative to a verb as Gaussian mixtures over real numbers.", "label": 1}
{"sent1": "The model uses an Indian Buffet Process prior to learn the feature values used in the loglinear method, and is the first algorithm for learning phonological constraints without presupposing constraint structure.", "sent2": "The model learns a system of constraints that explains observed data as well as the phonologically-grounded constraints of a standard analysis, with a violation structure corresponding to the standard constraints.", "label": 1}
{"sent1": "This noise yields sub-optimal classification performance.", "sent2": "These findings lead us to argue that preferential attachement seems to be an appropriate high level abstraction for language acquisition and change.", "label": 0}
{"sent1": "Achilles was used and evaluated in the bakeoff.", "sent2": "At last, confidence measure based approach is used to weigh all the results and output the best ones.", "label": 1}
{"sent1": "We also present a short report on the development of a named entity annotated corpus in five South Asian language, namely Hindi, Bengali, Telugu, Oriya and Urdu.", "sent2": "In this paper we first present a brief discussion of the problem of Named Entity Recognition (NER) in the context of the IJCNLP workshop on NER for South and South East Asian (SSEA) languages1 .", "label": 1}
{"sent1": "Also we have added some gazetteers and context patterns to the system to increase the performance.", "sent2": "Most of the existing work on IMT uses batch learning paradigm which does not allow translation systems to make use of the new input instantaneously.", "label": 0}
{"sent1": "Adequate annotated corpora are not yet available in Telugu.", "sent2": "Not much work has been done in NER for Indian languages in general and Telugu in particular.", "label": 1}
{"sent1": "These embeddings are typically based on distributional statistics, making it difficult for them to generalize to rare or unseen words.", "sent2": "We propose to improve word embeddings by incorporating morphological information, capturing shared sub-word features.", "label": 1}
{"sent1": "We propose an automatic algorithm for cross-lingual similarization of dependency grammars, which automatically learns grammars with high cross-lingual similarity.", "sent2": "For terms not covered by the dictionary, we use transitive closure inference and reach an F-score of 0.91, close to a level sufficient for practical use.", "label": 0}
{"sent1": "Our method applies graded response model from item response theory (IRT), which was originally developed for academic tests.", "sent2": "We conducted experiments on a public dataset from the Workshop on Statistical Machine Translation 2013, and found that our approach resulted in highly interpretable estimates and was less affected by noisy judges than previously proposed methods.", "label": 1}
{"sent1": "In this paper, we propose a variational model to learn this conditional distribution for neural machine translation: a variational encoderdecoder model that can be trained end-to-end.", "sent2": "In this paper, we propose a method that clearly separates terms (words and dependency relations) in a natural language query into important and other terms, and differently handles the terms according to their importance.", "label": 0}
{"sent1": "For this model, we derive its convex relaxation and show that it too has strong performance despite not having the local optima problems of non-convex objectives.", "sent2": "The approach is fully implemented in a dialogue system for autonomous robots.", "label": 0}
{"sent1": "Proofs of relationships between the level of Kappa agreement and the difference in performance between consecutive models are presented.", "sent2": "The experimental results show that the precision of polarity assignment with the automatically acquired lexicon was 94% on average, and our method is robust for corpora in diverse domains and for the size of the initial lexicon.", "label": 0}
{"sent1": "The current state-of-art methods 1) exploit both the annotated and unannotated data in a semi-supervised manner, and 2) learn morph lexicons and subsequently uncover segmentations by generating the most likely morph sequences.", "sent2": "Here we automatically construct a corpus of Hiberno-English (English as spoken in Ireland) using a variety of methods: filtering by national domain, filtering by orthographic conventions, and bootstrapping from a set of Irelandspecific terms (slang, place names, organisations).", "label": 0}
{"sent1": "We illustrate the extended framework by learning conditional random fields (CRFs) with quadratic penalties arising from a graph Laplacian.", "sent2": "To handle dynamically changing domains, techniques will be needed to transfer and reuse existing dialogue policies and rapidly adapt them using a small number of dialogues in the new domain.", "label": 0}
{"sent1": "The training algorithm repeats the training of a semi-Markov model and the update of the weights of training samples.", "sent2": "In the boosting, training samples that are incorrectly segmented or labeled have large weights.", "label": 1}
{"sent1": "We summarize decisions by extracting suitable phrases from DAs that concern the issue under discussion and its resolution.", "sent2": "We propose a language-independent word normalization method exemplified on modernizing historical Slovene words.", "label": 0}
{"sent1": "The theoretical consequences of these results for claims in the literature are pointed out.", "sent2": "form and distribution are investigated, with preliminary results showing: splits can occur within syntactic constituents, apparently at any point in the string; it is unusual for the separate parts to be complete units in their own right; explicit repair of the antecedent does not occur very often.", "label": 1}
{"sent1": "This technique uses a database of belief vector prototypes to choose the optimal system action.", "sent2": "In this work, the Monte-Carlo control technique is extended so as to reduce training over-fitting and to improve robustness to semantic noise in the user input.", "label": 1}
{"sent1": "We test this hypothesis in the context of a wizarded spoken dialogue tutoring system, where student learning is the primary performance metric.", "sent2": "We address the problem of automatically cleaning a large-scale Translation Memory (TM) in a fully unsupervised fashion, i.e.", "label": 0}
{"sent1": "However, coming up with sentence plan construction rules for a new domain can be difficult.", "sent2": "The freely available SPaRKy sentence planner uses hand-written weighted rules for sentence plan construction, and a useror domain-specific second-stage ranker for sentence plan selection.", "label": 1}
{"sent1": "To extract the feature, a syntax tree of each sentence of a document is calculated, which is then split up into length-independent patterns using pq-grams.", "sent2": "In this paper we propose a machinelearning approach to paragraph boundary identification which utilizes linguistically motivated features.", "label": 0}
{"sent1": "We then show how a classifier with features derived from a standard NLP pipeline outperforms a strong baseline by 34%.", "sent2": "Finally, we outline initial experiments on further improving accuracy by leveraging background knowledge about the relationships between entities.", "label": 1}
{"sent1": "In some cases, however, there are multiple stakeholders with their own individual goals, needs and preferences.", "sent2": "However, due to the diversity and uneven distribution of source sentences, there are two problems suffered by this method.", "label": 0}
{"sent1": "Twitter in particular has become the target of a myriad of content-based applications including trend analysis and event detection, but there has been little fundamental work on the analysis of word usage patterns in this text type.", "sent2": "The system is evaluated on seven different languages: Catalan, Chinese, Czech, English, German, Japanese and Spanish.", "label": 0}
{"sent1": "The presence of automatic speech recognizer (ASR) output of broadcast news in news streams can reduce performance and render our named entity recognition based approaches ineffective.", "sent2": "Therefore, novel sources of knowledge are required to achieve progress on this problem.", "label": 0}
{"sent1": "In formal accounts of machine translation, adjuncts are often treated as modifiers applying synchronously in source and target derivations.", "sent2": "But how well can the assumption of synchronous adjunction explain translation equivalence in actual parallel data?", "label": 1}
{"sent1": "In this paper, we propose to identify student leaders solely based on textual features, or specifically by analyzing how they influence other students?", "sent2": "example-based MT.", "label": 0}
{"sent1": "We then demonstrate the robustness of these findings using a predictive model that illustrates how accurately those factors can be used to predict whether a thread is resolved or unresolved.", "sent2": "This method has two distinguishing characteristics: it is cross-lingual and it does not rely on the availability of extensive manually-compiled lexical resources in target languages other than English.", "label": 0}
{"sent1": "Yet, to which degree do they suffer from this problem, i.e.", "sent2": "In this paper, we capture the argument relationships for Chinese semantic role labeling task, and improve the task?s performance with the help of argument relationships.", "label": 0}
{"sent1": "However, we show that spoken data is not unpredictably irregular and that language models can benefit from detailed consideration of spoken language features.", "sent2": "This paper considers one specific construction which is largely restricted to the spoken domain - the ZERO AUXILIARY and makes a predictive model of that construction for native speakers of British English.", "label": 1}
{"sent1": "Using a modified version of the Contenders Algorithm (Riggle, 2004b), we verify that Turbid Spreading makes typologically valid predictions about the types of harmony processes that may appear in natural language.", "sent2": "However, attempts to eliminate typological pathologies relying on hand-made inputs and candidate sets have been shown to be highly prone to error (Wilson, 2005).", "label": 1}
{"sent1": "The ?bottom-up?", "sent2": "in several languages (we have implemented English and Hebrew - and are exploring an implementation using the Bliss graphical language).", "label": 0}
{"sent1": "We investigate various phonetic patterns, both in stressed and unstressed syllables.", "sent2": "This paper presents a statistical unsupervised system, called BioNoculars, for extracting protein-protein interactions from biomedical text.", "label": 0}
{"sent1": "Experiments on English and Finnish are presented with varying amount of labeled data.", "sent2": "Results of the linguistic evaluation of Morpho Challenge improve rapidly already with small amounts of labeled data, surpassing the state-ofthe-art unsupervised methods at 1000 labeled words for English and at 100 labeled words for Finnish.", "label": 1}
{"sent1": "Morpho Challenge aims at language-independent unsupervised learning algorithms that can discover useful morpheme-like units from raw text material.", "sent2": "However, this inference becomes difficult especially when two words do not share a lexical root, do not have the same argument structure, or do not have the same part-of-speech.", "label": 0}
{"sent1": "For both methods, we present encouraging results, achieving significant improvements over the best reported SRL performance in the literature.", "sent2": "To address this, we generate fictitious worlds and use crowdsourced denotations on these worlds to filter out spurious logical forms.", "label": 0}
{"sent1": "In contrast to existing techniques, which have used only shallow syntactic features, we investigate the use of semantic features (semantic roles) for the task of Open IE.", "sent2": "As the problem of automatic domain template creation is rather new, there is no well-defined procedure for the evaluation of the domain template quality.", "label": 0}
{"sent1": "Experiments show the effectiveness of our approach, providing a low cost solution for the Cross Language Text Categorization task.", "sent2": "The evaluation suggests that the results may already be useful within a curation environment and are certainly a baseline for more complex approaches.", "label": 0}
{"sent1": "No translation, language, or distortion model probabilities are used as in earlier work on SMT.", "sent2": "The key component is a new procedure to directly optimize the global scoring function used by a SMT decoder.", "label": 1}
{"sent1": "This sparse prototype information is then propagated across a corpus using distributional similarity features, which augment an otherwise standard PCFG model.", "sent2": "Prior knowledge is specified declaratively, by providing a few canonical examples of each target phrase type.", "label": 1}
{"sent1": "Our focus will be on a comparison of Bayesian Networks and HMMs in terms of user satisfaction and naturalness.", "sent2": "While the former perform best in isolation, the latter present a scalable alternative within joint systems.", "label": 1}
{"sent1": "We then unify these variants, showing that compilation is possible if all components of the grammar are regular relations, including the harmony ordering on scored candidates.", "sent2": "Our results are very competitive: With minimal adaptation of our model we come in second for two of the tasks?right behind a version of the system presented here that includes predictions of the Stanford event extractor as features.", "label": 0}
{"sent1": "Somali, as a Cushitic language, has a basic pattern wherein a small ?core?", "sent2": "And for out-of-domain evaluation, our system also achieves the second for average score of all three languages.", "label": 0}
{"sent1": "Based on the semantics of the matched sentences, we then build a classifier using TiMBL.", "sent2": "We end with a metric which is composed of weighted metrics at individual layers, which correlates very well with human judgment.", "label": 0}
{"sent1": "We first present an unsupervised method for discovering the topics of a text.", "sent2": "The toolkit is efficient, accurate and currently supports a range of features including EM sequence alignment and several decoding techniques novel in the context of G2P.", "label": 0}
{"sent1": "fly.", "sent2": "MIMUS includes a gestures?enabled talking head which endows the system with a human?like personality.", "label": 1}
{"sent1": "In this way, we target the phrasal decoder?s weakness in order modeling, without affecting its strengths.", "sent2": "Here, we extend the LFG grammar acquisition approach to Arabic and the Penn Arabic Treebank (ATB) (Maamouri and Bies, 2004), adapting and extending the methodology of (Cahill and al., 2004) originally developed for English.", "label": 0}
{"sent1": "Our algorithm generates a summary by selecting and ordering sentences taken from multiple review texts according to two scores that represent the informativeness and readability of the sentence order.", "sent2": "We propose a novel algorithm for sentiment summarization that takes account of informativeness and readability, simultaneously.", "label": 1}
{"sent1": "We explore methods to automatically generate annotator rationales for document-level sentiment classification.", "sent2": "can produce substantial improvements in categorization performance (Zaidan et al, 2007).", "label": 1}
{"sent1": "To the best of our knowledge, this is the first attempt to approach discriminative segmentation with a context-free model.", "sent2": "We describe the systems submitted by SRI International and the University of the Basque Country for the Semantic Textual Similarity (STS) SemEval-2012 task.", "label": 0}
{"sent1": "Moreover, unlike recent approaches built upon the MIRA algorithm of Crammer and Singer (2003) (Watanabe et al, 2007; Chiang et al, 2008b), PRO is easy to implement.", "sent2": "Training proceeds in stages: \frst a constrained syntactic parser is trained such that the parses on training data meet the speci\fed semantic spans, then the non-terminal labels are enriched to contain semantic information and \fnally a constrained syntactic+semantic parser is trained on the parse trees resulting from the previous stage.", "label": 0}
{"sent1": "Chinese-toEnglish translation experiments using HiFST and HiPDT, FSA and PDA-based decoders, are presented using admissible (or exact) search, possible for HiFST with compact SCFG rulesets and HiPDT with compact LMs.", "sent2": "We present a novel text exploration model, which extends the scope of state-of-the-art technologies by moving from standard concept-based exploration to statement-based exploration.", "label": 0}
{"sent1": "Our model matches the results of its competitors in the first experiment, and betters them in the second.", "sent2": "The general improvement in results with increase in syntactic complexity showcases the compositional power of our model.", "label": 1}
{"sent1": "For example, lung and breath are similar thematically, while authoritative and superficial occur in similar syntactic contexts, but share little semantic similarity.", "sent2": "We automatically estimate the likelihood of external causation of events based on the distribution of causative and anticausative uses of verbs in the causative alternation.", "label": 0}
{"sent1": "Third, we integrate the relation topics in a kernel function, and use it together with SVM to construct detectors for new relations.", "sent2": "Anaphors referring to abstract entities are resolved with an extension of the algorithm presented by Eckert and Strube (2000).", "label": 0}
{"sent1": "The final prediction in the reranking stage is performed using linear interpolation of these models and discriminative model.", "sent2": "Difference, intersection and distance (Euclidian, Manhattan and Jaccard) of N -grams were considered for constructing a feature vector which is further introduced in a support vector machine classifier which allows to construct a classification model.", "label": 0}
{"sent1": "While a lot of progress has been made on efficient training with several loss functions, the problem of endowing learners with a mechanism for feature selection is still unsolved.", "sent2": "As it may be observed, the results obtained for Twitter and SMS sentiment classification are good considering that our proposal is unsupervised.", "label": 0}
{"sent1": "The performance of standard NLP tools is severely degraded on tweets.", "sent2": "This paper addresses this issue by re-building the NLP pipeline beginning with part-of-speech tagging, through chunking, to named-entity recognition.", "label": 1}
{"sent1": "Our approach to question answering involves the interactive construction of natural language queries.", "sent2": "language learning employs training data in the form of sentences paired with relevant but ambiguous perceptual contexts.", "label": 0}
{"sent1": "However, the input representations had several shortcomings which we have been aiming to address in the time since.", "sent2": "This paper reports on our work to date on improving the input representations and on our plans for the next edition of the SR Task.", "label": 1}
{"sent1": "The aim of our paraphrase patterns is to factor out different syntactic variations of interrogative words, since the interrogative part of a question adds a syntactic superstructure on the sentence part (i.e., the rest of the question), thereby making it difficult for an automatic system to analyze the question.", "sent2": "The patterns we derived are rules which map surface syntactic structures to semantic case frames, which serve as the canonical representation of questions.", "label": 1}
{"sent1": "Normalization and paraphrase detection tasks are built on top of a robust analyzer for English and are exclusively achieved using symbolic methods.", "sent2": "Both grammar development rules and information extraction rules are expressed within the same formalism and are developed in an integrated way.", "label": 1}
{"sent1": "In this paper, first we describe our basic idea of paraphrase acquisition.", "sent2": "We introduce here the Jena ANnotation Environment (JANE), a platform that supports the complete annotation lifecycle and allows for ?focused?", "label": 0}
{"sent1": "We demonstrate the effectiveness of our approach in the context of one form of unbalanced task: annotation of transcribed human-human dialogues for presence/absence of uncertainty.", "sent2": "In this model, the probabilities of parse trees are defined with only the probabilities of selecting lexical entries.", "label": 0}
{"sent1": "The proposed method applies a set of paraphrasing rules to the reference sentences in order to increase the similarity score for the expressions that differ only in their writing styles.", "sent2": "The EMMA evaluation script is publicly available from http://www.cs.bris.ac.uk/ Research/MachineLearning/ Morphology/Resources/.", "label": 0}
{"sent1": "Additionally, we present a method for ?closing?", "sent2": "a sufficient number of chart cells to ensure quadratic worst-case complexity of context-free inference.", "label": 1}
{"sent1": "Zero pronouns are then detected by case structure analysis based on automatically constructed case frames.", "sent2": "First, this model recognizes discourse entities and links all mentions to them.", "label": 1}
{"sent1": "While the existing metrics perform quite well, to further improve performance, we propose the use of a supervised machine learning algorithm that fine-tunes them.", "sent2": "Previous studies have demonstrated the effectiveness of a number of metrics such as the Jaccard coefficient, especially in synonym acquisition.", "label": 1}
{"sent1": "The ability of the algorithm to find real morpheme boundaries is evaluated against a gold standard for both Finnish and English.", "sent2": "In comparison with a state-of-the-art algorithm the new algorithm performs best on the Finnish data, and on roughly equal level on the English data.", "label": 1}
{"sent1": "Second, it allows to model different forms of search, such as feedback, associative retrieval and browsing at the same time.", "sent2": "it subsumes various IR models under one common representation.", "label": 1}
{"sent1": "Experiments with context, projectivity, and prior distributions show the relative performance effects of these kinds of prior knowledge.", "sent2": "Results show that prior distributions, projectivity, and part of speech information are not necessary to beat the right branching baseline.", "label": 1}
{"sent1": "this finding indicates disassortative mixing in the sense that links tend to connect vertices of dissimilar degrees.", "sent2": "Our results show asynchronous learning can provide substantial speedups compared to distributed and singleprocessor mini-batch algorithms with no signs of error arising from the approximate nature of the technique.", "label": 0}
{"sent1": "To accomplish this we use MINIPAR to parse the phrases and construct their corresponding trees.", "sent2": "In this approach, we train probabilities of lexical entry assignments to words in a target domain and then incorporate them into the original parser.", "label": 0}
{"sent1": "the weighted network of words, where edges indicate orthographic proximity between two words.", "sent2": "Moreover, on the condition that several relevant sample documents are available, application of low-dimensional LSI to these documents yielded comparable IR performance to local RF but in a different manner.", "label": 0}
{"sent1": "Then we investigate the correlation of our results with the outcomes of some psycholinguistic experiments.", "sent2": "The retrieval algorithm is efficient and is guaranteed to find the optimal k candidates.", "label": 0}
{"sent1": "We show the experimental results for extracting multi-word terms from two domain corpora (?natural area?", "sent2": "Our results show that with word class models, the baseline can be improved by up to 1.4% BLEU and 1.0% TER on the French?German task and 0.3% BLEU and 1.1% TER on the German?English task.", "label": 0}
{"sent1": "as a system ?", "sent2": "We integrate page counts for each word in the pair and lexico-syntactic patterns that occur among the top ranking snippets for the AND query using support vector machines.", "label": 0}
{"sent1": "The intersection of IBM-4 Viterbi alignments for both translation directions is used to project the annotations from English and French to Polish.", "sent2": "We also manually annotated the development set with CCG analyses, establishing an upper bound for our entailment system of 87%.", "label": 0}
{"sent1": "The results showed an interaction between the relative positions of objects and the linguistic roles that those objects play in the locative expression: proximity was a decreasing function of the distance between the head object in the expression and the prepositional clause object, and an increasing function the distance between the head and the third, distractor object.", "sent2": "This finding leads us to a new account for the semantics of spatial prepositions such as near.", "label": 1}
{"sent1": "Our approach is based on the so-called MultiNet paradigm, a knowledge representation formalism especially designed for the representation of natural language semantics.", "sent2": "The paper describes how the information about the semantic interpretation of PPs is represented in the lexicon and in PP interpretation rules and how this information is used during semantic analysis.", "label": 1}
{"sent1": "Directional particle verbs together with directional PPs present an additional problem: the particle and the preposition in the PP seem to provide redundant information.", "sent2": "These particle verbs have a characteristic feature: some of them license directional prepositional phrases in the accusative, some only allow for locative PPs in the dative, and some particle verbs can occur with PPs in the accusative and in the dative.", "label": 1}
{"sent1": "We perform uniform treebank queries and show that English has the highest noun attachment rate followed by Swedish and German.", "sent2": "We also show that the high rate in English is dominated by the preposition of.", "label": 1}
{"sent1": "Precision is only one of the criteria to identify the most effective patterns among the candidates found.", "sent2": "In this paper we present a purely semantic approach for hypernymy extraction based on semantic networks (SNs).", "label": 0}
{"sent1": "SIE is composed by a general purpose machine learning algorithm (SVM) combined with several customizable modules.", "sent2": "However, the quantity variable is no longer fixed by limited corpus resources.", "label": 0}
{"sent1": "This further facilitates the incorporation of various non-local features that are defined on the target side.", "sent2": "SICTF factorizes Open Information Extraction (OpenIE) triples extracted from a domain corpus along with additional side information in a principled way to induce relation schemas.", "label": 0}
{"sent1": "We developed a web-based annotation interface and with its help evaluated practicability of this metric in the MT research and development process.", "sent2": "We propose methods that transform word vectors into sparse (and optionally binary) vectors.", "label": 0}
{"sent1": "We present TPLEX, a semi-supervised learning algorithm for information extraction that can acquire extraction patterns from a small amount of labelled text in conjunction with a large amount of unlabelled text.", "sent2": "We present a discriminative structureprediction model for the letter-to-phoneme task, a crucial step in text-to-speech processing.", "label": 0}
{"sent1": "A plausible reason for such a performance improvement is the reduction in data sparsity.", "sent2": "However, such a reduction could be achieved with a lesser effort through the means of syntagma based word clustering.", "label": 1}
{"sent1": "We explore how one might instead search for a global optimum in parameter space, using branch-and-bound.", "sent2": "The usual practice is to settle for local optimization methods such as EM or gradient ascent.", "label": 1}
{"sent1": "internal constituent and dependency parses.", "sent2": "Our classifier considers the context of the two arguments, word pair information, as well as the arguments?", "label": 1}
{"sent1": "languages.", "sent2": "But pivoting requires additional parallel texts.", "label": 1}
{"sent1": "We show that the additional dependencies captured by the tree conditional random field allows it to perform better than directly inverting a previously developed hybrid tree semantic parser.", "sent2": "Furthermore, we demonstrate that the model performs better than a previous state-of-the-art natural language generation model.", "label": 1}
{"sent1": "The general F1 of the English tagger is over 76%, which is in line with the state of the art on super sense tagging while augmenting the number of classes.", "sent2": "We present a simple and effective framework for exploiting multiple monolingual treebanks with different annotation guidelines for parsing.", "label": 0}
{"sent1": "However, for multi-class problems CW learning updates and inference cannot be computed analytically or solved as convex optimization problems as they are in the binary case.", "sent2": "We present a visual user interface supporting the investigation of a set of linguistic features discriminating between pass and fail ?English as a Second or Other Language?", "label": 0}
{"sent1": "In this paper, we present preliminary work on key event detection in British royal wedding videos using automatic speech recognition (ASR) and visual data.", "sent2": "Multimedia data grow day by day which makes it necessary to index them automatically and efficiently for fast retrieval, and more precisely to automatically index them with key events.", "label": 1}
{"sent1": "To this end, we leverage a combination of visual similarity measures, image clustering and matching algorithms to acquire clusters of iconic images that are topically connected to the original seed images, while also allowing for various degrees of diversity.", "sent2": "These are used to query an online image repository (i.e., Flickr), in order to further acquire additional examples of topic-specific iconic relations.", "label": 1}
{"sent1": "First, we analyze Japanese named entities which appear in Mainichi Newspaper articles published in 1995, 1996, 1997, 1998 and 2005.", "sent2": "This analysis reveals that the number of named entity types and the number of named entity tokens are almost steady over time and that 70 ?", "label": 1}
{"sent1": "This work empirically studies the performance of these two classes of alignment algorithms and explores strategies to combine them to improve overall system performance.", "sent2": "Two kinds of features, including textual and contextual features, are investigated for this task.", "label": 0}
{"sent1": "Across various existing parsers, these two categories have the lowest accuracies, and mistakes made have consequences for downstream applications.", "sent2": "Prepositions and conjunctions are two of the largest remaining bottlenecks in parsing.", "label": 1}
{"sent1": "Our generative model is conceptually simpler than the pipelined approach and requires far less training data.", "sent2": "The accuracy of the original parser on questions is very poor, and we propose a novel technique for porting the parser to a new domain, by creating new labelled data at the lexical category level only.", "label": 0}
{"sent1": "To this end, we will compare several state-of-the-art approaches for Opinion Mining in newspaper articles in this paper.", "sent2": "Furthermore, we will introduce a new technique to extract entropy-based word connections which identifies the word combinations which create a tonality.", "label": 1}
{"sent1": "These algorithms typically aim at extracting biomolecular interactions from text by inspecting only the context of one sentence.", "sent2": "During the past few years, several novel text mining algorithms have been developed in the context of the BioNLP Shared Tasks on Event Extraction.", "label": 1}
{"sent1": "The PC task concerns the automatic extraction of biomolecular reactions from text.", "sent2": "It participated in the English lexical sample task.", "label": 0}
{"sent1": "To enhance the robustness, a robust statistical model based on both transfer lexicons and sentence lengths are proposed in this paper.", "sent2": "Since a large percentage of content words in the source text would be translated into the corresponding translation duals to preserve the meaning in the target text, transfer lexicons are usually regarded as more reliable cues for aligning sentences when the alignment task is performed by human.", "label": 1}
{"sent1": "My method induces models of sound correspondence that are similar to models developed for statistical machine translation.", "sent2": "In contrast to previous models, it does not approximate thematic fit as argument plausibility or ?fit with verb selectional preferences?, but directly as semantic role plausibility for a verb-argument pair, through similaritybased generalization from previously seen verb-argument pairs.", "label": 0}
{"sent1": "In this paper, we describe the University of Illinois system that participated in the shared task.", "sent2": "Entity detection and tracking is a relatively new addition to the repertoire of natural language tasks.", "label": 0}
{"sent1": "Our system obtains a precision, recall and F1 score of 0.27, 0.1333 and 0.1785, respectively, on the official test set.", "sent2": "An n-gram language model is used to rerank k-best sentence lists generated by the transducer.", "label": 1}
{"sent1": "The question reformulations generated from these patterns are further incorporated into the retrieval model.", "sent2": "In particular, it addresses two open issues connected with it, i.e.", "label": 0}
{"sent1": "While Rocchio selects the features to be added to the original query based on statistical evidence, we propose to base our feature selection also on argumentative criteria.", "sent2": "Thus, we restrict the expansion on features appearing only in sentences classified into one of our argumentative categories.", "label": 1}
{"sent1": "Furthermore, our method includes the function of canceling an inversion by restating a predicate when the translation is incomprehensible due to the inversion.", "sent2": "link to all known web-based definitions that correspond to them.", "label": 0}
{"sent1": "Deterministic parsers are fast, efficient, and simple to implement, but generally less accurate than optimal (or nearly optimal) statistical parsers.", "sent2": "The system is divided into two main components.", "label": 0}
{"sent1": "However, as the system is highly modular, we can easily adapt it to new language pairs and other types of annotation.", "sent2": "Using BLEU as a metric, the re-ranked translation achieves a relative improvement of 4.8%, significantly better than the model-best translation.", "label": 0}
{"sent1": "This task is part of an international evaluation organized by the TC-STAR project in 2006.", "sent2": "The proposed method achieves consistent improvements in the BLEU score on the development and test data.", "label": 1}
{"sent1": "Prior work falls into two categories, depending on the type of input used: (a) parallel corpora (e.g., multiple translations of the same text) or (b) comparable texts (non-parallel but on the same topic).", "sent2": "It is particularly important to neural networks, which are very likely to be overfitting.", "label": 0}
{"sent1": "The other is the CKY algorithm for probabilistic context free grammars.", "sent2": "One is the Viterbi algorithm for linear-chain models, such as HMMs or CRFs.", "label": 1}
{"sent1": "The quality of the clusters is found to be sensitive to the inclusion of syntactic frames, LSA vectors, morphological pattern, and subject animacy.", "sent2": "We apply pattern mining to automatically labeled edits in the revision histories of different Wikipedia articles.", "label": 0}
{"sent1": "The project is comprised of four research items, (1) building a description framework of lexical entries, (2) building sample lexicons, (3) building an upperlayer ontology and (4) evaluating the proposed framework through an application.", "sent2": "To achieve this goal, we have launched a two year project to create a common standard for Asian language resources.", "label": 1}
{"sent1": "These tasks were conventional multiclass classification, hiearchical classification, and a structured classification task: complete labeled dependency tree prediction.", "sent2": "Also, we report on a computational model for predicting types of filled pause.", "label": 0}
{"sent1": "These are  sequences of semantically related words  that reflect a text?s cohesive structure.", "sent2": "This paper describes a new method for  computing lexical chains.", "label": 1}
{"sent1": "The 150 most frequent Hungarian verbs were clustered on the basis of their complementation patterns, yielding a set of basic classes and hints about the features that determine verbal subcategorization.", "sent2": "syntactic realization, we investigate how one can obtain semantically motivated verb classes by automatic means.", "label": 1}
{"sent1": "We evaluate eight parsers (based on dependency parsing, phrase structure parsing, or deep parsing) using five different parse representations.", "sent2": "Our approach is to measure the impact of each parser when it is used as a component of an information extraction system that performs protein-protein interaction (PPI) identification in biomedical papers.", "label": 1}
{"sent1": "This general framework allows us to use arbitrary similarity functions between items, and to incorporate different information in our comparison, such as n-grams, dependency relations, etc.", "sent2": "We then find a maximum weight matching between the items such that each item in one sentence is mapped to at most one item in the other sentence.", "label": 1}
{"sent1": "scores.", "sent2": "Ratings of the same justification across judges differed significantly, signaling the need for a better characterization of the justification task.", "label": 1}
{"sent1": "This paper describes a two part supervised system which classifies words as hedge or nonhedged and sentences as certain or uncertain in biomedical and Wikipedia data.", "sent2": "We describe a novel leavingone-out approach to prevent over-fitting that allows us to train phrase models that show improved translation performance on the WMT08 Europarl German-English task.", "label": 0}
{"sent1": "A maximum entropy classifier is used for sentences not covered by the tree kernel classifier.", "sent2": "Participants were presented with datasets for different language pairs, where multi-directional entailment relations (?forward?, ?backward?, ?bidirectional?, ?no entailment?)", "label": 0}
{"sent1": "Our main approach is as follows.", "sent2": "For example, IE in a multilingual broadcast processing system has to deal with inaccurate automatic transcription and translation.", "label": 0}
{"sent1": "The best acceptance scores for uncertain sentences were determined using 10-fold cross validation on the training data.", "sent2": "New sentences received scores that correspond with those of their best scoring cue word, if present.", "label": 1}
{"sent1": "For comparison we also used the clinical part of the BioScope Corpus and trained it with Stanford NER.", "sent2": "This led to huge improvements in translation quality as more and more data was consumed.", "label": 0}
{"sent1": "We identify geriatrics as a clinical practice with a low average amount of uncertain sentences and a high average IAA, and neurology with a high average amount of uncertain sentences.", "sent2": "Speculative words are often n-grams, and uncertain sentences longer than average.", "label": 1}
{"sent1": "The scope of negation detection is limited to explicit rather than implied negations within single sentences.", "sent2": "A new negation corpus is presented that was constructed for the domain of English product reviews obtained from the open web, and the proposed negation extraction system is evaluated against the reviews corpus as well as the standard BioScope negation corpus, achieving 80.0% and 75.5% F1 scores, respectively.", "label": 1}
{"sent1": "Therefore, the proposed approach can not only capture source-tree-to-target-chunk correspondences but can also use forest structures that compactly encode an exponential number of parse trees to properly generate target function words during decoding.", "sent2": "In order to constrain the exhaustive attachments of function words, we limit to bind them to the nearby syntactic chunks yielded by a target dependency parser.", "label": 1}
{"sent1": "Negation is a very common linguistic construction that affects polarity and, therefore, needs to be taken into consideration in sentiment analysis.", "sent2": "This paper presents a survey on the role of negation in sentiment analysis.", "label": 1}
{"sent1": "Since verb meanings highly depend on their arguments we propose a verb thesaurus on the basis of possible shared meanings with predicate-argument structure.", "sent2": "In this paper, we propose a method to jointly optimize the two-step CRFs and also a fast algorithm to realize it.", "label": 0}
{"sent1": "The experimental results show that given the target word within a sentence, the best F-measures of SRL can achieve 60.42%.", "sent2": "For the BI and SRC subtasks, the best Fmeasures are 70.55 and 81%, respectively.", "label": 1}
{"sent1": "and ?one sense per word  association.?", "sent2": "In our word translation  disambiguation experiment, the results  show that our method achieved 42%  recall and 49% precision for Japanese-English newspaper texts, and 45%  recall and 76% precision for Chinese-Japanese technical documents.", "label": 1}
{"sent1": "The corpora were collected from dialogues in which two participants collaboratively solved Tangram puzzles with a puzzle simulator.", "sent2": "Unlike previous word-sequencebased models, our PAS-based model composes arguments into predicates by using the category information from the PAS.", "label": 0}
{"sent1": "Previous approaches depend on language-specific solutions (e.g., bilingual dictionaries, sequential machine translation) to evaluate document similarities, and the required transformations may alter the original document semantics.", "sent2": "Surface realisations typically depend on their target style and audience.", "label": 0}
{"sent1": "Preprocessed information on text, mostly syntactic, has been shown to be important for SRL.", "sent2": "Current research focuses on improving the performance assuming that this lower level information is given without any attention to the overall efficiency of the final system, although minimizing execution time is a necessity in order to support real world applications.", "label": 1}
{"sent1": "These tools, built on psychometric advances, are widely used because of availability.", "sent2": "The condition under which an NPI can occur in a sentence is for it to be in the scope of a negation with no quantifiers scopally intervening.", "label": 0}
{"sent1": "If human language comprehension is a rational process in the sense of making use of all available information sources, then we might expect uncertainty at the level of word-level input to affect sentence-level comprehension.", "sent2": "These words cause recognition failures, which propagate through pipeline systems impacting the performance of downstream applications.", "label": 0}
{"sent1": "Results of experiments on Shakespeare?s plays are presented along with discussion of how this work can be extended to unstructured texts (i.e.", "sent2": "novels).", "label": 1}
{"sent1": "We propose a method that takes as input an existing embedding, some labeled data, and produces an embedding in the same space, but with a better predictive performance in the supervised task.", "sent2": "However, some methods take days or weeks to learn good embeddings, and some are notoriously difficult to train.", "label": 1}
{"sent1": "For seven European language pairs, our evaluation estimates an average 10-point improvement to state-of-theart machine translation between 2007 and 2012, with Czech-to-English translation standing out as the language pair achieving most substantial gains.", "sent2": "We argue that the availability of such an online tool will facilitate the generation of in-depth annotated linguistic examples as part of linguistic research.", "label": 0}
{"sent1": "To overcome this problem, conversational systems must be able to learn new words automatically during human machine conversation.", "sent2": "One major bottleneck in conversational systems is their incapability in interpreting unexpected user language inputs such as out-ofvocabulary words.", "label": 1}
{"sent1": "We compare those new word embeddings with some well-known embeddings on named entity recognition and movie review tasks and show that we can reach similar or even better performance.", "sent2": "Instead, we propose to drastically simplify the word embeddings computation through a Hellinger PCA of the word cooccurence matrix.", "label": 1}
{"sent1": "It also incorporates the age of documents.", "sent2": "Our model is general in that it can be applied to all tasks which require an estimate of document?document, document?", "label": 1}
{"sent1": "This paper assumes that the DIH sometimes fails, and investigates other ways of quantifying the relationship between the cooccurrence contexts of two terms.", "sent2": "Recent hypernym detection measures have been based on the Distributional Inclusion Hypothesis (DIH).", "label": 1}
{"sent1": "corpus.", "sent2": "We present the first large-scale English ?allwords lexical substitution?", "label": 1}
{"sent1": "Using this framework, we address the problem of generating programming code from a mixed natural language and structured specification.", "sent2": "Comprehensive experiments were conducted on standard data sets.", "label": 0}
{"sent1": "Coherence models for entity resolution encourage all referring expressions in a document to resolve to entities that are related in the KB.", "sent2": "After discussing the solutions integrated into the current Resource Description Framework (RDF) representation of the JLP-O, the paper also briefly describes the extraction of a corpus-based lexicon from the recently released Balanced Corpus of Contemporary Written Japanese (BCCWJ; Maekawa et al., 2013), an authoritative sampling of the contemporary Japanese lexicon.", "label": 0}
{"sent1": "A variational inference method yields the topic embeddings as well as the topic mixing proportions for each document.", "sent2": "In this paper, we study visual language, both literal and sentimental, that describes the overall appearance and style of virtual characters.", "label": 0}
{"sent1": "We propose a new probabilistic graphical model called MCTA which can cope with the language gap and capture the common semantics in different languages.", "sent2": "We investigate the task of Cultural-common Topic Detection (CTD), which is aimed at discovering common discussion topics from news reader comments written in different languages.", "label": 1}
{"sent1": "In order to solve this ambiguation, formerly, people used to resort to many hand-coded rules.", "sent2": "Spoken dialog systems support the user by less distracting interaction than visual/hapticbased dialog systems.", "label": 0}
{"sent1": "Based on these assumptions, new valency entries are constructed for words in a plain bilingual dictionary, using entries with similar source-language meaning and the same target-language translations.", "sent2": "The method is based on two assumptions: words with similar meaning have similar subcategorization frames and selectional restrictions; and words with the same translations have similar meanings.", "label": 1}
{"sent1": "We evaluate different compositions for sentence representation on a standard dataset using the ROUGE evaluation measures.", "sent2": "The integration of this model into a phrase-based decoder improves a strong Arabic-English baseline already including state-of-the-art early distortion cost (Moore and Quirk, 2007) and hierarchical phrase orientation models (Galley and Manning, 2008).", "label": 0}
{"sent1": "Our experiment suggests that that distributional information is useful for dialogue act tagging but that simple models of compositionality fail to capture crucial information from word and utterance sequence; more advanced approaches (e.g.", "sent2": "However, scalability of such systems is a bottleneck due to the heavy cost of authoring and maintenance of rule sets and inevitable brittleness due to lack of coverage in the rule sets.", "label": 0}
{"sent1": "To this end, we use a maximum entropy model to automatically detect action itemrelated utterances from multi-party audio meeting recordings.", "sent2": "We compare the effect of lexical, temporal, syntactic, semantic, and prosodic features on system performance.", "label": 1}
{"sent1": "We propose the task of domain-specific image captioning, where many relevant visual details cannot be captured by off-the-shelf general-domain entity detectors.", "sent2": "To tackle the problem of joint syntactic?semantic analysis, the system relies on a syntactic and a semantic subcomponent.", "label": 0}
{"sent1": "We then filter the generated list using a DA morphological analyzer.", "sent2": "Both the closed and open tracks regarding to all four corpora MSRA, UPUC, CITYU, CKIP are involved in our systems?", "label": 0}
{"sent1": "The techniques are applied to an LFG grammar for German.", "sent2": "We present a new approach to stochastic modeling of constraintbased grammars that is based on loglinear models and uses EM for estimation from unannotated data.", "label": 1}
{"sent1": "We analyze the statistical properties of the resulting dataset and present evaluations of the core event extraction as well as negation and speculation detection components of the system.", "sent2": "We test our methods on a museum?s search log file, and compare the quality of the generated test collections against a collection with manually generated and judged known-item topics.", "label": 0}
{"sent1": "A degree-based clustering algorithm is applied to these graphs to discover different themes or topics within the document.", "sent2": "The system represents the documents as graphs formed from concepts and relations from the UMLS.", "label": 1}
{"sent1": "Input data has to be saved and analyzed several times, in order to detect underlying events and then summarize them.", "sent2": "Previous research has mostly focused on working in batches or with filtered streams.", "label": 1}
{"sent1": "However there is a bottleneck in MBL whereby any novel testing item has to be compared against all the training items in memory base.", "sent2": "For this reason there has been some interest in various forms of memory editing whereby some method of selecting a subset of the memory base is employed to reduce the number of comparisons.", "label": 1}
{"sent1": "These sets define the semantic behaviour of the main textual elements based on their syntactic role.", "sent2": "On the one hand, it is shown that Maximum Entropy models applied to WSD tasks provide good results.", "label": 1}
{"sent1": "This paper presents a method for combining different expressions of the re-sampling approach in a mixture of experts framework.", "sent2": "We present several complications in computing keystroke savings which may affect interpretation and comparison of results.", "label": 0}
{"sent1": "the availability of annotated data, the kind of dependencies in the data, and the availability of knowledge bases (grammars).", "sent2": "We therefore had to deviate from the generic code and make new design and implementation in many important cases.", "label": 0}
{"sent1": "It clusters sequences of tags together based on local distributional information, and selects clusters that satisfy a novel mutual information criterion.", "sent2": "The indexing actions that can be performed during parsing are also enumerated.", "label": 0}
{"sent1": "We use a large-margin approach to adapt parameterised edge weights to the data such that the shortest path is identical to the desired summary.", "sent2": "We devise a parameterised shortest path algorithm that can be written as a generalised linear model in a joint space of word graphs and compressions.", "label": 1}
{"sent1": "This theoretically plausible system can also perform the practically useful task of unsupervised learning of syntax.", "sent2": "In contrast, our method can be used with virtually any type of classifier.", "label": 0}
{"sent1": "Topic words are widely distributed in the stream of documents, and sometimes they frequently appear in the documents, and sometimes not.", "sent2": "We propose a method to reinforce topic words with low frequencies by collecting documents from the corpus, and applied Latent Dirichlet Allocation (Blei et al, 2003) to these documents.", "label": 1}
{"sent1": "Such models have applications both in psycholinguistics and in computational linguistics.", "sent2": "At each stage, we evaluate the intermediate results manually, and tune the later stages accordingly.", "label": 0}
{"sent1": "PDMM is an expansion of an existing probabilistic generative model: Parametric Mixture Model(PMM) by hierarchical Bayes model.", "sent2": "In this paper, we proposed a novel probabilistic generative model to deal with explicit multiple-topic documents: Parametric Dirichlet Mixture Model(PDMM).", "label": 1}
{"sent1": "We consider here the BTEC task of the 2006 IWSLT evaluation.", "sent2": "Smoothing probabilities is most important for tasks with a limited amount of training material.", "label": 1}
{"sent1": "It consists of several simple classifiers and a module which combines them under linguistically motivated constraints.", "sent2": "Numerative classifiers are ubiquitous in many Asian languages.", "label": 0}
{"sent1": "Using the RankNet learning algorithm, we train a pair-based sentence ranker to score every sentence in the document and identify the most important sentences.", "sent2": "into the supervised learning process.", "label": 0}
{"sent1": "We extract effective expressions from the important segments to define various viewpoints.", "sent2": "In text mining a viewpoint defines the important associations between key entities and it is crucial that the correct viewpoints are identified.", "label": 1}
{"sent1": "Each sub-corpus is deemed to be a domain.", "sent2": "We argue that by taking advantage of this information density, NLG systems applied to ontologies can guide the choice and construction of sentences to express useful ontological information, solely through the verbalisations of identifier names, and that by doing so, they can replace the extremely fussy and repetitive texts produced by ontology verbalisers with shorter and simpler texts which are clearer and easier for human readers to understand.", "label": 0}
{"sent1": "We present novel training criteria based on maximum likelihood estimation and expected loss computation.", "sent2": "We show significant improvements over a state-of-the-art minimum error rate training baseline on a large ChineseEnglish translation task.", "label": 1}
{"sent1": "Lexical analogies occur frequently in text and are useful in various natural language processing tasks.", "sent2": "Our method significantly outperforms other alignment techniques when applied to this novel alignment task, by a margin of at least 6.5 percentage points in F1-score.", "label": 0}
{"sent1": "For pos-tagging, we use a supervised machine learning approach, requiring annotated training and evaluation corpora and optionally a lexicon, all of which were prepared as part of the study.", "sent2": "In this study, we tackle the question of pos-tagging written Occitan, a lesser-resourced language with multiple dialects each containing several varieties.", "label": 1}
{"sent1": "By contrast, we propose a new model of lexical semantic relatedness that incorporates information from every explicit or implicit path connecting the two words in the entire graph.", "sent2": "We also describe a computer program that was developed to facilitate and standardize the annotation procedure for the task.", "label": 0}
{"sent1": "In deterministic approaches to this task, dependency trees are constructed by series of actions of attaching a bunsetsu chunk to one of the nodes in the tree being constructed.", "sent2": "Conventional techniques select the node based on whether the new bunsetsu chunk and each node in the trees are in a parent-child relation or not.", "label": 1}
{"sent1": "We evaluate the algorithm?s performance on gold trees and parser output using three different metrics.", "sent2": "Our method compares favorably with state-of-the-art algorithms that recover WH-traces.", "label": 1}
{"sent1": "The system comprises of two parts: A disambiguation module which differentiates causal connectors from their other senses, and a discourse relation annotation system which marks the spans of text that constitute the reason and the result/conclusion expressed by the causal relation.", "sent2": "The idea derives from the observation that WordNet may be seen as a graph in which synsets are connected through the binary relation ?a term belonging to synset sk occurs in the gloss of synset si?, and on the hypothesis that this relation may be viewed as a transmitter of such semantic properties.", "label": 0}
{"sent1": "To test this hypothesis we apply two techniques, Latent Semantic Analysis and n-gram overlap.", "sent2": "Training efficient statistical approaches for natural language understanding generally requires data with segmental semantic annotations.", "label": 0}
{"sent1": "We train a Bayesian model and test it on a monolingual and on a bilingual input.", "sent2": "Given a target word and a set of parameters, GCM evaluate the connectivity of the produced clusters, which correspond to subgraphs of the initial (unclustered) graph.", "label": 0}
{"sent1": "In particular, we focus on identifying and employing semantic classes of nouns and verbs with high tendency to encode cause or non-cause relations.", "sent2": "In this paper, we propose a model for the recognition of causality in verb-noun pairs by employing additional types of knowledge along with linguistic features.", "label": 1}
{"sent1": "A precision rate of 75?8.5% is found for the translations of English VPCs into Spanish.", "sent2": "This study thus shows that VPCs are a particularly good subset of the MWE spectrum to attack using word alignment methods, and that subtitles data provide a range of interesting expressions that do not exist in other corpus types.", "label": 1}
{"sent1": "As a preliminary study, we treat this task as a special kind of document summarization based on sentence extraction.", "sent2": "In this paper, we investigate the possibility to automatically generate sports news from live text commentary scripts.", "label": 1}
{"sent1": "Patterns are scored by their ability to extract more positive entities and less negative entities.", "sent2": "However, few of these factors have been formally examined.", "label": 0}
{"sent1": "The learned parameters are then used to initialize the supervised learning process.", "sent2": "Several semi-supervised learning methods have been proposed to leverage unlabeled data, but imbalanced class distributions in the data set can hurt the performance of most algorithms.", "label": 0}
{"sent1": "Previous work has shown that such lists can be generated using Information Retrieval (IR) search algorithms applied to the databases containing previously solved CPs and reranked with tree kernels (TKs) applied to a syntactic tree representation of the clues.", "sent2": "In this paper, we create a labelled dataset of 2 million clues on which we apply an innovative Distributional Neural Network (DNN) for reranking clue pairs.", "label": 1}
{"sent1": "Results are encouraging, with 86% to 96% agreement between our method and the manually created WALS database for a range of different word order features.", "sent2": "In this paper, we study direct transfer methods for multilingual named entity recognition.", "label": 0}
{"sent1": "Secondly, a linear layer is added to integrate different order neural models and trained with perceptron method.", "sent2": "The proposed parsers are evaluated on English and Chinese Penn Treebanks and obtain competitive accuracies.", "label": 1}
{"sent1": "It also makes it possible to jointly decide dependency and predicate-argument structure, which is usually implemented as two separate steps.", "sent2": "In this paper, we focus on the challenge of constituent syntactic parsing with treebanks of different annotations and propose a collaborative decoding (or co-decoding) approach to improve parsing accuracy by leveraging bracket structure consensus between multiple parsing decoders trained on individual treebanks.", "label": 0}
{"sent1": "We detail several measures that evaluate the relevance of the triples and the strength of their association.", "sent2": "Describing the main event of an image involves identifying the objects depicted and predicting the relationships between them.", "label": 0}
{"sent1": "To this end, we devise judicious features and develop a graph-based alignment algorithm by adapting and extending the SimRank random-walk method.", "sent2": "Our final result, a MAP score of 0.676 and P&20 score of 0.417 outperform a strong baseline based on search engine by 0.182 in MAP and 0.04 in P&20.", "label": 0}
{"sent1": "classification at message-level (subtask B), and polarity disambiguation of particular text spans within a message (subtask A).", "sent2": "We participated in both strands of the task, viz.", "label": 1}
{"sent1": "As a first step, an ad-hoc preprocessing is performed.", "sent2": "They are regarded as linguistically na?", "label": 0}
{"sent1": "Post-editing time prediction uses regression models, additionally fed with new elaborate features from the Statistical MT decoding process.", "sent2": "Sentence-level ranking of alternative MT outputs is done with pairwise classifiers using Logistic Regression with blackbox features originating from PCFG Parsing, language models and various counts.", "label": 1}
{"sent1": "Our submissions use the framework of Gaussian Processes to investigate lightweight approaches for this problem.", "sent2": "The standard tuning algorithm?MERT?only scales to tens of features.", "label": 0}
{"sent1": "RTMs achieve top performance in automatic, accurate, and language independent prediction of sentence-level and word-level statistical machine translation (SMT) quality.", "sent2": "RTMs are a computational model for identifying the translation acts between any two data sets with respect to a reference corpus selected in the same domain, which can be used for estimating the quality of translation outputs, judging the semantic similarity between text, and evaluating the quality of student answers.", "label": 1}
{"sent1": "We used a broad set of features (86 for German-to-English and 97 for English-to-Spanish) ranging from standard QE features to features based on pseudo-references and semantic similarity.", "sent2": "This paper introduces a new application of boosting for parse reranking.", "label": 0}
{"sent1": "For that, we use the post-edited and reference corpora during the training step.", "sent2": "One of the advantages of a grammar-based framework is that it is easy to combine grammars, and we use this ability to compare models that capture different kinds of linguistic structure.", "label": 0}
{"sent1": "Among these, we consider a novel technique to dynamically shape the reordering search space and effectively capture long-range reordering phenomena.", "sent2": "We propose an adaptive ensemble method to adapt coreference resolution across domains.", "label": 0}
{"sent1": "We also train a causal classifier using features from the open class markers and semantic features providing contextual information.", "sent2": "The results show that our features provide an 11.05 point absolute increase over the baseline on the task of identifying causality in text.", "label": 1}
{"sent1": "For evaluation of the method, we compared English results with the Subject Field Codes (SFC) resources.", "sent2": "We also compared each English and Japanese results to the first sense heuristics in the WSD task.", "label": 1}
{"sent1": "We present a newly developed manually annotated corpus of Modern Standard Arabic (MSA) together with a new polarity lexicon.The corpus is a collection of newswire documents annotated on the sentence level.", "sent2": "The model uses an Indian Buffet Process prior to learn the feature values used in the loglinear method, and is the first algorithm for learning phonological constraints without presupposing constraint structure.", "label": 0}
{"sent1": "In this work, we propose a character-based neural encoderdecoder model for this task.", "sent2": "Additionally, we extend our model to include morphemelevel and lexical information through a neural reranker.", "label": 1}
{"sent1": "The essential idea is that the descendant classes can share the information of the ancestor classes in a predefined taxonomy.", "sent2": "beliefs in Discourse Representation Theory (DRT) and presents a viable solution in the form of a dialogue-based DRT representation of beliefs.", "label": 0}
{"sent1": "The proposed approach is implemented and evaluated in a Mandarin spoken dialogue system for tour-guiding service.", "sent2": "The framework has been designed to decouple kernel functions and learning algorithms: once a new kernel function has been implemented it can be adopted in all the available kernelmachine algorithms.", "label": 0}
{"sent1": "A common subclass is integrating high precision rules with a Markov statistical sequence classifier.", "sent2": "We conclude that an awareness of such variation is necessary when deploying NLP systems for use in single or multiple subdomains.", "label": 0}
{"sent1": "We propose using a retrieval model based on finite state machines for fuzzy matching of speech sound patterns, and further for speech retrieval.", "sent2": "Languageindependent query expansion is achieved either by allowing a wide lattice output for an audio query, or by taking advantage of distinctive features in speech articulation to propose subwords most similar to the given subwords in a query.", "label": 1}
{"sent1": "Most of the users hardly know how to type in their native language and prefer to access the information through English based transliteration.", "sent2": "This paper addresses all these problems and presents a transliteration based search engine (inSearch) which is capable of searching 10 multi-script and multiencoded Indian languages content on the web.", "label": 1}
{"sent1": "The alignment is used to add and complete templates and infoboxes in one language with information derived from Wikipedia in another language.", "sent2": "Conventional wisdom dictates that synchronous context-free grammars (SCFGs) must be converted to Chomsky Normal Form (CNF) to ensure cubic time decoding.", "label": 0}
{"sent1": "In this paper we present preliminary results on quantifying Wikipedia multilinguality.", "sent2": "SMT has been used in paraphrase generation by translating a source sentence into another (pivot) language and then back into the source.", "label": 0}
{"sent1": "evaluation on the English,  Chinese and Japanese  corpora.", "sent2": "After giving golden testing set, we fix the bug and rerun the evaluation script, this time we obtain the score of 62.8% which is consistent with the results on developing set.", "label": 0}
{"sent1": "We test the validity of the acquired knowledge by means of an application to the problem of word sense disambiguation.", "sent2": "With a few exceptions, extensions to latent Dirichlet allocation (LDA) have focused on the distribution over topics for each document.", "label": 0}
{"sent1": "Each parameter setting is assigned a score according to one of the GCM and the highest scoring setting is then selected.", "sent2": "Therefore, our model allows the decoder to perform context-dependent rule selection during decoding.", "label": 0}
{"sent1": "As a side effect, sentences that are too long but partly relevant are doomed to either not appear in the final summary, or prevent inclusion of other relevant sentences.", "sent2": "The effort is put on promoting the interest of linguistics to students through fun material and good contact with teachers of languages.", "label": 0}
{"sent1": "We compare our model, which operates at the subsentence or ?concept?-level, to a sentencelevel model, previously solved with an ILP.", "sent2": "We present an Integer Linear Program for exact inference under a maximum coverage model for automatic summarization.", "label": 1}
{"sent1": "In this paper, we explore the use of the underspecified semantic formalism LRS, which combines the capability of precisely representing semantic distinctions with the robustness and modularity needed to represent meaning in real-life applications.", "sent2": "We show that a content-assessment approach built on LRS outperforms a previous approach on the CREG data set, a freely available corpus of answers to reading comprehension exercises by learners of German.", "label": 1}
{"sent1": "system.", "sent2": "Four main issues are investigated: (1) assessing system performance under various network tra\u000ec conditions; (2) a study on the usage and utility of multi-modality in the context of multilingual communication; (3) a comparison of the features of the individual speech recognition engines, and (4) an end-to-end evaluation of the system.", "label": 1}
{"sent1": "Since our initial submission, we have implemented additional routines and have now examined the differences in the features used for making sense selections.", "sent2": "Official SENSEVAL-2 results were generated using WordNet, and separately using the New Oxford Dictionary of English (NODE).", "label": 1}
{"sent1": "First-order classifiers are combined by a second-order classifier, which variously uses majority voting, weighted voting, or a maximum entropy model.", "sent2": "To understand the real effect of normalization on the parser, we tie normalization performance directly to parser performance.", "label": 0}
{"sent1": "In contrast to English, a Chinese word is usually composed of characters, and most of the characters themselves can be further divided into components such as radicals.", "sent2": "This paper considers the problem of learning Chinese word embeddings.", "label": 1}
{"sent1": "We thus propose a Senseval-3 lexical sample activity where the training data is collected via Open Mind Word Expert.", "sent2": "The experiments also show that using propagated features in conjunction with lexicallyderived features only (as can be obtained directly from a mention annotated corpus) yields similar performance to using feature types derived from many linguistic resources.", "label": 0}
{"sent1": "Our system works with English collections and bilingual questions (English/Spanish).", "sent2": "This paper presents a Spanish Question Classifier based on machine learning, automatic online translators and different language features.", "label": 1}
{"sent1": "The resulting web QA system is evaluated on the German test collection from QA@CLEF 2004.", "sent2": "Several parameter settings and strategies for accessing the web search engine are investigated.", "label": 1}
{"sent1": "The system has been trained and evaluated for Spanish in the scope of the Spanish Geography.", "sent2": "We take only original text information as input feature, without using any syntactic knowledge.", "label": 0}
{"sent1": "TERSEO was first extended to English through the automatic translation of the temporal expressions.", "sent2": "Then, an improved porting process was applied to Italian, where the automatic translation of the temporal expressions from English and from Spanish was combined with the extraction of new expressions from an Italian annotated corpus.", "label": 1}
{"sent1": "parameterized comparison generation algorithm.", "sent2": "The new domain was based around music and performers, and texts about the domain were generated using Methodius.", "label": 1}
{"sent1": "If we arrive back at the same starting point i.e.", "sent2": "the same word in the source language, then we hypothesise that the meanings of the words in the chain have not diverged significantly.", "label": 1}
{"sent1": "The evaluation gives results that exceed previous state-of-the-art results for comparable systems.", "sent2": "We also demonstrate that a little manual effort can improve the quality of sense examples, as measured by WSD accuracy.", "label": 1}
{"sent1": "Unfortunately, we find that MONA is not an option.", "sent2": "There are several reasons why the main being unsustainable query answer times.", "label": 1}
{"sent1": "Initial experiments on a preliminary data set of 22 fairy tales show encouraging results over a na?", "sent2": "This paper revisits an assumption that genre variation is continuous along multiple dimensions, and an early use of principal component analysis to find these dimensions.", "label": 0}
{"sent1": "To test whether the approach can help us understand the domain better, we use graph structure learning algorithm to derive the causal relationships between different forms of evidence.", "sent2": "This paper presents the first study towards Turkish paraphrase alignment.", "label": 0}
{"sent1": "That is, the generative approach is better except when the annotators are highly accurate in which case simple majority vote is often sufficient.", "sent2": "Additionally, we present a novel mean-field variational inference algorithm for the generative model that significantly improves on the previously reported state-of-the-art for that model.", "label": 1}
{"sent1": "This integration increases robustness, directs the search space and hence reduces processing time of the deep parser.", "sent2": "In this paper, we focus on one of the central integration facilities, the XSLT-based Whiteboard Annotation Transformer (WHAT), report on the benefits of XSLT-based NLP component integration, and present examples of XSL transformation of shallow and deep annotations used in the integrated architecture.", "label": 1}
{"sent1": "Also, the range of languages and tasks being researched continues to grow rapidly.", "sent2": "The quantity of text now available for training and processing is increasing dramatically.", "label": 1}
{"sent1": "We defined a kernel function, namely the Domain Kernel, that allowed us to plug ?external knowledge?", "sent2": "Measured against a manually annotated corpus of source and derived news text, we show that a combined classi\fer with features automatically selected performs best overall for the ternary classi\fcation achieving an average F 1 -measure score of 0.664 across all three categories.", "label": 0}
{"sent1": "In previous work, we have developed hidden Markov model (HMM) and maximum entropy (Maxent) classifiers that integrate textual and prosodic knowledge sources for detecting sentence boundaries.", "sent2": "In this paper, we evaluate the use of a conditional random field (CRF) for this task and relate results with this model to our prior work.", "label": 1}
{"sent1": "Log-linear models allow statistical alignment models to be easily extended by incorporating syntactic information.", "sent2": "What is especially interesting is that we find strong, statistically significant gains on dependency recovery on out-of-domain tests (Brown vs. WSJ).", "label": 0}
{"sent1": "We automatically annotate training text with positive and negative examples of fact extractions and train Rote, Na?", "sent2": "Equipped with a probabilistic model and a large lexicon, the grammar has also been tested in widecoverage machine translation.", "label": 0}
{"sent1": "The reranking model makes use of syntactic features together with a parameter estimation method that is based on the perceptron algorithm.", "sent2": "This model makes simultaneous statistical judgments about the relations for a set of related entities.", "label": 0}
{"sent1": "The first step of the method is to parse the source language string that is being translated.", "sent2": "This paper addresses the task of constructing a timeline of events mentioned in a given text.", "label": 0}
{"sent1": "We show that both models improve performance on the word sense disambiguation task over previous unsupervised approaches, with the Concept model showing the largest improvement.", "sent2": "We also present a brief analysis of remaining errors.", "label": 0}
{"sent1": "In this paper, we present an unsupervised bootstrapping approach for WSD which exploits huge amounts of automatically generated noisy data for training within a supervised learning framework.", "sent2": "The method is evaluated using the 29 nouns in the English Lexical Sample task of SENSEVAL2.", "label": 1}
{"sent1": "This general framework allows us to accurately recover both grammatical and semantic information as well as non-local dependencies.", "sent2": "The method is based on graph rewriting using memorybased learning, applied to dependency structures.", "label": 1}
{"sent1": "We show that we can use word clusters for learning rules, and significantly improve on a baseline with only slightly worse performance than for standard POS-tags on an English?German translation task.", "sent2": "We also show that for an all words WSD task this automatic method is best focussed on words that are salient to the domain, and on words with a different acquired predominant sense in that domain compared to that acquired from a balanced corpus.", "label": 0}
{"sent1": "The regression model uses a variety of indicative features and is trained discriminatively to minimize the distance between the estimated and the ground truth bigram frequency in the reference summary.", "sent2": "During testing, the sentence selection problem is formulated as an ILP problem to maximize the bigram gains.", "label": 1}
{"sent1": "In order to handle the subtree extraction problem, we investigate a new class of submodular maximization problem, and a new algorithm that has the approximation ratio 12(1 ?", "sent2": "Along came statistical approaches, which use large corpora to directly guide translations toward expressions people would actually say.", "label": 0}
{"sent1": "We begin by presenting the notion of ?almost everywhere tight grammars?", "sent2": "and show that linear CFGs follow it.", "label": 1}
{"sent1": "However, most previous approaches to bilingual tagging assume word alignments are given as fixed input, which can cause cascading errors.", "sent2": "We observe that NER label information can be used to correct alignment mistakes, and present a graphical model that performs bilingual NER tagging jointly with word alignment, by combining two monolingual tagging models with two unidirectional alignment models.", "label": 1}
{"sent1": "In this paper we aim to solve a new problem of resolving entity morphs to their real targets.", "sent2": "We exploit temporal constraints to collect crosssource comparable corpora relevant to any given morph query and identify target candidates.", "label": 1}
{"sent1": "temporal and dyad dependence?to infer latent event classes.", "sent2": "We quantitatively evaluate the model?s performance on political science benchmarks: recovering expert-assigned event class valences, and detecting real-world conflict.", "label": 1}
{"sent1": "Our system expands tokens in a tweet with semantically similar expressions using a large novel distributional thesaurus and calculates the semantic relatedness of the expanded tweets to word lists representing positive and negative sentiment.", "sent2": "We present a sentiment classification system that participated in the SemEval 2014 shared task on sentiment analysis in Twitter.", "label": 1}
{"sent1": "In this work we try to push the approach to the limit, working not on the level of words, but treating both the source and target sentences as a string of letters.", "sent2": "We try to find out if a nearly unmodified state-of-the-art translation system is able to cope with the problem and whether it is capable to further generalize translation rules, for example at the level of word suffixes and translation of unseen words.", "label": 1}
{"sent1": "These properties of variant transduction arise from combining techniques for paraphrase generation, classi\fcation, and examplematching.", "sent2": "No intermediate semantic representations are involved in the speci\fcation, and the con\frmation requests used in the dialog are constructed automatically.", "label": 1}
{"sent1": "Conversational context for multiple concurrent activities is represented using a ?Dialogue Move Tree?", "sent2": "Significant improvement over traditional word alignment techniques is shown as well as improvement on several machine translation tests.", "label": 0}
{"sent1": "Similarly, a verb?s form within a particular binyan is determined both by default rules and by overriding rules specific to individual verbs.", "sent2": "Our result is a concise set of rules defining the morphology of all strong verbs in all binyanim.", "label": 1}
{"sent1": "Previous statistical approaches for automatic word spacing have used models that make use of inaccurate probabilities because they do not consider the previous spacing state.", "sent2": "However, most approaches to representation learning for lexical semantics assign a single vector to every surface word type.", "label": 0}
{"sent1": "We demonstrate the utility of the annotations that result in two ways.", "sent2": "In this paper we argue that existing general purpose approaches usually only focus on one of two issues related to the difficulties faced by adaptation: 1) difference in base feature statistics or 2) task differences that can be detected with labeled data.", "label": 0}
{"sent1": "In order to select the most suitable tag and arc from the proposed ones, we use several ensemble techniques, the result of which is a valid dependency tree.", "sent2": "In our experiments we use state-of-the-art taggers and dependency parsers to obtain an extended version of the treebank for Bulgarian, BulTreeBank, which, in addition to the standard CoNLL fields, contains predicted morphosyntactic tags and dependency arcs for each word.", "label": 1}
{"sent1": "German is not exceptional in this regard, as other morphologically-rich languages such as Czech, Tamil or Greek, offer similar challenges that make context-free constituent parsing less attractive.", "sent2": "The particular values of the categories are sorted according to a frequency ratio.", "label": 0}
{"sent1": "While we find that co-training and word clusters produce the most promising results, there is little additive improvement when combining the two techniques, which suggests that in the absence of large grammatical discrepancies between the training and test domains, they address largely the same problem, that of unknown vocabulary, with word clusters being a somewhat more effective solution for it.", "sent2": "Our highest results were achieved by a combination of word clusters and co-training, significantly improving on the baseline, by up to 1.67%.", "label": 1}
{"sent1": "Evaluation on a small test set of student data shows improvement over the baseline, both by training on native or non-native text.", "sent2": "Temporal evidence classification, i.e., finding associations between temporal expressions and relations expressed in text, is an important part of temporal relation extraction.", "label": 0}
{"sent1": "the transcriptions for sentence parsing, resulting in a 25% improvement in parse success rate by completely cleaning the texts of disfluencies and errors.", "sent2": "We discuss the need to adapt existing NLP technology to non-canonical domains such as spoken learner language, while emphasising the worth of continued integration of manual and automatic annotation.", "label": 1}
{"sent1": "In this work, we propose a novel method for obtaining more details about actual translation errors in the generated output by introducing the decomposition of Word Error Rate (WER) and Position independent word Error Rate (PER) over different Partof-Speech (POS) classes.", "sent2": "Furthermore, we investigate two possible aspects of the use of these decompositions for automatic error analysis: estimation of inflectional errors and distribution of missing words over POS classes.", "label": 1}
{"sent1": "Finally, a post-processing step is applied to ?correct?", "sent2": "Later, for better estimation of labels, Conditional Random Fields (CRFs) are used with previously learned chunk and several dependency and morphosyntactic features.", "label": 1}
{"sent1": "We first used an SVM classifier with a wide range of features, including bag of word features (unigram, bigram), POS features, stylistic features, readability scores and other statistics of the tweet being analyzed, domain names, abbreviations, emoticons in the Twitter text.", "sent2": "Then we investigated the effectiveness of these features.", "label": 1}
{"sent1": "In this paper we present a new cheap and fast methodology that allows fast experiment building and evaluation with fully-automated analysis at a low cost.", "sent2": "We present a comparative study of transition-, graph- and PCFG-based models aimed at illuminating more precisely the likely contribution of CFGs in improving Chinese dependency parsing accuracy, especially by combining heterogeneous models.", "label": 0}
{"sent1": "Besides obvious instances, where the same word appears with different polarities in different dictionaries, the dictionaries exhibit complex cases, which cannot be detected by mere manual inspection.", "sent2": "The dictionaries have substantial inaccuracies.", "label": 1}
{"sent1": "In this paper we focus on the discovery of temporal footprints from encyclopaedic descriptions.", "sent2": "Finding the overall opinion in a text can be challenging to both human readers and computers alike.", "label": 0}
{"sent1": "We present an automated approach that is based on the hypothesis that if two sentences are a) found in the same cluster of news articles and b) contain temporal expressions that reference the same point in time, they are likely to refer to the same event.", "sent2": "We employ Laplacian Eigenmaps (LE) to project the latent topic distributions into low-dimensional semantic representations while preserving the intrinsic local geometric structure.", "label": 0}
{"sent1": "Propositional Knowledge Graphs (PKG).", "sent2": "To address these limitations, we propose in this position paper a novel representation for ID ?", "label": 1}
{"sent1": "It is an effective approach to reduce feature dimensionality and feature sparseness which are clearly useful for many NLP applications.", "sent2": "This paper proposes an unsupervised label propagation algorithm (Un-LP) for word clustering which uses multi-exemplars to represent a cluster.", "label": 1}
{"sent1": "A number of such words are identified that often appear in impressive sentences, including jinsei (human life), hitobito (people), koufuku (happiness), yujou (friendliness), seishun (youth), and ren?ai (love).", "sent2": "Impressive sentences in Japanese are collected and examined for characteristic words.", "label": 1}
{"sent1": "We present the model and implementations for both English and German, and give evaluation results for both implementations.", "sent2": "We then examine how far the approach can account for the different break patterns which are associated with slow, normal and fast speech rates.", "label": 1}
{"sent1": "We present a model that predicts German nominal compounds by splitting them into their modifier and head components, instead of trying to predict them as a whole.", "sent2": "The model is improved further by the use of class-based modifierhead bigrams constructed using semantic classes automatically extracted from a corpus.", "label": 1}
{"sent1": "The proposed multimedia summarization works upon a multimodal document that consists of a video, keyframes of scenes, and transcripts of the scenes.", "sent2": "In this paper, we show how we already adapted it to other very different lexical databases.", "label": 0}
{"sent1": "We also describe robust processing within the framework of HPSG.", "sent2": "It works efficiently, and gives more informative results because it maximizes the amount of information in the result, while other default unification maximizes it in the default.", "label": 1}
{"sent1": "First, it specifically optimizes model weights for downstream consensus decoding procedures.", "sent2": "Using two different versions of SentiWordNet and testing regression and classification models across tasks and datasets, our learning approach consistently outperforms the single metrics, providing a new state-ofthe-art approach in computing words?", "label": 0}
{"sent1": "Accurate results (93.0%) are achieved in the special case of the mass-count distinction for nouns.", "sent2": "We demonstrate the applicability of our model on three diverse tasks: a new color description task, a new financial news task and an established direction-following task.", "label": 0}
{"sent1": "Such functions introduce new objects in the discourse context, that have to be taken into account in classical contextual processing tasks, such as reference resolution or question answering.", "sent2": "We present our machine learning system which utilizes lexical, syntactical and semantic based feature sets.", "label": 0}
{"sent1": "The main feature of this method is that it can be applied to different languages without requiring major modifications.", "sent2": "Question retrieval in cQA archives aims to find the existing questions that are semantically equivalent or relevant to the queried questions.", "label": 0}
{"sent1": "Although the reuse of text by journalists has been studied in linguistics, we are not aware of any investigation using existing computational methods for this particular task.", "sent2": "We find that a large improvement is achieved with one word lookahead, but that more lookahead results in relatively small additional improvements.", "label": 0}
{"sent1": "However, with an effectively limitless quantity of text available, extraction rate and representation size need to be considered.", "sent2": "Given fixed training time and computational resources, it makes sense for systems to invest time in extracting high quality contextual information from a fixed corpus.", "label": 1}
{"sent1": "Since lexical hierarchies are not necessarily ideally suited for this task, we also pose the question: how far down the hierarchy must the algorithm descend before all the terms within the subhierarchy behave uniformly with respect to the semantic relation in question?", "sent2": "The PC task continues as an open challenge with data, resources and tools available from http://2013.bionlp-st.org/", "label": 0}
{"sent1": "The model combines full and partial parsing techniques to reach full grammar coverage on unseen data.", "sent2": "The treebank annotations are used to provide partially labeled data for discriminative statistical estimation using exponential models.", "label": 1}
{"sent1": "This is exactly the kind of problem which can be solved by dynamic programming over graphical models.", "sent2": "?", "label": 1}
{"sent1": "As the model size becomes huge in a practical setting, and the decoder considers multiple syntactic structures for each word alignment, several pruning techniques are necessary.", "sent2": "We also introduce a model of the diversity of ideas, topic entropy, using it to show that COLING is a more diverse conference than ACL, but that both conferences as well as EMNLP are becoming broader over time.", "label": 0}
{"sent1": "For a language like English, it is often feasible to match most of those conditions, but in low-resource languages, it presents a problem.", "sent2": "The Named Entity Recognition (NER) task has been garnering significant attention in NLP as it helps improve the performance of many natural language processing applications.", "label": 0}
{"sent1": "Since people in different languages may express implicit opinions in different ways, in this work we investigate implicit opinions expressed via goodFor/badFor events in Chinese.", "sent2": "The positive results have provided evidences that such implicit opinions and inference rules are similar in Chinese and in English.", "label": 1}
{"sent1": "The polarity preference of a word, here an adjective, reflects the distribution of positive, negative and neutral arguments the word takes (here: its nominal head).", "sent2": "Candidates are generated on the basis of polarity preferences of adjectives derived from a large domain-independent corpus.", "label": 1}
{"sent1": "Our system detects the aspect terms with Fmeasure 68.65% and their polarities with accuracy 66.27%.", "sent2": "Experiments reveal empirically that a relatively small amount of data is sufficient and can potentially be further reduced through specific selection criteria.", "label": 0}
{"sent1": "After implementing M2 as a scorer in the Moses tuning framework, we investigate interactions of dense and sparse features, different optimizers, and tuning strategies for the CoNLL-2014 shared task.", "sent2": "We notice erratic behavior when optimizing sparse feature weights with M2 and offer partial solutions.", "label": 1}
{"sent1": "The agreements are regarded as a set of valuable constraints for regularizing the learning of both models on unlabeled data.", "sent2": "Several statistical approaches have been reported in the literature.", "label": 0}
{"sent1": "Using our transfer learning method we improve baseline NMT models by an average of 5.6 BLEU on four low-resource language pairs.", "sent2": "We also introduce a LWFG parser as a deductive system, used as an inference engine during LWFG induction.", "label": 0}
{"sent1": "In this paper, we present a clustering method that exploits the two-part question-answer structure in QA datasets to improve clustering quality.", "sent2": "Clustering of QA datasets from CQA systems provides a means of organizing the content to ease tasks such as manual curation and tagging.", "label": 1}
{"sent1": "Our proposed neural network models the interactions among all input components using syntactic and semantic embeddings, lexical matching, and domain-specific features.", "sent2": "Discourse markers (DMs) are ubiquitous cohesive devices used to connect what is said or written.", "label": 0}
{"sent1": "The evaluation is conducted using two corpora: the Prague Dependency Treebank and Czech National Corpus.", "sent2": "Given that some revisions are unavoidable, we next present a pair of methods for predicting the stability and accuracy of ISR results.", "label": 0}
{"sent1": "For semantic role labelling, each argument of the noun-verb complex predicate must be given a role label.", "sent2": "By comparing our framework with that of existing resources, including VerbNet and FrameNet, we demonstrate that our extended LCS framework can give a formal definition of semantic role labels, and that multiple roles of arguments can be represented strictly and naturally.", "label": 0}
{"sent1": "This paper investigates examples of the phonological variable of consonant cluster reduction in Twitter.", "sent2": "Does phonological variation get transcribed into social media text?", "label": 1}
{"sent1": "In this paper, we attempt to model lexical information in a context sensitive manner, encoding our belief that the use of language depends on the participants in the conversation.", "sent2": "With the evolution of online communication methods, conversations are increasingly handled via email, internet forums and other such methods.", "label": 1}
{"sent1": "The system employs a number of preprocessing steps and machine learning classifiers for correction of determiner and preposition errors in non-native English texts.", "sent2": "By describing the modules of an online application, we would like to outline how a linguistic tool can help the linguist.", "label": 0}
{"sent1": "The second pair of classifiers determines which is the most likely correction given a masked determiner or preposition.", "sent2": "The hyperparameters that govern the classifiers are optimized on the shared task training data.", "label": 1}
{"sent1": "We propose here to complement previous efforts for ?cleaning up?", "sent2": "N-best hypotheses from recognizers are rescored by additional scores that measure the correlation of the pitch-accent patterns between the acoustic signal and lexical cues.", "label": 0}
{"sent1": "Many such approaches learn semantics from large corpora, with each document considered to be unstructured bags of words, ignoring syntax and compositionality within a document.", "sent2": "Distributed models of semantics assume that word meanings can be discovered from ?the company they keep.?", "label": 1}
{"sent1": "We designed this scheme to enable development of computational models of tutorial dialogues and to provide an intermediate representation suitable for question and tutorial act generation.", "sent2": "In this paper we describe DISCUSS, a dialogue move taxonomy layered over semantic representations.", "label": 1}
{"sent1": "Here we study semantic change at a finer-grained level, the decade, making use of recent newspaper corpora.", "sent2": "The two methods differ in the data they use for learning the hash functions - the first method uses a set of names in a given language/script whereas the second uses a set of bilingual names.", "label": 0}
{"sent1": "To facilitate learning and evaluation, our framework enriches a collection of role-play dialogues with additional training data, including paraphrases of user utterances, and multiple independent judgments by external referees about the best policy response for the character at each point.", "sent2": "We present a dialogue collection and enrichment framework that is designed to explore the learning and evaluation of dialogue policies for simple conversational characters using textual training data.", "label": 1}
{"sent1": "This corpus is composed of human-machine dialogues in the domain of hotel reservation and tourist information.", "sent2": "However, such a model could still make mistakes if its features favor a wrong entity type.", "label": 0}
{"sent1": "First we try to collect some semantic information by using Amazon?s Mechanical Turk (AMT).", "sent2": "We analyzed the effect of bilingual language models and show where they could help to better model the translation process.", "label": 0}
{"sent1": "Feasibility of this scheme is demonstrated with experiments using a domain of baseball news.", "sent2": "In order to automatically select useful domain-dependent P-A templates, statistical measures are introduced, resulting to a completely unsupervised learning of the information structure given a corpus.", "label": 1}
{"sent1": "Our proposed system achieves an F-score of 49.57% on the corpus used in the BioNLP?09 shared task, which is only two points lower than the best performing system by UTurku.", "sent2": "They are usually trained on humanannotated datasets, which are very costly due to its task-specific nature.", "label": 0}
{"sent1": "The currently best methods for this task are based on analyzing the dependency tree (DT) representation of sentences.", "sent2": "Yet existing semantic grammars fail to do so.", "label": 0}
{"sent1": "which relaxes these restrictions and leads to much wider entailment discovery.", "sent2": "Our system is truly end-to-end, requiring no feature engineering or data preprocessing, thus making it applicable to a wide range of sequence labeling tasks.", "label": 0}
{"sent1": "For terms not covered by the dictionary, we use transitive closure inference and reach an F-score of 0.91, close to a level sufficient for practical use.", "sent2": "Yet in practice, all implemented constraint-oriented parsing strategies still need to discriminate between ?important?", "label": 0}
{"sent1": "To this end, we have refined a recent dataset of biomolecular events extracted from text, and integrated these predictions with records from public gene databases.", "sent2": "With more than 20 million citations in PubMed, text mining provides the ideal tool for generating additional large-scale homology-based predictions.", "label": 1}
{"sent1": "The form of the lexicon, as well as the process of its semi-automatic creation is described.", "sent2": "the combination of words into larger units ?", "label": 0}
{"sent1": "The connectedness of the graph holds information about the different meanings of words that occur in the translations.", "sent2": "We present EpiReader, a novel model for machine comprehension of text.", "label": 0}
{"sent1": "In this paper, we describe a clinical question answering system that focuses on a class of commonly-occurring questions: ?What is the best drug treatment for X?", "sent2": "?, where X can be any disease.", "label": 1}
{"sent1": "In particular, we investigate two techniques ?", "sent2": "Our methods were developed by considering two operational dimensions: (1) information-gathering technique, and (2) granularity of the information.", "label": 1}
{"sent1": "One obstacle in developing methods for automatically interpreting ASNs is the lack of annotated data.", "sent2": "We tackle this challenge by exploiting cataphoric shell nouns (CSNs) whose construction makes them particularly easy to interpret (e.g., the fact that X).", "label": 1}
{"sent1": "We propose a scalable semi-supervised feature engineering approach.", "sent2": "Mitchell et al used a manually-acquired set of verbs as the basis for their semantic model; in this paper, we also consider automatically acquired feature-norm-like semantic representations.", "label": 0}
{"sent1": "The nonparametric Bayesian framework of adaptor grammars is extended to this richer grammar formalism to propose a probabilistic model that can learn word segmentation and morpheme lexicons, including ones with discontiguous strings as elements, from unannotated data.", "sent2": "This system predicts what a user is going to write as he is keying it in.", "label": 0}
{"sent1": "We implement and evaluate different unsupervised methods for learning event pairs that are likely to be CONTINGENT on one another.", "sent2": "We refine event pairs that we learn from a corpus of film scene descriptions utilizing web search counts, and evaluate our results by collecting human judgments of contingency.", "label": 1}
{"sent1": "In this approach, we train probabilities of lexical entry assignments to words in a target domain and then incorporate them into the original parser.", "sent2": "This paper describes an effective approach to adapting an HPSG parser trained on the Penn Treebank to a biomedical domain.", "label": 1}
{"sent1": "We introduce the supertagging probabilities as a reference distribution for the log-linear model of the probabilistic HPSG.", "sent2": "GF ?resource grammars?", "label": 0}
{"sent1": "The second pass is a traditional parser which works with the subgrammar and the input text.", "sent2": "A first pass computes a sub-grammar which is a specialized part of the large grammar selected by the input text and various filtering strategies.", "label": 1}
{"sent1": "These techniques are based on top-down backtracking search.", "sent2": "We achieve an F-score of 84.4% for task-A and 62.71% for task-B and the systems are ranked 3rd and 29th respectively.", "label": 0}
{"sent1": "By adopting second-order feature maps, the primal form of the perceptron produces models with comparable accuracy to more complex architectures, with no need for approximations.", "sent2": "Further gains in accuracy are obtained by designing features for parsing extracted from semantic annotations generated by a tagger.", "label": 1}
{"sent1": "Similarly, a user must follow step by step the instructions in order to reach the results expected.", "sent2": "In this paper, we explore facets of instructional texts: general prototypical structures, rhetorical structure and natural argumentation.", "label": 1}
{"sent1": "But the causes of these errors are diverse, and the extent to which the accuracy of generation over individual syntactic phenomena is unknown.", "sent2": "Evaluation metrics are usually reported as single averages across all possible types of errors and syntactic forms.", "label": 1}
{"sent1": "Our message classifier achieves an accuracy of 71.8%, compared with 52.8% from the most frequent class and 58.6% from a model based entirely on time expression features.", "sent2": "We first create a past, present, and future message classifier, engineering features and evaluating a variety of classification techniques.", "label": 1}
{"sent1": "task of replacing non-standard words with their standard counterparts.", "sent2": "In this work we build a taxonomy of normalization edits and present a study of normalization to examine its effect on three different downstream applications (dependency parsing, named entity recognition, and text-to-speech synthesis).", "label": 1}
{"sent1": "In this work, we propose different active learning techniques for interactive machine translation.", "sent2": "By performing 10-fold cross validation on the Timebank corpus, we achieved an F1 score of 59.61% based on the graphbased evaluation, which is 0.16 percentage points higher than that of the local approach.", "label": 0}
{"sent1": "How can we recognize that two CENTRAL PROPOSITIONS realize the same FACET of the argument?", "sent2": "State-of-the-art coreference systems underperform a simple classifier on our new dataset, motivating non-newswire data for future coreference research.", "label": 0}
{"sent1": "First, we generate potential spatial knowledge deterministically.", "sent2": "Second, we determine whether it can be inferred and a degree of certainty.", "label": 1}
{"sent1": "Then, we propose a novel model for representing word meaning in context based on this context representation.", "sent2": "The defined tasks for the framework are: the hypernym extraction from Internet texts for unknown terms delivered by the speech recognizer; the mapping of those and their hypernyms into ontological concepts and instances; and the following integration of them into the system?s ontology.", "label": 0}
{"sent1": "Our approach infers an ordering for adjectives with comparable performance to previous work, but also for adverbs with an accuracy of 71%.", "sent2": "We will discuss the content and format of the data releases and how the software and data can be used by other NLP researchers.", "label": 0}
{"sent1": "As an additional contribution, we provide a bootstrapping technique for identifying and tagging address terms in dialogue.", "sent2": "1", "label": 1}
{"sent1": "We analyze our proposed model both for its ability to capture word repetition via the cache and for its suitability as a language model for speech recognition and retrieval.", "sent2": "We then investigate quantitatively the contribution of this question classifier to a feature driven question answering system.", "label": 0}
{"sent1": "Whilst experimental results show strong performance in-domain it has been recognised that quality suffers when models are applied to heterogeneous text collections.", "sent2": "The alignment error rate which we achieve (AER = 0.5040) is significantly better (about 10% decrease in AER) than the alignment error rates of the state-of-art models (Och and Ney, 2003) (Best AER = 0.5518) on the English-Hindi dataset.", "label": 0}
{"sent1": "We note that although many contributions have been done on pattern ranking schemas, few explored the use of word-level semantic similarity.", "sent2": "Through this network we identify communities of vowels, which essentially reflect their patterns of co-occurrence across languages.", "label": 0}
{"sent1": "In order to minimize the manual re-annotation effort, we build on the recently introduced concept of aliasing complex predicates to existing PropBank rolesets which encompass the same meaning and argument structure.", "sent2": "We contrast different approaches on real examples, show that our estimates based on multiple derivations favor phrasal re-orderings that are linguistically better motivated, and establish that our larger rules provide a 3.63 BLEU point increase over minimal rules.", "label": 0}
{"sent1": "About 3.5 million pairwise alignments of Bulgarian phonetic dialect data are used to compare four algorithms with a manually corrected gold standard.", "sent2": "The algorithms evaluated include three variants of the Levenshtein algorithm as well as the Pair Hidden Markov Model.", "label": 1}
{"sent1": "Second, the language data is automatically analyzed and enriched, and language profiles are created from the enriched data.", "sent2": "Third, a search facility is provided to allow linguists to search the original data, the enriched data, and the language profiles in a variety of ways.", "label": 1}
{"sent1": "the GENIA corpus ?", "sent2": "tractable, we propose to split the non-entity class into sub-classes, using part-of-speech information.", "label": 1}
{"sent1": "Machine translation outputs in four different European languages were taken into account: English, Spanish, French and German.", "sent2": "Furthermore, SSE is a general framework.", "label": 0}
{"sent1": "We find that both models are competitive with regression models built over the scores of established MT evaluation metrics.", "sent2": "Strictly corpus-based measures of semantic distance conflate co-occurrence information pertaining to the many possible senses of target words.", "label": 0}
{"sent1": "than the best single system.", "sent2": "We present the results of corpus analysis which show a correlation between certain forms and possible readings, together with some indication of maximum likely distance between request and the utterance being clari\fed.", "label": 0}
{"sent1": "System combination experiments on the WMT09 test sets from five source languages to English are presented.", "sent2": "The best BLEU scores were achieved by combing the English outputs of three systems from all five source languages.", "label": 1}
{"sent1": "One method is adapted from POS tagging, the other is based on finite state transducers.", "sent2": "The UMLS contains a very rich lexicon while the promise of a NER system is to carry out contextsensitive tagging.", "label": 0}
{"sent1": "For some tasks, a system combination was used to generate a final hypothesis.", "sent2": "An additional English hypothesis was produced by combining all three final systems for translation into English.", "label": 1}
{"sent1": "A phrase from MEDLINE becomes a candidate term in the Metathesaurus if the following two requirements are met: 1) a demodified term created from this phrase is found in the terminology and 2) the modifiers removed to create the demodified term also modify existing terms from the terminology, for a given semantic category.", "sent2": "A manual review of a sample of candidate terms was performed.", "label": 1}
{"sent1": "suffers from serious performance degradation with the stemming-only query-term-to-text-word matching paradigm.", "sent2": "particularly in terms of derivation and (single-word) composition ?", "label": 1}
{"sent1": "Key characteristics of PASTAWeb are the seamless integration of the PASTA extraction results (templates) with WWWbased technology, the dynamic generation of WWW content from ?static?", "sent2": "data and the fusion of information extracted from multiple documents.", "label": 1}
{"sent1": "Experiments using technical documents show that such a classi\fer tends to treat features in a categorical manner.", "sent2": "This results in performance that is worse than when extracting sentences using a naive Bayes classi\fer.", "label": 1}
{"sent1": "Scope detection is done by gathering the tokens that occur within the scope of a negated DRS.", "sent2": "The result is a system that is fairly reliable for cue detection and scope detection.", "label": 1}
{"sent1": "As a part of the task, we have assembled the first dataset of graded relational similarity ratings across 79 relation categories.", "sent2": "Three teams submitted six systems, which were evaluated using two methods.", "label": 1}
{"sent1": "With the inferred latent topics, BiTAM models facilitate coherent pairing of bilingual linguistic entities that share common topical aspects.", "sent2": "Efficient variational approximation algorithms are designed for inference and parameter estimation.", "label": 1}
{"sent1": "In contrast, standard heuristics based on shallow pattern-matching give only a 3% improvement, showing that the notion of an informer is non-trivial.", "sent2": "There was a 14% improvement in performance when paraphrases were used for document retrieval.", "label": 0}
{"sent1": "Patterns are weighted by obtaining statistically estimated lower bounds on their precision for extracting word pairs from a given relation.", "sent2": "We build a broad-coverage sense tagger based on a nonparametric Bayesian topic model that automatically learns sense clusters for words in the source language.", "label": 0}
{"sent1": "At the core of the paper is the attempt to grade the similarity of two sentences by finding the maximal weighted bipartite match between the tokens of the two sentences.", "sent2": "The paper aims to come up with a system that examines the degree of semantic equivalence between two sentences.", "label": 1}
{"sent1": "Difference, intersection and distance (Euclidian, Manhattan and Jaccard) of N -grams were considered for constructing a feature vector which is further introduced in a support vector machine classifier which allows to construct a classification model.", "sent2": "We have counted the number of N grams for three types of textual entities (character, word and PoS tags) that exist in the pair of sentences from which we are interested in determining the judgment of textual entailment.", "label": 1}
{"sent1": "We tested various configurations of our system, focusing on various levels of hyperparameter optimisation and feature selection.", "sent2": "The system participated in the task for all five languages and obtained winning scores for four of them when asked to predict the best translation(s).", "label": 1}
{"sent1": "The second procedure aims at building a predictive model using as predictors MeanMaxSim and (transformed) lexical features describing the differences between each sentence of a pair.", "sent2": "Compared to the wordoverlap baseline, it has the advantage of taking into account the distributional similarity between words that are also involved in compositional models.", "label": 1}
{"sent1": "However, they can be very useful after extensive filtering in targeted paraphrasing of Czech reference sentences prior to the evaluation.", "sent2": "Parmesan first performs targeted paraphrasing of reference sentences, then it computes the Meteor score using only the exact match on these new reference sentences.", "label": 1}
{"sent1": "However, because BLEU computes a geometric mean of n-gram precisions, it often correlates poorly with human judgment on the sentence-level.", "sent2": "Syntax-based vector spaces are used widely in lexical semantics and are more versatile than word-based spaces (Baroni and Lenci, 2010).", "label": 0}
{"sent1": "We designate this metric as Automatic Evaluation of Machine Translation in which the Prize is Applied to a Chunkbased metric (APAC).", "sent2": "We demonstrate effectiveness on an entity and relation extraction system including both performance improvements and robustness to reductions in annotated data.", "label": 0}
{"sent1": "Various metrics exist for MT evaluation: BLEU (Papineni, 2002), METEOR (Alon Lavie, 2007), TER (Snover, 2006) etc., but are found inadequate in quite a few language settings like, for example, in case of free word order languages.", "sent2": "Until now, however, it has never been shown that search engines for common usage have a positive impact on writing performance.", "label": 0}
{"sent1": "In addition to some standard metrics, the two submissions take advantage of novel metrics that consider linguistic structures, lexical relationships, and semantics to compare both source and reference translation against the candidate translation.", "sent2": "We show how it can be applied both for resolving and producing REs.", "label": 0}
{"sent1": "It is a simple modification of the standard BLEU metric using a monolingual alignment of reference and test sentences.", "sent2": "The alignment is computed as a minimum weighted maximum bipartite matching of the translated and the reference sentence words with respect to the relative edit distance of the word prefixes and suffixes.", "label": 1}
{"sent1": "The tool provides facilities for general and target based opinion marking on different type of posts (i.e.", "sent2": "The approach induces a probabilistic CCG grammar that represents the meaning of individual words and defines how these meanings can be combined to analyze complete sentences.", "label": 0}
{"sent1": "Named entity disambiguation is challenging because entity mentions can be ambiguous and an entity can be referenced by different surface forms.", "sent2": "These non-verbal signals have tight temporal and semantic links to spoken content.", "label": 0}
{"sent1": "I propose to build discriminative SMT models using both tree-to-string and tree-to-tree approaches.", "sent2": "Many statistical translation models can be regarded as weighted logical deduction.", "label": 0}
{"sent1": "Facilitating communication via unordered message formulation, however, requires new methods of prediction.", "sent2": "We investigate the relationship between dialog length and task completion.", "label": 0}
{"sent1": "These costs, normally associated with human caregivers, can be mitigated to some extent given automated systems that mimic some of their functions.", "sent2": "By comparing our induced clusters to reference clusters generated from WordNet, we demonstrate that our method effectively identifies sense-based translation clusters and benefits from both monolingual and parallel corpora.", "label": 0}
{"sent1": "From these alignments, we automatically extract narrative recall scores which can then be used for diagnostic screening.", "sent2": "The new translation hash sampler enables us to scale elegantly to complex models (for the first time) and large vocabulary/corpora sizes.", "label": 0}
{"sent1": "Results on a Wall Street Journal (WSJ) task demonstrate that DNN LMs offer improvements over a single hidden layer NNLM.", "sent2": "Motivated by the success of DNNs in acoustic modeling, we explore deep neural network language models (DNN LMs) in this paper.", "label": 1}
{"sent1": "The goal of this paper is to exploit this parallelism in order to eliminate the main bottleneck in automatic Twitter translation, namely the lack of bilingual sentence pairs for training SMT systems.", "sent2": "Such communication often happens in parallel in different languages, e.g., microblog posts related to the same events of the Arab spring were written in Arabic and in English.", "label": 1}
{"sent1": "Experiments using in-domain and out-of-domain training on disparate corpora show that our system uniformly outperforms state-of-the-art supervised extract-based approaches.", "sent2": "This paper addresses a very specific problem that happens to be  common in health science research.", "label": 0}
{"sent1": "Our system is evaluated on four datasets used in a recent comprehensive Chinese word segmentation competition.", "sent2": "State-of-the-art performance is obtained.", "label": 1}
{"sent1": "These tags are used when the tagger hesitates between the different components of the ambiguous tags.", "sent2": "The ambiguity takes the form of ambiguous tags which denote subsets of the tagset.", "label": 1}
{"sent1": "In this paper, we employ an approach combining classifier weighting and SMOTE algorithm oversampling to improve verbal feedback prediction in Arabic, English, and Spanish dyadic conversations.", "sent2": "However, predicting verbal feedback across languages is challenging due to languagespecific differences, inter-speaker variation, and the relative sparseness and optionality of verbal feedback.", "label": 1}
{"sent1": "The predictions of individual features can then be combined according to their predictive strength, resulting in a model, whose parameters can be reliably and efficiently estimated.", "sent2": "Experimental results show that our approach is stable and flexible, and outperforms traditional tfidf methods.", "label": 0}
{"sent1": "from the original feature set used in supervised NLP systems.", "sent2": "Our labelled corpus for the task is composed of data from large scale evaluations completed over the span of several years.", "label": 0}
{"sent1": "We present a generative probabilistic modeling approach to building content distributions for use with statistical multi-document summarization where the syntax words are learned directly from the data with a Hidden Markov Model and are thereby deemphasized in the term frequency statistics.", "sent2": "The standard approach of using an a priori stopword list tends to result in both undercoverage, where syntactical words are seen as semantically relevant, and overcoverage, where words related to content are ignored.", "label": 1}
{"sent1": "It is based on a generation space in the form of a Hidden Markov Model (HMM).", "sent2": "Our factor graph model combines these detection confidences with probabilistic knowledge mined from text corpora to estimate the most likely subject, verb, object, and place.", "label": 0}
{"sent1": "We focus our attention on DMOZ, a popular Web directory, and propose two algorithms to infer such a model from its manually-curated hierarchy of categories.", "sent2": "While finegrained subjectivity annotations are rarely available, encouraging results have been obtained by modeling subjectivity as a latent variable.", "label": 0}
{"sent1": "We show that a simple discriminative classifier can learn with high accuracy which span-1 chart cells to close to phrase-level unary productions.", "sent2": "Furthermore, the results of these services are not comparable due to different formats.", "label": 0}
{"sent1": "We first remove lexical items from the treebanks and map part-of-speech tags into a common tagset.", "sent2": "We then train a language model on tag sequences in otherwise unlabeled target data and rank labeled source data by perplexity per word of tag sequences from less similar to most similar to the target.", "label": 1}
{"sent1": "The new addition to the algorithm shows a clear advantage in parsing speed.", "sent2": "Second, we present a bootstrapping technique that narrows down discrepancies between gold-standard and automatic parses used as features.", "label": 1}
{"sent1": "Syntax is exploited by means of tree kernels whereas lexical semantics is derived from heterogeneous resources, e.g.", "sent2": "In experiments in the SemEval-2015 TimeLine task we show that our distantly supervised approach matches the state-of-the-art performance while joint inference further improves on it by 3.2 F-score points.", "label": 0}
{"sent1": "This paper takes two popular IE algorithms ?", "sent2": "SVM and Perceptron ?", "label": 1}
{"sent1": "In this paper, we propose a unified definition for the notion of (formal) analogical proportion, which applies to a wide range of algebraic structures.", "sent2": "Future spoken interaction are required to be multilingual, understand and act on large scale knowledge bases in all its forms (from structured to unstructured).", "label": 0}
{"sent1": "This focuses the system on substrings having syntactic function, and yields clusterto-cluster transformation rules which enable the system to process unknown morphological forms of known words accurately.", "sent2": "A stem-weighting algorithm based on Hubs and Authorities is used to clarify ambiguous segmentation points.", "label": 1}
{"sent1": "Active learning has been shown to reduce the amount of labelled data required to train a supervised learner by selectively sampling more informative data points for human annotation.", "sent2": "As NLP becomes increasingly wide-spread and uses more data from social media, however, the situation has changed: the outcome of NLP experiments and applications can now have a direct effect on individual users?", "label": 0}
{"sent1": "Using this approach, we obtained an F-measure of 68.14% on the development set of the data provided for the CONLL-2005 shared task.", "sent2": "Efficiency is a prime concern in syntactic MT decoding, yet significant developments in statistical parsing with respect to asymptotic efficiency haven?t yet been explored in MT.", "label": 0}
{"sent1": "For each node of the tree, the model must predict a semantic role label, which is interpreted as the labelling for the corresponding syntactic constituent.", "sent2": "We define a random field over the structure of each sentence?s syntactic parse tree.", "label": 1}
{"sent1": "We apply this alignment model to both French-English and Romanian-English language pairs.", "sent2": "Moreover, the CRF has efficient training and decoding processes which both find globally optimal solutions.", "label": 1}
{"sent1": "For that purpose, we define ClueWeb InfoSimba, a cross-level similarity corpus-based metric.", "sent2": "Verb classes which integrate a wide range of linguistic properties (Levin, 1993) have proved useful for natural language processing (NLP) applications.", "label": 0}
{"sent1": "In addition, we utilize the RankBoost-based reranking algorithm to rerank the N-best outputs of the HMMbased tagger using various n-gram, morphological, and dependency features.", "sent2": "We present a method which, given a few words defining a concept in some language, retrieves, disambiguates and extends corresponding terms that define a similar concept in another specified language.", "label": 0}
{"sent1": "We describe the features used in each stage.", "sent2": "The parser first identifies dependencies using a deterministic parsing method and then labels those dependencies as a sequence labeling problem.", "label": 1}
{"sent1": "We participated in the CoNLL Shared Task-2007 and evaluated our system for ten languages.", "sent2": "Online training facilitates the use of high dimensional features without creating memory bottlenecks unlike the popular SVMs.", "label": 1}
{"sent1": "but are not translations of each other.", "sent2": "Theoretically, this may be justified as (discriminatively) minimizing an imputed empirical risk.", "label": 0}
{"sent1": "During the training, the parser was trained with these additional features in addition to these described in (McDonald et al., 2005).", "sent2": "In this paper we develop a story generator that leverages knowledge inherent in corpora without requiring extensive manual involvement.", "label": 0}
{"sent1": "We highlight the properties of our statistical framework, which is based on conditional random fields (CRFs) and implemented as an efficient, publicly available toolkit.", "sent2": "Training data is created semiautomatically by aligning a parallel corpus of corrected medical reports and corresponding transcripts generated via automatic speech recognition.", "label": 1}
{"sent1": "However, there has been little work on reducing the manual effort involved in building high-quality, complex regular expressions for information extraction tasks.", "sent2": "Regular expressions have served as the dominant workhorse of practical information extraction for several years.", "label": 1}
{"sent1": "Second, we relax the independence assumption and use a simple graphical model to rank documents according to their likelihood of belonging to the core.", "sent2": "Neural machine translation (NMT) models typically operate with a fixed vocabulary, but translation is an open-vocabulary problem.", "label": 0}
{"sent1": "Positive examples are taken from observed predicate-argument pairs, while negatives are constructed from unobserved combinations.", "sent2": "We present a discriminative method for learning selectional preferences from unlabeled text.", "label": 1}
{"sent1": "The syntactic model is a projective parser using pseudo-projective transformations, and the semantic model uses global inference mechanisms on top of a pipeline of classifiers.", "sent2": "To tackle the problem of joint syntactic?semantic analysis, the system relies on a syntactic and a semantic subcomponent.", "label": 1}
{"sent1": "The MERS model combines local contextual information around rules and information of sub-trees covered by variables in rules.", "sent2": "Our method achieves an accuracy of around 70% on the paraphrase acquisition task.", "label": 0}
{"sent1": "Our annotation scheme makes clear distinctions between 4 types of it, providing guidelines for many erroneous cases.", "sent2": "Several statistical models are built for the classification of it, showing encouraging results.", "label": 1}
{"sent1": "selecting a representative set of citation sentences that highlight the contribution of the target paper).", "sent2": "Slot values can influence each other via a unification mechanism.", "label": 0}
{"sent1": "When evaluated on DUC 2004-2007 corpora, we obtain better than existing state-of-art results in both generic and query-focused document summarization.", "sent2": "Lastly, we show that several well-established methods for document summarization correspond, in fact, to submodular function optimization, adding further evidence that submodular functions are a natural fit for document summarization.", "label": 1}
{"sent1": "Furthermore, we find that a small set of constraints is applicable across the domains, and that using domain-specific constraints can further improve performance.", "sent2": "1", "label": 1}
{"sent1": "This paper presents a novel approach for multi-instance learning with overlapping relations that combines a sentence-level extraction model with a simple, corpus-level component for aggregating the individual facts.", "sent2": "We apply our model to learn extractors for NY Times text using weak supervision from Freebase.", "label": 1}
{"sent1": "We present ConceptResolver, a component for the Never-Ending Language Learner (NELL) (Carlson et al, 2010) that handles both phenomena by identifying the latent concepts that noun phrases refer to.", "sent2": "Focusing on Italian MWEs containing at least one adjective, we set out to explore how candidate POS-patterns listed in relevant literature and lexicographic sources compare with POS sequences exhibited by statistically significant n-grams including an adjective position extracted from a large corpus of Italian.", "label": 0}
{"sent1": "We propose a semisupervised approach for training NMT models on the concatenation of labeled (parallel corpora) and unlabeled (monolingual corpora) data.", "sent2": "A challenging problem with typology-based phylogenetic inference is that the changes of typological features over time are less intuitive than those of lexical features.", "label": 0}
{"sent1": "Unlike prior work, which first learns the embeddings from parallel data and then plugs them in a supervised learning problem, our approach is oneshot: a single optimization problem combines a co-regularizer for the multilingual embeddings with a task-specific loss.", "sent2": "A failure analysis points out factors that could contribute to improvements in both precision and recall, including pattern generalisation, pattern pruning, and term matching.", "label": 0}
{"sent1": "We use this framework to reinterpret an existing distributionalsemantic model (Word2Vec) as approximating an entailment-based model of the distributions of words in contexts, thereby predicting lexical entailment relations.", "sent2": "Using a mean-field approximation, we develop approximate inference procedures and entailment operators over vectors of probabilities of features being known (versus unknown).", "label": 1}
{"sent1": "Our model, CODE-NN , uses Long Short Term Memory (LSTM) networks with attention to produce sentences that describe C# code snippets and SQL queries.", "sent2": "In this paper, we present the first completely datadriven approach for generating high level summaries of source code.", "label": 1}
{"sent1": "In this paper, we describe our approaches used for sentiment analysis in twitter (task 9) organized in SemEval 2014.", "sent2": "Microblogging websites (such as Twitter, Facebook) are rich sources of data for opinion mining and sentiment analysis.", "label": 1}
{"sent1": "For Task-A, a CRF based sequencing algorithm was used to find different medical entities and a binary SVM classifier was used to find relationship between entities.", "sent2": "This allows us to go back and forth between the two representations, and define objective functions for the unsupervised learning of head assignments in terms of features of the implicit lexicalized tree grammars.", "label": 0}
{"sent1": "This paper discusses how the canonical isomorphism between tensors and multilinear maps can be exploited to simulate a full-blown quantifier-free predicate calculus using tensors.", "sent2": "The crowdsourced corpora will be made available in http://www.cs.cmu.edu/ ~lingwang/microtopia/.", "label": 0}
{"sent1": "In addition to soliciting papers from the research community, WMT also features a shared translation task for evaluating MT systems.", "sent2": "We show that previous approaches for global disambiguation can be improved, but even then the local disambiguation provides a baseline which is very hard to beat.", "label": 0}
{"sent1": "Recent work has shown that evaluation metrics that explicitly account for target language word order correlate better with human judgments of translation quality.", "sent2": "Reordering is a major challenge for machine translation between distant languages.", "label": 1}
{"sent1": "We used the ranking of these systems to measure how strongly automatic metrics correlate with human judgments of translation quality for 21 evaluation metrics.", "sent2": "This year featured a Haitian Creole to English task translating SMS messages sent to an emergency response service in the aftermath of the Haitian earthquake.", "label": 1}
{"sent1": "To remedy this, we attempt at approximating SemPOS using only tagger output and a few heuristics.", "sent2": "Term translation is of great importance for statistical machine translation (SMT), especially document-informed SMT.", "label": 0}
{"sent1": "Five different European languages are taken into account: English, Spanish, French, German and Czech.", "sent2": "First, we collect a data-set of 107 languages with known grapheme-phoneme relationships, along with a short text in each language.", "label": 0}
{"sent1": "Since MTeRater only assesses fluency, we build a meta-metric, MTeRaterPlus, that incorporates adequacy by combining MTeRater with other MT evaluation metrics and heuristics.", "sent2": "We show the effectiveness of online learning algorithms by evaluating them on several bug report datasets collected from open issue trackers associated with large open-source projects.", "label": 0}
{"sent1": "The adequacy component consists in: i) using ontologies to align predicates (verbs), ii) using semantic roles to align predicate arguments (core arguments and modifiers), and iii) matching predicate arguments using distributional semantics.", "sent2": "In this work, we present an approach for multilingual portability of Spoken Language Understanding systems.", "label": 0}
{"sent1": "We identify both linguistic features of the posts and features that capture the underlying relationships between posts and users.", "sent2": "In this paper, we propose a novel algorithm, called graph co-regularized non-negative matrix tri-factorization (GNMTF), from the geometric perspective.", "label": 0}
{"sent1": "Hypothesising a target NULL word is not without problems, however.", "sent2": "Most word alignment models assume a target NULL word from which they generate these untranslatable source words.", "label": 1}
{"sent1": "voting score for a comment is highly correlated with its metadata information such as published time and author reputation.", "sent2": "Several Feature Selection algorithms were employed.", "label": 0}
{"sent1": "(ii) Retrospective Learner is a new learning technique that adapts to the unlabeled target data.", "sent2": "Chinese named entities occur frequently in formal and informal environments.", "label": 0}
{"sent1": "The linear combination assumes that all the features are in a linear relationship and constrains that each feature interacts with the rest features in an linear manner, which might limit the expressive power of the model and lead to a under-fit model on the current data.", "sent2": "We here propose three different approaches to incorporate costs into the AL selection mechanism and evaluate them on the MUC7T corpus, an extension of the MUC7 newspaper corpus that contains such annotation time information.", "label": 0}
{"sent1": "These evaluations are performed using a novel set of syntactic features, including measures of complexity.", "sent2": "Our model produces a consistent output, where the named entity spans do not conflict with the phrasal spans of the parse tree.", "label": 0}
{"sent1": "We propose a new concept, sentiment relevance, to make this distinction and argue that it better reflects the requirements of sentiment analysis systems.", "sent2": "English and Czech.", "label": 0}
{"sent1": "In this paper, we present a novel approach which performs high quality filtering automatically, through modelling not just words but also users, framed as a bilinear model with a sparse regulariser.", "sent2": "Corry is a system for coreference resolution in English.", "label": 0}
{"sent1": "We firstly introduce a system based on supervised machine learning, which is strictly constrained and uses the training data as the only source of information.", "sent2": "This system is then extended by unsupervised methods for latent semantics discovery (LDA and semantic spaces) as well as the approach based on sentiment vocabularies.", "label": 1}
{"sent1": "The entire process required very little manual effort.", "sent2": "Recent years have seen a trend towards empirically motivated and more data-driven approaches in the field of referring expression generation (REG).", "label": 0}
{"sent1": "For the disorder mention normalization (Task B), variations of disorder mentions were considered whenever exact matches were not found in the training data or in the UMLS.", "sent2": "We demonstrate that even when these models are used as a mere preprocessing step for German-English translation, they significantly outperform Moses?", "label": 0}
{"sent1": "To distinguish between these query classes, we introduce novel metrics based on the entropy of the click distributions of individual searchers.", "sent2": "Previously proposed clickthrough-based metrics of query ambiguity tend to conflate informational and ambiguous queries.", "label": 1}
{"sent1": "?", "sent2": "We report on work in progress on extracting lexical simplifications (e.g., ?collaborate?", "label": 1}
{"sent1": "Since frequent batch retraining is computationally demanding we introduce a fast incremental alternative using an online version of the EM algorithm.", "sent2": "We show incorporating recent sentence pairs from the stream improves performance compared with a static baseline.", "label": 1}
{"sent1": "Furthermore, we compare a ML classifier with a Reinforcement Learning (RL) approach in simulation and using ratings from real student users.", "sent2": "We show that this method generates output closer to the feedback that lecturers actually generated, achieving 3.5% higher accuracy and 15% higher F-score than multiple simple classifiers that keep a history of selected templates.", "label": 1}
{"sent1": "While dynamic programming is viable for bigram-based sentence compression, finding optimal compressed trees within graphs is NP-hard.", "sent2": "We explore instead the use of Lagrangian relaxation to decouple the two subproblems and solve them separately.", "label": 1}
{"sent1": "A social-elimination game called Killer Game is introduced as a case study 1 .", "sent2": "We propose a novel subgroup detection method that combines linguistic signals and signed network analysis for dynamic clustering.", "label": 1}
{"sent1": "Moreover, we have introduced a regression model that boosts the observations of word cooccurrences used in the context-based projection method.", "sent2": "Within this context, we have carried out a study on the influence of unbalanced specialized comparable corpora on the quality of bilingual terminology extraction through different experiments.", "label": 1}
{"sent1": "To evaluate the performance of the acquired causeeffect terms, we conduct three evaluations: (1) human-based, (2) comparison with existing knowledge bases and (3) application driven (SemEval-1 Task 4) in which the goal is to identify the relation between pairs of nominals.", "sent2": "We then translated this dataset to English using Google Translate and Bing Translator.", "label": 0}
{"sent1": "Second, the WSD predictions are used to build a supplementary language model for each sentence, aimed to favor translations that seem more adequate in this specific sentential context.", "sent2": "Both approaches lead to significant improvements in translation performance, highlighting the usefulness of source side disambiguation for SMT.", "label": 1}
{"sent1": "In particular this contribution is targeted towards tackling the poor performance of a state-of-the-art system on negated sentences.", "sent2": "The corpus expansion is achieved by high quality rephrasing of existing sentences to their negated counterparts making use of semantic transfer.", "label": 1}
{"sent1": "Our contributions include new tunable metrics, an improved beam search strategy, an n-best extraction method that increases suggestion diversity, and a tuning procedure for a hierarchical joint model of alignment and translation.", "sent2": "1", "label": 0}
{"sent1": "It tends to ignore past alignment information, however, which often leads to over-translation and under-translation.", "sent2": "A compositional-semantics procedure is then used to map the augmented parse tree into a final meaning representation.", "label": 0}
{"sent1": "First, a text classifier built using topic distribution vectors is used to assign content from the web to various sections on a Wikipedia article.", "sent2": "In this framework, the knowledge of a human translator is combined with a MT system.", "label": 0}
{"sent1": "The concept of fuzzy matching allows matching of sequences that contain textual fragments and known XML elements independently of how concurrent annotations and original markup are merged.", "sent2": "We show that approximate inference in BAYESUM is possible on large data sets and results in a stateof-the-art summarization system.", "label": 0}
{"sent1": "We propose a probabilistic approach to generating code-mixed text as an L2 technique for increasing retention in adult lexical learning through reading.", "sent2": "A vast majority of L1 vocabulary acquisition occurs through incidental learning during reading (Nation, 2001; Schmitt et al., 2001).", "label": 1}
{"sent1": "guage  of  blogs  is  not  restricted  to  the  more  informal  levels  of  expression.", "sent2": "Preliminary  surveys  show  that  the  lan?", "label": 1}
{"sent1": "Data are stored in a XML repository, so as to use the capabilities of this language.", "sent2": "Moreover, we introduce bidirectional recurrent neural models to the problem of machine translation, allowing us to use the full source sentence in our models, which is also of theoretical interest.", "label": 0}
{"sent1": "The rules are then used for generating new sentence pairs.", "sent2": "An SVM classifier is built to filter the generated sentence pairs.", "label": 1}
{"sent1": "We built five classifiers with English as an input language and translations in the five supported languages (viz.", "sent2": "Experimental results demonstrate that our approach outperforms state-of-the-art methods for both opinion expression tasks.", "label": 0}
{"sent1": "It is inattentive to structure.", "sent2": "Since many automated proficiency scoring systems use fluency features such as speaking rate as one of the important features, students may engage in strategies designed to manipulate their speaking rate as measured by the system.", "label": 0}
{"sent1": "With this work we want to draw attention  to this fact.", "sent2": "Whereas they are expected  to be of a very high quality because of their  importance  for  the  followup  developments,  they still contain a considerable number of errors.", "label": 1}
{"sent1": "We focus especially on abstract concepts and emotions to show that even they tend to have strong colour associations.", "sent2": "A wordchoice question was used to obtain sense-level annotations and to ensure data quality.", "label": 1}
{"sent1": "We compare the performance when using features extracted from automatically generated annotations against that when using human annotations.", "sent2": "Named entity disambiguation concerns linking a potentially ambiguous mention of named entity in text to an unambiguous identifier in a standard database.", "label": 0}
{"sent1": "Recent studies have shown that inversion transduction grammars are reasonable constraints for word alignment, and that the constrained space could be efficiently searched using synchronous parsing algorithms.", "sent2": "Experiment results on NIST ChineseEnglish test sets demonstrate that 1) our model significantly outperforms previous lexical selection methods and 2) modeling correlations between local words and global topics can further improve translation quality.", "label": 0}
{"sent1": "Second, the language models proposed are context aware, in the sense that they take into account the partial corrections and the source sentence by using a combination of ngrams and word-based IBM models.", "sent2": "First, HTR decoding is tightly coupled with the IMT system.", "label": 1}
{"sent1": "Using four years of data from the Text Analysis Conference, we analyze the performance of eight ROUGE variants in terms of accuracy, precision and recall in finding significantly different systems.", "sent2": "Our experiments show that some of the neglected variants of ROUGE, based on higher order n-grams and syntactic dependencies, are most accurate across the years; the commonly used ROUGE-1 scores find too many significant differences between systems which manual evaluation would deem comparable.", "label": 1}
{"sent1": "Each component contains a large set of features trained in a maximumentropy framework.", "sent2": "We model the feature space with a log-linear combination of multiple mixture components.", "label": 1}
{"sent1": "The annotations are provided with a well-defined model-theoretic interpretation for use in the content-based comparison of annotations.", "sent2": "For phrase-based models, recent work has shown that on-demand grammar extraction can be greatly accelerated by parallelization on general purpose graphics processing units (GPUs), but these algorithms do not work for hierarchical models, which require matching patterns that contain gaps.", "label": 0}
{"sent1": "We apply our method to the Dutch language.", "sent2": "The best results are achieved when using synonymy and antonymy relations only, and ranking positive and negative words simultaneously.", "label": 1}
{"sent1": "Existing statistical systems for MT often treat different derivatives of the same lemma as if they were independent of each other.", "sent2": "In this paper we argue that a better exploitation of the bilingual training data can be achieved by explicitly taking into account the interdependencies of the different derivatives.", "label": 1}
{"sent1": "Especially our newly developped method to perform a multi-pass A* search with an iteratively improved heuristic function allows us to translate even long sentences.", "sent2": "We develop various sophisticated admissible and almost admissible heuristic functions.", "label": 1}
{"sent1": "While the F-score is similar to the one of the first experiment (n-best parsing and reranking), the first experiment results in higher recall (75.48% vs. 73.69%) and the third one in higher precision (75.43% vs. 73.26%).", "sent2": "Providing the parser with different scope possibilities and reranking the resulting parses results in an increase in F-score from 69.76 for the baseline to 74.69.", "label": 1}
{"sent1": "The goal is to classify a phrase within a short piece of text as positive, negative or neutral.", "sent2": "In the evaluation, classifiers trained on Twitter data are tested on data from other domains such as SMS, blogs as well as sarcasm.", "label": 1}
{"sent1": "Taking this knowledge into account can be beneficial to disambiguate commands with multiple interpretations.", "sent2": "Moreover, our model performs better than syntactic models on datasets with high syntactic variance.", "label": 0}
{"sent1": "This paper presents a new agreement measure inspired by Kappa coefficient to compute inter-annotator reliability when the annotators have freedom to categorize a text into more than one class.", "sent2": "The extended reliability coefficient has been applied to measure the quality of an affective text corpus.", "label": 1}
{"sent1": "We describe how phrase orientation probabilities can be extracted from wordaligned training data for use with hierarchical phrase inventories, and show how orientations can be scored in hierarchical decoding.", "sent2": "RST offers a formal framework for hierarchical text organization with strong applications in discourse analysis and text generation.", "label": 0}
{"sent1": "We evaluate these models on two cross-lingual document classification tasks, outperforming the prior state of the art.", "sent2": "But while the two tasks are pretty similar, they differ in a fundamental respect: in EL the textual mention can be linked to a named entity which may or may not contain the exact mention, while in WSD there is a perfect match between the word form (better, its lemma) and a suitable word sense.", "label": 0}
{"sent1": "While there is of course substantial overlap in the content of the various schemes for these sentences, no one of the schemes is ideal.", "sent2": "Wall Street Journal sentences can serve as a useful basis for these negotations.", "label": 1}
{"sent1": "Not to mention that the 80% success rate of conversion is not meaningful for parsers that boast 90% accuracy.", "sent2": "This paper introduces Chart Inference (CI), an algorithm for deriving a CCG category for an unknown word from a partial parse chart.", "label": 0}
{"sent1": "In the supervised approach, we train classification algorithms on a summarized collection of documents with the purpose of inducing a keyword identification model.", "sent2": "Both our approaches are based on the graph-based syntactic representation of text and web documents, which enhances the traditional vector-space model by taking into account some structural document features.", "label": 1}
{"sent1": "derives the notion of negation scope assumed in this task from the structure of logical-form meaning representations.", "sent2": "We relate the task-specific interpretation of (negation) scope to the concept of (quantifier and operator) scope in mainstream underspecified semantics.", "label": 1}
{"sent1": "The automatic captioning procedure requires summarizing multiple web documents that contain information related to images?", "sent2": "This paper reports an initial study that aims to assess the viability of a state-of-the-art multi-document summarizer for automatic captioning of geo-referenced images.", "label": 1}
{"sent1": "We will explore supervised and unsupervised approaches motivated by distributional characterists of the specific domain and availability of data sets.", "sent2": "The task can be seen as a special case of a more general Information Extraction problem: to classify short text snippets in various languages into a large number of classes.", "label": 1}
{"sent1": "Here, a new method based on using a statistical machine translation system has been introduced to mitigate the effects of data sparsity for training classifiers.", "sent2": "In this paper, we describe an efficient A* search algorithm for statistical machine translation.", "label": 0}
{"sent1": "Many techniques for simulating users and errors have been proposed for use in improving and evaluating spoken dialog systems, but most of them are not easily applied to various dialog systems or domains because some are limited to specific domains or others require heuristic rules.", "sent2": "This paper presents an N-best reranking method based on keyphrase extraction.", "label": 0}
{"sent1": "In addition to the symmetrization, we introduce a smoothed lexicon model.", "sent2": "The standard lexicon model is based on full-form words only.", "label": 1}
{"sent1": "However, existing uncertainty cues are ineffective in social media context because of its specific characteristics.", "sent2": "We propose a probabilistic model to learn the subword lexicon optimized for a given task.", "label": 0}
{"sent1": "In this paper we describe the design and evaluation of a FAQ retrieval engine for Croatian.", "sent2": "Unlike general purpose retrieval engines, FAQ retrieval engines have to address the lexical gap between the query and the usually short answer.", "label": 1}
{"sent1": "Because the gold dependency information is usually annotated only on transcribed texts, we also introduce an alignment-based method for transferring the gold dependency annotation to the ASR output texts to construct training data for our parser.", "sent2": "In this work, we propose a parsing method that handles both disfluency and ASR errors using an incremental shift-reduce algorithm with several novel features suited to ASR output texts.", "label": 1}
{"sent1": "and answer to the user while being aware of their emotion and intent.", "sent2": "We propose a surprisingly effective Occam?s razor automation of HMEANT that combines standard shallow semantic parsing with a simple maximum weighted bipartite matching algorithm for aligning semantic frames.", "label": 0}
{"sent1": "Consequently, we are participating only for the English/French and English/German language pairs.", "sent2": "We extend this approach to allow each block of text to be a mixture of multiple classes.", "label": 0}
{"sent1": "to infer which paragraphs are related to each other and form larger segments on a higher level.", "sent2": "We propose a novel method to predict the interparagraph discourse structure of text, i.e.", "label": 1}
{"sent1": "Unlike the state-of-the-art approaches, our model is language-independent and also neutral with respect to the intended use of the punctuation.", "sent2": "Translation into morphologically rich languages is an important but recalcitrant problem in MT.", "label": 0}
{"sent1": "We introduce SimpleScience, a lexical simplification approach for scientific terminology.", "sent2": "Although developed as part of a suite of tools aimed at providing question answering systems with information about both temporal and intensional relations among events, it can be used independently as an event extraction tool.", "label": 0}
{"sent1": "variables mapping, significantly outperforming baselines.", "sent2": "We apply this technique in the framework of label propagation and evaluate it on two different classification tasks, a multi-class lexicon acquisition task and a word sense disambiguation task.", "label": 0}
{"sent1": "To address this issue, we developed a hypergraph-based approach to account for group-based spatial relations and uncertainties in perceiving the environment.", "sent2": "Finally, we propose a refinement of our paraphrases by classifying them into natural logic entailment relations.", "label": 0}
{"sent1": "and ?X is from Y?)", "sent2": "into clusters corresponding to underlying semantic relation types (e.g., BornIn, Located).", "label": 1}
{"sent1": "To bring hope to ?tail?", "sent2": "We derive features from this graph structure?centrality, communities, and local flow of information.", "label": 0}
{"sent1": "(e.g., semantic role labeling?SRL).", "sent2": "(e.g., part-of-speech tagging) to ?deep?", "label": 1}
{"sent1": "Tree kernels applied to such structures enable a simple way to generate highly discriminative structural features that combine syntactic and semantic information encoded in the input trees.", "sent2": "Within this context, we have carried out a study on the influence of unbalanced specialized comparable corpora on the quality of bilingual terminology extraction through different experiments.", "label": 0}
{"sent1": "This massively multilingual encyclopedia makes it possible to create lexicons for a large number of language pairs.", "sent2": "The key idea is to formulate a joint optimization framework to learn latent user and item representations, with simultaneously learned social factors and latent topic variables.", "label": 0}
{"sent1": "We represent each document by a term-entity model and cluster the documents using a contextual similarity metric.", "sent2": "We propose an unsupervised algorithm that extracts such phrases from the Web.", "label": 1}
{"sent1": "We present a case study, studying the effect of combining the existing index terms of a paper with additional terms from papers citing that paper in our corpus.", "sent2": "Finally, we discuss the need for experimentation for the practical validation of our claim.", "label": 1}
{"sent1": "Focusing on this task, and still adhering to the rule-based framework, this paper presents a bunch of experiments on the automatic porting to Italian of a system originally developed for Spanish.", "sent2": "Different automatic rule translation strategies are evaluated and discussed, providing a comprehensive overview of the challenge.", "label": 1}
{"sent1": "It then describes a hybrid extraction system based on a multilingual parser.", "sent2": "This paper describes our system for participating SemEval2013 Task2-B (Kozareva et al., 2013): Sentiment Analysis in Twitter.", "label": 0}
{"sent1": "We begin with a formal characterization of lexical systems as ?pure?", "sent2": "directed graphs, solely made up of nodes corresponding to lexical entities and links.", "label": 1}
{"sent1": "The method is applicable to texts of any format, and not specific to HTML documents labeled with URLs.", "sent2": "This leads to smaller pools than traditional round robin pooling, thus reduces significantly the manual assessment workload.", "label": 0}
{"sent1": "Evaluating semantic relatedness measures is usually performed by comparison with human judgments.", "sent2": "Semantic relatedness is a special form of linguistic distance between words.", "label": 1}
{"sent1": "It has been evaluated on a test set composed of 1,000 translation units (TUs) randomly extracted from the English-Italian version of MyMemory, a large-scale public TM.", "sent2": "Results indicate its effectiveness in automatic removing ?bad?", "label": 1}
{"sent1": "We propose a discriminative, feature-rich approach using large-margin learning.", "sent2": "As an example, we use the task of information access in a multi-domain dialogue system.", "label": 0}
{"sent1": "Secondly our approach does not increase the decoding complexity.", "sent2": "We evaluate the proposed approach on English and Chinese data.", "label": 1}
{"sent1": "Paradigmatic lexical relations are explicitly captured by word clustering on large-scale unlabeled data and are used to design new features to enhance a discriminative tagger.", "sent2": "The core components of our translation systems are phrase based (Hindi-English) and factored (English-Hindi) SMT systems.", "label": 0}
{"sent1": "negation or hedging) and form a single system for document labeling and content shift detection.", "sent2": "The usefulness is investigated of the sequence of system question types and the word graphs corresponding to the respective user utterances.", "label": 0}
{"sent1": "a proof, while estimating the proof?s validity.", "sent2": "This raises a search challenge of finding the best possible proof.", "label": 1}
{"sent1": "Several computational cognitive models have explored aspects of this phenomenon, but their results are hard to compare given the high variability in the linguistic properties represented in their input.", "sent2": "Fifty instances of each target word were provided, consisting of a total of 2,500 instances for the evaluation.", "label": 0}
{"sent1": "Machine comprehension of unstructured, real-world text is a major research goal for natural language processing.", "sent2": "We present EpiReader, a novel model for machine comprehension of text.", "label": 1}
{"sent1": "We argue that a better approach is to look for answers that are related to the question in a relevant way, according to the information need of the question, which may be determined through task-specific embeddings.", "sent2": "With causality as a use case, we implement this insight in three steps.", "label": 1}
{"sent1": "This problem requires jointly interpreting a question and an environment using background knowledge to select the correct answer.", "sent2": "Situated question answering is the problem of answering questions about an environment such as an image or diagram.", "label": 1}
{"sent1": "To this end, we train two neural network models (an incremental one and a non-incremental one) on large amounts of automatically rolelabelled text.", "sent2": "Furthermore, such a model can be used to provide a probability distribution over fillers for a thematic role which is not mentioned in the text at all.", "label": 1}
{"sent1": "Based on our model, we derive a dynamic programming inference algorithm and an ExpectationMaximization style unsupervised learning algorithm.", "sent2": "We describe a mechanism for the interpretation of arguments, which can cope with noisy conditions in terms of wording, beliefs and argument structure.", "label": 0}
{"sent1": "Specifically, triples are represented as atomic formulae and modeled by the translation assumption, while rules represented as complex formulae and modeled by t-norm fuzzy logics.", "sent2": "The key idea is to represent and model triples and rules in a unified framework.", "label": 1}
{"sent1": "Specifically, we represent words in the space of discourse connectives as a way to directly encode their rhetorical function.", "sent2": "Our examples illustrate the usefulness of this feature, and our evaluation results show that the precision of Semantic Role Analysis is very high.", "label": 0}
{"sent1": "Such importance degree and text representation are calculated with multiple computational layers, each of which is a neural attention model over an external memory.", "sent2": "Recent work has proposed the use of an extracted tree grammar as the basis for treebank analysis and search queries, in which queries are stated over the elementary trees, which are small chunks of syntactic structure.", "label": 0}
{"sent1": "We will see, through classical visualization methodologies (Kruskal & Wish, 1977) and exhaustive experiments, that clustering may not be the best approach for automatic pattern identification.", "sent2": "We then describe an alternative kind of structural bias, toward ?broken?", "label": 0}
{"sent1": "This work aims at a middle way.", "sent2": "Our system finds a low-cost edit sequence which transforms the premise into the hypothesis; learns to classify entailment relations across atomic edits; and composes atomic entailments into a top-level entailment judgment.", "label": 1}
{"sent1": "The method builds a weighted graph of mentions and candidate entities, and computes a dense subgraph that approximates the best joint mention-entity mapping.", "sent2": "Features are the key to obtain an accurate question classifier.", "label": 0}
{"sent1": "We introduce here the Jena ANnotation Environment (JANE), a platform that supports the complete annotation lifecycle and allows for ?focused?", "sent2": "With ever-increasing demands on the diversity of annotations of language data, the need arises to reduce the amount of efforts involved in generating such value-added language resources.", "label": 1}
{"sent1": "The data in the corpus consists of the syntactic derivation tree of each sentence annotated with the full syntactic and pragmatic context, as well as the eye and eyebrow displays and rigid head motion used by the the speaker.", "sent2": "The corpus is based on a recording of a single speaker reading scripted output in the domain of the target generation system.", "label": 1}
{"sent1": "The markup is enhanced by a document-specific XSLT script which contains document-specific formatting instructions.", "sent2": "The overall maintenance is achieved by system-wide XSLT scripts.", "label": 1}
{"sent1": "tokenization requires a completely automatic approach.", "sent2": "unlike other work on MWUs ?", "label": 1}
{"sent1": "It also allows monolingual and bilingual searches including the specification of alignment constraints.", "sent2": "Our experiments show that the SWSD classifiers trained on the ICC generated data by requiring only 59% of the labels can achieve the same performance as the classifiers trained on the full dataset.", "label": 0}
{"sent1": "Accurate automatic recognition of these types of language can inform an analysis of document sentiment.", "sent2": "The framework describes a taxonomy of the types of language used to convey evaluation and position oneself with respect to the evaluations of other people.", "label": 1}
{"sent1": "Yawat is a tool to support distributed, manual word- and phrase-alignment of parallel text through an intuitive, web-based interface.", "sent2": "Kwipc is an interface for displaying words or bilingual word pairs in parallel, word-aligned context.", "label": 1}
{"sent1": "There have been research activities for building Japanese text corpora annotated with coreference and predicate-argument relations as are done in the Kyoto Text Corpus version 4.0 (Kawahara et al, 2002) and the GDATagged Corpus (Hasida, 2005).", "sent2": "sentences or tweets) into its hybrid loss function for learning sentiment-specific phrase embedding (SSPE).", "label": 0}
{"sent1": "The paper focusses on a methodology for treebank conversion which consists in splitting the process in steps corresponding to the kinds of information that have to be converted, i.e.", "sent2": "With the recent addition of internal noun phrase annotation, dependency parsing and applications down the NLP pipeline are likely affected.", "label": 0}
{"sent1": "Our experiments on the TAC-KBP 2010 data show that incorporating such contextual information indeed aids in disambiguating the named entities and consistently improves the entity linking performance.", "sent2": "We present a new semi-supervised training procedure for conditional random fields (CRFs) that can be used to train sequence segmentors and labelers from a combination of labeled and unlabeled training data.", "label": 0}
{"sent1": "The system relies on cross-linguistic evidence from a set of five Romance languages: Spanish, Italian, French, Portuguese, and Romanian.", "sent2": "In the TFIDF (term frequency, inverse document frequency) weighting framework, we incorporated partof-speech (POS) information, word clustering, and sentence salience score.", "label": 0}
{"sent1": "Building upon existing techniques designed to quantitatively analyze style and affect in texts, we examined elements of poetic craft such as diction, sound devices, emotive language, and imagery.", "sent2": "While it is generally accepted that many translation phenomena are correlated with linguistic structures, employing linguistic syntax for translation has proven a highly non-trivial task.", "label": 0}
{"sent1": "Our method, adapted from work in topic segmentation and plagiarism detection, predicts breaks based on a curve of stylistic change which combines information from a diverse set of features, most notably co-occurrence in larger corpora via reduced-dimensionality vectors.", "sent2": "Eliot, which is traditionally analyzed in terms of numerous voices which appear throughout the text.", "label": 1}
{"sent1": "Our online models build character-level PAT trie structures on the fly using heavily data-unfolded implementations of an mutable daughter maps with a long integer count interface.", "sent2": "We describe the implementation steps required to scale high-order character language models to gigabytes of training data without pruning.", "label": 1}
{"sent1": "The paper describes the non-trivial issues of the compilation process, highlighting several shortcomings of some published algorithms, especially where replace rules are concerned.", "sent2": "Compilation to FSA facilitates the use of grammars developed with the proprietary XFST toolbox on a publicly available platform.", "label": 1}
{"sent1": "We investigate this using simple generic Bracketing ITGs containing no language-specific linguistic knowledge.", "sent2": "We design a comma predictor for general Chinese text based on conditional random field models with linguistic features.", "label": 0}
{"sent1": "To construct the data for training and testing, we extracted acronym-definition pairs from MEDLINE abstracts and manually annotated each pair with positional information about the letters in the acronym.", "sent2": "We formalize the generation process as a sequence labeling problem on the letters in the definition (expanded form) so that a variety of Markov modeling approaches can be applied to this task.", "label": 1}
{"sent1": "All data have been updated with original MEDLINE text excerpts, PubMed identifiers, and tokenization independence to facilitate data accuracy, consistency and usability.", "sent2": "The MedPost corpus has been updated to include 1,000 additional sentences from the clinical medicine domain.", "label": 1}
{"sent1": "The paper proposes a probabilistic approach to the task, which is both accurate and efficient.", "sent2": "These two level features are concatenated to form the final extracted feature vector.", "label": 0}
{"sent1": "One way to tackle this problem is to train a generative model with latent variables on the mixture of data from the source and target domains.", "sent2": "Utterances in dialogues have been previously annotated with a concept-value flat semantics for studying and evaluating spoken language understanding modules in dialogue systems.", "label": 0}
{"sent1": "Association is modeled using a query entity click graph, blending general query click logs with vertical query click logs.", "sent2": "We present a sentiment classification system that participated in the SemEval 2014 shared task on sentiment analysis in Twitter.", "label": 0}
{"sent1": "This method can efficiently estimate query importance by compressing query data, but the potential risk is information loss resulted from the compression.", "sent2": "The development and proliferation of social media services has led to the emergence of new approaches for surveying the population and addressing social issues.", "label": 0}
{"sent1": "Furthermore, using feature augmentation and selection according to the information gain criteria for cross-domain sentiment classification, our proposed approach performs either better or comparably compared to previous approaches.", "sent2": "of statistics at various levels of granularity yields substantially improved results over a probabilistic baseline.", "label": 0}
{"sent1": "We automatically create a sentiment sensitive thesaurus using both labeled and unlabeled data from multiple source domains to find the association between words that express similar sentiments in different domains.", "sent2": "An analysis was performed to test this hypothesis using a manually annotated word alignment (WA) corpus for Chinese-English SMT.", "label": 0}
{"sent1": "star ratings).", "sent2": "We evaluate the model using small, widely used sentiment and subjectivity corpora and find it out-performs several previously introduced methods for sentiment classification.", "label": 1}
{"sent1": "A number of different features are extracted and ablation tests are used to investigate their contribution to overall performance.", "sent2": "A comparison between regression and rank preference models further supports our method.", "label": 1}
{"sent1": "We propose a novel framework to predict wordlevel and sentence-level MT errors with a large number of novel features.", "sent2": "We test the approach on the task of lexical access; that is, the prediction of a word given a phonetic transcription.", "label": 0}
{"sent1": "We then replace the human semantic role annotators with automatic shallow semantic parsing to further automate the evaluation metric, and show that even the semiautomated evaluation metric achieves a 0.34 correlation coefficient with human adequacy judgment, which is still about 80% as closely correlated as HTER despite an even lower labor cost for the evaluation procedure.", "sent2": "The results show that our proposed metric is significantly better correlated with human judgment on adequacy than current widespread automatic evaluation metrics, while being much more cost effective than HTER.", "label": 1}
{"sent1": "Our method uses a decipherment model which combines information from letter n-gram language models as well as word dictionaries.", "sent2": "We have shown that even simple features like point-wise mutual information are useful for word-alignment task in English-Hindi parallel corpora.", "label": 0}
{"sent1": "In this paper, we present several language model implementations that are both highly compact and fast to query.", "sent2": "These range from simple character and word n-grams and common subsequences to complex features such as Explicit Semantic Analysis vector comparisons and aggregation of word similarity based on lexical-semantic resources.", "label": 0}
{"sent1": "We carried out an extensive human evaluation which allowed us not only to rank the different MT systems, but also to perform higher-level analysis of the evaluation process.", "sent2": "Despite their different levels of expertise, these actors need to interact and understand each other but the communication is not always easy and effective.", "label": 0}
{"sent1": "In addition to its own functionality, it provides interfaces to external software and corpora.", "sent2": "Clairlib is compatible with all the common platforms and operating systems.", "label": 1}
{"sent1": "During inference of the probabilistic model, we use posterior expectation constraints to require that a minimum proportion of the dependencies we infer be instances of these rules.", "sent2": "Most of the existing work on IMT uses batch learning paradigm which does not allow translation systems to make use of the new input instantaneously.", "label": 0}
{"sent1": "BLEU, TER) focus on different aspects of translation quality; our multi-objective approach leverages these diverse aspects to improve overall quality.", "sent2": "Our approach is based on the theory of Pareto Optimality.", "label": 1}
{"sent1": "In this paper, we experiment with different graph pruning which guarantees the translation quality improvement due to reordering at a very low increase of computational cost.", "sent2": "This technique supplies reordering constraints to an SMT system, using statistical criteria.", "label": 1}
{"sent1": "The goal of this paper is to show that this common wisdom can also be brought to bear upon SMT.", "sent2": "Detection of fine-grained opinions and beliefs holds promise for improved social media analysis for social science research, business intelligence, and government decision-makers.", "label": 0}
{"sent1": "We consider two scenarios, 1) Monolingual samples in the source and target languages are available and 2) An additional small amount of parallel corpus is also available.", "sent2": "In this work, we show how to predict what the learning curve would look like if we were to manually translate increasing amounts of data.", "label": 1}
{"sent1": "HVR extends the conventional voice input by allowing users to provide complementary partial lexical information via touch input to improve the efficiency and accuracy of voice recognition.", "sent2": "We present a new automatic and empirical measure of antonymy that combines corpus statistics with the structure of a published thesaurus.", "label": 0}
{"sent1": "Textual entailment, an established indicator of semantic relationships between text units, is used to measure sentence connectivity and construct the graph on which WMVC operates.", "sent2": "It poses the text summarization task as an optimization problem, and attempts to solve it using Weighted Minimum Vertex Cover (WMVC), a graph-based algorithm.", "label": 1}
{"sent1": "One of the main advantages of this technique is its capability to learn specific probability distributions that better fit subsets of the training dataset.", "sent2": "Babelfy is online at http://babelfy.org", "label": 0}
{"sent1": "These models however tend to disregard the syntactic structures when they are applied to larger sentences.", "sent2": "We show improvement on the task of sentiment classification with respect to several baselines, and observe that the approach is most useful when the training set is sufficiently small.", "label": 0}
{"sent1": "We use these estimates as parameters on a HMM that models the sentence generation process, with hidden nodes as sentence components and image detections as the emissions.", "sent2": "Experimental results show that our strategy of combining vision and language produces readable and descriptive sentences compared to naive strategies that use vision alone.", "label": 1}
{"sent1": "These properties imply that corroborating system improvements with additional measures always increases the overall reliability of the evaluation process.", "sent2": "After this, we formalize and verify empirically a set of properties that every text evaluation measure based on similarity to human-produced references satisfies.", "label": 1}
{"sent1": "This formulation allows us to combine structural components of phrase-based and syntax-based MT in a single model.", "sent2": "Our approach gives a substantial increase of 3.9% endto-end F 1 on the 2013 KBP Slot Filling evaluation, yielding a net F 1 of 37.7%.", "label": 0}
{"sent1": "Our model learns pairwise costs of a word immediately preceding another word.", "sent2": "Instead of using a parser and then using rules to order the source side sentence we learn a model that can directly reorder source side sentences to match target word order using a small parallel corpus with highquality word alignments.", "label": 1}
{"sent1": "We show that the model produces clusters of relation trigger words which better correspond with manually annotated relations than several existing clustering techniques.", "sent2": "Most supervised language processing systems show a significant drop-off in performance when they are tested on text that comes from a domain significantly different from the domain of the training data.", "label": 0}
{"sent1": "We apply this approach to a knowledge base of approximately 500,000 beliefs extracted imperfectly from the web by NELL, a never-ending language learner (Carlson et al, 2010).", "sent2": "Unfortunately, this leads to inconsistent and often unrealistic evaluation scenarios.", "label": 0}
{"sent1": "We formulate this task in a vector space model that represents adjectives and nouns as vectors in a semantic space defined over possible attributes.", "sent2": "The definitions of two coreference scoring metrics?B 3 and CEAF?are underspecified with respect to predicted, as opposed to key (or gold) mentions.", "label": 0}
{"sent1": "Exploiting dictionary definitions explicitly in our model yields a better understanding of word semantics leading to better text modeling.", "sent2": "This representation scheme, based on the blackboard architectural model, allows a very wide variety of linguistic and non-linguistic information to be stored in one place and operated upon by any number of processing modules.", "label": 0}
{"sent1": "How to consume subjective information of this volume becomes an interesting and important research question.", "sent2": "In this paper, we describe experiments on a modestsized corpus of regulation annotated with a novel variant of logical form, called abstract syntax trees (ASTs).", "label": 0}
{"sent1": "To supplement a morphological dictionary with these resources, we propose a new task of Japanese noun phrase segmentation.", "sent2": "We apply non-parametric Bayesian language models to segment each noun phrase in these resources according to the statistical behavior of its supposed constituents in text.", "label": 1}
{"sent1": "In this model, inference on sequences is modeled as cascaded decision.", "sent2": "In this study, we also construct a balanced benchmark dataset with 2,162 sentences from BNC for English LVCs.", "label": 0}
{"sent1": "Several different translation strategies were explored.", "sent2": "This paper describes the development of a statistical machine translation system based on the Moses decoder for the 2007 WMT shared tasks.", "label": 1}
{"sent1": "We propose a principled framework of embedding entities that integrates hierarchical information from large-scale knowledge bases.", "sent2": "We propose a new approach to identifying semantically similar words across languages.", "label": 0}
{"sent1": "We define a query graph that resembles subgraphs of the knowledge base and can be directly mapped to a logical form.", "sent2": "that are then used to transform lemmas into inflected word forms.", "label": 0}
{"sent1": "The resulting data is used to train the semantic parser.", "sent2": "For Wikipedia, our best method obtains a median prediction error of just 11.8 kilometers.", "label": 0}
{"sent1": "The model is applied to the task of mapping sentences to hierarchical representations of their underlying meaning.", "sent2": "We further propose to exploit the user relationships to identify the deceptive answers, based on the hypothesis that similar users will have similar behaviors to post deceptive or authentic answers.", "label": 0}
{"sent1": "In this paper, we view such subsentential interactions in light of compositional semantics, and present a novel learningbased approach that incorporates structural inference motivated by compositional semantics into the learning procedure.", "sent2": "We present a weakly-supervised induction method to assign semantic information to food items.", "label": 0}
{"sent1": "We present a new NLI aligner, the MANLI system, designed to address these challenges.", "sent2": "We report on the scores attained and errors corrected and missed.", "label": 0}
{"sent1": "Moreover, as the knowledge in each level is modeled independently and the combination is processed in the model level, the information inherently in each knowledge source has a chance to be thoroughly exploited.", "sent2": "By simulations, the effectiveness of the analyzer is investigated, and then a LVCSR system embedding the presented analyzer is evaluated.", "label": 1}
{"sent1": "Current phrase reordering models can properly handle swaps between adjacent phrases, but they typically lack the ability to perform the kind of long-distance reorderings possible with syntax-based systems.", "sent2": "In this paper, we present a novel hierarchical phrase reordering model aimed at improving non-local reorderings, which seamlessly integrates with a standard phrase-based system with little loss of computational efficiency.", "label": 1}
{"sent1": "These documents are then used to adapt the MT system to increase the probability of generating texts that resemble the comparable document.", "sent2": "We perform search by using an SMT decoder in forced decoding mode to produce a bag-ofwords representation of the target documents to be ranked.", "label": 0}
{"sent1": "Using the translated portion of the Chinese treebank, our model is trained iteratively to maximize the marginal likelihood of training tree pairs, with alignments treated as latent variables.", "sent2": "The resulting bitext parser outperforms state-of-the-art monolingual parser baselines by 2.5 F1 at predicting English side trees and 1.8 F1 at predicting Chinese side trees (the highest published numbers on these corpora).", "label": 1}
{"sent1": "To illustrate, we extract research threads from citation graphs and construct timelines from news articles.", "sent2": "To this end, we focus on extracting diverse sets of threads?singlylinked, coherent chains of important documents.", "label": 1}
{"sent1": "Empirical evaluation on the task of named entity coordinate term extraction shows that this framework is preferable to vector-based models for smallsized corpora.", "sent2": "Consequently, it remains crucial to carefully assess the use of HBMs along with alternative, possibly simpler, candidate models.", "label": 0}
{"sent1": "Features are the key to obtain an accurate question classifier.", "sent2": "The amount of code available makes necessary to develop systems supporting education that could address the problem of detection of source code re-use.", "label": 0}
{"sent1": "In this paper we present our ideas of how an enhanced electronic dictionary can help people to find the word they are looking for.", "sent2": "This is a clearly a case where computers (electronic dictionaries) can be of great help.", "label": 1}
{"sent1": "We evaluate and discuss the system based on the analysis of the collected data about site visits during this five-year period.", "sent2": "The dictionary structure is inspired by the WordNet basic design.", "label": 1}
{"sent1": "We attempt three ways of automatic construction to corroborate the effect of the directionality of dictionaries.", "sent2": "First, we introduce ?one-time look up?method using a Korean-to-English and a Japanese-to-English dictionary.", "label": 1}
{"sent1": "In particular, we focus on the cooking domain, where the instructions correspond to the recipe.", "sent2": "Our technique relies on an HMM to align the recipe steps to the (automatically generated) speech transcript.", "label": 1}
{"sent1": "The MMSKIP-GRAM models achieve good performance on a variety of semantic benchmarks.", "sent2": "The V measure favors solutions having a large number of clusters, while the range of scores given by VI depends on the size of the dataset.", "label": 0}
{"sent1": "In this paper, we propose a lightly supervised approach based on label regularization to infer the age, ethnicity, and political orientation of Twitter users.", "sent2": "Most existing approaches rely on supervised learning algorithms, which require manual data annotation and therefore are costly to develop and adapt over time.", "label": 1}
{"sent1": "Our experiments are based on Bulgarian-English parallel and comparable texts but the method is to a great extent language-independent and particularly suited to less-resourced languages, since it does not need parsed or semantically annotated data.", "sent2": "In this paper, we describe an approach based on off-the-shelf parsers and semantic resources for the Recognizing Textual Entailment (RTE) challenge that can be generally applied to any domain.", "label": 0}
{"sent1": "To help the development of new technology, we are running an open search engine infrastructure, TSUBAKI, on a high-performance computing environment.", "sent2": "In this paper, we describe TSUBAKI infrastructure.", "label": 1}
{"sent1": "The results revealed that our method outperformed baseline methods with less than one hundred utterances as training data, which can be reasonably prepared for new domains.", "sent2": "We evaluated our method in two different domains.", "label": 1}
{"sent1": "According to the proposed approach, the unknown word is re-split into a subword sequence followed by subword translation with a subwordbased translation model.", "sent2": "?Subword?", "label": 1}
{"sent1": "We then use the set of transliteration hypotheses as a guide to finding relevant Web pages and mining contextual information for the transliteration hypotheses from the Web page.", "sent2": "We generate a set of Chinese, Japanese, and Korean transliteration hypotheses for a given English word.", "label": 1}
{"sent1": "After manually classifying the basic modification patterns, we analysed the factors that trigger a change in verb voice from passive to active using SVM.", "sent2": "Our goal is to construct a system that notifies (English-to-Japanese) volunteer translators of awkward translations.", "label": 1}
{"sent1": "Language patterns in the later part of electronic negotiation are highly indicative of the successful or unsuccessful outcome of the process, whereas in face-toface negotiations, the first part of the negotiation is more useful for predicting the outcome.", "sent2": "We analyze the linguistic behaviour of participants in bilateral electronic negotiations, and discover that particular language characteristics are in contrast with face-to-face negotiations.", "label": 1}
{"sent1": "First, we integrate two online databases to extend the coverage of our bilingual dictionaries.", "sent2": "We use Wikipedia as a translation tool based on the inter-language links between the Korean edition and the Chinese or English editions.", "label": 1}
{"sent1": "The polarities of words in a sentence are not always the same as that of the sentence, because there can be polarity-shifters such as negation expressions.", "sent2": "Broad domain question answering is often difficult in the absence of structured knowledge bases, and can benefit from shallow lexical methods (broad coverage) and logical reasoning (high precision).", "label": 0}
{"sent1": "We applied the method to acquire the generalized translation knowledge for KoreanEnglish translation.", "sent2": "We develop a framework for decisions made via in pipeline models, which addresses these difficulties, and presents and evaluates it in the context of bottom up dependency parsing for English.", "label": 0}
{"sent1": "However, they tend to address this problem without considering linguistic information in Chinese NEs.", "sent2": "We explore the possibility of using an existing lexical hierarchy for the purpose of placing words from a noun compound into categories, and then using this category membership to determine the relation that holds between the nouns.", "label": 0}
{"sent1": "Apart from the orthographic and collocation features, we have experimented on the efficiency of using gazetteer lists as features.", "sent2": "We also worked on semi-automatic induction of context patterns and experimented with using these as features of the MaxEnt method.", "label": 1}
{"sent1": "Information that aid agencies can actually act on, ?actionable?", "sent2": "information, will be sparse so there is great potential to (semi)automatically identify actionable communications.", "label": 1}
{"sent1": "In this paper, we describe preliminary results based on the application of computational linguistics techniques to quantitatively analyze this hypothesis.", "sent2": "Our contributions in this work are threefold: 1) We develop a multi-corpus parallel dataset with translation direction labels at the sentence level, 2) we perform a comparative evaluation of previously introduced features for translation direction detection in a cross-domain setting and 3) we generalize a previously introduced type of features to outperform the best previously proposed features in detecting translation direction and achieve 0.80 precision with 0.85 recall.", "label": 0}
{"sent1": "This work suggests a bounded definition for three properties (accuracy, non-ambiguity and verifiability) considering the main characteristics that software requirements must exhibit to satisfy those objectives.", "sent2": "A software prototype that combines natural language processing (NLP) techniques and specialized dictionaries was built to examine software requirements written in English with the goal of identifying whether or not they satisfy the desired properties.", "label": 1}
{"sent1": "For the first method, we conduct controlled experiments on ChineseEnglish and Arabic-English translation tasks to compare the quality of word alignment, and to measure effects of two different methods in selecting alignment links from manually aligned corpus.", "sent2": "We demonstrate the usages of both methods by selecting alignment links from manually aligned corpus and apply links generated from bilingual dictionary on unlabelled data.", "label": 1}
{"sent1": "We also design the FET grammar to analyze the intonation patterns and produce tone marks as a result of our analysis.", "sent2": "We present a proof-of-the-concept working example to validate our proposal.", "label": 1}
{"sent1": "Our work is the first that consciously avoids gender bias in topics, thereby providing stronger evidence to gender-specific styles in language beyond topic.", "sent2": "In addition, our comparative study provides new insights into robustness of various stylometric techniques across topic and genre.", "label": 1}
{"sent1": "Our agent incrementally understands spoken instructions and immediately controls a mobile robot based on the incremental understanding results and situation information such as the locations of obstacles and moving history.", "sent2": "It is also expected to immediately react to the instructions.", "label": 1}
{"sent1": "Standard methods generally focus on singlestage barge-in detection, applying the dialogue policy irrespective of the barge-in context.", "sent2": "Unfortunately, this approach performs poorly when used in challenging environments.", "label": 1}
{"sent1": "We focus in particular on cloud based ASRs that recently have become available to the community.", "sent2": "We argue that by taking advantage of this information density, NLG systems applied to ontologies can guide the choice and construction of sentences to express useful ontological information, solely through the verbalisations of identifier names, and that by doing so, they can replace the extremely fussy and repetitive texts produced by ontology verbalisers with shorter and simpler texts which are clearer and easier for human readers to understand.", "label": 0}
{"sent1": "The rules apply to observed system actions and partially observable user acts, without using any knowledge obtained from external resources (i.e.", "sent2": "This paper presents a generic dialogue state tracker that maintains beliefs over user goals based on a few simple domainindependent rules, using basic probability operations.", "label": 1}
{"sent1": "As a solution we describe a method enlarging the vocabulary of a language model to an almost infinite size and capturing their context information.", "sent2": "In this paper we identify the related issue of subdomain variation, i.e., differences between subsets of a domain that might be expected to behave homogeneously.", "label": 0}
{"sent1": "Currently these models are manually created over time.", "sent2": "Towards this, we propose an unsupervised technique to generate domain models automatically from call transcriptions.", "label": 1}
{"sent1": "?X near Y?).", "sent2": "The model can help motivate the choice between topological and projective prepositions.", "label": 1}
{"sent1": "In this paper, I will present the incremental ontology learning framework On2L.", "sent2": "The knowledge sources used include local collocations, parts-of-speech, and surrounding words.", "label": 0}
{"sent1": "word length, word counts, and word association, are integrated.", "sent2": "Our feature-based algorithm combines knowledge about content using a text-based algorithm as a feature and about form using linguistic and acoustic cues about topic shifts extracted from speech.", "label": 0}
{"sent1": "All three parsers bene?t from the use of automatically derived lemmas, while morphological features seem to be less important.", "sent2": "The results show that all three systems achieve competitive performance, with a best labeled attachment score over 88%.", "label": 1}
{"sent1": "The mechanism can easily be implemented by modifying a graphbased parsing model and introducing a set of new features.", "sent2": "This relies on the fact that short dependencies are generally more accurate than long dependencies in graph-based models and may be used as features to help parse long dependencies.", "label": 1}
{"sent1": "Our experiments reveal certain universal trends found across the networks for seven different languages from three different language families, which are neither reported nor explained by any of the previous studies and models of word-cooccurrence networks.", "sent2": "We hypothesize that since word co-occurrences are governed by syntactic properties of a language, the network has much constrained topology than that predicted by the previously proposed growth model.", "label": 1}
{"sent1": "The first method, rule arithmetic, constructs new rules as combinations of existing and reliable rules used in the bilingual chart, significantly improving the translation accuracy on the German-English and Farsi-English translation task.", "sent2": "Bilingual chart parsing and EM algorithm are used to train bitext correspondences.", "label": 1}
{"sent1": "For a given noisy sentence, a weighted list of possible clean tokens for each noisy token are obtained.", "sent2": "The clean sentence is then obtained by maximizing the product of the weighted lists and the language model scores.", "label": 1}
{"sent1": "One of the methods of the second set uses a classical technique in the field of artificial intelligence, the A* algorithm to obtain the suitable alignment.", "sent2": "Even if two comparable documents have few or no parallel sentence pairs, there is still potential for parallelism in the sub-sentential level.", "label": 0}
{"sent1": "We compare several popular embeddings to Brown clusters, via multiple types of features, in both news and web domains.", "sent2": "We find that all embeddings yield significant parsing gains, including some recent ones that can be trained in a fraction of the time of others.", "label": 1}
{"sent1": "We test each of these hypotheses with a targeted change to a state-of-the-art baseline.", "sent2": "Recent advances in the technology of stylometry (the study of authorial style) or ?authorship attribution?", "label": 0}
{"sent1": "The pilot discussed here uses double annotation of take multi-word expressions, where annotations provide information on the best strategy for adding the multi-word expression to the lexicon.", "sent2": "This research discusses an approach to adding multiword expressions to the PropBank lexicon in an effective yet semantically rich fashion.", "label": 1}
{"sent1": "constituent degrees of compositionality, ?", "sent2": "We demonstrate that the feature norms are potentially useful for research on the nounnoun compounds and their semantic transparency: The feature overlap of the compounds and their constituents correlates with human ratings on the compound?", "label": 1}
{"sent1": "In order to find out if and to what degree the presence of VPCs causes problems for statistical machine translation systems, we collected a set of 59 verb pairs, each consisting of a German VPC and a synonymous simplex verb.", "sent2": "We analyse the structure of German VPCs and compare them to VPCs in English.", "label": 1}
{"sent1": "We evaluate our model as a ranking problem and compute the MAP and P&N score to validate the ranking result.", "sent2": "This bag-of-vectors approach however did not produced encouraging results.", "label": 0}
{"sent1": "Besides, we  propose an alternative filtering approach to clean the crawled data and to further  optimize the domain-specific SMT system.", "sent2": "The collected  data is used for adapting the language  model and translation model to boost the  overall translation quality.", "label": 1}
{"sent1": "We deployed six different kinds of terminology extraction methods, and participated in three different tasks: FR?EN and EN?", "sent2": "It is based on the multidimensional dialogue act taxonomy and associated context model as developed in Dynamic Interpretation Theory (DIT).", "label": 0}
{"sent1": "Other characteristics of our submission include: the use of sampling for building MOSES?", "sent2": "We have evaluated GrawlTCQ on an AFP English corpus of 57,441 news over 10 categories.", "label": 0}
{"sent1": "In this paper, we examine the accuracy of three randomized methods of significance testing in the context of machine translation: paired bootstrap resampling, bootstrap resampling and approximate randomization.", "sent2": "Temporal resolution systems are traditionally tuned to a particular language, requiring significant human effort to translate them to new languages.", "label": 0}
{"sent1": "Sparse alignments with high precision on the link level, for translation units, and on the subset of crossing links, like intersected HMM models, are preferred.", "sent2": "A small-scale evaluation study reveals that most of the resulting sentences are adequate to good.", "label": 0}
{"sent1": "We propose a neural probabilistic structured-prediction model for transition-based dependency parsing, which integrates search and learning.", "sent2": "To combat this, this work looks at ambiguity detection at the term, rather than the instance, level.", "label": 0}
{"sent1": "It also significantly outperforms McDonald et al.", "sent2": "A key assumption underlying previous work is that the context surrounding an ambiguous word is indicative of its meaning.", "label": 0}
{"sent1": "In contrast, our model induces relations between sentences while optimizing a task-specific objective.", "sent2": "This design provides limited opportunities for guiding the discourse parser based on the requirements of the target task.", "label": 1}
{"sent1": "We address the issue of automatically identifying and resolving implicit arguments in Chinese discourse.", "sent2": "For their resolutions, we present an approach that combines the information about overtly labeled arguments and frame-to-frame relations defined by FrameNet.", "label": 1}
{"sent1": "Formalized adjectival resources are, indeed, scarce for French and they mostly focus on morphological and syntactic information.", "sent2": "Our objective is, therefore, to contribute enriching the available set of resources by taking advantage of reliable lexicographic data and formalizing it with the well-established lexical functions formalism.", "label": 1}
{"sent1": "the hierarchy at an appropriate level of generalisation or on a ?walking?", "sent2": "We propose a Laplacian structured sparsity model to study computational branding analytics.", "label": 0}
{"sent1": "We suggest a model which is confined to simple lexical information, but is formulated as a principled generative probabilistic model.", "sent2": "We focus our attention on the task of ranking textual inferences and show substantially improved results on a recently investigated question answering data set.", "label": 1}
{"sent1": "We further propose a duration-based regularization component to find bursty events.", "sent2": "Generating candidate sentences corresponding to different possible coordination structures and comparing them with a language model is employed to help determine which coordination structure is best.", "label": 0}
{"sent1": "and ?arguments?", "sent2": "In user-generated product reviews, the ?predicate?", "label": 1}
{"sent1": "Graphics Processing Units (GPUs) have previously been used to accelerate CKY chart evaluation, but gains over CPU parsers were modest.", "sent2": "In this paper, we explore the use of Random Forests (RFs) (Amit and Geman, 1997; Breiman, 2001) in language modeling, the problem of predicting the next word based on words already seen before.", "label": 0}
{"sent1": "Despite an extremely large space of possible expressions, we demonstrate effective learning of a globally normalized log-linear distribution.", "sent2": "This learning is enabled by a new, multi-stage approximate inference technique that uses a pruning model to construct only the most likely logical forms.", "label": 1}
{"sent1": "In addition, our model can accommodate the subtlety that whether two words are similar depends on which topic they appear in, which allows word with multiple senses to be put into different topics properly.", "sent2": "We derive a variational inference method to infer the posterior probabilities and learn model parameters and present techniques to deal with the hardto-compute partition function in MRF.", "label": 1}
{"sent1": "Entities were identified in noun chunks by use of dictionaries, and events (?The left atrium is dilated?)", "sent2": "We describe how the Data Contributors of MultiLing collected and generated a multilingual multi-document summarization corpus on 10 different languages: Arabic, Chinese, Czech, English, French, Greek, Hebrew, Hindi, Romanian and Spanish.", "label": 0}
{"sent1": "To leverage annotated newswire data, we employ an importance weighting scheme.", "sent2": "Taken all together, we establish a new state-of-the-art on two common test sets.", "label": 1}
{"sent1": "Using  the  lexicon  extracted  from  the  training  corpus and lexicon from the available  word  list,  we  used  two  statistical  taggers  for  comparison  reasons.", "sent2": "We present a series of experiments that illustrate how an evolutionary reinforcement learning algorithm can produce strategies that are both optimal and easily inspectable by human developers.", "label": 0}
{"sent1": "We also discuss about a difficulty  of  building  treebank  and  mention  a  toolkit for assisting on a Thai CGs tree  building  and  a  tree  format  representations.", "sent2": "Beside, an idea of how to group a word  that has the same functions are presented to gain a certain type of category per  word.", "label": 1}
{"sent1": "The  KYOTO system uses  an  open text  representation format and a central ontology to  enable  extraction  of  knowledge  and facts  from large volumes of text  in  many different languages.", "sent2": "We implemented a semantic tagging approach that performs off-line reasoning.", "label": 1}
{"sent1": "First, The leaf categories in the Goi-Taikei hierarchy are semi-automatically aligned with semantically equivalent Wikipedia categories.", "sent2": "as an upper ontology.", "label": 1}
{"sent1": "The arising M-step energies are non-trivial and handled via projected gradient ascent.", "sent2": "This paper describes a learning method that exploits unlabeled data to tackle data sparseness problem.", "label": 0}
{"sent1": "We compare two approaches: (1) acquiring patterns in the source language, performing source language extraction, and then translating the resulting templates to the target language, and (2) translating the texts and performing pattern discovery and extraction in the target language.", "sent2": "This module, which creates extraction patterns starting from a user?s narrative task description, allows rapid customization to new extraction tasks.", "label": 1}
{"sent1": "A robust WSD system will be constructed by combining these two classifiers.", "sent2": "In our experiments, the F-measure and applicability of our proposed method were 3.4% and 10% greater, respectively, compared with a single classifier obtained by supervised learning.", "label": 1}
{"sent1": "Each selection context is associated with a meaning, which can be expressed in any of various formal or computational manifestations.", "sent2": "We conclude by describing our plans for further improvements, and for applying the same mathematical principles to other problems in natural language processing.", "label": 0}
{"sent1": "Our approach involves application of two new methods?", "sent2": "Using a continuous space model for the translation model and the target language model, an improvement of 1.5 BLEU on the test data is observed.", "label": 0}
{"sent1": "Supplied with limited lexicon resources, TNT outperforms the Brill tagger with state-of-the-art performance figures (close to 97% accuracy).", "sent2": "Moreover, an ensemble of all representations achieves the best results, suggesting their complementarity.", "label": 0}
{"sent1": "Experimental results show that expanding training data size significantly contributes to the performance.", "sent2": "Also we discover that the Web-based re-ranking method can be successfully applied to the English-Korean transliteration.", "label": 1}
{"sent1": "Our system controls the produced summary by using these selected keywords.", "sent2": "In this paper we study how to identify persuasive posts in the online forum discussions, using data from Change My View sub-Reddit.", "label": 0}
{"sent1": "The framework is flexible, allowing fast adaptation to applications and it is scalable.", "sent2": "We apply it in combination with a terabyte corpus to answer natural language tests, achieving encouraging results.", "label": 1}
{"sent1": "This project started 4 years ago with French and Japanese.", "sent2": "The Papillon project is a collaborative project to establish a multilingual dictionary on the Web.", "label": 1}
{"sent1": "In this paper, we formulate a novel recursive method for minimum description length (MDL) word segmentation, whose basic operation is resegmenting the corpus on a prefix (equivalently, a suffix).", "sent2": "Automatic word segmentation is a basic requirement for unsupervised learning in morphological analysis.", "label": 1}
{"sent1": "Manual substructural alignment is time-consuming, error-prone and requires considerable knowledge of both source and target languages and how they are related.", "sent2": "The paper describes a weakly supervised approach for decomposing words into all morphemes: stems, prefixes and suffixes, using wordforms with marked stems as training data.", "label": 0}
{"sent1": "More than 78% of total arcs are pruned while retaining 99.5% of the true dependencies.", "sent2": "Overall, our results demonstrated that the system could not improve with the use of this semantic information, but its precision was increased.", "label": 0}
{"sent1": "We could further increase the parsing and training speed with a parallel feature extraction and a parallel parsing algorithm.", "sent2": "We are convinced that the Hash Kernel and the parallelization can be applied successful to other NLP applications as well such as transition based dependency parsers, phrase structrue parsers, and machine translation.", "label": 1}
{"sent1": "In this paper, we propose a unsupervised method for determining the optimal weights for context words according to their distance.", "sent2": "We address the creation of cross-lingual textual entailment corpora by means of crowdsourcing.", "label": 0}
{"sent1": "This paper discusses one particular approach to data sharing and exchange that was developed for NLG ?", "sent2": "Our parser achieved statistically significant improvements over a baseline system that trains on only fully connected parses for Bulgarian, Spanish and Hindi.", "label": 0}
{"sent1": "as a conjunction and ?because of?", "sent2": "The resulting relational model of the domain can be extended by specifying additional relational features in a declarative way using a logic programming language.", "label": 0}
{"sent1": "It is unrealistic for an evaluation to simply show a human evaluator the whole period from the beginning of a dialog up to the time point at which a referring expression is used.", "sent2": "We also provide a brief survey of datasets and evaluation design used in previous work to highlight the need of developing a standard evaluation for automatic tweet summarization task.", "label": 0}
{"sent1": "We show that the often-used frequency-based selection performs badly compared to maximum entropy feature selection, and that models with a few hundred well-picked features are competitive to models with no feature selection applied.", "sent2": "In the experiments described in this paper, we compressed a model of approximately 490.000 features to 1.000 features.", "label": 1}
{"sent1": "In addition, model-based testing (MBT) is a promising testing technique for the verification of critical software.", "sent2": "Test cases generated by MBT tools are logical descriptions.", "label": 1}
{"sent1": "To make ontologies accessible to human domain experts, several research groups have developed ontology verbalisers using Natural Language Generation.", "sent2": "In practice ontologies are usually composed of simple axioms, so that realising them separately is relatively easy; there remains however the problem of producing texts that are coherent and efficient.", "label": 1}
{"sent1": "We describe a method for generating sentential paraphrases by using a large aligned monolingual corpus of news headlines acquired automatically from Google News and a standard Phrase-Based Machine Translation (PBMT) framework.", "sent2": "In this paper we investigate the automatic generation and evaluation of sentential paraphrases.", "label": 1}
{"sent1": "systems identified and, if appropriate, replaced references to people in texts.", "sent2": "There were three GREC Tasks at Generation Challenges 2010: GREC-NER required participating systems to identify all people references in texts; for GRECNEG, systems selected coreference chains for all people entities in texts; and GRECFull combined the NER and NEG tasks, i.e.", "label": 1}
{"sent1": "du Maine/Universita?t Stuttgart) submission for the NEG task at GREC?10.", "sent2": "The resulting phrase-paraphrase probabilities are built upon the conversion of the commute times into artificial cooccurrence counts with a novel technique.", "label": 0}
{"sent1": "Conservative Dollo phylogeny is more permissive, and has been used in biological applications.", "sent2": "Our submissions use the framework of Gaussian Processes to investigate lightweight approaches for this problem.", "label": 0}
{"sent1": "The research community in this field has actively proposed and improved methods to detect and classify the opinions and sentiments expressed in different types of text - from traditional press articles, to blogs, reviews, fora or tweets.", "sent2": "The system is composed of three components: a syntactic dependency parser, a predicate classifier and a semantic parser.", "label": 0}
{"sent1": "agreement or disagreement on an issue by exploiting information contained in each of the posts.", "sent2": "However, combining morphosyntactic word disambiguation with a word based 4-gram language model results in a relative improvement in the BLEU score of 2.3% on the development set and 1.9% on the test set.", "label": 0}
{"sent1": "We present a method which enables us to take the contextual emotion of a word and the syntactic structure of the sentence into account to classify sentences by emotion classes.", "sent2": "We show that this promising method outperforms both a method based on a Bag-of-Words representation and a system based only on the prior emotions of words.", "label": 1}
{"sent1": "Finally, we observe that only 50% of each user?s small vocabulary is shared with any other, indicating the importance of the flexibility of a conversational interface that allows users to converge to their own preferred vocabulary.", "sent2": "Keywords Spoken Language System; NoviceExpert; Lexical Entrainment", "label": 1}
{"sent1": "Dialogue capabilities include handling spoken corrections for an entire dialogue move, reestablishing context in response to a user request, responding to user barge-in, and help on demand.", "sent2": "The current system has been partially reimplemented for better efficiency and in response to feedback from astronauts and astronaut training personnel.", "label": 1}
{"sent1": "Callers calling in are greeted with an open-ended ?How may I help you??", "sent2": "prompt (Thomson and Wisowaty, 1999; Chu-Carroll and Carpenter, 1999; Gorin et al, 1997).", "label": 1}
{"sent1": "Automatic solutions are nowadays being sought both to make possible the comparison of different approaches by means of reliable indicators with generic evaluation methodologies and also to reduce system development costs.", "sent2": "The results obtained by using the patterns in paraphrase recognition were quite promising.", "label": 0}
{"sent1": "?nez et al, 2008) without needing to construct resources manually.", "sent2": "In Japanese dependency parsing, Kudo?s relative preference-based method (Kudo and Matsumoto, 2005) outperforms both deterministic and probabilistic CKY-based parsing methods.", "label": 0}
{"sent1": "The methods were developed to evaluate a system used by political scientists to extract event information from news leads about international politics.", "sent2": "The nature of this data presents two problems for evaluators: 1) the frequency distribution of event types in international event data is strongly skewed, so a random sample of newsleads will typically fail to contain any low frequency events.", "label": 1}
{"sent1": "can effectively monitor the surge and lead people to their topics of interest.", "sent2": "A list of ?buzzing topics?", "label": 1}
{"sent1": "Low-quality bilingual data tends to produce incorrect translation knowledge and also degrades translation modeling performance.", "sent2": "Previous work often used supervised learning methods to filter lowquality data, but a fair amount of human labeled examples are needed which are not easy to obtain.", "label": 1}
{"sent1": "The primary use of our work is a way of ?binning?", "sent2": "The prediction done by our framework is well correlated with the empirical gold standard data, which is a repository of < L,DP, SC > and TDI pairs for a set of sentences.", "label": 1}
{"sent1": "We apply the approach to a large data set of color descriptions, where statistical evaluation documents its accuracy.", "sent2": "We show that significantly better results can often be obtained if the final evaluation criterion is taken directly into account as part of the training procedure.", "label": 0}
{"sent1": "These clusters then comprise training data for the extractor.", "sent2": "NEWSSPIKE-RE uses a novel probabilistic graphical model to cluster sentences describing similar events from parallel news streams.", "label": 1}
{"sent1": "Existing approaches to this task require substantial human effort.", "sent2": "Named entity disambiguation is the task of linking an entity mention in a text to the correct real-world referent predefined in a knowledge base, and is a crucial subtask in many areas like information retrieval or topic detection and tracking.", "label": 0}
{"sent1": "Following initial analysis, we present a detailed study of protein association and dissociation reactions, proposing a new event class and representation for the latter and, as a step toward its automatic extraction, introduce a manually annotated resource incorporating the type among a total of nearly 1300 annotated event instances.", "sent2": "We focus on three semantic components: an Image component that retrieves images for the concepts in the text, an idiom detection component and a topic model component.", "label": 0}
{"sent1": "Results show that using 34 million web links approaches Wikipedia performance.", "sent2": "Our system achieves 1.8% accuracy higher than the stateof-the-part parser of Spitkovsky et al.", "label": 0}
{"sent1": "We empirically demonstrate its effectiveness in terms of perplexity and as a feature function in string-to-tree SMT from English to German and Russian.", "sent2": "We also show that using a syntactic evaluation metric to tune the log-linear parameters of an SMT system further increases translation quality when coupled with a syntactic language model.", "label": 1}
{"sent1": "This task presents a number of opportunities for the automatic support of manual curation efforts.", "sent2": "5% of the size of 3-gram ASR lattices.", "label": 0}
{"sent1": "In the shared task we looked at one particular aspect of cross-sentence links between argument structures, namely linking locally uninstantiated roles to their co-referents in the wider discourse context (if such co-referents exist).", "sent2": "We used decision trees, decision rules, logistic regression and lazy classifiers.", "label": 0}
{"sent1": "The number of target words was 50, with 22 nouns, 23 verbs, and 5 adjectives.", "sent2": "Dynamic Programming (DP) is an important class of algorithms widely used in many areas of speech and language processing.", "label": 0}
{"sent1": "The results show that in all languages the participants where able to beat the most frequent sense heuristic as estimated from general corpora.", "sent2": "The reduction of the model size can be up to 94% with the translation quality being preserved.", "label": 0}
{"sent1": "Its English portion, PPDB:Eng, contains over 220 million paraphrase pairs, consisting of 73 million phrasal and 8 million lexical paraphrases, as well as 140 million paraphrase patterns, which capture many meaning-preserving syntactic transformations.", "sent2": "The paraphrases are extracted from bilingual parallel corpora totaling over 100 million sentence pairs and over 2 billion English words.", "label": 1}
{"sent1": "Therefore the heuristic for generating negative examples has a serious flaw.", "sent2": "examples generated by the labeling process are false negatives because the knowledge base is incomplete.", "label": 1}
{"sent1": "This paper presents experiments into modelling the substitutability of discourse connectives.", "sent2": "Experiments conducted on the Brown corpus show a recall of 0.982, for an ambiguity rate of 1.233 which is to be compared with a baseline recall of 0.978 for an ambiguity rate of 1.414 using the same ambiguous tags and with a recall of 0.955 corresponding to the one best solution of standard tagging (without ambiguous tags).", "label": 0}
{"sent1": "This method generates 50-best lists that are of substantially higher quality than previously obtainable.", "sent2": "We used these parses as the input to a MaxEnt reranker (Johnson et al, 1999; Riezler et al, 2002) that selects the best parse from the set of parses for each sentence, obtaining an f-score of 91.0% on sentences of length 100 or less.", "label": 1}
{"sent1": "This model is then trained, so that the parameters of the probabilistic model reflect the generalizations in the training data.", "sent2": "In this paper we propose a method for defining kernels in terms of a probabilistic model of parsing.", "label": 1}
{"sent1": "We show how the boosting algorithm can be applied to the all-subtrees representation and how it selects a small and relevant feature set efficiently.", "sent2": "This paper argues that such an all-subtrees representation is extremely redundant and a comparable accuracy can be achieved using just a small set of subtrees.", "label": 1}
{"sent1": "To confirm the feasibility of our QBTE approach, we conducted experiments on the CRL QA Data based on 10-fold cross validation, using Maximum Entropy Models (MEMs) as an ML technique.", "sent2": "This paper tackles the problem of stability in ISR.", "label": 0}
{"sent1": "Moreover, the dialogue type, the modality and the channel quality all influence the decision of when to clarify and at which level of the grounding process.", "sent2": "Automatic image annotation is an attractive approach for enabling convenient access to images found in a variety of documents.", "label": 0}
{"sent1": "?Peter.?)", "sent2": "Semantic role labeling (SRL) is crucial to natural language understanding as it identifies the predicate-argument structure in text with semantic labels.", "label": 0}
{"sent1": "Experimental results are reported for a Chinese-to-English task, showing an improvement of 0.5%?1.8% BLEU score absolute on various test sets and better computational efficiency than reordering during decoding.", "sent2": "Our approach also outperforms two commercial grammar checking software packages.", "label": 0}
{"sent1": "We also show that the phrasal translation tables produced by the ITG are superior to those of the flat joint phrasal model, producing up to a 2.5 point improvement in BLEU score.", "sent2": "We demonstrate that the consistency constraints that allow flat phrasal models to scale also help ITG algorithms, producing an 80-times faster inside-outside algorithm.", "label": 1}
{"sent1": "We have shown that by using the structural features, we have obtained a decrease of 2.3% in the absolute value of alignment error rate (AER).", "sent2": "These features are particularly useful for language pairs with high structural divergence (like English-Hindi, EnglishJapanese).", "label": 1}
{"sent1": "We propose a generative model for function word insertion (prepositions, definite/indefinite articles, etc.)", "sent2": "and subphrase reordering.", "label": 1}
{"sent1": "We investigate word disambiguation using morphosyntactic categories, n-best hypotheses reranking, and the combination of both methods with word or morphosyntactic n-gram language model reranking.", "sent2": "The purpose of this work is to explore the integration of morphosyntactic information into the translation model itself, by enriching words with their morphosyntactic categories.", "label": 1}
{"sent1": "Most of the previous work on statistical machine translation relies on (local) associations of target words/phrases with source words/phrases for lexical selection.", "sent2": "In contrast, in this paper, we present a novel approach to lexical selection where the target words are associated with the entire source sentence (global) without the need for local associations.", "label": 1}
{"sent1": "Using dynamic programming, we efficiently find a reordering that approximates the highest attainable BLEU score given a reference and a set of reordering constraints.", "sent2": "We investigate the best possible (oracle) BLEU score achievable under different reordering constraints.", "label": 1}
{"sent1": "We describe an ongoing project that aims to annotate the English section of the CHILDES database with grammatical relations in the form of labeled dependency structures.", "sent2": "Experiments show that our system outperforms the state-of-art systems and improves the F 1 score.", "label": 0}
{"sent1": "In this perliminary study, we show that a state-ofthe-art subcategorization acquisition system of Preiss et al (2007) can be used to extract largescale subcategorization (frequency) information from the (i) child and (ii) child-directed speech within the CHILDES database without any domain-specific tuning.", "sent2": "To this end, we adapt a formalism known as unordered tree alignment to our probabilistic setting.", "label": 0}
{"sent1": "Infants under six months of age are capable of making fine-grained discriminations of object boundaries and three-dimensional space.", "sent2": "Recognition requires the ability to categorize objects and events.", "label": 1}
{"sent1": "We extend this work to look at models that distinguish semantic relations.", "sent2": "We show that this improves labelling quality, in particular for argument grammatical functions, in an intrinsic evaluation, and, importantly, grammar coverage for treebankbased (Lexical-Functional) grammar acquisition and parsing, in an extrinsic evaluation.", "label": 0}
{"sent1": "We evaluate BLEU, METEOR and AL-BLEU on our human judgments corpus and show that AL-BLEU has the highest correlation with human judgments.", "sent2": "We are releasing the dataset and software to the research community.", "label": 1}
{"sent1": "Distributional models have been successful in modelling the meanings of content words, but logical semantics is necessary to adequately represent many function words.", "sent2": "We follow formal semantics in mapping language to logical representations, but differ in that the relational constants used are induced by offline distributional clustering at the level of predicateargument structure.", "label": 1}
{"sent1": "Most importantly, instead of deciding upfront which types of features are important, we use the learning framework of preference re-ranking kernels to learn the features automatically.", "sent2": "We integrate several layers of linguistic information encapsulated in tree-based structures, making use of both the reference and the system output simultaneously, thus bringing our ranking closer to how humans evaluate translations.", "label": 1}
{"sent1": "Our approach naturally deals with the ambiguity present in the input parse forest, but, at the same time, takes into account only the parts of the input forest used by the current translation hypothesis.", "sent2": "The method provides improvement from 0.6 up to 1.0 point measured by (Ter ?", "label": 1}
{"sent1": "For that purpose we apply the neural network to the same text the subjects are reading, and explore the ability of these three vector representations to predict the observed word-by-word brain activity.", "sent2": "We study the alignment between the latent vectors used by neural networks and brain activity observed via Magnetoencephalography (MEG) when subjects read a story.", "label": 1}
{"sent1": "It is not always apparent which single attribute will lead to the best domains, and more than one attribute might impact classification.", "sent2": "Experiment results show that as a standalone speller, our model outperforms all the baseline systems.", "label": 0}
{"sent1": "To approach this problem, we collected a small corpus of German microtexts in a text generation experiment, resulting in texts that are authentic but of controlled linguistic and rhetoric complexity.", "sent2": "Despite recent advances in discourse parsing and causality detection, the automatic recognition of argumentation structure of authentic texts is still a very challenging task.", "label": 1}
{"sent1": "In this paper, we are primarily concerned with the extraction of connections between biomedical relations, a connection that we call a higher order relation.", "sent2": "Most methods extract keyphrases according to their statistical properties in the given document.", "label": 0}
{"sent1": "The second parameter quantifies the degree to which a given entity is the antecedent for a detected zero pronoun.", "sent2": "To compute these parameters efficiently, we use corpora with/without annotations of anaphoric relations.", "label": 1}
{"sent1": "If an article is controversial, an online ?Article for Deletion?", "sent2": "Wikipedia contains millions of articles, collaboratively produced.", "label": 1}
{"sent1": "WELT is a tool under development for eliciting endangered language data and formally documenting a language, based on WordsEye (Coyne and Sproat, 2001), a text-to-scene generation tool that produces 3D scenes from text input.", "sent2": "Large-scale experiments on Chinese to English translation show that our model exhibits state-of-the-art performance by significantly outperforming the phrase-based model.", "label": 0}
{"sent1": "We also briefly discuss some of the features of the systems which are particularly helpful to endangered languages fieldwork and which should also be of interest to computational linguists, these being a service that automates the identification of utterances within audio/video, another that automates the alignment of audio recordings and transcriptions, and a number of services that automate the morphological parsing task.", "sent2": "We present a new dataset that contains candidate extractive and abstractive compressions of source sentences.", "label": 0}
{"sent1": "The paper reports on the setup of this catalogue, and concentrates on the technical issues involved in its creation, storage and display.", "sent2": "Our experimental evaluation over thousands of real questions indicates that indeed it is beneficial to personalize satisfaction predictions when sufficient prior user history exists, significantly improving accuracy over a ?one-size-fits-all?", "label": 0}
{"sent1": "We demonstrate that good results can be obtained using the robust EM-HMM learner when provided with good initial conditions, even with incomplete dictionaries.", "sent2": "normalization issues caused our correlation values to decrease.", "label": 0}
{"sent1": "This paper reports progress on a complete open-source software infrastructure supporting the rapid development of tools for transcribing and annotating time-series data.", "sent2": "Ensemble methods are state of the art for many NLP tasks.", "label": 0}
{"sent1": "The system consists of a rule-based component and a machine learned statistical model which uses a variety of construct-relevant features.", "sent2": "It is important to identify and filter out these deceptive answers.", "label": 0}
{"sent1": "At the participant level, correlation coefficients between machine overall scores and average human overall scores were: Kindergarten: 0.88; Grades 1-2: 0.90; Grades 3-5: 0.94; Grades 6-8: 0.95; Grades 9-12: 0.93.", "sent2": "We carried out a competitive evaluation of three leading treebank parsers on an annotated corpus from the human molecular biology domain, and on an extract from the Penn Treebank for comparison, performing a detailed analysis of the kinds of errors each parser made, along with a quantitative comparison of syntax usage between the two corpora.", "label": 0}
{"sent1": "average surprisal values decrease with EFL training.", "sent2": "Preliminary results seem to support this idea.", "label": 1}
{"sent1": "= 0.65.", "sent2": "This paper explores truecasing issues and proposes a statistical, language modeling based truecaser which achieves an accuracy of ?98% on news articles.", "label": 0}
{"sent1": "The resulting clusterings are then used in training partially class-based language models.", "sent2": "Query expansion by pseudo-relevance feedback is a well-established technique in both mono- and cross- lingual information retrieval, enriching and disambiguating the typically terse queries provided by searchers.", "label": 0}
{"sent1": "We validate our methods on a challenging dataset of young English language learners (ELLs) interacting with an automatic spoken assessment system.", "sent2": "We use WordNet to determine semantic relatedness.", "label": 0}
{"sent1": "suggests solutions to identified problems.", "sent2": "While prior studies have focused on peer review of papers, similar issues arise when reviewing diagrams and other artifacts.", "label": 1}
{"sent1": "Our systems focused on using a simple set of features, featuring a mix of semantic similarity resources, lexical match heuristics, and part of speech (POS) information.", "sent2": "Furthermore, we have developed a filtering algorithm to eliminate ambiguity when tagging candidate NEs.", "label": 0}
{"sent1": "We consider that the first and third approaches obtained a comparable performance, meanwhile the second approach got a very poor behavior.", "sent2": "This is the first work we are aware of to successfully integrate a supertagger with a full parser which uses an automatically extracted grammar.", "label": 0}
{"sent1": "This level is somewhat similar to results on lexical sample tasks with open class words, indicating that significant progress has been made.", "sent2": "The data generated in the task provides ample opportunitites for further investigations of preposition behavior.", "label": 1}
{"sent1": "Participating systems are free to use any lexical resource.", "sent2": "There is a subtask which requires identifying cases where the word is functioning as part of a multiword in the sentence and detecting what that multiword is.", "label": 1}
{"sent1": "Due to the intention of a pedophile of hiding his/her true identity (name, age, gender and location) its detection is a challenge.", "sent2": "According to previous research, fixated discourse is one of the main characteristics inherent to the language of online sexual predation.", "label": 1}
{"sent1": "Recent advances in the technology of stylometry (the study of authorial style) or ?authorship attribution?", "sent2": "have made it possible to identify the author with high reliability in a non-confrontational setting.", "label": 1}
{"sent1": "Moreover, we introduce bidirectional recurrent neural models to the problem of machine translation, allowing us to use the full source sentence in our models, which is also of theoretical interest.", "sent2": "Experiments show that the proposed method successfully reinforces countability prediction and outperforms other methods used for comparison.", "label": 0}
{"sent1": "We propose two neural network architectures: one that handles standard two-way selectional preferences and one that is able to deal with multi-way selectional preferences.", "sent2": "The model?s performance is evaluated on a pseudo-disambiguation task, on which it is shown to achieve state of the art performance.", "label": 1}
{"sent1": "Previous work studied generation from automatically detected visual information but produced a limited class of sentences, hindered by currently unreliable recognition of activities and attributes.", "sent2": "In this paper, we describe how we created two state-of-the-art SVM classifiers, one to detect the sentiment of messages such as tweets and SMS (message-level task) and one to detect the sentiment of a term within a message (term-level task).", "label": 0}
{"sent1": "that bag-of-words models based on secondorder statistics mainly capture paradigmatic relations and that syntagmatic relations need to be gathered from first-order models ?", "sent2": "Contrary to what has been argued in the literature (Rapp, 2002; Sahlgren, 2006) ?", "label": 1}
{"sent1": "a phrase-based model and a hierarchical phrase-based model.", "sent2": "Our approach is based on a large set of novel features that capture varied aspects of how words change when used in new domains.", "label": 0}
{"sent1": "The constrained message polarity model is then used to tag nearly half a million unlabeled tweets.", "sent2": "In this paper, we propose using NLP to add a ?qualitative?", "label": 0}
{"sent1": "As a preliminary step, the proposed approach indirectly (and automatically) exploits the scope of negation cues and the semantic roles of involved entities for reducing the skewness in the training data as well as discarding possible negative instances from the test data.", "sent2": "Then, a state-of-the-art hybrid kernel is used to train a classifier which is later applied on the instances of the test data not filtered out by the previous step.", "label": 1}
{"sent1": "In this study, we investigate the impact of such domain-specific features on the performance of recognizing and classifying mentions of pharmacological substances.", "sent2": "For coreference resolution, we propose a link type based pre-cluster pair model.", "label": 0}
{"sent1": "The polarity detection of a tweet is modeled as a classification task, tackled through a Multiple Kernel approach.", "sent2": "In this paper, the UNITOR system participating in the SemEval-2013 Sentiment Analysis in Twitter task is presented.", "label": 1}
{"sent1": "Unlike existing parsers, our incremental TSG parser can generate partial trees that include predictions about the upcoming words in a sentence.", "sent2": "In this paper, we mimic a scanning process to extract biographical facts.", "label": 0}
{"sent1": "Given a spoken query, we generate a transcription and detect OOV words through speech recognition.", "sent2": "This process generates a very large number of features, many of which are highly correlated.", "label": 0}
{"sent1": "The taxonomy is induced via a bootstrapping algorithms starting with a few seeds.", "sent2": "Because of the multilingual authors (mountaineers, scientists) and the assumed multilingual readers, the texts contain numerous code-switching elements.", "label": 0}
{"sent1": "The first mapping reduces classification errors by 4.0% to 83.9% over a test set of more than one million 65-character strings in 1366 languages, and by 2.6% to 76.7% over a subset of 781 languages.", "sent2": "are applied to the n-gram probabilities in five trainable open-source language identifiers.", "label": 1}
{"sent1": "Therefore, alternative methods, IMPACT and RIBES, were proposed and they have shown much stronger correlation than BLEU.", "sent2": "We discuss experimentation and analysis in initial and secondary pilot studies.", "label": 0}
{"sent1": "Most importantly, we show that such pivoting aids in learning of additional phrase pairs which are not learned when the direct sourcetarget corpus is small.", "sent2": "We obtained improvements of up to 3 BLEU points using multiple pivots for Japanese to Hindi translation compared to when only one pivot is used.", "label": 1}
{"sent1": "We propose a method to learn metaphors as linear transformations in a vector space and find that, across a variety of semantic domains, explicitly modeling metaphor improves the resulting semantic representations.", "sent2": "The evaluation task meant to determine whether automatic measures of evaluation can function well in the multi-lingual domain.", "label": 0}
{"sent1": "In this paper, we broaden the scope of these models to build sentence-level representations, and argue that phrase representations are best evaluated in terms of the inference decisions that they support, invariant to the particular syntactic constructions used to guide composition.", "sent2": "We propose two evaluation methods in relation classification and QA which reflect these goals, and apply several recent compositional distributional models to the tasks.", "label": 1}
{"sent1": "However, sense features complement structure information and lead to improved performance.", "sent2": "We present a statistical IMT system able to learn from user feedback by means of the application of online learning techniques.", "label": 0}
{"sent1": "We extend the bound to sequence clustering, wherein classes represent longer context such as phrases.", "sent2": "The new bound is dominated by the maximum number of sequences represented by each cluster, which is polynomial in the vocabulary size.", "label": 1}
{"sent1": "In this paper, we demonstrate that it is possible to learn procedural dialog systems given only light supervision, of the type that can be provided by non-experts.", "sent2": "This work presents two different translation models using recurrent neural networks.", "label": 0}
{"sent1": "Then we formulate a parsing strategy as a two-stage process where (i) coordinated and subordinated clauses of the sentence are parsed separately with respect to the sentence clause chart and (ii) their dependency trees become subtrees of the final tree of the sentence.", "sent2": "Then by making use of the reconstruction error, we propose a unified scheme to determine which feature or example a classifier is most likely to benefit from having labeled.", "label": 0}
{"sent1": "We evaluate distributional thesauri against manually created taxonomies both for English and German for five unsupervised parsers.", "sent2": "On the other hand, we explore whether single unsupervised parsers, or their combination, can contribute to better distributional similarities, or even replace supervised parsing as a preprocessing step for word similarity.", "label": 1}
{"sent1": "Beginning with a small bitext and corresponding phrase-based SMT model, we improve coverage by using bilingual lexicon induction techniques to learn new translations from comparable corpora.", "sent2": "Then, we supplement the model?s feature space with translation scores estimated over comparable corpora in order to improve accuracy.", "label": 1}
{"sent1": "Consequently, it is beneficial for the consumers of Twitter to know the origin of a tweet, as it affects how they view and interpret this information.", "sent2": "We further demonstrate excellent domain transfer of discourse information, suggesting these discourse features have general utility to non-factoid question answering.", "label": 0}
{"sent1": "In this paper we present a discourse informed model which is capable of producing document compressions that are coherent and informative.", "sent2": "The task is typically performed on isolated sentences without taking the surrounding context into account, even though most applications would operate over entire documents.", "label": 1}
{"sent1": "In contrast to previous work, which combines NMT models with separately trained language models, we note that encoder-decoder NMT architectures already have the capacity to learn the same information as a language model, and we explore strategies to train with monolingual data without changing the neural network architecture.", "sent2": "This paper presents a chunking-based discriminative approach to full parsing.", "label": 0}
{"sent1": "However, these require manually labeled training examples which are expensive to create and consequently supervised WSD systems are normally limited to disambiguating a small set of ambiguous terms.", "sent2": "Our experimental results indicate the effectiveness of our approach.", "label": 0}
{"sent1": "Rich semantic resources such as WordNet provide local semantic information at the lexical level.", "sent2": "However, effectively combining this information to compute scores for phrases or sentences is an open problem.", "label": 1}
{"sent1": "In this paper, we exploit a convolutional deep neural network (DNN) to extract lexical and sentence level features.", "sent2": "We use WordNet to determine semantic relatedness.", "label": 0}
{"sent1": "Although, both the varieties share a common grammar, they differ significantly in their vocabulary to an extent where both become mutually incomprehensible (Masica, 1993).", "sent2": "Finding concepts in natural language utterances is a challenging task, especially given the scarcity of labeled data for learning semantic ambiguity.", "label": 0}
{"sent1": "This transformation makes all of the techniques developed for CFGs available to PBDGs.", "sent2": "We demonstrate this by describing a maximum posterior parse decoder for PBDGs.", "label": 1}
{"sent1": "?This material is based upon work supported in part by the Defense Advanced Research Projects Agency (DARPA) under GALE Contract No.", "sent2": "Our results provide the first known empirical evidence that lexical semantics are indeed useful for SMT, despite claims to the contrary.", "label": 1}
{"sent1": "representationally in its features and algorithmically in its learning procedure.", "sent2": "As a consequence, existing systems are incapable of performing ad-hoc type classification on arbitrary input texts.", "label": 0}
{"sent1": "permits some alternative techniques of interest.", "sent2": "While discriminative methods, such as those presented in McDonald et al (2005b), obtain very high accuracy on standard dependency parsing tasks and can be trained and applied without marginalization, ?summing trees?", "label": 1}
{"sent1": "done for accents of English.", "sent2": "A number of different techniques are evaluated, including hierarchical phrase reordering, translation model interpolation, domain adaptation techniques, weighted phrase extraction, word class language model, continuous space language model and system combination.", "label": 0}
{"sent1": "In this paper, we investigate the impact of implicit and explicit attitude in two genres of social media discussion data, more formal wikipedia discussions and a debate discussion forum that is much more informal.", "sent2": "Experimental results strongly suggest that implicit attitude is an important complement for explicit attitudes (expressed via sentiment) and it can improve the sub-group detection performance independent of genre.", "label": 1}
{"sent1": "We represent each medical event as a time duration, with a corresponding start and stop, and learn to rank the starts/stops based on their proximity to the admission date.", "sent2": "Such a representation allows us to learn all of Allen?s temporal relations between medical events.", "label": 1}
{"sent1": "A sparse tensor formalization guarantees efficiency and parallelizability.", "sent2": "The synset/lexeme embeddings obtained live in the same vector space as the word embeddings.", "label": 1}
{"sent1": "In this paper, we provide an analysis of methods of comparison and identify areas of concern with respect to widely used measures, such as the ability to gain by prediction of aggregate statistics specific to gold label distributions or by optimally conservative variance in prediction score distributions.", "sent2": "Issues can arise during comparison of quality estimation prediction score distributions and gold label distributions, however.", "label": 1}
{"sent1": "We show that, although an isometric embedding is untractable, it is possible to achieve good non-isometric embeddings.", "sent2": "Our results show asynchronous learning can provide substantial speedups compared to distributed and singleprocessor mini-batch algorithms with no signs of error arising from the approximate nature of the technique.", "label": 0}
{"sent1": "Recent studies on relation extraction are mostly supervised.", "sent2": "Relation Extraction (RE) is the task of extracting semantic relationships between entities in text.", "label": 1}
{"sent1": "We extend a non-parametric model of word segmentation by adding phonological rules that map from underlying forms to surface forms to produce a mathematically well-defined joint model as a first step towards handling variation and segmentation in a single model.", "sent2": "Current computational models of unsupervised word segmentation usually assume idealized input that is devoid of these kinds of variation.", "label": 1}
{"sent1": "This is a major cause of data sparseness for corpus-based approaches to lexical semantics, such as distributional semantic models of word meaning.", "sent2": "The grammar is trained on a large corpus by a simple supervised method, and evaluated on a syllabification task achieving 96.88% word accuracy on word tokens, and 90.33% on word types.", "label": 0}
{"sent1": "We further show that our methodology can be used to predict more fine-grained phonetic distinctions.", "sent2": "a supervised summarizer, based on a genetic algorithm (GA), that ranks document sentences and extracts top?ranking sentences into a summary, (2) POLY ?", "label": 0}
{"sent1": "We exploit this wide variation with bagging, sampling from automatically extracted seeds to reduce semantic drift.", "sent2": "However, we demonstrate that performance varies greatly depending on these seeds, and favourable seeds for one algorithm can perform very poorly with others, making comparisons unreliable.", "label": 1}
{"sent1": "However, this approach neglects logical constraints between temporal relations of different types that we believe to be helpful.", "sent2": "Different from the vanilla encoder-decoder model that generates target translations from hidden representations of source sentences alone, the variational model introduces a continuous latent variable to explicitly model underlying semantics of source sentences and to guide the generation of target translations.", "label": 0}
{"sent1": "We develop a kernelized soft relational clustering algorithm that makes use of the learned distance function to partition the entities into fuzzy sets of identities.", "sent2": "Our parser yields an improvement of 5% absolute in F-measure over the best previous result.", "label": 0}
{"sent1": "), but also the correct level of generality (e.g., ?Composers?", "sent2": "Analysing new languages also tests formalisms, exposing their strengths and weaknesses.", "label": 0}
{"sent1": "For that purpose, we extract naturally occurring errors and their contexts from the Wikipedia revision history.", "sent2": "We have applied both LSA and PLSA in our system for grading essays written in Finnish, called Automatic Essay Assessor (AEA).", "label": 0}
{"sent1": "It is based on word-document cooccurrence statistics in the training corpus and a dimensionality reduction technique.", "sent2": "However, it doesn?t consider the word-order or syntactic information, which can improve the knowledge representation and therefore lead to better performance of an ITS.", "label": 1}
{"sent1": "This paper discusses how a corpus of L2 essays for English was rated using the parser, and how the automatic evaulations compared to those obtained by manual methods.", "sent2": "ungrammatical compositions.", "label": 1}
{"sent1": "Our evaluation demonstrates that the hybrid CarmelTC approach outperforms two ?bag of words?", "sent2": "Our goal has been to combine the strengths of both of these approaches while avoiding some of the weaknesses.", "label": 1}
{"sent1": "Retraining translation models yields modest improvements.", "sent2": "First, we extend existing parallel corpora using co-training, wherein machine translations are selectively added to training corpora with multiple source texts.", "label": 1}
{"sent1": "The translations of meaning-equivalent sentences correspond to ?rough translations.?", "sent2": "A meaning-equivalent sentence shares the main meaning with an input despite lacking some unimportant information.", "label": 1}
{"sent1": "Different methods are proposed, based on a statistical translation model.", "sent2": "This new QBTE approach liberates QA systems from the heavy burden imposed by question types (or answer types).", "label": 0}
{"sent1": "Our method is empirically evaluated using English-Japanese parallel corpora of 6 million words.", "sent2": "Results indicate that it works well for multi-word translations, giving 56-84% accuracy at 19% token coverage and 11% type coverage.", "label": 1}
{"sent1": "in less appropriate locations.", "sent2": "For this task SenseClusters was configured to construct representations of the instances to be clustered using the centroid of word cooccurrence vectors that replace the words in an instance.", "label": 0}
{"sent1": "In typical scenarios, transcribed in-domain data is limited but large amounts of out-of-domain (OOD) data is available.", "sent2": "In this study, we investigate how semi-supervised training performs with OOD data.", "label": 1}
{"sent1": "We also strive to find the levels of difficulties in annotating various classes of words, with senses.", "sent2": "In this paper, we present a hypothesis regarding the cognitive sub-processes involved in the task ofWSD.We support our hypothesis using the experiments conducted through the means of an eye-tracking device.", "label": 1}
{"sent1": "and Barrier, 2004), as instantiated in the SPMRL Shared Task (Seddah et al., 2013).", "sent2": "In this paper, we investigate various strategies to predict both syntactic dependency parsing and contiguous multiword expression (MWE) recognition, testing them on the dependency version of French Treebank (Abeille?", "label": 1}
{"sent1": "Experiments show (i) automatically generated error case frames achieve a performance comparable to conventional methods; (ii) error case frames are intuitively interpretable and manually modifiable to improve them; (iii) feedback messages provided by error case frames are effective in language learning assistance.", "sent2": "Instead, we employ evolutionary search techniques to explore the space of possible stories which we argue are well suited to the story generation task.", "label": 0}
{"sent1": "Our system uses the domain-specific data as one dataset to build a robust system.", "sent2": "The method could be used both in a semi-supervised setting where a training set of labeled words is used, and in an unsupervised setting where a handful of seeds is used to define the two polarity classes.", "label": 0}
{"sent1": "We use the SemEval 2007 Preposition Sense Disambiguation datasets to evaluate our system and compare its results to those of the systems participating in the workshop.", "sent2": "We derived linguistically motivated features from both sides of the preposition.", "label": 1}
{"sent1": "We study this problem as a new task ?", "sent2": "multiple source parser adaptation.", "label": 1}
{"sent1": "We revisit two previously studied approaches, one that hurt parsing performance and one that achieved minor improvements, and propose a new method that aims to better integrate prosodic breaks into parsing.", "sent2": "Grammatical relationships, stored in dictionaries, are utilized in translation selection essentially.", "label": 0}
{"sent1": "into a semiMarkov conditional random field model of entity extraction in ad creatives.", "sent2": "Utilizing recent work in constraint-based semi-supervised learning, this paper injects light weight supervision specified as these ?constraints?", "label": 1}
{"sent1": "This paper explores the use of information extraction (IE) techniques to create richer linguistic features than traditional bag-of-words models.", "sent2": "The models are trained on a per year basis, whereby only papers published up until a given year are used to learn that year?s author topics.", "label": 0}
{"sent1": "The second study investigated how shared visual space and monitoring shape the processes of feedback  and communication in task-oriented interactions.", "sent2": "The results provide insights for the development of human-inspired and robust natural language interfaces in robots.", "label": 1}
{"sent1": "We present a novel corpus study and associated typology that aims to situate these responses in the broader class of indirect question?answer pairs (IQAPs).", "sent2": "We then model the different types of IQAPs using Markov logic networks, which combine first-order logic with probabilities, emphasizing the ways in which this approach allows us to model inferential uncertainty about both the context of utterance and intended meanings.", "label": 1}
{"sent1": "This means that dialog systems can guide users?", "sent2": "We also find that user adaptation is affected by perceived system adaptation.", "label": 1}
{"sent1": "Each of the presented approaches is tested on a standard corpus of clinical texts.", "sent2": "The obtained results show that the hybrid approach based on both machine learning and domain knowledge obtains the best performance.", "label": 1}
{"sent1": "Secondly, we will demonstrate the deployed system which enables participants to call up and speak to the SDS recently created.", "sent2": "A parallel corpus of texts in English and in Inuktitut, an Inuit language, is presented.", "label": 0}
{"sent1": "The language modeling and dialog management techniques developed for this purpose are also briefly described.", "sent2": "Finally, several use cases with screen shots are presented.", "label": 1}
{"sent1": "Some gaze streams do not link to the content of the spoken utterances and thus can be potentially detrimental to word acquisition.", "sent2": "However, unlike in the typical settings for psycholinguistic studies, eye gaze can serve different functions in human-machine conversation.", "label": 1}
{"sent1": "Second, we present a framework for generating the clarification potential of an instruction by inferring its conversational implicatures with respect to a particular context.", "sent2": "We introduce a method for filtering this noise allowing highly accurate learning of bilingual lexicons.", "label": 0}
{"sent1": "We describe a graph-based approach for finding the optimal permutation.", "sent2": "We evaluated the models by comparing the synthesized sentences with reference sentences using the standard BLEU metric(Papineni et al, 2001).", "label": 0}
{"sent1": "We analyzed graphically and statistically how the global properties of these networks varied across different genres, and among different network types within the same genre.", "sent2": "Each document of a particular genre was converted into a network of words with word collocations as edges.", "label": 1}
{"sent1": "Other Wikipedia features - namely redirects, anchor texts, and inter-language links - are used to tag additional NEs, which appear without links in Wikipedia texts.", "sent2": "Each Wikipedia link is transformed into an NE type of the target article in order to produce the NE annotation.", "label": 1}
{"sent1": "However, great amounts of human effort is necessary to build and maintain an annotated corpus.", "sent2": "These abstracts represent a huge amount of information that could be used to generate annotations for proteins automatically.", "label": 0}
{"sent1": "Unlike previous approaches, we use linguistic information to derive error generation probabilities and build corpora to correct several error types, including open-class errors.", "sent2": "Artificial errors are injected into a set of error-free sentences in a probabilistic manner using statistics from a corpus.", "label": 1}
{"sent1": "In particular, our algorithm does not constraint the scoring function in opposite to Viterbi based decoders.", "sent2": "This paper describes a new method to compare reordering constraints for Statistical Machine Translation.", "label": 0}
{"sent1": "To import structural information, we employ re-ranking technique to incorporate thematic rank relations into local semantic role classification results.", "sent2": "Experimental results show that automatic prediction of thematic hierarchy can help semantic role classification.", "label": 1}
{"sent1": "We demonstrate that an acoustic-based context model can achieve accuracies over 79% on binary pitch accent recognition when trained on withingroup data.", "sent2": "prosodic errors, we investigate automatic pitch accent labeling for nonnative speech.", "label": 1}
{"sent1": "In this paper, we create a general and unified framework for IS methods.", "sent2": "C4.5 was applied to induce the classification models of the placement.", "label": 0}
{"sent1": "Moreover, many applications in computational linguistics require the computation of similarities over pair of syntactic or semantic trees.", "sent2": "Recently, there is a growing interest in working with tree-structured data in different applications and domains such as computational biology and natural language processing.", "label": 1}
{"sent1": "However, the knowledge on the document side, i.e.", "sent2": "Most of the existing multi-document summarization methods decompose the documents into sentences and work directly in the sentence space using a term-sentence matrix.", "label": 1}
{"sent1": "In addition, we propose to incorporate global features which explicitly capture the dependencies of multiple triggers and arguments.", "sent2": "In this article we address compound splitting of specialized terms.", "label": 0}
{"sent1": "without the user having to ask for it?", "sent2": "as in real radio broadcast.", "label": 1}
{"sent1": "In-car dialogue systems typically resemble non-co-located conversations more, and share their negative impact (Strayer et al., 2013).", "sent2": "interlocutors (Drews et al., 2004).", "label": 1}
{"sent1": "From the confidence label assigned for each word in the MT hypothesis, we add six scores to the baseline loglinear model in order to re-rank the N-best list.", "sent2": "Our results on the PDTB yields a significant 14.1% improvement over the baseline.", "label": 0}
{"sent1": "To this end we propose a novel algorithm that analyzes dependency structures of queries and known relevant text passages and acquires transformational patterns that can be used to retrieve relevant textual content.", "sent2": "To this end, we focus on extracting diverse sets of threads?singlylinked, coherent chains of important documents.", "label": 0}
{"sent1": "We make use of a latent parse that encodes a language-flexible representation of time, and extract rich features over both the parse and associated temporal semantics.", "sent2": "Using the implemented paraphraser and the obtained patterns, a paraphrasing experiment was conducted and the results were evaluated.", "label": 0}
{"sent1": "The first approach is via a standard tuning procedure optimizing for BLEU score and the second one is via a reranking approach optimizing for MAP score.", "sent2": "We propose two ways to achieve the adaptation effect and both of them are aimed at tuning parameter weights on a set of parallel queries.", "label": 1}
{"sent1": "The quality of this search space can thus be evaluated by computing the best achievable hypothesis in the lattice, the so-called oracle hypothesis.", "sent2": "The search space of Phrase-Based Statistical Machine Translation (PBSMT) systems can be represented under the form of a directed acyclic graph (lattice).", "label": 1}
{"sent1": "This paper studies such issues by analysing two training data selection techniques: one based on approximating the probability of an indomain corpus; and another based on infrequent n-gram occurrence.", "sent2": "While the chart-based approach has been the dominant approach for CCG, the shift-reduce method has been little explored.", "label": 0}
{"sent1": "To facilitate evaluation, we obtain annotations for articles in four topical groups, allowing annotators to identify domain-specific entity types in addition to standard categories.", "sent2": "Our variational EM learning algorithm alternately reestimates this phylogeny and the transducer parameters.", "label": 0}
{"sent1": "We approach the task in two steps, involving Conditional Random Fields and Probabilistic Context-Free Grammars, integrated in a single parsing algorithm.", "sent2": "Two aspects make the task more difficult with respect to previous NER tasks: i) named entities annotated used in this work have a tree structure, thus the task cannot be tackled as a sequence labelling task; ii) the data used are more noisy than data used for previous NER tasks.", "label": 1}
{"sent1": "Spectral method is applied to find the best cuts of the graph.", "sent2": "We further cast the model as a neural network and propose an unsupervised algorithm to jointly train word representations with co-compositionality.", "label": 0}
{"sent1": "Our system achieves 3.8% total error rate in English.", "sent2": "We show similar improvements in preliminary results on artificial data for Russian and Arabic.", "label": 1}
{"sent1": "We then show that combining these acquisition age distributions for all words in a document provides an effective semantic component for predicting reading difficulty of new texts.", "sent2": "On WSJ15, we attain a state-of-the-art F-score of 90.9%, a 14% relative reduction in error over previous models, while being two orders of magnitude faster.", "label": 0}
{"sent1": "the influence of local context.", "sent2": "The methodology developed addresses one issue related to metonymy resolution ?", "label": 1}
{"sent1": "We obtain this abstract through a generative model that requires no labeled data, instead leveraging repetition across multiple documents.", "sent2": "We propose a novel form of semantic analysis called reading to learn, where the goal is to obtain a high-level semantic abstract of multiple documents in a representation that facilitates learning.", "label": 1}
{"sent1": "We additionally show how our cluster-ranking framework naturally allows discourse-new entity detection to be learned jointly with coreference resolution.", "sent2": "Experimental results on the ACE data sets demonstrate its superior performance to competing approaches.", "label": 1}
{"sent1": "Combining all these pairwise preferences to find the best global reordering is NP-hard.", "sent2": "Email is an important way of communication in our daily life and it has become the subject of various NLP and social studies.", "label": 0}
{"sent1": "We propose a new structure called weighted alignment matrix to encode all possible alignments for a parallel text compactly.", "sent2": "We use Gaussian Processes, a state-ofthe-art bayesian non-parametric model, with a novel periodic kernel.", "label": 0}
{"sent1": "The model operates on a feature representation in which sentence level translations are represented by enumerating all the known phrase level translations that occur inside them.", "sent2": "For these reasons, to improve automatic ontology translations, we first focus on identifying relevant unambiguous and domain-specific sentences from a large set of generic parallel corpora.", "label": 0}
{"sent1": "The former shows a potential for time-series similarity measures to identify specific semantic relatedness between words, which results in state-of-the-art performance in query suggestion while providing complementary information to more traditional distributional similarity measures.", "sent2": "(MWEs) in an annotated corpus.", "label": 0}
{"sent1": "Starting out from a formalism for entailment-rule application we present a novel packed data-structure and a corresponding algorithm for its scalable implementation.", "sent2": "Efficient inference with such knowledge then becomes a fundamental problem.", "label": 1}
{"sent1": "Our approach improves upon Sherif and Kondrak?s (2007b) state-of-theart decoder, creating a 28.5% relative improvement in transliteration accuracy on a Japanese katakana-to-English task.", "sent2": "We also conduct a controlled comparison of two feature paradigms for discriminative training: indicators and hybrid generative features.", "label": 1}
{"sent1": "Since data annotation is usually costly, methods to reduce the amount of data are needed.", "sent2": "Our studies of correspondences in the two languages show that case markers and suffixes in Hindi are predominantly determined by the combination of suffixes and semantic relations on the English side.", "label": 0}
{"sent1": "We advocate the use of relatively simple tags that do not require deep linguistic knowledge of the language but provide more structural information than POS tags and can be derived from automatically generated parse trees ?", "sent2": "Considering phrases that correspond to syntactic categories in the parse trees we develop techniques to augment (declare a syntactically motivated category for a phrase pair) and generalize (form mixed terminal and nonterminal phrases) the phrase table into a synchronous bilingual grammar.", "label": 0}
{"sent1": "(2001)-style) and global (Integer Linear Programming, Denis and Baldridge (2007)style) models of coreference.", "sent2": "We will demo three different versions of the system: an anyto-any multilingual version involving the languages Japanese, English, French and Arabic, a bidirectional English ?", "label": 0}
{"sent1": "Computational  estimation of  this  quantity  is  important  for various applications such as information retrieval.", "sent2": "This methodology reduces the amount of required handcrafted knowledge, and can infer gradability of words independent of their part of speech.", "label": 0}
{"sent1": "While detecting questions in standard language data corpus is relatively easy, it becomes a great challenge for online content.", "sent2": "Online questions are usually long and informal, and standard features such as question mark or 5W1H words are likely to be absent.", "label": 1}
{"sent1": "A general problem of this approach is that there is only a loose relation to the final translation quality on unseen text.", "sent2": "Often, the training procedure for statistical machine translation models is based on maximum likelihood or related criteria.", "label": 1}
{"sent1": "Our method is based on two sources of information: (1) the correlation between the text and the specification tree and (2) noisy supervision as determined by the success of the generated C++ parser in reading input examples.", "sent2": "We model the problem as a joint dependency parsing and semantic role labeling task.", "label": 1}
{"sent1": "Localized error detection finds specific mis-recognized words in a user utterance.", "sent2": "We address the problem of localized error detection in Automatic Speech Recognition (ASR) output to support the generation of targeted clarifications in spoken dialogue systems.", "label": 1}
{"sent1": "Then, this model is used to create additional sentencespecific word- and phrase-level translations that are added to a standard translation model as ?synthetic?", "sent2": "Furthermore, a new domain-verb association measure is presented to show the association relationships between inferred verbs and domains to which the verbs are possibly applied.", "label": 0}
{"sent1": "Our system addresses lexical feature sparsity given the small amount of training data by using an autoencoder network to map sparse lexical feature vectors into 30 compressed features.", "sent2": "Our flirtationdetection system uses prosodic, dialogue, and lexical features to detect a speaker?s intent to flirt with up to 71.5% accuracy, significantly outperforming the baseline, but also outperforming the human interlocuters.", "label": 1}
{"sent1": "All of the commonly used statistical parsers use context-free dynamic programming algorithms and as such work bottom up on the entire sentence.", "sent2": "Extracting meaning from short text segments is difficult as there is little semantic redundancy between terms; hence methods based on shallow semantic analysis may fail to accurately estimate meaning.", "label": 0}
{"sent1": "The experiments show that the LABTG approach significantly outperforms a baseline BTGbased system and a state-of-the-art phrasebased system on the NISTMT-05 Chineseto-English translation task.", "sent2": "Moreover, we empirically demonstrate that the proposed method achieves better translation selection and phrase reordering.", "label": 1}
{"sent1": "This paper presents a novel approach to producing a brief textual summary of a simple bar chart.", "sent2": "It outlines our approach to augmenting the core message of the graphic to produce a brief summary.", "label": 1}
{"sent1": "However, such concepts are comparatively rare in everyday language.", "sent2": "In this work, we present a new means of extending the scope of multi-modal models to more commonly-occurring abstract lexical concepts via an approach that learns multimodal embeddings.", "label": 1}
{"sent1": "Our approach is based on identifying candidates and ranking them using Log-Likelihood Ratio.", "sent2": "Then, it relies on several filters to filter the list of candidates, namely: Word-Alignment, POS patterns, and Syntax.", "label": 1}
{"sent1": "We translate out-of-vocabulary words and transliterate named entities in a post-processing stage.", "sent2": "Since parallel corpus is limited, many words are not translated.", "label": 1}
{"sent1": "We specifically show how to instantiate PEP in the case of string-valued random variables, where we adaptively approximate finite-state distributions by variable-order n-gram models.", "sent2": "On phonological inference problems, we obtain substantial speedup over previous related algorithms with no significant loss in accuracy.", "label": 1}
{"sent1": "While results from DSTC 1 mention performance limitations, an examination of the errors made by dialog state trackers was not discussed in depth.", "sent2": "A primary motivation of the Dialog State Tracking Challenge (DSTC) is to allow for direct comparisons between alternative approaches to dialog state tracking.", "label": 1}
{"sent1": "While this has been typically done with a keyboard and a mouse, pen-based devices set an opportunity for making such corrections in a comfortable way, as if proofreading on physical paper.", "sent2": "We show that relying on linguistic information dramatically improves the accuracy of compound extraction, reducing over one third of the errors compared with the best baseline.", "label": 0}
{"sent1": "Instead of learning word-specific substitution patterns, a global model for lexical substitution is trained on delexicalized (i.e., non lexical) features, which allows to exploit the power of supervised methods while being able to generalize beyond target words in the training set.", "sent2": "The first workshop on statistical parsing of MRLs hosts a variety of contributions which show that despite languagespecific idiosyncrasies, the problems associated with parsing MRLs cut across languages and parsing frameworks.", "label": 0}
{"sent1": "and ?cohesiveness?", "sent2": "In this paper we investigate an application of feature clustering for word sense disambiguation, and propose a semisupervised feature clustering algorithm.", "label": 0}
{"sent1": "Expressions generated using this method are often overspecified and may be underspecified, akin to expressions produced by people.", "sent2": "Our method separates absolute properties like color from relative properties like size to stochastically generate a diverse set of outputs.", "label": 1}
{"sent1": "Our participation in Semeval task #17 focused on producing running systems for all languages in the task, and we attained good results in all except Chinese.", "sent2": "Testing with five different classifiers, we can report an increased accuracy that outperforms the best system in the SemEval task.", "label": 0}
{"sent1": "Using the built dataset, the system classifies the meaning of adjectives into positive or negative sentiment polarity according to the given context.", "sent2": "Our approach is fully automatic.", "label": 1}
{"sent1": "Unlike prior work inspired by SRL, we cast this problem as an anaphora resolution task and embed it in an entity-based coreference resolution (CR) architecture.", "sent2": "Linking implicit semantic roles is a challenging problem in discourse processing.", "label": 1}
{"sent1": "These links serve as an excellent resource for obtaining lexical translations, or building multilingual dictionaries and semantic networks.", "sent2": "traverse the route using prerecorded route segments.", "label": 0}
{"sent1": "In addition, we conduct a comparative study of different encoders including additive composition, RNN, LSTM, and GRU for composing distributed representations of relational patterns.", "sent2": "We also present Gated Additive Composition, which is an enhancement of additive composition with the gating mechanism.", "label": 1}
{"sent1": "The model is then extended to the general log-linear framework in order to rescore with other features like n-gram language models.", "sent2": "The use of A* search can dramatically reduce the time required to find a best parse by conservatively estimating the probabilities of parse completions.", "label": 0}
{"sent1": "While Markov logic is capable of constructing arbitrary first-order formulae over the data, the complexity of these formulae is often limited in practice because of the size and connectivity of the resulting network.", "sent2": "Markov logic is a highly expressive language recently introduced to specify the connectivity of a Markov network using first-order logic.", "label": 1}
{"sent1": "Finally, we discuss the idea that the ?pathway to healthcare?", "sent2": "The system combines several classifiers and works in two phases.", "label": 0}
{"sent1": "Current coreference resolvers restrict anaphors to at most a single antecedent.", "sent2": "As we show in this paper, relaxing this constraint poses serious problems in coreference chain-building, where each chain is intended to refer to a single entity.", "label": 1}
{"sent1": "We search for ciphers which permit writing under the Xenotext constraints, incorporating ideas from cipher-cracking algorithms, and using n-gram data to assess a cipher?s ?writability?.", "sent2": "The molecular machinery of life requires that these two poems encipher each other under a symmetric substitution cipher.", "label": 1}
{"sent1": "Experiments with AAN datasets show a significant improvement compared to the baselines to achieve the true labels of the references (46% better correlation).", "sent2": "To this end, we collect a rich annotated dataset with references labeled by the intensity, and propose a novel graph-based semisupervised model, GraLap to label the intensity of references.", "label": 1}
{"sent1": "After that, to make the sparse relationship denser, we propose a Bayesian method to calculate the probability of connections between users and other video describing words.", "sent2": "microblogs, and build the direct relationships between users and the appeared words.", "label": 1}
{"sent1": "Data-driven methods have been proposed to mine formulas from KBs automatically, where random sampling and approximate calculation are common techniques to handle big data.", "sent2": "Deep inference on a large-scale knowledge base (KB) needs a mass of formulas, but it is almost impossible to create all formulas manually.", "label": 1}
{"sent1": "However, propositionalization does not scale beyond domains with only few entities and rules.", "sent2": "A recent approach regularizes relation and entity representations by propositionalization of first-order logic rules.", "label": 1}
{"sent1": "Unfortunately KBs often suffer from being too restrictive, as the schema cannot support certain types of answers, and too sparse, e.g.", "sent2": "Wikipedia contains much more information than Freebase.", "label": 1}
{"sent1": "We evaluate this model on a collection of news articles about immigration, showing that personas help predict the coarse-grained framing annotations in the Media Frames Corpus.", "sent2": "Fully unsupervised pattern-based methods for discovery of word categories have been proven to be useful in several languages.", "label": 0}
{"sent1": "We consider 9 types of features and use a subset of them in our submitted system.", "sent2": "The training data are constrained to the data provided by the task organizers (No other tweet data are used).", "label": 1}
{"sent1": "in the context of information-seeking dialogues.", "sent2": "Here we account for scenarios with a continuous incoming stream of parallel training data.", "label": 0}
{"sent1": "We examine two different perspectives to the problem of topic analysis needed for carrying out a successful dialogue.", "sent2": "This paper presents two collective disambiguation approaches using a graph representation where possible KB candidates for NE textual mentions are represented as nodes and the coherence relations between different NE candidates are represented by edges.", "label": 0}
{"sent1": "The reason is that dealing with verb errors requires a new paradigm; essentially all research done on correcting grammatical errors assumes a closed set of triggers ?", "sent2": "While useful, the effectiveness of these models is highly dependent on the availability of quality parallel monolingual corpora (e.g., question-answer pairs) in the absence of which they are troubled by noise issue.", "label": 0}
{"sent1": "The Zipf?s law of meaning is used as a way of pre-setting the sense number for the parametric model.", "sent2": "We believe that concepts generalize the contexts, allowing the model to measure the sense similarity at a more general level.", "label": 1}
{"sent1": "We show that the new algorithm is several times faster than other statistical PMCFG parsing algorithms on real-sized grammars.", "sent2": "This approach aims to integrate different types of evidence from the collaborative referential discourse into a unified scheme.", "label": 0}
{"sent1": "Hence, we can interpret various modelling components, transforming them into indirect ?suggestions?", "sent2": "The experimental results point out that a strong prediction performance is achieved, especially for models based on the Gaussian Processes framework.", "label": 1}
{"sent1": "We use the word vectors to expand entity sets used for training classifiers in a bootstrapped pattern-based entity extraction system.", "sent2": "Our experiments show that the classifiers trained with the expanded sets perform better on entity extraction from four online forums, with 30% F 1 improvement on one forum.", "label": 1}
{"sent1": "We develop a MAP-EM algorithm that uses triangulation as a prior, and show how to extend it to a multi-task setting.", "sent2": "Our approach builds upon model triangulation, following Wang et al., which approximates a source-target model by combining source-pivot and pivot-target models.", "label": 1}
{"sent1": "We show that subsequence based features perform better than state-ofthe-art classifier for the purpose of cognate identification.", "sent2": "The contribution of this paper is the use of subsequence features for cognate identification.", "label": 1}
{"sent1": "However, a previous study (Sporleder and Lascarides, 2008) showed that models trained on these synthetic data do not generalize very well to natural (i.e.", "sent2": "Word error reductions of 0.5% absolute are reported using only a very limited amount of additional processing time.", "label": 0}
{"sent1": "Given a set of indicators, our method learns how to best separate types of mention pairs into equivalence classes for which we construct distinct classification models.", "sent2": "In effect, our approach finds an optimal feature space (derived from a base feature set and indicator set) for discriminating coreferential mention pairs.", "label": 1}
{"sent1": "However, few models in ad hoc information retrieval (IR) use paths for document ranking due to the prohibitive cost of parsing a retrieval collection.", "sent2": "Specifically, combinations of decision trees and language models are used to predict sentence ends and interruption points and, given these events, transformationbased learning is used to detect edit disfluencies and conversational fillers.", "label": 0}
{"sent1": "This analysis seeks to identify common linguistic patterns which hold for all of the translations from the same author.", "sent2": "Based on the experimental results, it is ascertained that both document-level metrics and n-gram features prove useful for distinguishing between authorial contributions in our translation corpus and their individual efficacy increases further when these two feature types are combined, resulting in classification accuracy of greater than 90 % on the task of predicting the original author of a textual segment using a Support Vector Machine classifier.", "label": 1}
{"sent1": "We introduce a novel taxonomy of such approaches and apply it to treebanks across a typologically diverse range of 26 languages.", "sent2": "We also use an online margin-based algorithm with efficient kernel computation.", "label": 0}
{"sent1": "This is performed by augmenting a standard MT system with domainspecific phrase dictionaries automatically mined from the online Wikipedia.", "sent2": "We evaluate the MTurk annotations by using positive and negative control candidate translations.", "label": 0}
{"sent1": "We apply this technique for Hindi-English transliteration task.", "sent2": "respectively, then there is more likely a ?DirectorOf?", "label": 0}
{"sent1": "The second component, Similarity Matcher, returns a ranked list of word images which are most similar to the query based on a cosine similarity metric.", "sent2": "A manual Relevance feedback is applied based on Rocchio?s formula, which re-formulates the query vector to return an improved ranked listing of word images.", "label": 1}
{"sent1": "We have described two methodologies for the preparation of gazetteers1.", "sent2": "This paper describes our approaches for the preparation of gazetteers for named entity recognition (NER) in Indian languages.", "label": 1}
{"sent1": "We have evaluated our syllable inventory on 2,728 sentences spread over 258 pages and observed a coverage of 99.96%.", "sent2": "In both cases, the quality of the alignments is crucial for the success of the translation process.", "label": 0}
{"sent1": "in traditional songs when praising the  host?s diligence  in  a ceremony  celebrating the  completion  of  a  workhouse.", "sent2": "and ?block-wise compression?", "label": 0}
{"sent1": "Based on these experiments, The Knowledge Management System (KMS) was developed to combine these two capabilities and to serve as a unified basis for other types of document exploration.", "sent2": "KMS has been extended to include web question answering, both general and topic-based summarization, information extraction, and document exploration.", "label": 1}
{"sent1": "Vi-xfst also keeps track of dependencies among the regular expressions at a very finegrained level.", "sent2": "So when a certain regular expression is modified as a result of testing, only the dependent regular expressions are recompiled resulting in an improvement in development process time, by avoiding file level recompiles which usually causes redundant regular expression compilations.", "label": 1}
{"sent1": "a physician?s diagnostic self-awareness).", "sent2": "Shedding light on the cognitive processes related to such awareness could also help improve medical education.", "label": 1}
{"sent1": "Six different feature extraction strategies were applied to this corpus and combined in various parametrizations in different classifiers.", "sent2": "to complete syntactic structures on the basis of prechunked input.", "label": 0}
{"sent1": "3LB annotation scheme has been developed for three languages (Spanish, Catalan and Basque).", "sent2": "We augment the model with information from the contents of bills, comparing different hypotheses about how a committee decides a bill?s fate.", "label": 0}
{"sent1": "We introduce a TAG?based formalism that encodes a strong notion of incrementality directly into the operations of the formal system.", "sent2": "We evaluate Basilisk on six semantic categories.", "label": 0}
{"sent1": "This architecture is then instantiated in the form of an incremental parser which receives suitability feedback on NP constituents from a reference resolution module.", "sent2": "We use a sequence of hand-crafted reordering rules applied to English parse trees.", "label": 0}
{"sent1": "Deterministic parsing takes the extreme position that there can only be one analysis for any sentence prefix.", "sent2": "ACT relies on automatic word-level alignment (using GIZA++) between a source sentence and respectively the reference and candidate translations, along with other heuristics for comparing translations of discourse connectives.", "label": 0}
{"sent1": "Our thesis is that a suitable learning bias for grammar induction is to minimize the degree of lookahead required, on the underlying tenet that language evolution drove grammars to be efficiently parsable in incremental fashion.", "sent2": "We define a new learning task, minimum average lookahead grammar induction, with strong potential implications for incremental parsing in NLP and cognitive models.", "label": 1}
{"sent1": "In this paper, we analyze its potential for incremental processing and conclude that strict incrementality is not achievable within this framework.", "sent2": "However, we also show that it is possible to minimize the number of structures that require nonincremental processing by choosing an optimal parsing algorithm.", "label": 1}
{"sent1": "We categorized them along multiple dimensions including evidence of mental illness, presence and nature of any threat, and level of threat.", "sent2": "We analyzed a sample of communications to judges that were referred to security personnel for evaluation as constituting potential threats.", "label": 1}
{"sent1": "We find that the words used by children with typical development tend to be used by other children with typical development, while the words used by children with autism overlap less with those used by children with typical development and even less with those used by other children with autism.", "sent2": "We explore two approaches for event status classification: (1) a feature-based SVM classifier augmented with a novel induced lexicon of future-oriented verbs, such as ?threatened?", "label": 0}
{"sent1": "To do so, we first concretely define what it means to be visual, annotate visual text and then develop algorithms to automatically classify noun phrases as visual or non-visual.", "sent2": "We find that using text alone, we are able to achieve high accuracies at this task, and that incorporating features derived from computer vision algorithms improves performance.", "label": 1}
{"sent1": "In addition to describing our approach, we formalize the task of translation sense clustering and describe a procedure that leverages WordNet for evaluation.", "sent2": "We also report results using data from the monolingual French and English GIGAWORD corpora.", "label": 0}
{"sent1": "As a result, most topic models generate topics independently from a single underlying distribution and require millions of parameters, in the form of multinomial distributions over the vocabulary.", "sent2": "In current statistical machine translation (SMT), erroneous word reordering is one of the most serious problems.", "label": 0}
{"sent1": "We augment the model with information from the contents of bills, comparing different hypotheses about how a committee decides a bill?s fate.", "sent2": "These models give significant reductions in prediction error and highlight the importance of bill substance in explanations of policy-making and agenda-setting.", "label": 1}
{"sent1": "In particular, we show that the transfer phase in a Machine Translation system based on tectogrammatical dependency trees can be seen as a task suitable for HMTM.", "sent2": "We achieved a better accuracy for assigning function labels than a predicate-argument structure analyzer by using grammatical functions as dependency label.", "label": 0}
{"sent1": "We report on experiments to find experts in a university domain using two different methods to extract a ranked list of candidates: a database-driven method and a data-driven method.", "sent2": "The first one is based on a fixed list of experts (e.g.", "label": 1}
{"sent1": "exist in any dictionary.", "sent2": "When tracking 4.4 million topics against 52 million documents in constant time and space, we demonstrate that counter to expectations, simple single-pass clustering can outperform locality sensitive hashing for nearest neighbour search on streams.", "label": 0}
{"sent1": "We add the frame information to an extract of the Swedish side of the Kotus and JRC-Acquis corpora using an automatic frame labeler and copy it to the Finnish side.", "sent2": "We present a low-resource, data-driven, and language-independent approach that uses a hybrid word- and consonant-level conditional Markov model.", "label": 0}
{"sent1": "In this paper we measure the effectiveness of very limited initial constraints: specifically, annotations of a small number of words in the training data.", "sent2": "We vary the amount and distribution of initial partial annotations, and compare the results to unsupervised and supervised approaches.", "label": 1}
{"sent1": "We test a preliminary version of this model on English-French data.", "sent2": "We compare different ways of generating senses and assess the quality of the alignments relative to the IBM HMM model, as well as the generated sense probabilities, in order to gauge the usefulness in Word Sense Disambiguation.", "label": 1}
{"sent1": "However, Sequential Monte Carlo (SMC) approaches, i.e.", "sent2": "Pattern clusters are discovered in a large corpus independently of any particular training set, in an unsupervised manner.", "label": 0}
{"sent1": "As part of this investigation, we collected a dataset of autocorrection mistakes from true text message users and experimented with a rich set of features in our self-assessment task.", "sent2": "Our experimental results indicate that there are salient cues from the text message discourse that allow systems to assess their own behaviors with high precision.", "label": 1}
{"sent1": "interact with humans.", "sent2": "The interpretations explain the subsuming role (?listed in?)", "label": 0}
{"sent1": "We use information from reports on the game of cricket.", "sent2": "Dealing with terminology is a difficult but unavoidable task for language processing applications, such as Information Extraction in technical domains.", "label": 0}
{"sent1": "TUNAREG?09 used data from the TUNA Corpus of paired representations of entities and human-authored referring expressions.", "sent2": "The shared task was to create systems that generate referring expressions for entities given representations of sets of entities and their properties.", "label": 1}
{"sent1": "One of the reasons for this seems to be that entities might be identified faster since the conversation partner has already some knowledge about how his conversation partner builds referring expressions.", "sent2": "In particular, the precision of statistical methods has been largely over-estimated, while the precision of knowledge-based approaches has been under-estimated.", "label": 0}
{"sent1": "Developing this kind of model is critical to deal with more complex domains in the future.", "sent2": "As a first step in our research, we validate the model with the TUNA corpus to show that it includes conventional domain modeling as a subset.", "label": 1}
{"sent1": "These results illuminate incorrect assumptions and improper practices regarding preprocessing, evaluation metrics, and the collection of gold image annotations.", "sent2": "The algorithm exhibited scalable performance on the datasets.", "label": 0}
{"sent1": "places where most prominent topic shifts occur.", "sent2": "The results suggest that, while the overall agreement is relatively low, the annotators show high agreement on a subset of topical breaks ?", "label": 1}
{"sent1": "We define entropybased measures that estimate the correspondence of target-language phrases to translationese, thereby eliminating the need to annotate the parallel corpus with information pertaining to the direction of translation.", "sent2": "We take advantage of information pertaining to the direction of translation in constructing phrase tables, by adapting the translation model to the special properties of translationese.", "label": 1}
{"sent1": "For a large list of verbs, we obtain several indicators about their lexical aspect by querying the web for expressions where these verbs occur in contexts associated with specific aspectual types.", "sent2": "the problems of the recent TempEval challenges.", "label": 1}
{"sent1": "Due to the domain-specificity of this task, event extraction systems must be retrained with new annotated data for each domain.", "sent2": "All components are open source and adaptable to different application scenarios.", "label": 0}
{"sent1": "The end result is a network of 31,609 interactions amongst 7,748 proteins.", "sent2": "Experiments on a clearly stated partition of the ACE 2004 data show that stem-based features can significantly improve the performance of the EDT system by 2 absolute F-measure points.", "label": 0}
{"sent1": "Normalized switch graphs represent the combinatorial potential of a set of analyses derived from lexical and structural ambiguities.", "sent2": "Packing these subanalyses and memoizing the results leads directly to a dynamic programming algorithm for Lambek grammars.", "label": 1}
{"sent1": "One solution is to maintain multiple candidate interpretations of each sentence until the system acquires disambiguating evidence.", "sent2": "Unfortunately, the number of alternatives explodes quickly.", "label": 1}
{"sent1": "Results show the effectiveness of the proposed multi-view compact representation paradigm.", "sent2": "Experiments are conducted on the DECODA corpus of conversations.", "label": 1}
{"sent1": "We study our RF approach in the context of \u0002 -gram type language modeling.", "sent2": "We first extend the study on Chinese shallow parsing presented in (Chen et al, 2006) by raising a set of additional features.", "label": 0}
{"sent1": "Each variable-length text is represented by several independent feature vectors; one word vector per sentence or paragraph.", "sent2": "An experimental evaluation shows that our method improved the success rate of retrieval by generating confirmation more efficiently than using a conventional confidence measure.", "label": 0}
{"sent1": "A marginal log-likelihood objective function is devised for the segmentation model, which is optimized for enhancing the sentiment classification performance.", "sent2": "This has painful consequences such as high frequency of parsing errors related to coordination.", "label": 0}
{"sent1": "A semi-supervised model, called mixing population and individual property PU learning (MPIPUL), is proposed.", "sent2": "Firstly, some reliable negative examples are identified from the unlabeled dataset.", "label": 1}
{"sent1": "In this paper, we propose a novel approach to learning topic representation for parallel data using a neural network architecture, where abundant topical contexts are embedded via topic relevant monolingual data.", "sent2": "However, it is often limited to contexts within sentence boundaries, hence broader topical information cannot be leveraged.", "label": 1}
{"sent1": "Parameters of the neural network are trained using guided learning in the second phase.", "sent2": "Our model boosts performance in a language acquisition task and yields good discourse segmentations compared with human annotators.", "label": 0}
{"sent1": "We use translation models and language models to exploit lexical correlations and solution post character respectively.", "sent2": "In this paper, we present a technique for unsupervised solution post identification leveraging a so far unexplored textual feature, that of lexical correlations between problems and solutions.", "label": 1}
{"sent1": "We test our algorithm on three attribute domains: spouse, education and job; experimental results demonstrate our approach is able to make accurate predictions for users?", "sent2": "attributes based on their tweets.", "label": 1}
{"sent1": "External knowledge has been shown to be an effective way to alleviate this problem.", "sent2": "The version that uses our planning framework is significantly more effective than the other four versions.", "label": 0}
{"sent1": "The detection of subjects and objects from Japanese sentences is more difficult than that from English, while it is the key process to generate correct English word orders.", "sent2": "We present a simple joint inference of deep case analysis and zero subject generation for the pre-ordering in Japanese-toEnglish machine translation.", "label": 1}
{"sent1": "This paper proposes a novel event-extraction method, which aims to automatically extract lexical-level and sentence-level features without using complicated NLP tools.", "sent2": "We show that English-French pairs of terms are highly transliterated in contrast to the EnglishChinese pairs.", "label": 0}
{"sent1": "In this paper, we propose a context-aware topic model for lexical selection, which not only models local contexts and global topics but also captures their correlations.", "sent2": "Previous studies separately exploit sentence-level contexts and documentlevel topics for lexical selection, neglecting their correlations.", "label": 1}
{"sent1": "The only requirements are a running system in a source language and word-aligned parallel data.", "sent2": "We propose a cross-lingual framework for fine-grained opinion mining using bitext projection.", "label": 1}
{"sent1": "This metric is optimal in the sense of global quadratic minimization, and can be obtained from the clusters in the training data in a supervised fashion.", "sent2": "reasoning and specific facts already known to the user as first-order logic and translating this into a tractable linear program.", "label": 0}
{"sent1": "Modified TFIDF is used to generate a stop-word list automatically.", "sent2": "Information retrieval (IR) performance, provided by engines such as Lucene, places a bound on overall system performance.", "label": 0}
{"sent1": "We describe the variety of machine learning approaches that we explored, including Winnow, language modeling, logistic regression and maximum-entropy models.", "sent2": "In comparison with previous models, which either use arbitrary windows to compute similarity between words or use lexical affinity to create sequential models, in this paper we focus on models intended to capture the co-occurrence patterns of any pair of words or phrases at any distance in the corpus.", "label": 0}
{"sent1": "The key novelty is that we utilize the sequential patterns hidden among document elements when determining their authorships.", "sent2": "This paper proposes an unsupervised approach for segmenting a multiauthor document into authorial components.", "label": 1}
{"sent1": "We introduce a model that forms word representations by learning the extent to which specific words contribute to the text?s score.", "sent2": "Past work has relied on faceted browsing of document metadata or on natural language processing of document text.", "label": 0}
{"sent1": "The major NLP challenge for personal assistants is machine understanding: translating natural language user commands into an executable representation.", "sent2": "However achieving independence from both the dialog system and the task performed seems to be more and more a utopia.", "label": 0}
{"sent1": "The TLE provides manually annotated POS tags and Universal Dependency (UD) trees for 5,124 sentences from the Cambridge First Certificate in English (FCE) corpus.", "sent2": "Extrinsic evaluation on a document clustering task reveals a significant improvement when using seed information, even over other models that use seed information na?", "label": 0}
{"sent1": "In this paper, we propose a sentence rewriting based semantic parsing method, which can effectively resolve the mismatch problem by rewriting a sentence into a new form which has the same structure with its target logical form.", "sent2": "Although many algorithms have been developed to harvest lexical resources, few organize the mined terms into taxonomies.", "label": 0}
{"sent1": "In this paper, we overcome this shortcoming using a constrained multi-task pairwisepreference learning approach that enables the data from multiple tasks to be combined effectively.", "sent2": "Furthermore, contrary to some recent research, we show that high performance AES systems can be built with little or no task-specific training data.", "label": 1}
{"sent1": "However, a striking feature of all these approaches is that they rely on the existence of previously seen unambiguous compounds, meaning they are prone to the problem of sparse data.", "sent2": "The idea is illustrated through a comparative study of auxiliary structures in HPSG-based grammars for German and Dutch.", "label": 0}
{"sent1": "However, accurate evaluation of its potential in real-life contexts is still a questionable issue.", "sent2": "The past decade has witnessed exciting work in the field of Statistical Machine Translation (SMT).", "label": 1}
{"sent1": "Using only a non-parallel text corpus, we compute the paraphrasability metrics between two words from their similarity in context.", "sent2": "We then filter words such as proper nouns from external knowledge.", "label": 1}
{"sent1": "grammars is necessary in order to explain their non-occurrence in the languages of the world.", "sent2": "A discriminative word lexicon using source context information proved beneficial for all translation directions.", "label": 0}
{"sent1": "The model presented captures 7-15% more phonologically plausible underlying forms than a simple majority solution, because it prefers ?pure?", "sent2": "Clustering is a central technique in NLP.", "label": 0}
{"sent1": "We argue that its limited effectiveness is due to the lack of lexicalization.", "sent2": "FR query tasks, and the CLIR task.", "label": 0}
{"sent1": "Most of these approaches are based on classification or statistical machine translation (SMT).", "sent2": "All of our code and data will be made publicly available to encourage reproducible research in this area.", "label": 0}
{"sent1": "These translation methods are trained from parallel corpora.", "sent2": "The sense-based translation part is trained via phrase alignment in sentence pairs in a Japanese and JSL corpus.", "label": 1}
{"sent1": "The performance decrease for both languages in both translation directions is mainly due to lexical divergences.", "sent2": "We also release a new dataset of human-authored rewrites of math word problems in several themes.", "label": 0}
{"sent1": "Triangulation uses a third language as a pivot between the source and target languages to achieve an improved and more efficient translation model in most cases.", "sent2": "We also combined multi-pivot models using linear mixture and obtained significant improvement in BLEU scores compared to the direct source-target models.", "label": 1}
{"sent1": "The collected web data is semantically processed in order to acquire rich in-domain knowledge.", "sent2": "We compare those new word embeddings with some well-known embeddings on named entity recognition and movie review tasks and show that we can reach similar or even better performance.", "label": 0}
{"sent1": "The named entity recognition will be performed using conditional random fields.", "sent2": "In a GermanEnglish Moses system with target-side syntax, improved estimates yielded a 63% reduction in CPU time; for a Hiero-style version, the reduction is 21%.", "label": 0}
{"sent1": "We present an annotated corpus of over 8000 definite descriptions in scientific articles.", "sent2": "Still, the problem of automatic generation of punctuation marks has been largely neglected for a long time.", "label": 0}
{"sent1": "We propose a model capable of detecting irony in the social network Twitter.", "sent2": "Evaluation of the best configurations on the SANCL-2012 test data (Petrov and McDonald, 2012) showed that they outperform all the shared task submissions that used a single parser to parse test data, averaging the results across all the test sets.", "label": 0}
{"sent1": "The addition of such an annotation layer to a corpus already containing deep semantic annotation should therefore be of particular interest.", "sent2": "We present a representation for common sense spatial knowledge and an approach to extract it from 3D scene data.", "label": 0}
{"sent1": "a larger vocabulary whose meanings can be learned from a smaller vocabulary through definition alone, as long as the meanings of the smaller vocabulary are themselves already grounded.", "sent2": "We provide simple algorithms to compute reachable sets for any given dictionary.", "label": 1}
{"sent1": "We use the psuedo inverse of the Laplacian to derive estimates for commute times in graphs.", "sent2": "Further, we show that this pseudo inverse based measure could be improved by discarding the least significant eigenvectors, corresponding to the noise in the graph construction process, using singular value decomposition.", "label": 1}
{"sent1": "We correct these errors in CCGbank using a gold-standard corpus of NP structure, resulting in a much more accurate corpus.", "sent2": "The registers run in a near-unbroken sequence form 1398 to the present day; the early volumes are a UNESCO UK listed cultural artefact.", "label": 0}
{"sent1": "After applying all possible transformations to a sentence, we are left with a set of candidate simplified sentences.", "sent2": "We propose a method for the task of identifying the general positions of users in online debates, i.e., support or oppose the main topic of an online debate, by exploiting local information in their remarks within the debate.", "label": 0}
{"sent1": "This decrease seems to be due to longer word duration.", "sent2": "(1) For disfluencies, effects depend on the type of disfluency: errors increase by up to 15% (absolute) for words near fragments, but decrease by up to 7.2% (absolute) for words near repetitions.", "label": 1}
{"sent1": "In practice, this means that an adaptor grammar learns the structures useful for generating the training data as well as their probabilities.", "sent2": "We evaluate on a common dataset for template schema extraction.", "label": 0}
{"sent1": "We also present a novel method for measuring sentence relatedness that can be implemented in either version of Roget?s or in WordNet.", "sent2": "We examine the differences in content between the 1911 and 1987 versions of Roget?s, and we test both versions with each other and WordNet on problems such as synonym identification and word relatedness.", "label": 1}
{"sent1": "Our method does not require any additional annotated data other than the data that a regular translation system uses.", "sent2": "We study text exchanged between users in online communities.", "label": 0}
{"sent1": "The corpus was built by a novel method: paid participants were contacted through a Web-interface, a procedure which allowed dynamic, fast and inexpensive development of data collection methods.", "sent2": "For this purpose we present a Wikipedia-based corpus of Whyquestions and corresponding answers and articles.", "label": 1}
{"sent1": "The main idea is to look for verbs, prepositions, and coordinating conjunctions that can help make explicit the hidden relations between the target nouns.", "sent2": "Human annotators used these guidelines to annotate a 1.3M word broadcast news corpus in French.", "label": 0}
{"sent1": "multi-labeled document).", "sent2": "Unlike other, supervised or unsupervised, methods for keyphrase extraction our proposed methods utilizes both the document?s text and label information for the task of extracting label specific keyphrases.", "label": 1}
{"sent1": "We report promising results of a supervised learning approach, which is based on a cascade of classifiers designed to properly handle the skewed data which is inherent to the defined task.", "sent2": "We investigate this idea in several ways.", "label": 0}
{"sent1": "U = 0.72 for argument components and ?", "sent2": "We propose an approach to natural language inference based on a model of natural logic, which identifies valid inferences by their lexical and syntactic features, without full semantic interpretation.", "label": 0}
{"sent1": "In contrast to other domains, one objective in literary translation is to preserve the experience of reading a text when moving to the target language.", "sent2": "Most of these approaches show improvement over the results achieved individually by the tools for tagging and parsing.", "label": 0}
{"sent1": "We experiment with translation rules which contain the core arguments for the predicates in the source side of a MT system, and observe that using these rules significantly improves the translation quality.", "sent2": "We propose to account for this in a simple modification of the windowDiff metric.", "label": 0}
{"sent1": "Moreover, when we switch the tuning function from BLEU to the LRscore which promotes reordering, we observe total improvements of 1.21 BLEU, 1.30 LRscore and 3.36 TER over the baseline.", "sent2": "Our approach significantly improves Chinese?English machine translation on a large-scale task by 0.84 BLEU points on average.", "label": 1}
{"sent1": "The proposed method employs PCA to capture the hidden components, and incorporates them into a joint learning framework to improve the performance.", "sent2": "Experiments with real-world data sets and evaluation metrics validate the effectiveness of the proposed method.", "label": 1}
{"sent1": "errors from projected approach such as tagset mismatch between languages, achieving state-of-the-art performance (91.3%) across 8 languages.", "sent2": "Additionally, we use a small amount of annotated data to learn to ?correct?", "label": 1}
{"sent1": "Code mixing data is not abundantly available for training language models.", "sent2": "In this paper, we propose novel structured language modeling methods for code mixing speech recognition by incorporating a well-known syntactic constraint for switching code, namely the Functional Head Constraint (FHC).", "label": 1}
{"sent1": "Previous approaches heavily depend on languagespecific knowledge and pre-existing natural language processing (NLP) tools.", "sent2": "However, compared to English, not all languages have such resources and tools available.", "label": 1}
{"sent1": "As a result, the task of deceptive review detection has been gaining increasing attention.", "sent2": "This paper looks at treebank-training of generators, an alternative method for building statistical models for NLG from raw corpora, and two different ways of using treebank-trained models during generation.", "label": 0}
{"sent1": "Lattices compactly represent lexical variation, but word order variation leads to a combinatorial explosion of states.", "sent2": "Experiments in English and Polish, as well as comparisons with other recent unsupervised morphology learning algorithms demonstrate the effectiveness of this technique.", "label": 0}
{"sent1": "This is, to the best of our knowledge, the first fully unsupervised humor generation system.", "sent2": "The perplexity for both of these models significantly improve upon the trigram model base-line as well as the best previous grammarbased language model.", "label": 0}
{"sent1": "In this work, we propose a discourse structureoriented classification of the comma that can be automatically extracted from the Chinese Treebank based on syntactic patterns.", "sent2": "Thus, we introduce the VQA-HAT (Human ATtention) dataset.", "label": 0}
{"sent1": "In this work, we adapt a machine translation metric to measure content coverage, apply an enhanced discourse coherence model to evaluate summary readability, and combine both in a trained regression model to evaluate overall responsiveness.", "sent2": "In this paper, we report the results of acquisition experiments.", "label": 0}
{"sent1": "writing is an increasingly active area of research.", "sent2": "However, most research has mainly focused on errors concerning articles and prepositions even though tense/aspect errors are also important.", "label": 1}
{"sent1": "In this paper we present a systematic study investigating (combinations of) sequence and convolution kernels using different types of substructures in document-level sentiment classification.", "sent2": "Temporal resolution systems are traditionally tuned to a particular language, requiring significant human effort to translate them to new languages.", "label": 0}
{"sent1": "In contrast to previous approaches, the proposed technique allows us to easily integrate relevant contextual information.", "sent2": "We test our approach on eight languages reaching a new state-of-the-art level for the lemmatisation task.", "label": 1}
{"sent1": "These abilities make BIUTEE an appealing RTE system for two research communities: (1) researchers of end applications, that can benefit from generic textual inference, and (2) RTE researchers, who can integrate their novel algorithms and knowledge resources into our system, saving the time and effort of developing a complete RTE system from scratch.", "sent2": "Its main advantages are its ability to utilize various types of knowledge resources, and its extensibility by which new knowledge resources and inference components can be easily integrated.", "label": 1}
{"sent1": "I report on the translation quality of a machine translation (MT) system where both techniques are implemented.", "sent2": "Two different techniques have been implemented to compute structural similarity: leaves and tree-edit distance.", "label": 1}
{"sent1": "Current approaches based on generative or discriminative models have different but important shortcomings that limit their accuracy.", "sent2": "In spoken dialog systems, statistical state tracking aims to improve robustness to speech recognition errors by tracking a posterior distribution over hidden dialog states.", "label": 1}
{"sent1": "Our model simultaneously learns a set of properties of a product and captures aggregate user sentiments towards these properties.", "sent2": "Unlike Pourpre, but like human assessors, Nuggeteer creates a judgement for each candidatenugget pair, and can use existing judgements instead of guessing.", "label": 0}
{"sent1": "The semi-supervised learning plus the gazetteers alleviate the lack of training data.", "sent2": "We study a novel shallow information extraction problem that involves extracting sentences of a given set of topic categories from medical forum data.", "label": 0}
{"sent1": "In this paper, we target out-of-vocabulary words in short text messages and propose a method for identifying and normalising ill-formed words.", "sent2": "Our method uses a classifier to detect ill-formed words, and generates correction candidates based on morphophonemic similarity.", "label": 1}
{"sent1": "We evaluate our proposed methods on a large Twitter data set.", "sent2": "We also explore the impact of human interpretation of paraphrasing on the alignment of paraphrase sentence pairs.", "label": 0}
{"sent1": "Unlike typical extraction setups, these environments are characterized by short, one sentence messages with heavily colloquial speech.", "sent2": "Our features are simple to implement making the approach easily replicable.", "label": 0}
{"sent1": "We present a novel re-ranking approach that incorporates a variety of score and n-gram features, in order to leverage transliterations from multiple languages.", "sent2": "A key challenge is the lack of an adequate corpus of messages annotated for language that reflects the linguistic diversity present on Twitter.", "label": 0}
{"sent1": "Basilisk hypothesizes the semantic class of a word based on collective information over a large body of extraction pattern contexts.", "sent2": "Basilisk begins with an unannotated corpus and seed words for each semantic category, which are then bootstrapped to learn new words for each category.", "label": 1}
{"sent1": "Our work explores ensemble efficacy for the more complex task of automatic thesaurus extraction on up to 300 million words.", "sent2": "We examine our conflicting results in terms of the constraints on, and complexity of, different contextual representations, which contribute to the sparsenessand noise-induced bias behaviour of NLP systems on very large corpora.", "label": 1}
{"sent1": "Individual models to be combined are based on maximum entropy models, one of which always considers surrounding contexts of a fixed length, while the other considers those of variable lengths according to the number of constituent morphemes of named entities.", "sent2": "As an algorithm for learning the second stage classifier, we employ a decision list learning method.", "label": 1}
{"sent1": "This approach was recently used in the SemEval 2015 Twitter sentiment analysis challenge, attaining state-of-the-art results.", "sent2": "(2) For prosodic features, there are more errors for words with extreme values than words with typical values.", "label": 0}
{"sent1": "We achieve 95% transcription accuracy by combining transcriptions from multiple crowd workers.", "sent2": "We also get spoken English grades from the crowd.", "label": 1}
{"sent1": "We evaluate the reconstructed paragraph using standard metrics like ROUGE and Entity Grid, showing that neural models are able to encode texts in a way that preserve syntactic, semantic, and discourse coherence.", "sent2": "We introduce an LSTM model that hierarchically builds an embedding for a paragraph from embeddings for sentences and words, then decodes this embedding to reconstruct the original paragraph.", "label": 1}
{"sent1": "To this date, most of the successful SRL systems were built on top of some form of parsing results (Koomen et al., 2005; Palmer et al., 2010; Pradhan et al., 2013), where pre-defined feature templates over the syntactic structure are used.", "sent2": "Manually-created lexicons have limited coverage and do not include most semantically contrasting word pairs.", "label": 0}
{"sent1": "Contrary to previous approaches which tend  to use unilingual models of the user's second  language (L2), this new approach uses a simple  roundtrip  Machine  Translation  method  which  leverages  information about  both the  author?s first (L1) and second languages.", "sent2": "is available, which is usually not the case.", "label": 0}
{"sent1": "?team?)", "sent2": "and relations (e.g., ?playsForTeam(athlete,team)?).", "label": 1}
{"sent1": "We simulate how a practitioner would go about tackling a new problem, including parameter tuning using cross validation (CV).", "sent2": "This paper describes preliminary work in exploring the relative effectiveness of speech versus text based tutoring.", "label": 0}
{"sent1": "However, the suitability of unlabeled data for multiclass tasks using SVM has never been tested before.", "sent2": "A previous study on supervised and semi-supervised SVM classification over binary taxonomies showed how the latter clearly outperforms the former, proving the suitability of unlabeled data for the learning phase in this kind of tasks.", "label": 1}
{"sent1": "We show that our algorithm achieves an average improvement of 12 in recall and 4 in precision compared to the supervised algorithm.", "sent2": "We also show that our algorithm achieves high accuracy when the training and test sets are from different domains.", "label": 1}
{"sent1": "The results show that the two methods behave similarly in various conditions.", "sent2": "We conducted experiments on the TIMIT database and a standard synthetic data set from UCI Machine Learning repository.", "label": 1}
{"sent1": "We apply an extended and modified version of the approach of Tinsley et al (2007), extracting syntax-based phrase pairs from a large parallel parsed corpus, combining them with PBSMT phrases, and performing joint decoding in a syntax-based MT framework without loss of translation quality.", "sent2": "This effectively addresses the low coverage of purely syntactic MT without discarding syntactic information.", "label": 1}
{"sent1": "The package implements well-known word space algorithms, such as LSA, and provides a comprehensive set of matrix utilities and data structures for extending new or existing models.", "sent2": "We present the S-Space Package, an open source framework for developing and evaluating word space algorithms.", "label": 1}
{"sent1": "The dependency relation model is a kind of tree-based reordering model, and can handle non-local reorderings which sequential word-based models often cannot handle properly.", "sent2": "To evaluate the proposed method, we also constructed a large-scale dataset collected from Twitter.", "label": 0}
{"sent1": "We then apply the log probability of the phrase orientation classifier as an extra feature in a phrase-based MT system, and get significant BLEU point gains on three test sets: MT02 (+0.59), MT03 (+1.00) and MT05 (+0.77).", "sent2": "By encoding order information in the dependency labels, we show that any off-theshelf, trainable dependency parser can be used to produce constituents.", "label": 0}
{"sent1": "alignments may be 1 : 1, island-free or sure-possible sorted.", "sent2": "whether for a grammar and a string pair the grammar induces an alignment of the two strings, reduces to the universal recognition problem, but restrictions may be imposed on the alignment sought, e.g.", "label": 1}
{"sent1": "We modeled the node rotation, monotone or swap, using word alignments based on a training parallel corpus and sourceside parse-trees.", "sent2": "While narrating full articles proved too onerous a task to be viable, using other Turkers to perform vetting was very successful.", "label": 0}
{"sent1": "Our focus is on identifying systematic differences across words and annotators that can account for IA variation.", "sent2": "We identify three lexical use factors: semantic specificity of the context, sense concreteness, and similarity of senses.", "label": 1}
{"sent1": "Since a given sense can be lexicalized differently in translation, do we observe one translation per discourse?", "sent2": "In this paper we describe the design and evaluation of a FAQ retrieval engine for Croatian.", "label": 0}
{"sent1": "Our experiments find that, for noun and verb sense disambiguation tasks, each type of context selector may assist target selectors in disambiguation.", "sent2": "Overall results for verb, adjective, and adverb disambiguation are well above a random baseline and slightly below the most frequent sense baseline, a point which noun sense disambiguation overcomes.", "label": 1}
{"sent1": "In pattern generation from a parallel corpus, Compositional Constituents that could be generalized were 74% of independent words, 24% of phrases and only 15% of clauses.", "sent2": "To realize high quality machine translation, we proposed a Non-Compositional Language Model, and developed a sentence pattern dictionary of 226,800 pattern pairs for Japanese compound and complex sentences consisting of 2 or 3 clauses.", "label": 1}
{"sent1": "We propose an algorithm based on a tournament model, in which the relative preferences are directly modeled by one-onone games in a step-ladder tournament.", "sent2": "We present a novel randomised language model which uses an online perfect hash function to efficiently deal with unbounded text streams.", "label": 0}
{"sent1": "The meaning representation language is constructed in a way that allows us to handle massive ambiguity caused by: the specifics of the Sumerian writing system (signs?", "sent2": "polyvalence, lack of mid-word signs), our incomplete knowledge of the Sumerian language and frequent damages of documents.", "label": 1}
{"sent1": "Contrary to previous claims, our results demonstrate that the systems based on dependencies perform roughly as well as those based on constituents: For the argument classification task, dependencybased systems perform slightly higher on average, while the opposite holds for the argument identification task.", "sent2": "However, because different Kanji characters convey different meanings and impressions, characters must be selected carefully.", "label": 0}
{"sent1": "Unsupervised concept acquisition algorithms have been shown to produce good results, and are preferable over manual preparation of concept resources, which is labor intensive, error prone and somewhat arbitrary.", "sent2": "For a bird?s-eye view of alignment patterns within a sentence, the tool is also able to display alignments as alignment matrices.", "label": 0}
{"sent1": "But how far around this point does the region of similar meaning extend?", "sent2": "The morphology of Semitic languages is unique in the sense that the major word-formation mechanism is an inherently non-concatenative process of interdigitation, whereby two morphemes, a root and a pattern, are interwoven.", "label": 0}
{"sent1": "However, naive incorporation of this semantic information may result in poor performance due to increased ambiguity.", "sent2": "Effectively incorporating information regarding semantically related words into the feature space is known to produce robust, accurate classifiers and is one apparent motivation for efforts to automatically generate such resources.", "label": 1}
{"sent1": "In particular we introduce an algorithm that semi-automatically discovers patterns encoding reciprocity based on a set of simple but effective pronoun templates.", "sent2": "In this paper we address the problem of identifying reciprocal relationships in English.", "label": 1}
{"sent1": "feedback, we train a simplified ?Baby?", "sent2": "III and Marcu (2005), that extends seq2seq to learn global sequence scores.", "label": 0}
{"sent1": "In this paper, we argue that the current AES systems can be further improved by taking into account the agreement between human and machine raters.", "sent2": "To this end, we propose a rankbased approach that utilizes listwise learning to rank algorithms for learning a rating model, where the agreement between the human and machine raters is directly incorporated into the loss function.", "label": 1}
{"sent1": "While this provides useful statistics for frequent nouns, many infrequent nouns cannot be classified using this method.", "sent2": "Adaptor grammars (Johnson et al, 2007b) are a non-parametric Bayesian extension of Probabilistic Context-Free Grammars (PCFGs) which in effect learn the probabilities of entire subtrees.", "label": 0}
{"sent1": "It provides a 16% relative improvement over the baseline approach that uses a fixed context window of adjacent words.", "sent2": "We introduce a new method for disambiguating word senses that exploits a nonlinear Kernel Principal Component Analysis (KPCA) technique to achieve accuracy superior to the best published individual models.", "label": 0}
{"sent1": "The algorithm assesses the quality of a parse tree using POS sequence statistics collected from a batch of parsed sentences.", "sent2": "We evaluate the algorithm by using an unsupervised POS tagger and an unsupervised parser, selecting high quality parsed sentences from English (WSJ) and German (NEGRA) corpora.", "label": 1}
{"sent1": "We discuss two existing information theory based measures, V and VI, and show that they are both hard to use when comparing the performance of different algorithms and different datasets.", "sent2": "The V measure favors solutions having a large number of clusters, while the range of scores given by VI depends on the size of the dataset.", "label": 1}
{"sent1": "We introduce an algorithm for sense-based semantic ordering of index terms which approximates Cruse?s description of a sense spectrum.", "sent2": "Following semantic ordering, text classification by support vector machines can benefit from semantic smoothing kernels that regard semantic relations among index terms while computing document similarity.", "label": 1}
{"sent1": "Based on novels over several different genres, we probe the predictive power of statistical stylometry in discriminating successful literary works, and identify characteristic stylistic elements that are more prominent in successful writings.", "sent2": "Our model also integrates lexical information.", "label": 0}
{"sent1": "The multiple senses can be captured by employing several vectors per word in a multi-prototype distributional model, prototypes that can be obtained by first constructing all the context vectors for the word and then clustering similar vectors to create sense vectors.", "sent2": "Most distributional models of word similarity represent a word type by a single vector of contextual features, even though, words commonly have more than one sense.", "label": 1}
{"sent1": "We propose a novel document representation based on such continuous word embeddings.", "sent2": "Our experiments show that the proposed approach outperforms several baselines in terms of both extraction quality and fluency.", "label": 0}
{"sent1": "The discourse model extends the sentence model and is based on a recurrent neural network that is conditioned in a novel way both on the current sentence and on the current speaker.", "sent2": "We propose four new methods to accurately determine word sense dominance using raw text and a published thesaurus.", "label": 0}
{"sent1": "Results show that discourse connectives are not translated into comparable forms (or even any form at all), in up to 18% of human reference translations from English to French or German.", "sent2": "In practice ontologies are usually composed of simple axioms, so that realising them separately is relatively easy; there remains however the problem of producing texts that are coherent and efficient.", "label": 0}
{"sent1": "a distribution of pointwise mutual information between all pairs of content word types in a text.", "sent2": "We use the average of the distribution, which we term lexical tightness, as a single measure of the amount of association in a text.", "label": 1}
{"sent1": "Aspect Based Sentiment Analysis (Pontiki et al., 2014) challenge.", "sent2": "As supervised machine learning methods for addressing tasks in natural language processing (NLP) prove increasingly viable, the focus of attention is naturally shifted towards the creation of training data.", "label": 0}
{"sent1": "The UMLS contains a very rich lexicon while the promise of a NER system is to carry out contextsensitive tagging.", "sent2": "MetaMap is developed to link the text of medical documents to the knowledge embedded in UMLS Metathesaurus.", "label": 1}
{"sent1": "Crosslevel semantic similarity measures the degree of relatedness between texts of varying lengths such as Paragraph to Sentence and Sentence to Phrase.", "sent2": "Latent Semantic Analysis was used to evaluate the cross-level semantic relatedness between the texts to achieve above baseline scores, tested on the training and test datasets.", "label": 1}
{"sent1": "This is reasonable enough for the task of retrieving broadcast news stories, where word error rates are relatively low, and the stories are long enough to contain much redundancy.", "sent2": "Recent work on spoken document retrieval has suggested that it is adequate to take the singlebest output of ASR, and perform text retrieval on this output.", "label": 1}
{"sent1": "Detecting and removing such disfluencies can substantially improve the usefulness of spontaneous speech transcripts.", "sent2": "We formalize two particular types of DP algorithms under each of these frameworks: the Viterbi-style topological algorithms and the Dijkstra-style best-first algorithms.", "label": 0}
{"sent1": "We report the performance of the MBR decoders on a Chinese-to-English translation task.", "sent2": "Our results show that MBR decoding can be used to tune statistical MT performance for specific loss functions.", "label": 1}
{"sent1": "We provide experimental results on the NIST 2003 Chinese-English large data track evaluation.", "sent2": "We introduce two novel perceptroninspired reranking algorithms that improve on the quality of machine translation over the baseline system based on evaluation using the BLEU metric.", "label": 1}
{"sent1": "We show that with minimal changes, the classifier may be retrained for use with French Web documents.", "sent2": "For both English and French, the classifier maintains consistently good correlation with labeled grade level (0.63 to 0.79) across all test sets.", "label": 1}
{"sent1": "Our best performing feature set contains both acoustic-prosodic and other types of linguistic features, extracted from both the current turn and a context of previous student turns, and yields a prediction accuracy of 84.75%, which is a 44% relative improvement in error reduction over a baseline.", "sent2": "Our results suggest that the intelligent tutoring spoken dialogue system we are developing can be enhanced to automatically predict and adapt to student emotions.", "label": 1}
{"sent1": "In this paper we describe CRAB ?", "sent2": "Chemical cancer risk assessment is a literature-dependent task which could greatly benefit from text mining support.", "label": 1}
{"sent1": "Focus is placed on the linguistic mismatch between the user input and the system?s expectations, and on its implications in terms of language modeling and parsing performance.", "sent2": "Our results motivate further research on the use of LHs for modeling the writing style of authors for related tasks, such as authorship verification and plagiarism detection.", "label": 0}
{"sent1": "Because of the length limitations of Twitter-like sites, the performances of existing methods usually drop sharply.", "sent2": "Different from previous studies, which are usually focused on automatically extracting keyphrases from documents or articles, in this study, we considered the problem of automatically extracting keyphrases from tweets.", "label": 1}
{"sent1": "We then use Ranking SVM to rerank the candidates both in the solving and generation process.", "sent2": "In the riddle generation phase, we use a template-based method and a replacement-based method to obtain candidate riddle descriptions.", "label": 1}
{"sent1": "In this paper, we investigate the use of such wikis to create Question-Answering (QA) systems for a given topic.", "sent2": "and ?The Simpsons?.", "label": 1}
{"sent1": "ZSL promises to scale visual recognition by borrowing distributed semantic models learned from linguistic corpora and turning them into visual recognition models.", "sent2": "However the popular word-vector DSM embeddings are relatively impoverished in their expressivity as they model each word as a single vector point.", "label": 1}
{"sent1": "We capture the alignment by using a novel probabilistic model that models tree-edit operations on dependency parse trees.", "sent2": "We present a method for automatically generating input parsers from English specifications of input file formats.", "label": 0}
{"sent1": "We also formalize the notion of subtlety through its relation to semantic space dimensionality.", "sent2": "Using this formalization and our learning models, several of our intuitions about subtlety, dimensionality, and context are quantified and empirically tested.", "label": 1}
{"sent1": "We mine the Web using lexico-syntactic patterns to infer sentiment expectation of nouns, and then exploit character-sentiment model to reduce noises caused by the Web data.", "sent2": "In this paper, we present a new learning scenario, heterogeneous transfer learning, which improves learning performance when the data can be in different feature spaces and where no correspondence between data instances in these spaces is provided.", "label": 0}
{"sent1": "By integrating tokenization and translation features in a discriminative framework, our joint decoder outperforms the baseline translation systems using 1-best tokenizations and lattices significantly on both ChineseEnglish and Korean-Chinese tasks.", "sent2": "We formalize this problem, and explore a variety of content, structure, and interaction features for this task using standard machine learning techniques.", "label": 0}
{"sent1": "So, to guarantee the quality of emotion lexicons, we use an iterative feedback to combine manual labeling and the automatic ranking algorithm above.", "sent2": "Both entity and relation extraction can benefit from being performed jointly, allowing each task to correct the errors of the other.", "label": 0}
{"sent1": "I gave John a book and I gave a book to John).", "sent2": "Dative variation is a widely observed syntactic phenomenon in world languages (e.g.", "label": 1}
{"sent1": "The NTU-MC thrives on the mantra of \"more data is better data and more annotation is better information\".", "sent2": "Experiments show that our approach achieves significant improvements over the baseline system.", "label": 0}
{"sent1": "It then extracts paraphrase query-query and title-title pairs from the query-title paraphrases with a pivot approach.", "sent2": "Domain adaptation is an important research topic in sentiment analysis area.", "label": 0}
{"sent1": "Firstly, we use a multi-pivot approach to acquire a set of candidate paraphrases for a source sentence S. Then, we employ two kinds of techniques, namely the selection-based technique and the decoding-based technique, to produce a best paraphrase T for S using the candidates acquired in the first stage.", "sent2": "Our method, thus, requires gold standard trees only on the source side of a bilingual corpus in the training phase, unlike the joint parsing model, which requires gold standard trees on the both sides.", "label": 0}
{"sent1": "For the purpose of full use of readily available human annotations, it is significant to simultaneously utilize multiple corpora of different annotation standards.", "sent2": "The problem is partially solved either by introducing heuristics or by agreement constraints such that two directional word alignments agree with each other.", "label": 0}
{"sent1": "In our approach, we assign different weights to different system outputs, and add a weighted merging stage to the conventional SRL combination architecture.", "sent2": "And existing combination strategies trust each individual system?s output with the same confidence when merging them into a pool of candidates.", "label": 1}
{"sent1": "Operating on transcripts of speech which contain disfluencies, our particular focus here is the identification and correction of speech repairs using a noisy channel model.", "sent2": "We introduce an approximation to the BLEU score (Papineni et al, 2001) that satisfies these conditions.", "label": 0}
{"sent1": "Irrelevance in vector spaces is modelled using orthogonality, so query vectors are made orthogonal to the negated term or terms.", "sent2": "Our algorithm effectively removes the necessity of manual intervention and formulation of negative categories, with performance closely approaching that obtained using negative categories defined by a domain expert.", "label": 0}
{"sent1": "We evaluate these constraints on two tasks: the Verbmobil task and the Canadian Hansards task.", "sent2": "We show a connection between the ITG constraints and the since 1870 known Schro?der numbers.", "label": 1}
{"sent1": "Task based evaluation shows a 26% F-measure improvement in named entity recognition when using truecasing.", "sent2": "Results from a human rating study confirm that users are sensitive to this extended notion of context and assign ratings that are significantly higher (up to 14%) than those for taking only local context into account.", "label": 0}
{"sent1": "We show that spectral analysis is useful for compensating for the paucity of labeled examples by learning from unlabeled data.", "sent2": "The proposed method significantly outperforms a number of methods that employ techniques such as EM and co-training.", "label": 1}
{"sent1": "Propbank is a corpus in which the arguments of each verb predicate are annotated with their semantic roles.", "sent2": "Propbank annotation also requires the choice of a sense id for each predicate, defined in the corresponding frameset file.", "label": 1}
{"sent1": "We employ two different representations of the context in which a target word occurs.", "sent2": "We also provide a demonstration outline for illustrating the toolkit?s features to potential users, whether they be newcomers to the field or power users interested in extending the toolkit.", "label": 0}
{"sent1": "In a number of categorization tasks including text categorization, negative examples are usually more common than positive examples and there may be several different types of negative examples.", "sent2": "We propose one type of TOP (Tangent vector Of the Posterior log-odds) kernel and apply it to text categorization.", "label": 1}
{"sent1": "To select the proper number of \u0000, we use a \u0001\u0002\u0003\u0003 \u0004\u0005\u0006\u0007\b\t\u0002\u0006 which measures the degree of our disappointment in any differences between the true distribution over inputs and the learner?s prediction.", "sent2": "Once the optimal number of \u0000 is selected, for each cluster, the procedure is repeated.", "label": 1}
{"sent1": "We also compare three smoothing techniques for prepositional phrases.", "sent2": "Three thesauruses are compared on this task: two existing generic thesauruses and a new specialist PP thesaurus tailored for this problem.", "label": 1}
{"sent1": "This paper presents a novel approach to categorize sentences in scientific abstracts into four sections, objective, methods, results, and conclusions.", "sent2": "METHOD: Formalizing the categorization task as a sequential labeling problem, we employ Conditional Random Fields (CRFs) to annotate section labels into abstract sentences.", "label": 1}
{"sent1": "The experiments to construct taxonomies were conducted for evaluation by using data from three different languages: Chinese, Japanese and Thai.", "sent2": "The parser is coupled with an on-line averaged perceptron (Collins, 2002) as the learning method.", "label": 0}
{"sent1": "Senses of these implicit discourse relations that hold between a sentence pair, however, are challenging to infer.", "sent2": "Our methodology involved using the OpenDMAP semantic parser with manually-written rules.", "label": 0}
{"sent1": "However, such hand-crafted patterns are likely to have low coverage of causal expressions, and it is also difficult to assign suitable weights to the patterns by hand.", "sent2": "Conventional systems use hand-crafted patterns to extract and evaluate answer candidates.", "label": 1}
{"sent1": "This paper introduces a new, cluster-based query expansion method that learns queries known to be successful when applied to similar questions.", "sent2": "We present efficient dynamic programming algorithms for both constraints.", "label": 0}
{"sent1": "When evaluating this method, we obtained language detection accuracy of 96.7% when an appropriate language had to be chosen from among three languages.", "sent2": "We also compare our automatically inferred acquisition ages with norms from existing oral studies, revealing interesting historical trends as well as differences between oral and written word acquisition processes.", "label": 0}
{"sent1": "Candidate lexical translation probabilities are based on the probability that their induced hyponyms and/or hypernyms are translations of one another.", "sent2": "We argue that building such predictive models can help us better evaluate performance of NLP components that cannot be distinguished based on F-score alone, and illustrate our approach by comparing the current interpretation component in the system to a new classifier trained on the evaluation data.", "label": 0}
{"sent1": "With only a small amount of bilingual training data and limited tools for Hindi, we achieve reasonable performance and substantial improvements over the baseline phrase-based system.", "sent2": "Our approach eschews the use of parsing or other sophisticated linguistic tools for the target language (Hindi) making it a useful framework for statistical machine translation from English to Indian languages in general, since such tools are not widely available for Indian languages currently.", "label": 1}
{"sent1": "We evaluate our approach by conducting experiments using relevance feedback data collected from users using a popular search engine.", "sent2": "The results have shown improvement over baseline, proving that our approach can be applied to personalization of web search.", "label": 1}
{"sent1": "The key issue in creating such a resource is to establish a practical method of computing semantic equivalence and syntactic substitutability, i.e., paraphrasability, between given pair of expressions.", "sent2": "We conclude by outlining current directions of research including specialized grammars and automatic detection of confusion.", "label": 0}
{"sent1": "However they differ in the portions of the brain to which they are more sensitive, in the frequency bands they can detect, and to the amount of noise to which they are subject.", "sent2": "The new trend in sentiment classification is to use semantic features for representation of documents.", "label": 0}
{"sent1": "It also aims to capture existing interdependencies between these areas.", "sent2": "BVE adds to VE the ability to incorporate information about word boundaries previously found by the algorithm into future segmentations.", "label": 0}
{"sent1": "This involves a mapping from a semantic encoding of time to a set of tense/aspect permutations.", "sent2": "It consists in estimating the plausibility of sentences where the named entity to be classified is substituted with the ones contained in the training data, in our case, a partially populated ontology.", "label": 0}
{"sent1": "Methods traditionally employed do not investigate the full range of triples occurring in human-generated norms (e.g.", "sent2": "Our model aims to identify highly informative sentences that are aspect-specific in online custom reviews.", "label": 0}
{"sent1": "Specifically, we find that the low entropy of natural languages can allow us, with high probability, to bound the depth of the heuristic values expanded in the search.", "sent2": "Instead of resorting to an external dictionary, we translate source vector features by using a cross-lingual Word Sense Disambiguation method.", "label": 0}
{"sent1": "This may be partly due to the perceived complexity of implementation, and partly due to the lack of standard methodology for applying these methods to MT.", "sent2": "This papers aims to shed light on large-margin learning for MT, explicitly presenting the simple passive-aggressive algorithm which underlies many previous approaches, with direct application to MT, and empirically comparing several widespread optimization strategies.", "label": 1}
{"sent1": "In this paper, we shed the light on the usefulness of AAN citing sentences for understanding research trends and summarizing previous discoveries and contributions.", "sent2": "We also propose and motivate several different uses and applications of citing sentences.", "label": 1}
{"sent1": "We find that the government-sponsored bakeoffs brought new researchers to the field, and bridged early topics to modern probabilistic approaches.", "sent2": "Last, we identify steep increases in author retention during the bakeoff era and the modern era, suggesting two points at which the field became more integrated.", "label": 1}
{"sent1": "To conduct our study we labeled the gender of authors in the ACL Anthology mostly manually, creating a useful resource for other gender studies.", "sent2": "Finally, our study of historical patterns in female participation shows that the proportion of women authors in computational linguistics has been continuously increasing, with approximately a 50% increase in the three decades since 1980.", "label": 1}
{"sent1": "In this study I employ collocation segmentation to extract terms from the large and complex ACL Anthology Reference Corpus, and also briefly research and describe the history of the ACL.", "sent2": "Task based evaluation shows a 26% F-measure improvement in named entity recognition when using truecasing.", "label": 0}
{"sent1": "This study aims to investigate the trends of text reuse in the ACL submissions, if any.", "sent2": "We carried a set of analyses on two spans of five years papers (the past and the present) of ACL using a publicly available text reuse detection application to notice the behaviour.", "label": 1}
{"sent1": "These models make different assumptions about the kinds of information available in corpora that is relevant to representing conceptual knowledge.", "sent2": "In this paper we present a fully unsupervised nonparametric Bayesian model that jointly induces POS tags and morphological segmentations.", "label": 0}
{"sent1": "In this paper, we propose to embed local and non-local word reordering decisions in a synchronous context free grammar, and leverages the grammar in a chartbased decoder.", "sent2": "dependency structures bridge the gap between the surface-syntactic structures as produced by state-of-the-art dependency parsers and semantic logical forms in that they abstract away from surfacesyntactic idiosyncrasies, but still keep the linguistic structure of a sentence.", "label": 0}
{"sent1": "Experiments run on three language pairs (Arabic-English, Chinese-English, and Spanish-English) show that one can achieve relatively decent performance by propagating information from a language with richer resources such as English into a foreign language alone (no resources or models in the foreign language).", "sent2": "Furthermore, while examining the performance using various degrees of linguistic information in a statistical framework, results show that propagated features from English help improve the source-language system performance even when used in conjunction with all feature types built from the source language.", "label": 1}
{"sent1": "is the de facto standard for evaluation and development of statistical machine translation systems.", "sent2": "B???", "label": 1}
{"sent1": "We describe conditions on the loss function that will enable efficient implementation of MBR decoders on lattices.", "sent2": "?1 ?", "label": 0}
{"sent1": "In this paper, we present the first unsupervised approach that is competitive with supervised ones.", "sent2": "Some unsupervised approaches have been proposed (e.g., Haghighi and Klein (2007)), but they are less accurate.", "label": 1}
{"sent1": "This paper presents a framework that informs local decisions with two types of implicit global constraints: transitivity (A before B and B before C implies A before C) and time expression normalization (e.g.", "sent2": "last month is before yesterday).", "label": 1}
{"sent1": "However, in many NLP applications such as Machine Translation, Information Extraction and Question Answering, it is desirable to make the temporal location of the situations explicit.", "sent2": "We describe a machine learning framework where different sources of information can be combined to predict the temporal location of situations in Chinese text.", "label": 1}
{"sent1": "Second, we apply supervised machine learning techniques, whereas most existing systems apply rule-based algorithms.", "sent2": "As far as we know, this way of approaching the negation scope finding task is novel.", "label": 1}
{"sent1": "To accomplish this, the training procedure determines for each feature function its exact error surface on a given set of candidate translations.", "sent2": "The feature function weights are then adjusted by traversing the error surface combined over all sentences and picking those values for which the resulting error count reaches a minimum.", "label": 1}
{"sent1": "Correctly identifying different types of you can be beneficial to machine translation systems.", "sent2": "Each of these different types often corresponds to a different term when translated into another language.", "label": 1}
{"sent1": "We adopt a supervised machine learning framework that ranks answer candidates to FU Qs.", "sent2": "Both the answer ranking and the classification of FU Qs is done in this framework, based on a host of measures that include shallow and deep inter-utterance relations, automatically collected dialogue management meta information, and human annotation.", "label": 1}
{"sent1": "The semantics are expressions of an underspecified logical form that has properties making it particularly suitable for statistical mapping from text.", "sent2": "In order to perform efficient posterior inference and large-scale training, we build a neural posterior approximator conditioned on both the source and the target sides, and equip it with a reparameterization technique to estimate the variational lower bound.", "label": 0}
{"sent1": "Recent papers have given contradictory results when comparing Bayesian estimators to Expectation Maximization (EM) for unsupervised HMM POS tagging, and we show that the difference in reported results is largely due to differences in the size of the training data and the number of states in the HMM.", "sent2": "We invesigate a variety of samplers for HMMs, including some that these earlier papers did not study.", "label": 1}
{"sent1": "But it has no clear probabilistic semantics.", "sent2": "Arguably the most advanced approach to abduction, especially for natural language processing, is weighted abduction, which uses logical formulas with costs to guide inference.", "label": 1}
{"sent1": "We propose a simple logistic regression model that incorporates and extends this heuristic and investigate its robustness across three languages and three domains.", "sent2": "In this paper, we take a closer look at a prominent strategy for their automatic acquisition from newspaper corpora, pairing first sentences of articles with their titles.", "label": 1}
{"sent1": "These representations are then used as feature vectors in a supervised learning model using multivariate multiple regression.", "sent2": "In brief, distributional semantic spaces containing representations for complex constructions such as Adjective-Noun and Verb-Noun pairs, as well as for their constituent parts, are built.", "label": 1}
{"sent1": "lasts seconds or minutes.", "sent2": "With the help of gates and constant error carousels in the memory block structure, the model could handle interactions between words through a flexible compositional function.", "label": 0}
{"sent1": "Another important ingredient of the proposed framework is a framework for semantifying bilingual lexical resource entries.", "sent2": "The GENETAG corpus has been modified to reflect new definitions of genes and proteins.", "label": 0}
{"sent1": "?ve Bayesian models achieve 84.90% and 57.87% accuracy in classifying NARRATION and BACKGROUND / ELABORATION relations respectively (16% and 23% above baseline).", "sent2": "We also incorporate precision focused scores over lexical and POS information derived from the BLEU measure, and lexical and POS features computed over split-bigrams from the ROUGE-S measure.", "label": 0}
{"sent1": "We first derive from WordNet senses a smaller set of abstract, general ?supersenses?.", "sent2": "We describe the methodology for constructing axioms defining event-related words, anchored in core theories of change of state and causality.", "label": 1}
{"sent1": "In this paper, we go significantly beyond stateof-the-art word overlap approaches, and apply a threshold-based Personalized PageRank method for the disambiguation step.", "sent2": "We exploited constituent parse trees in addition to syntactic dependency relations in resolving hedging scope.", "label": 0}
{"sent1": "We provide a series of semantic templates to recognize CONFINEMENT relations in Web texts, and then implement a system for recognizing CONFINEMENT between sentence pairs.", "sent2": "The method is based on two assumptions: words with similar meaning have similar subcategorization frames and selectional restrictions; and words with the same translations have similar meanings.", "label": 0}
{"sent1": "We elaborate on ideas described in Hobbs et al (1993) and implement the abductive inference procedure in a system called Mini-TACITUS.", "sent2": "The results show that a simple classifier relying on the lexicon outperforms two baselines on a sensory classification task, both at word and sentence level, and confirm the soundness of the proposed approach for the construction of the lexicon and the usefulness of the resource for computational applications.", "label": 0}
{"sent1": "The language data are an integral part of the social interaction in the game and consist of chat dialogue, which is only constrained by the cultural context, as set by the nature of the provided virtual environment.", "sent2": "Nowadays, most of the statistical translation systems are based on phrases (i.e.", "label": 0}
{"sent1": "We then aggregate those selected sentences by means of a word graph model.", "sent2": "We exploit a ranking strategy to select the best path in the word graph as an abstract sentence.", "label": 1}
{"sent1": "Automatic voice selection is essential for realising more sophisticated MT and summarisation systems, because it impacts the readability of generated texts.", "sent2": "However, to the best of our knowledge, the NLG community has been less concerned with explicit voice selection.", "label": 1}
{"sent1": "Based on various features collected from the training corpus, the system statistically learns template representations and document structure and produces well?formed texts (as evaluated by crowdsourced and expert evaluations).", "sent2": "Tests are run on real-world text acquired from freely available sources.", "label": 0}
{"sent1": "SALT?s version of disfluency annotations ?", "sent2": "This method allows us to conduct experiments on a large dataset of unannotated data.", "label": 0}
{"sent1": "We introduce a novel algorithm that is language independent: it exploits a maximum entropy letters model trained over the known words observed in the corpus and the distribution of the unknown words in known tag contexts, through iterative approximation.", "sent2": "The algorithm achieves 30% error reduction on disambiguation of unknown words over a competitive baseline (to a level of 70% accurate full disambiguation of unknown words).", "label": 1}
{"sent1": "Our empirical results have shown that, even when computer vision algorithms produce many errors (e.g.", "sent2": "While end-to-end neural machine translation (NMT) has made remarkable progress recently, NMT systems only rely on parallel corpora for parameter estimation.", "label": 0}
{"sent1": "This paper presents our work on abstractive summarization of line graphs.", "sent2": "Our methodology involves hypothesizing the intended message of a line graph and using it as the core of a summary of the graphic.", "label": 1}
{"sent1": "We then use this weak supervision to ?sprinkle?", "sent2": "The architecture has been gaining attention from industry and academia alike, resulting in a large volume of UIMA-compliant processing components.", "label": 0}
{"sent1": "The thematic segmentation task is modeled as a binaryclassification problem, where the different classes correspond to the presence or the absence of a thematic boundary.", "sent2": "We investigate the appropriateness of using a technique based on support vector machines for identifying thematic structure of text streams.", "label": 1}
{"sent1": "To understand the real effect of normalization on the parser, we tie normalization performance directly to parser performance.", "sent2": "In this paper, we take a parser-centric view of normalization that aims to convert raw informal text into grammatically correct text.", "label": 1}
{"sent1": "We first extract the triplets for the target word in each sentence, then use the intersection of all related words of these triplets from the Internet.", "sent2": "This paper describes the implementation of our system at CLP 2010 bakeoff of Chinese word sense induction.", "label": 1}
{"sent1": "We show that three factors are strong predictors of performance in isolation: the amount of reordering, the morphological complexity of the target language and the historical relatedness of the two languages.", "sent2": "This paper investigates the effect of different explanatory variables on the performance of a phrase-based system for 110 European language pairs.", "label": 1}
{"sent1": "method, where constraint violations in alternative strings are matched through violation alignment in order to remove suboptimal candidates.", "sent2": "Based on these findings, we implement methods inside a conditional random field segmenter that directly optimize segmentation granularity with respect to the MT task, providing an improvement of 0.73 BLEU.", "label": 0}
{"sent1": "We explore two methods to make the system scalable at runtime.", "sent2": "One extremely effective method for estimating the model parameters is minimum error rate training (MERT), which is an efficient form of line optimisation adapted to the highly nonlinear objective functions used in machine translation.", "label": 0}
{"sent1": "In contrast to previous work, our method uses no form of supervision, and does not require linguistically informed preprocessing.", "sent2": "The effectiveness of parsers based on manually created resources, namely a grammar and a lexicon, rely mostly on the quality of these resources.", "label": 0}
{"sent1": "Current evaluation metrics fall into two classes: heuristic approaches, like BLEU, and those using supervised learning trained on human judgement data.", "sent2": "We provide a brief overview of GL before moving on to our proposed methodology for annotating with GLML.", "label": 0}
{"sent1": "Proposed data-driven solutions to the problem have ranged from simple approaches that make minimal use of NLP tools to more complex approaches that rely on numerous language-dependent resources.", "sent2": "Therefore, it becomes an important and challenging topic to analyze Chinese-English mixed texts.", "label": 0}
{"sent1": "The methods also provide a practical means of optimizing the system through component analysis and cost valuation.", "sent2": "SWAN is a rule-based system that gives feedback based on various quality metrics based on years of experience from scientific writing classes including 960 scientists of various backgrounds: life sciences, engineering sciences and economics.", "label": 0}
{"sent1": "In this paper we discuss the range of possible forms for clari\fcation requests, together with the range of readings they can convey.", "sent2": "We present the results of corpus analysis which show a correlation between certain forms and possible readings, together with some indication of maximum likely distance between request and the utterance being clari\fed.", "label": 1}
{"sent1": "Each device in the network carries the linguistic and dialogue management information which is pertinent to it and uploads it dynamically to the relevant language processing components in the spoken language interface.", "sent2": "We introduce and describe a spoken language dialogue system architecture which supports Plug and Playable networks of objects in its domain.", "label": 1}
{"sent1": "The bulk of previous SR work assumed strong domain knowledge or hand-tagged training examples.", "sent2": "This environment establishes a number of constraints on the design of systems aimed at physicians in real-world settings.", "label": 0}
{"sent1": "We developed a two-step approach in which pairs are initially extracted using ensembles of up to five different classifiers and then relabeled to one of the four categories.", "sent2": "To pursue the goal of an Open Domain NLP (train once, test anywhere), we propose ADUT (ADaptation Using label-preserving Transformation), an approach that avoids the need for retraining and does not require knowledge of the new domain, or any data from it.", "label": 0}
{"sent1": "In this paper we firstly review some of the existing approaches in relation extraction generally and biomedical relations especially.", "sent2": "And secondly we will explain our SVM based approaches that use lexical, morphosyntactic and parse tree features.", "label": 1}
{"sent1": "We evaluate three feature sets, syntactic features derived from deep parsing, enhanced optionally with features derived from DrugBank or from both DrugBank and MetaMap.", "sent2": "), a model for sentence extraction in query-focused summarization.", "label": 0}
{"sent1": "We build two global models, one for predicate labelling and one for role labelling, each tailored to the task at hand.", "sent2": "However, there are still many questions about the best way to learn such extractors.", "label": 0}
{"sent1": "Our model is built on top of the hybrid tree semantic parsing framework, where natural language sentences and their corresponding semantics are assumed to be generated jointly from an underlying generative process.", "sent2": "Experimental results on ChineseEnglish machine translation tasks show an average improvement of 0.45 BLEU and 1.22 TER points across 5 different NIST test sets.", "label": 0}
{"sent1": "In previous self-training algorithms, the learner tries to convert the most confidently predicted unlabeled examples of each class into labeled training examples.", "sent2": "We solve this task via a semi-supervised approach and adopt the self-training algorithm for learning with little labeled data.", "label": 1}
{"sent1": "But annotated data is needed in order to train and evaluate these systems, which usually involves a costly process.", "sent2": "The optimal policy for choosing transitions can be found with the SARSA algorithm.", "label": 0}
{"sent1": "approach to gathering language-labeled Twitter messages for evaluating language identification.", "sent2": "We present the method to construct this dataset, as well as empirical results over existing datasets and off-theshelf language identifiers.", "label": 1}
{"sent1": "However, when we apply the three best-performing classifiers to unseen tweets that do not carry the hashtag but might have carried it according to human annotators, the classifiers manage to attain a precision-at-250 of .7 for only two of the hashtags.", "sent2": "This set is split into different clinical practices and analyzed by means of descriptive statistics and pairwise Inter-Annotator Agreement (IAA) measured by F 1 -score.", "label": 0}
{"sent1": "We propose a Joint Topic Viewpoint model (JTV) for the unsupervised identification and the clustering of arguing expressions according to the latent topics they discuss and the implicit viewpoints they voice.", "sent2": "A set of experiments is conducted on online debates documents.", "label": 1}
{"sent1": "One of the challenges of this work is the fact that the system explores the entire document.", "sent2": "Using convolutional neural network models, we measure the similarity of entity mentions with entities in the knowledge base (KB) and the similarity of relation patterns and relations in the KB.", "label": 0}
{"sent1": "Both abbreviation detection and sentence delimitation showed an accuracy of about 93%.", "sent2": "We evaluate the appearance of introspection in texts by searching words related to it, and focus on simple studies on the Bible.", "label": 0}
{"sent1": "In one, we use a lexicon of historical word?", "sent2": "We present the relevant lexicons and two experiments.", "label": 1}
{"sent1": "Sequences of POS tags for each sentence (exactly, nouns, adjectives, verbs and pronouns) are processed as ?words?", "sent2": "We believe that simulated feedback can be immensely beneficial to web search engine and personalization research communities by greatly reducing efforts involved in collecting user feedback.", "label": 0}
{"sent1": "With the best performing setting we obtain very good average precision of 0.973 and 0.883 on different gold standards.", "sent2": "The presented approach works on non-parallel datasets, is knowledge-lean and language-independent, which makes it attractive for natural language processing tasks that often lack the lexical resources and cannot afford to build them by hand.", "label": 1}
{"sent1": "We discuss to what extent the recall of NE recognition can be improved by reducing the space of NE categories.", "sent2": "We also present several extensions to the binary model which give an improvement of the recall.", "label": 1}
{"sent1": "The motivation behind this method is that if we only have a weak language model for T1 and translations in T1 and T2 are associated, we can use the information from a strong language model over T2 to disambiguate the translations in T1, providing better translation results.", "sent2": "We propose a method for simultaneously translating from a single source language to multiple target languages T1, T2, etc.", "label": 1}
{"sent1": "The features in our model are inspired by OT?s Markedness and Faithfulness constraints.", "sent2": "We evaluate the results with a variety of clustering evaluation metrics and achieve equivalent or better performances than previously reported.", "label": 0}
{"sent1": "Frequently, languages in contact are related, having a common ancestor from which they still retain visible structure.", "sent2": "This relatedness makes it difficult to distinguish contact-induced change from inherited similarities.", "label": 1}
{"sent1": "We show that the proposed method reconstructs known language families more accurately than baseline methods.", "sent2": "Lastly, assuming the monogenesis hypothesis, we attempt to reconstruct a common ancestor of the world?s languages.", "label": 1}
{"sent1": "Experimental results over evaluation sets of noun phrases from multiple sources demonstrate that interpretations extracted from queries have encouraging coverage and precision.", "sent2": "Both entity and relation extraction can benefit from being performed jointly, allowing each task to correct the errors of the other.", "label": 0}
{"sent1": "This approach eliminates much of the complex infrastructure of modern speech recognition systems, making it possible to directly train a speech recognizer using errors generated by spoken language understanding tasks.", "sent2": "We present an approach to speech recognition that uses only a neural network to map acoustic input to characters, a character-level language model, and a beam search decoding procedure.", "label": 1}
{"sent1": "Embodied in the form of images with text descriptions, little do we know about the ?language of memes?.", "sent2": "This paper presents an analysis of an annotator?s behaviour during her/his annotation process for eliciting useful information for natural language processing (NLP) tasks.", "label": 0}
{"sent1": "First, the dependency parser can be trained on a training set much larger than the training set for the tree-to-graph algorithm, resulting in a more accurate AMR parser overall.", "sent2": "Cross language text categorization has attracted more and more attention for the organization of these heterogeneous document collections.", "label": 0}
{"sent1": "Previous work on finding optimal solutions in MERT (Galley and Quirk, 2011) established a worstcase complexity that was exponential in the number of sentences, in contrast we show that exponential dependence in the worst-case complexity is mainly in the number of features.", "sent2": "Crucially the approach relies on having parallel corpora.", "label": 0}
{"sent1": "The semantic representation of Universal Networking Language (UNL), represents only the inherent meaning in a sentence without any syntactic details.", "sent2": "The SemEval 2012 task of Semantic Textual Similarity aims at finding the semantic similarity between two sentences.", "label": 1}
{"sent1": "The lexical metrics are based on wordoverlap.", "sent2": "A shallow syntactic metric is based on the overlap of base-phrase labels.", "label": 1}
{"sent1": "Unlike current approaches that build feature sets using similarity scores, we have developed these feature sets with the cardinalities of the commonalities and differences between pairs of objects being compared.", "sent2": "The acquired knowledge can be shown to subsequently contribute to task completion.", "label": 0}
{"sent1": "This paper examines creating a new dependency structure through ensemble learning using a hybrid of the outputs of various parsers.", "sent2": "The tool was designed to build the NTU-Multilingual Corpus (Tan and Bond, 2012).", "label": 0}
{"sent1": "These features are converted into natural language descriptions using context free grammar.", "sent2": "The work starts with implementation of conventional image processing techniques to extract high level features from video.", "label": 1}
{"sent1": "This classification task provides a convenient tool to probe the nature of telephone conversations.", "sent2": "By simultaneously inferring latent topics and topic distributions over relations, LDA-SP combines the benefits of previous approaches: like traditional classbased approaches, it produces humaninterpretable classes describing each relation?s preferences, but it is competitive with non-class-based methods in predictive power.", "label": 0}
{"sent1": "(2011) recently argued for training parameters to minimize the task-specific loss of whatever approximate inference and decoding methods will be used at test time.", "sent2": "With much less parameters to train, our model can achieve comparable or even better results on word-similarity tasks compared with conventional methods.", "label": 0}
{"sent1": "However, many systems that address these tasks focus on a single task and may or may not generalize well.", "sent2": "These rules are treated as discrete and independent events.", "label": 0}
{"sent1": "The third system (average) simply takes the average of the scores for each item from the other two systems to take advantage of the merits of both systems.", "sent2": "For this reason we only provide a brief description of that.", "label": 1}
{"sent1": "The significance of this study is that the proposed method selects the best dependency and case structure that are consistent within each clause and between clauses.", "sent2": "We illustrate how we use sublexical units for handling simple productive derivational morphology and more interesting cases such as causativization, etc., which change verb valency.", "label": 0}
{"sent1": "We find a gain in French parsing performance: from a baseline of F1=86.76% to F1=87.37% using morphological clustering, and up to F1=88.29% using further unsupervised clustering.", "sent2": "An inference engine is built to achieve inference on abstract denotations.", "label": 0}
{"sent1": "On the other hand, the second method, which is based on reparsing with one of observed errors corrected, assesses inter-dependencies among errors by examining which other errors were to be corrected as a result if a specific error was corrected.", "sent2": "Experiments show that these two methods are complementary and by being combined, they can provide useful clues as to how to improve a given grammar.", "label": 1}
{"sent1": "Several methods have been proposed to gather sense annotations using large numbers of untrained annotators, with mixed results.", "sent2": "Gathering word sense annotations is a laborious and difficult task.", "label": 1}
{"sent1": "To our best knowledge, this is the first work that exploits treebanking decisions for this task.", "sent2": "We also reflect on practical lessons learned from launching a demo for the general public.", "label": 0}
{"sent1": "The optimal policy for choosing transitions can be found with the SARSA algorithm.", "sent2": "At each time step, a transition is picked up to construct the dependency tree in terms of the long-run reward.", "label": 1}
{"sent1": "If the input, instead of a string, is a Directed Acyclic Graph (DAG), only simple RCGs can still be parsed in polynomial time.", "sent2": "These methods acquire translation rules from pairs of similar sentences in a bilingual text corpora.", "label": 0}
{"sent1": "While prior feature-based dynamic programming parsers have restricted training and evaluation to artificially short sentences, we present the first general, featurerich discriminative parser, based on a conditional random field model, which has been successfully scaled to the full WSJ parsing data.", "sent2": "Questions serving the latter purpose, called rhetorical questions, are often lexically and syntactically indistinguishable from other types of questions.", "label": 0}
{"sent1": "However, various parameters such as similarity measures must be handtuned to make it work effectively.", "sent2": "These procedures use acoustic information in combination with different levels of morphological and contextual constraints.", "label": 0}
{"sent1": "Our goal is to use bilingual cues to learn improved parsing models for each language and to evaluate these models on held-out monolingual test data.", "sent2": "We investigate the task of unsupervised constituency parsing from bilingual parallel corpora.", "label": 1}
{"sent1": "Previously, sentiment analysis was mostly studied under data-driven and lexicon-based frameworks.", "sent2": "Such work generally exploits textual features for fact-based analysis tasks or lexical indicators from a sentiment lexicon.", "label": 1}
{"sent1": "In the lab condition, we test how feasible the automatic extraction of GREs really is and achieve F-scores, under different, not directly comparable test conditions though, for the rule and the ML systems which amount to 34% and 44%, respectively.", "sent2": "In the REGULONDB condition, we investigate how robust both methodologies are by comparing them with this routinely used database.", "label": 1}
{"sent1": "However, few of the methods pay attention to non-entity words and clicked websites in queries, which also help conveying user intent.", "sent2": "Knowledge graphs are recently used for enriching query representations in an entity-aware way for the rich facts organized around entities in it.", "label": 1}
{"sent1": "However, unsupervised learning of polarity is difficult, owing in part to the prevalence of sentimentally ambiguous reviews, where reviewers discuss both the positive and negative aspects of a product.", "sent2": "Basically, we use Support Vector Machines (SVM) as learning algorithm and a set of simple features to build three different models.", "label": 0}
{"sent1": "Although spoken by nearly 30 million people, very little computational linguistic work has been done for this language.", "sent2": "Assamese is a morphologically rich, agglutinative and relatively free word order Indic language.", "label": 1}
{"sent1": "However, as an MT system is an aggregation of state-of-the-art NLP technologies without any intervention of human beings, it is unavoidable that quite a few sentence pairs are beyond its analysis and that will therefore not contribute to the system.", "sent2": "Furthermore, they in turn may act against our objectives to make the overall performance worse.", "label": 1}
{"sent1": "We present a two-level annotation scheme.", "sent2": "This paper presents a methodology for the comparative performance analysis of the parsers developed for different grammar frameworks.", "label": 0}
{"sent1": "We compare our system to a word-substitution baseline and two state-of-the-art systems, all trained and tested on paired sentences from the English part of Wikipedia and Simple Wikipedia.", "sent2": "This paper gives a detailed description of the ACT (Accuracy of Connective Translation) metric, a reference-based metric that assesses only connective translations.", "label": 0}
{"sent1": "Through a set of POS tagging experiments, it is shown that the classifier trained with the proposed loss functions reduces serious errors compared to state-of-the-art POS taggers.", "sent2": "In a query-by-example image retrieval experiment on data set of people performing actions, we find an 8.8% relative increase in MAP and an 8.6% relative increase in Precision@10 when images are represented using the Visual Dependency Representation compared to a bag-of-terms baseline.", "label": 0}
{"sent1": "A major challenge facing this task is the system coverage, i.e., for any user-created nonstandard term, the system should be able to restore the correct word within its top n output candidates.", "sent2": "We study the use of phonological features and affinity statistics for transliteration alignment at phoneme and grapheme levels.", "label": 0}
{"sent1": "We demonstrate also that n-way jackknifing is a useful technique for producing automatic (rather than gold) partof-speech tags to train Chinese dependency parsers.", "sent2": "We then developed a new algorithm for attribute selection based on observations from a corpus, which outperformed a simple base algorithm by a significant margin.", "label": 0}
{"sent1": "linguists) can log in and adjust linguistic analyses in real time, at various levels of analysis, such as boundaries (tokens, sentences) and tags (part of speech, lexical categories).", "sent2": "The demo will illustrate the different features of the platform, including navigation, visualization and editing.", "label": 1}
{"sent1": "In this paper we focus on its understanding component that supports in-domain interactions, and also small talk.", "sent2": "Given that some revisions are unavoidable, we next present a pair of methods for predicting the stability and accuracy of ISR results.", "label": 0}
{"sent1": "The framework allows the extraction of several quality indicators from source segments, their translations, external resources (corpora, language models, topic models, etc.", "sent2": "The idea is to relate correspondences between sounds in wordlists to translational equivalences between words in bitexts (bilingual corpora).", "label": 0}
{"sent1": "One way to handle such texts is to modify them prior to translation.", "sent2": "We compare these to the usual verb?argument paraphrase test using corpus statistics, and frequencies obtained by scraping the Google search engine interface.", "label": 0}
{"sent1": "It provides an open-source C++ implementation for the entire forest-to-string MT pipeline, including rule extraction, tuning, decoding, and evaluation.", "sent2": "In this paper we describe Travatar, a forest-to-string machine translation (MT) engine based on tree transducers.", "label": 1}
{"sent1": "Our approach achieves 11.6%-25% higher F-score over state-ofthe-art English slot filling methods.", "sent2": "Thus we design a graph-based algorithm to automatically identify triggers based on personalized PageRank and Affinity Propagation for a given (query, filler) pair and then label the slot type based on the identified triggers.", "label": 1}
{"sent1": "JoBimText is an open source platform for large-scale distributional semantics based on graph representations.", "sent2": "Our experiments on two data sets in English and Korean show that the consideration of the factors results in performance improvement in keyword extraction from meeting transcripts.", "label": 0}
{"sent1": "We applied our algorithm to two different domains; semantic similarity of documents collected from the Web, and phenotype descriptions in genomic data.", "sent2": "Experiments show that our algorithm can handle the high-dimensional big data and outperform competing approximations in both domains.", "label": 1}
{"sent1": "Thus, an ?iterative seeding?", "sent2": "The selected seed set affects accuracy, but how to select a good seed set is not yet clear.", "label": 1}
{"sent1": "We identify relevance in terms of the semantic and syntactic similarities between two texts.", "sent2": "This makes it difficult to test their performance on new data sets, or to compare them against past algorithms implemented for different data sets.", "label": 0}
{"sent1": "The blocking step groups records by shared properties to determine which pairs of records should be examined by the pairwise linker as potential duplicates.", "sent2": "Similarly, a user must follow step by step the instructions in order to reach the results expected.", "label": 0}
{"sent1": "It outputs a list of professional skills that are relevant to a given input text.", "sent2": "This paper presents a system that performs skill extraction from text documents.", "label": 1}
{"sent1": "Existing models can only deal with isolated phenomena (e.g., garden paths) on small, specifically selected data sets.", "sent2": "The challenge is to build models that integrate multiple aspects of human language processing at the syntactic, semantic, and discourse level.", "label": 1}
{"sent1": "The MASC infrastructure enables the incorporation of contributed annotations into a single, usable format that can then be analyzed as it is or ported to any of a variety of other formats.", "sent2": "MASC includes data from a much wider variety of genres than existing multiply-annotated corpora of English, and the project is committed to a fully open model of distribution, without restriction, for all data and annotations produced or contributed.", "label": 1}
{"sent1": "By using a synchronous grammar, the method transforms parse trees containing annotation errors into the ones whose errors are corrected.", "sent2": "But the causes of these errors are diverse, and the extent to which the accuracy of generation over individual syntactic phenomena is unknown.", "label": 0}
{"sent1": "We also introduce several new ?path?", "sent2": "This paper summarizes our participation in task #17 of SemEval?2 (All?words WSD on a specific domain) using a supervised class-based Word Sense Disambiguation system.", "label": 0}
{"sent1": "into HAL.", "sent2": "In this paper, we pursue two methods for incorporating syntactic-semantic information from textual ?events?", "label": 1}
{"sent1": "However, cross-validation metrics that test whether the system makes exactly the same choices as the corpus on each item have recently been shown not to correlate well with human judgements of quality.", "sent2": "This literary format?s structured dialogue allows us to make assumptions about who is participating in a conversation.", "label": 0}
{"sent1": "Revealing relations between the parts by jointly segmenting and predicting links between the segments, would help to visualize such documents and construct friendlier user interfaces.", "sent2": "To overcome these limitations, we suggest to perform a linear transformation of the context vectors, which is defined by a matrix.", "label": 0}
{"sent1": "Reconcile is designed to facilitate the rapid creation of coreference resolution systems, easy implementation of new feature sets and approaches to coreference resolution, and empirical evaluation of coreference resolvers across a variety of benchmark data sets and standard scoring metrics.", "sent2": "With the aim to facilitate consistent and realistic experimental evaluations in coreference resolution, we present Reconcile, an infrastructure for the development of learning-based noun phrase (NP) coreference resolution systems.", "label": 1}
{"sent1": "We present incremental-based, transformation-based learning for semantic processing tasks.", "sent2": "A disadvantage is that the rule extraction procedure is time-consuming.", "label": 1}
{"sent1": "Our system achieves 93.49 Fmeasure, a significant improvement over the best reported performance 92.0.", "sent2": "We are further concerned with the effect of parsing in Chinese SRL.", "label": 1}
{"sent1": "We therefore propose to reorder VS constructions into SV order for SMT word alignment only.", "sent2": "In addition, implementing reordering is difficult because the boundaries of VS constructions are hard to detect accurately, even with a state-of-the-art Arabic dependency parser.", "label": 1}
{"sent1": "In an evaluation experiment using the Penn Treebank (WSJ section), the proposed model achieved higher accuracy than did previous deterministic models.", "sent2": "We show that the results achieved by state-of-the-art data-driven parsers on Hungarian and English (which is at the other end of the configurational-nonconfigurational spectrum) are quite similar to each other in terms of attachment scores.", "label": 0}
{"sent1": "Automatically mined rules are also used for realization.", "sent2": "We evaluated 5 different versions of a system that tutors on an abstract sequence learning task.", "label": 1}
{"sent1": "TKA?", "sent2": "performs only the inside pass before extracting k-best lists top down.", "label": 1}
{"sent1": "We then relax the constraint and show that one-reentrant unification grammars generate exactly the class of tree-adjoining languages.", "sent2": "We thus relate the commonly used and linguistically motivated formalism of unification grammars to more restricted, computationally tractable classes of languages.", "label": 1}
{"sent1": "We have tested this approach with a comparable corpus of news written in English and Spanish.", "sent2": "An additional advantage of the approach is that it does not need any information about the right number of clusters; the algorithm calculates it.", "label": 1}
{"sent1": "An initial evaluation study with several sighted users and one partially sighted user showed that an introduction message is certainly preferred by most participants.", "sent2": "Yet a topic phrase alone, such as ?SXSW?, can rarely present the information clearly.", "label": 0}
{"sent1": "mas with a precision of 96% and a re?", "sent2": "(iii) Sentence-internal punctuation boundaries help with longer-distance dependencies, since punctuation correlates with constituent edges.", "label": 0}
{"sent1": "Examples of these are names of diseases and infectious agents, such as bacteria and viruses.", "sent2": "We also established that the comparison generation algorithm could generalize to the music domain.", "label": 0}
{"sent1": "In this framework, the concept of multidimensional category model is introduced for representing classes.", "sent2": "In contrast with traditional flat and hierarchical category models, the multi-dimensional category model classifies each text document in a collection using multiple predefined sets of categories, where each set corresponds to a dimension.", "label": 1}
{"sent1": "The accuracy of our parser was 92.8%, which was higher than that for the parser with the \fxed history (89.8%).", "sent2": "In the experiment, we built an SLM-based parser with a \fxed history and one with ACTs, and compared their parsing accuracies.", "label": 1}
{"sent1": "This analysis currently doesn?t take into account negation phenomena.", "sent2": "We participated in both the open and closed tracks and submitted results using both predicted and gold mentions.", "label": 0}
{"sent1": "CTs operate on alternative text representation models taking lexical organization, quantitative text characteristics, and text structure into account.", "sent2": "The evaluation is conducted using two corpora: the Prague Dependency Treebank and Czech National Corpus.", "label": 0}
{"sent1": "This model considers not only word n-gram information, but also dependency information between words.", "sent2": "The evaluation part consists of a model for generating an appropriate text when given keywords.", "label": 1}
{"sent1": "This means that many corpora can be used.", "sent2": "The search terms which are left after preprocessing are then grouped according to co-occurrence statistics which have been derived from a newspaper corpus.", "label": 0}
{"sent1": "In order to ensure decidability, several constraints on grammars, commonly known as off-line parsability (OLP) were suggested.", "sent2": "We investigate whether measures of readability can be used to identify age-specific TV programs.", "label": 0}
{"sent1": "Comprehensive experimentation reveals our new hybrid method to be the most effective for large documents.", "sent2": "This paper proposes a new methodology to improve the accuracy of a term aggregation system using each author?s text as a coherent corpus.", "label": 0}
{"sent1": "Given an IE system for a source language (e.g., English), we can transfer its annotations to corresponding texts in a target language (e.g., French) and learn information extraction rules for the new language automatically.", "sent2": "In addition, despite being designed for syntactic analysis, our system also achieves stateof-the-art numbers on the structural sentiment task of Socher et al.", "label": 0}
{"sent1": "Grammatical relationships, stored in dictionaries, are utilized in translation selection essentially.", "sent2": "?, respectively.", "label": 0}
{"sent1": "In an experiment for a mid-size UBG, we show that our novel approach is feasible.", "sent2": "We combine lexical, syntactic, and discourse features to produce a highly predictive model of human readers?", "label": 0}
{"sent1": "Previous work onMWE identification has relied primarily on surface statistics, which perform poorly for longer MWEs and cannot model discontinuous expressions.", "sent2": "Multiword expressions (MWE), a known nuisance for both linguistics and NLP, blur the lines between syntax and semantics.", "label": 1}
{"sent1": "by  a  pre-annotation  and  by  several  useful  features  implemented  in  the  annotation  tool.", "sent2": "We present methods of helping the annotators  ?", "label": 1}
{"sent1": "In this study we try to learn automatically two classifications, \u0000\u0002\u0001\u0004\u0003\u0006\u0005\b\u0007 \t\f\u000b\u000e \u0004\u0005\f\u000f \u0010\u0011\u000f\u0013\u0012 and \u0000\u0002\u000b\u000e\u0010\u0014\u0003\u0016\u0015\f\u000b\u0017\u000f , relevant for this problem.", "sent2": "While several recent works on dealing with large bilingual collections of texts, e.g.", "label": 0}
{"sent1": "The second step, automatic term recognition, extracts important terms from the corpus by using Nakagawa?s method.", "sent2": "The first step, compiling corpus step, collects texts that contain the given seed term by using search engines.", "label": 1}
{"sent1": "We confirm the importance of combining four types of multimodal features: lexical, syntactic structure, eye gaze, and prosody.", "sent2": "We present our results on three diverse NLP tasks, showing state-of-the-art results.", "label": 0}
{"sent1": "The system derives disambiguating queries (DQs) that draw out additional information.", "sent2": "We have been investigating an interactive approach for Open-domain QA (ODQA) and have constructed a spoken interactive ODQA system, SPIQA.", "label": 1}
{"sent1": "A new, more portable version of the FrameNet software is also being made available to researchers elsewhere, including the Spanish FrameNet project.", "sent2": "An interim version of the FrameNet data was released in October, 2002 and is being widely used.", "label": 1}
{"sent1": "Willex has two major new functions.", "sent2": "However, we also show that extending data for SMT is more effective.", "label": 0}
{"sent1": "For task 2, we applied a cluster validation method to estimate the number of senses of a target word in untagged data, and then grouped the instances of this target word into the estimated number of clusters.", "sent2": "Solving the visual symbol grounding problem has long been a goal of artificial intelligence.", "label": 0}
{"sent1": "not all words have good substitutes.", "sent2": "In an experiment for a mid-size UBG, we show that our novel approach is feasible.", "label": 0}
{"sent1": "ARIS learns to categorize verbs with 81.2% accuracy, and is able to solve 77.7% of the problems in a corpus of standard primary school test questions.", "sent2": "In this paper we also propose a heuristic method for the treatment of social networking profiles.", "label": 0}
{"sent1": "from a very large database of known facts.", "sent2": "for instance, that cats have tails or tomatoes are round ?", "label": 1}
{"sent1": "Experiment results show that all three models can achieve significant improvements over the baseline.", "sent2": "Additionally, we can obtain a further improvement when combining the three models.", "label": 1}
{"sent1": "This happens naturally in Syntax-Based Machine Translation and Hierarchical Phrase-Based Machine Translation (where the representation will be the set of the target-side half of the synchronous rules used to parse the input sentence).", "sent2": "The translation performance matches the result we achieve with a joint extraction on all training bitexts while the system is kept smaller due to a considerably lower overall number of phrases.", "label": 0}
{"sent1": "The annotations are evaluated in several ways.", "sent2": "The annotations are also generalized on a 2-dimensional model of affect to obtain information on sentence valence/polarity (positive/negative) useful in sentiment analysis.", "label": 1}
{"sent1": "We propose a paraphrasing model for LVCs that is based on transforming the Lexical Conceptual Structures (LCSs) of verbal elements.", "sent2": "This process is framed as a linear assignment task, which allows to control some well-formedness constraints.", "label": 0}
{"sent1": "After an overview of relevant aspects of Turkish, we present a description of the multi-word expressions we handle.", "sent2": "We then summarize the computational setting in which we employ a series of components for tokenization, morphological analysis, and multi-word expression extraction.", "label": 1}
{"sent1": "BioGrapher first attempts to answer a question by searching in a given collection of biographies, using techniques tailored for the restricted nature of the domain.", "sent2": "We simulate the effects of lookahead by summing probabilities over possible parses for the lookahead words and using this sum to choose which parse to pursue.", "label": 0}
{"sent1": "Because the main concern of the QA system for the home robot is the precision, rather than coverage (No answer is better than wrong answers), our approach is try to achieve high accuracy in QA.", "sent2": "This approach learns role assignment in filler-gap constructions in a manner consistent with current developmental findings and is extremely robust to initialization variance.", "label": 0}
{"sent1": "These entities at the core of the model are originally found and resolved using a combination of information extraction and record linkage techniques.", "sent2": "The metadata we create is roughly an order of magnitude smaller than the content being modeled, it provides the end-user with context sensitive information about the hyperlinked entities in focus.", "label": 1}
{"sent1": "This translation allows us to automatically transform Mikrokosmos sources into OWL and thus provide a powerful ontology in the formalism of the semantic web.", "sent2": "We learned that a domainspecific resource produces better results than a bigger, but more general one.", "label": 0}
{"sent1": "With this method, we can predict the label sequence while taking the whole input sequence information into consideration.", "sent2": "In this paper we describe the three approaches we submitted to the Semantic Textual Similarity task of SemEval 2012.", "label": 0}
{"sent1": "It consists of a hand-held scanner and sophisticated parsing and translation software to provide readers a limited number of translations selected on the basis of a linguistic analysis of the whole scanned text fragment (a phrase, part of the sentence, etc.).", "sent2": "In this paper, we attempt to explain the emergence of the linguistic diversity that exists across the consonant inventories of some of the major language families of the world through a complex network based growth model.", "label": 0}
{"sent1": "In particular, since pedophiles are known to be emotionally unstable, we were interested in investigating if emotion-based features could help in their detection.", "sent2": "We have used a corpus of predators?", "label": 1}
{"sent1": "In translation, out-ofvocabulary words were preprocessed in a knowledge-lite fashion to identify a likely equivalent.", "sent2": "In training, two reordering strategies were studied: (i) reorder on the basis of the alignments from Giza++, and (ii) reorder by moving all verbs to the end of segments.", "label": 1}
{"sent1": "In contrast, we apply different morphological decompositions of words using the unsupervised Morfessor algorithms.", "sent2": "While translation models trained using the morphological decompositions did not improve the BLEU scores, we show that the Minimum Bayes Risk combination with a word-based translation model produces significant improvements for the Germanto-English translation.", "label": 1}
{"sent1": "We show the effectiveness of such features in both classification and regression of MT quality.", "sent2": "By dynamically training the QE model for the document-specific MT model, we are able to achieve consistency and prediction quality across multiple documents, demonstrated by the higher correlation coefficient and F-scores in finding Good sentences.", "label": 1}
{"sent1": "These code switches are subsequently translated to L2 given the L2 context.", "sent2": "Recent efforts have tried to overcome this issue by using statistics from speech lattices instead of only the 1best transcripts; however, these efforts have invariably used the classical vector space retrieval model.", "label": 0}
{"sent1": "Such systems alleviate the need for O(nC2) corpora, significantly.", "sent2": "We introduce structural correspondence learning to automatically induce correspondences among features from different domains.", "label": 0}
{"sent1": "We evaluate our algorithm on three different NLP tasks ?", "sent2": "This paper develops a novel joint learning algorithm for both tasks, that uses the final prediction to guide the selection of the best intermediate representation.", "label": 1}
{"sent1": "of high-frequency words can be dealt with more elegantly, and in a way that to our knowledge has not been considered in LDA, through the use of appropriate weighting schemes comparable to those sometimes used in Latent Semantic Indexing (LSI).", "sent2": "We show, however, that the ?problem?", "label": 1}
{"sent1": "We optimize different ranking objectives in a stochastic gradient descent framework.", "sent2": "We apply our system for the domain of educational sciences by focusing primarily on crawling scientific educational publications in the web.", "label": 0}
{"sent1": "In this paper, we propose a learning to rank algorithm for entity linking.", "sent2": "It effectively utilizes the relationship information among the candidates when ranking.", "label": 1}
{"sent1": "The multilingual experience of such users can be significantly improved if they could express their information need in their native language while searching for English Wikipedia articles.", "sent2": "Sentiment analysis of short texts such as single sentences and Twitter messages is challenging because of the limited contextual information that they normally contain.", "label": 0}
{"sent1": "These two abilities develop in parallel, however, raising the question of whether they might interact.", "sent2": "To explore the question, we present a new Bayesian segmentation model that incorporates aspects of word learning and compare it to a model that ignores word meanings.", "label": 1}
{"sent1": "We show that modeling morphological and phonological variation leads to a substantial average gain of F=0.206 and an error reduction of up to 63.8% for specific labels, relative to a baseline system optimized over word-sequences.", "sent2": "Broad-coverage relation extraction either requires expensive supervised training data, or suffers from drawbacks inherent to distant supervision.", "label": 0}
{"sent1": "This feature is particularly useful in IMT since it allows the user feedback to be taken into account.", "sent2": "The online learning techniques proposed here incrementally update the statistical models involved in the translation process.", "label": 1}
{"sent1": "Although they fall short of the performance of the hand-crafted feature set of Charniak and Johnson (2005) developed for parse tree reranking, they do so with an order of magnitude fewer features.", "sent2": "Furthermore, since the TSGs employed are learned in a Bayesian setting, the use of their derivations can be viewed as the automatic discovery of tree patterns useful for classification.", "label": 1}
{"sent1": "To derive this method, we develop a stick-breaking representation of adaptor grammars, a representation that enables us to define adaptor grammars with recursion.", "sent2": "This paper describes a variational inference algorithm for adaptor grammars, providing an alternative to Markov chain Monte Carlo methods.", "label": 1}
{"sent1": "We apply this technique to part-of-speech induction, grammar induction, word alignment, and word segmentation, incorporating a few linguistically-motivated features into the standard generative model for each task.", "sent2": "To the best of our knowledge, this work is the first to both (i) develop a domain adaptation algorithm for the coreference resolution problem and (ii) have the above features as an ensemble method.", "label": 0}
{"sent1": "This paper presents a simple but effective translation model, called the Head-Driven HPB (HD-HPB) model, which incorporates head information in translation rules to better capture syntax-driven information in a derivation.", "sent2": "This filter improved the performance of the baseline filter in identifying responses with topic problems.", "label": 0}
{"sent1": "The matching criterion is based on lexical similarity scoring of the semantic role fillers through a simple context vector model which can readily be trained using any publicly available large monolingual corpus.", "sent2": "We will discuss the content and format of the data releases and how the software and data can be used by other NLP researchers.", "label": 0}
{"sent1": "We document the quality improvements of these systems as measured through automated quality measures and crowdsourced human quality assessments.", "sent2": "We discuss several machine translation systems that we trained using aligned text from product listing descriptions written in multiple languages.", "label": 1}
{"sent1": "Lexical chains have been successfully employed to evaluate lexical cohesion of text segments and to predict topic boundaries.", "sent2": "This paper investigates the use of a modified self-organising map (SOM) to select a subset of the memory items for comparison.", "label": 0}
{"sent1": "In previous work on selectional preference acquisition, the classes used for representation are selected according to the coverage of argument tokens rather than being selected according to the coverage of argument types.", "sent2": "In our distributional thesaurus models and one of the methods using WordNet we select classes for representing the preferences by virtue of the number of argument types that they cover, and then only tokens under these classes which are representative of the argument head data are used to estimate the probability distribution for the selectional preference model.", "label": 1}
{"sent1": "logically annotated treebanks in a functioncentred way.", "sent2": "Pars, that assigns dependencies to morpho?", "label": 1}
{"sent1": "The system consists of three phases: a probabilistic vine parser (Eisner and N. Smith, 2005) that produces unlabeled dependency trees, a probabilistic relation-labeling model, and a discriminative minimum risk reranker (D. Smith and Eisner, 2006).", "sent2": "The system is designed for fast training and decoding and for high precision.", "label": 1}
{"sent1": "The algorithm parses sentences in linear time and labeling is integrated with the parsing.", "sent2": "A constraint procedure is made to use more structure information.", "label": 1}
{"sent1": "A decision list learner was used in this work.", "sent2": "This paper presents an approach to dependency parsing which can utilize any standard machine learning (classification) algorithm.", "label": 1}
{"sent1": "We additionally propose a simple modification to the architecture to allow for the use of both task-specific and static vectors.", "sent2": "Learning task-specific vectors through fine-tuning offers further gains in performance.", "label": 1}
{"sent1": "However, Training this discriminative model using large-scale parallel corpus might be computationally expensive.", "sent2": "Initial experiments to learn the four possible translations with Decision Trees give promising results.", "label": 0}
{"sent1": "These improvements allow us to successfully decipher the second part of the famous Beale cipher (see (Ward et al., 1885) and e.g.", "sent2": "(King, 1993)): Having 182 different cipher symbols while having a length of just 762 symbols, the decipherment is way more challenging than the decipherment of the previously deciphered Zodiac408 cipher (length 408, 54 different symbols).", "label": 1}
{"sent1": "We are able to distinguish 50 different cipher types (specified by the American Cryptogram Association) with an accuracy of 58.5%.", "sent2": "It is realized as a regression task in a vector space model.", "label": 0}
{"sent1": "Such framework suffers from error propagation and is unable to leverage information in later modules for prior components.", "sent2": "In this paper, we propose a four-level Dirichlet Process based model (DP-4) to jointly learn the word distributions from the corpus, domain and document levels simultaneously.", "label": 1}
{"sent1": "These time scopes specify the time periods when a given fact was valid in real life.", "sent2": "Without temporal scope, many facts are underspecified, reducing the usefulness of the data for upper level applications such as Question Answering.", "label": 1}
{"sent1": "Although there are many social science studies of self-disclosure, they are based on manual coding of small datasets and questionnaires.", "sent2": "Self-disclosure, the act of revealing oneself to others, is an important social behavior that strengthens interpersonal relationships and increases social support.", "label": 1}
{"sent1": "only one pass is necessary to collect moment statistics.", "sent2": "Unlike other semi-supervised methods, no decoding passes are necessary on the unlabeled data and no graph needs to be constructed?", "label": 1}
{"sent1": "This year, the ST?11 provides a further generalization on three key aspects: text type, subject domain, and targeted event types.", "sent2": "Recently, the focus in the BioNLP domain has shifted from binary relations to more expressive event representations, largely owing to the international popularity of the BioNLP Shared Task (ST) of 2009.", "label": 1}
{"sent1": "We do not apply Machine Learning, instead the system classifies with an empirically derived salience measure based on the dependency labels of the true mentions.", "sent2": "We then decompose the emotion classification task into two sub-steps: sentiment polarity classification (coarsegrained emotion classification), and emotion classification (fine-grained emotion classification).", "label": 0}
{"sent1": "We improved the best performing system of BioNLP 2009 overall, and ranked first amongst 15 teams in finding ?Localization?", "sent2": "By using grammar generated SLMs we can improve both recognition and understanding performance considerably over using the original grammar.", "label": 0}
{"sent1": "The event rules are learned by identifying the key contextual dependencies from full syntactic parsing of annotated text.", "sent2": "A graph-based approach is employed to automatically learn rules for detecting biological events in the life-science literature.", "label": 1}
{"sent1": "Similar to our earlier system, syntactic dependencies form the basis of our approach.", "sent2": "In this spirit, we re-engineered and extended our event extraction system, emphasizing linguistic generalizations and avoiding domain-, event typeor text type-specific optimizations.", "label": 1}
{"sent1": "This system was developed for the BioNLP?11 Shared Task and extends our BioNLP?09 Shared Task winning Turku Event Extraction System.", "sent2": "We present a system for extracting biomedical events (detailed descriptions of biomolecular interactions) from research articles.", "label": 1}
{"sent1": "OntoNotes also provides additional layers of integrated annotation, capturing additional shallow semantic structure.", "sent2": "Our algorithm generates a summary by selecting and ordering sentences taken from multiple review texts according to two scores that represent the informativeness and readability of the sentence order.", "label": 0}
{"sent1": "Our system is a collection of deterministic coreference resolution models that incorporate lexical, syntactic, semantic, and discourse information.", "sent2": "In this paper however, we examine the performance of the automatically acquired first sense in isolation since it turned out that the first sense taken from SemCor outperformed many systems in SENSEVAL-2.", "label": 0}
{"sent1": "In total, 14 tasks are provided.", "sent2": "Our main focus has been on building the infrastructure and gathering the data.", "label": 0}
{"sent1": "In this paper, we first discuss LL in general and then LL for sentiment classification in particular.", "sent2": "We formalize named entity categorization as a task of categorizing anchor texts with linked HTML texts which glosses a named entity.", "label": 0}
{"sent1": "In this work, we explore n-gram models over Minimal Translation Units (MTUs) to explicitly capture contextual dependencies across phrase boundaries in the channel model.", "sent2": "As a result, they rely on large phrase pairs and target language models to recover contextual effects in translation.", "label": 1}
{"sent1": "For ten natural languages and a limited domain of geometric shapes and their properties and relations we define sequential transducers to produce pairs consisting of an utterance in that language and its meaning.", "sent2": "These rules are treated as discrete and independent events.", "label": 0}
{"sent1": "While deep learning methods like Recurrent Neural Network or Convolutional Neural Network have been proved to be powerful for sentence modeling, prior studies paid less attention on interactions between sentences.", "sent2": "Error types covered by our system are article/determiner, preposition, and noun number agreement.", "label": 0}
{"sent1": "This paper presents a discriminative approach for generating candidate strings.", "sent2": "speeding up the feature extraction step for little to no cost in prediction performances.", "label": 0}
{"sent1": "We demonstrate the effectiveness of our method on cross-language text categorization.", "sent2": "We propose a principled framework of embedding entities that integrates hierarchical information from large-scale knowledge bases.", "label": 0}
{"sent1": "In this paper we present a novel algorithm which encodes the structure of a knowledge base in a continuous vector space, combining random walks and neural net language models in order to produce novel word representations.", "sent2": "We compare two REG algorithms in terms of their performance: the classic Incremental Algorithm and the more recent Graph algorithm.", "label": 0}
{"sent1": "We incorporate different features into the system and perform experiments on the ACE 2005 corpus.", "sent2": "Our approach achieves better overall performance for precision, recall and Fmeasure metrics as compared to SVM-based and LLDA-based models.", "label": 1}
{"sent1": "The proposed sense-based translation model enables the decoder to select appropriate translations for source words according to the inferred senses for these words using maximum entropy classifiers.", "sent2": "Thus, the research reported herein overlaps heavily with that of the machine-translation, lexicon-construction, and information-retrieval communities.", "label": 0}
{"sent1": "The weights of local and non-local features are learned together in the training process with guaranteed convergence.", "sent2": "Our algorithm allows the use of all types of non-local features whose values are determined from the sequence and the labels.", "label": 1}
{"sent1": "We investigate the effectiveness of such representations in the automated relation extraction from texts.", "sent2": "We process the above data by means of Support Vector Machines along with the syntactic tree, the partial tree and the word sequence kernels.", "label": 1}
{"sent1": "The preprocessing phase comprises treatment of emoticon, slang terms, lemmatization and POS-tagging.", "sent2": "Cultural heritage, and other special domains, pose a particular problem for information retrieval: evaluation requires a dedicated test collection that takes the particular documents and information requests into account, but building such a test collection requires substantial human effort.", "label": 0}
{"sent1": "We introduce a novel supervised learning model for mapping verb instances to VN classes, using rich syntactic features and class membership constraints.", "sent2": "However, verbs are polysemous with respect to their VN classes.", "label": 1}
{"sent1": "Common Sense can be defined as the knowledge shared by a group of people in a given time, space and culture; and this knowledge, here, is represented by a semantic network called ConceptNet.", "sent2": "This paper reports an ongoing work in applying Common Sense knowledge to Machine Translation aiming at generating more culturally contextualized translations.", "label": 1}
{"sent1": "One important type of contextual information concerns who or what a coreferring pronoun corefers to (i.e., its antecedent).", "sent2": "Languages differ significantly in how they achieve coreference, and awareness of antecedents is important in choosing the correct pronoun.", "label": 1}
{"sent1": "We exploit Bayesian nonparametrics and collapsed Gibbs sampling to discover salient patterns in a corpus.", "sent2": "We evaluate the patterns qualitatively and also add them as features to an MT system, reporting promising preliminary results.", "label": 1}
{"sent1": "In this paper, we recast the machine translation problem in the familiar terms of a sequence labeling task, thereby enabling the use of enriched feature sets and exact training and inference procedures.", "sent2": "Our similarity estimator relies on a support vector regressor with RBF kernel.", "label": 0}
{"sent1": "We also combine all the four models using an ensemble based approach to get the final result.", "sent2": "In our approaches, we selected lexical and syntactic features based on n-grams of characters, words, Penn TreeBank (PTB) and Universal Parts Of Speech (POS) tagsets, and perplexity values of character of n-grams to build four different models.", "label": 1}
{"sent1": "We design features across all the L1 languages not making use of knowledge of prompt and proficiency level.", "sent2": "During system development, we experimented with various techniques for feature filtering and combination optimized with respect to the notion of mutual information and information gain.", "label": 1}
{"sent1": "These noun groups represent the likelihood of a particular noun-verb combination in a large corpus.", "sent2": "In this paper, we present a semi-automatic method to obtain noun groups based on their co-occurrences with light verbs.", "label": 1}
{"sent1": "We evaluated our approach on a corpus of manually annotated data.", "sent2": "Our results show that the proposed methods are able to improve over a fully unsupervised baseline system.", "label": 1}
{"sent1": "The highest single-reference BLEU score is achieved by the hierarchical system and reaches 21.58% but this figure depends on the randomly selected test set.", "sent2": "From this analysis, specific verb reordering lattices are then built on the test sentences before decoding them.", "label": 0}
{"sent1": "We have built a Hybrid system which gives 90.804% F1-scores and 94.697% F1-scores for identification of clauses?", "sent2": "Finally, we find that a minimal amount of pre-processing can lead to better results than using either the raw data or highly processed data.", "label": 0}
{"sent1": "These new lexicons and WSD improve the quality of translation in most cases, as we show by examples.", "sent2": "We propose to adapt Open IE technology for event-based stock price movement prediction, extracting structured events from large-scale public news without manual efforts.", "label": 0}
{"sent1": "In this work we compare several standard and state of the art online RL algorithms that are used to train the dialogue manager in a dynamic environment, aiming to aid researchers / developers choose the appropriate RL algorithm for their system.", "sent2": "Extensive experiments have validated the effectiveness of the corpus-based method for classifying the word?s sentiment polarity.", "label": 0}
{"sent1": "The analyses of linguistic properties showed that ease of error detection was associated with changing parts-of-speech of reference words in SR errors.", "sent2": "Many methods of text summarization combining sentence selection and sentence compression have recently been proposed.", "label": 0}
{"sent1": "cell biology and pharmacology, at the level of named entity information.", "sent2": "The effective detection of an opinion holder depends on the consideration of various cues on various levels of representation, though they are hard to formulate explicitly as features.", "label": 0}
{"sent1": "We then explored the impact of vocabulary profile features in an automated speech scoring context, with particular focus on the impact of two factors: genre of reference corpora and the characteristics of item-types.", "sent2": "Experiments show that imposing these constraints allows important gains in accuracy, with regard to the most probable alignments predicted by the model.", "label": 0}
{"sent1": "To that end, we present results with the CoMiC-EN Content Assessment system (Meurers et al., 2011a) on the dataset published by Mohler et al.", "sent2": "(2011) and outline what was necessary to perform this comparison.", "label": 1}
{"sent1": "I explore the possibility of learning error correcting rules from the given manually annotated data using features such as word length and word endings only.", "sent2": "The training of the model is explained.", "label": 0}
{"sent1": "The Support Vector Machine algorithm achieved an accuracy of 98% for 90 languages and the YALI algorithm based on a scoring function had an accuracy of 95.4%.", "sent2": "In order to isolate the impact of individual factors, 5 different algorithms and 3 different number of languages are used.", "label": 1}
{"sent1": "?ve Bayes (NB) classifiers and develop one model which maximizes precision.", "sent2": "Our systems focused on using a simple set of features, featuring a mix of semantic similarity resources, lexical match heuristics, and part of speech (POS) information.", "label": 0}
{"sent1": "But in order for the evaluation to be meaningful, the rankings obtained from human assessment must be consistent and repeatable.", "sent2": "It is, thus, applicable to any kind of machine translation system.", "label": 0}
{"sent1": "A set of classification problems commonly seen in a text stream is stored to reuse the classification results, while the set size is controlled by removing the least-frequently-used or least-recently-used classification problems.", "sent2": "The key idea behind the classifier is to reuse results for past classification problems to solve forthcoming classification problems.", "label": 1}
{"sent1": "In this paper, we present a statistical implementation of the analysis-transfergeneration methodology in rule-based translation.", "sent2": "Understanding the correct meaning of a syntactic form is of great importance to many NLP applications.", "label": 0}
{"sent1": "Evaluation results in ROUGE metrics indicate the comparable performance between IPS and the best competing system but IPS produces summaries with much more user satisfaction according to evaluator ratings.", "sent2": "The second model captures correlations between events, while the third model ensures consistency between arguments of the same event.", "label": 0}
{"sent1": "Based on the translation probabilities between the words in descriptions and the tags estimated on a large set of description-tags pairs, we build a word trigger method (WTM) to suggest tags according to the words in a resource description.", "sent2": "We showed that our tagger reaches state-of-the-art results for French in the standard evaluation conditions (i.e.", "label": 0}
{"sent1": "We evaluate on two standard dialog resources, the Communicator and Let?s Go datasets, and demonstrate that our model has substantially better fit to held out data than competing approaches.", "sent2": "Our goals are latent, and take the form of topics in a topic model, clustering together semantically equivalent and phonetically confusable strings, implicitly modelling synonymy and speech recognition noise.", "label": 1}
{"sent1": "Spectral methods are attractive as they provide globally consistent estimates of the model parameters and are very fast and scalable, unlike EM methods, which can get stuck in local minima.", "sent2": "Our submission achieved the 4th position out of 19 participating systems.", "label": 0}
{"sent1": "However, due to the diversity and uneven distribution of source sentences, there are two problems suffered by this method.", "sent2": "First, its performance is highly dependent on the choice of a development set, which may lead to an unstable performance for testing.", "label": 1}
{"sent1": "Compared with the traditional approaches which utilize the first pass translation hypotheses, cross-lingual data selection model avoids the problem of noisy proliferation.", "sent2": "Given a source sentence in the translation task, this model directly estimates the probability that a sentence in the target LM training corpus is similar.", "label": 1}
{"sent1": "discourse structure as a useful information source.", "sent2": "Cognitive linguistics has reached a stage of maturity where many researchers are looking for an explicit formal grounding of their work.", "label": 0}
{"sent1": "Due to the presence of this quasi-standard, the question of to which degree parsing results depend on the properties of treebanks was often ignored.", "sent2": "In this paper, we use two similar German treebanks, Tu?Ba-D/Z and NeGra, and investigate the role that different annotation decisions play for parsing.", "label": 1}
{"sent1": "This fact is exploited by word sense disambiguation (WSD) systems which back off to the predominant sense of a word when contextual clues are not strong enough.", "sent2": "The domain of a document has a strong influence on the sense distribution of words, but it is not feasible to produce large manually annotated corpora for every domain of interest.", "label": 1}
{"sent1": "We describe 10 sketch methods, including existing and novel variants.", "sent2": "of frequency distributions.", "label": 1}
{"sent1": "We evaluate performance on two opinion extraction tasks, and, in contrast to previous sequence labeling approaches to the task, explore the usefulness of segmentlevel syntactic parse features.", "sent2": "We extend the original semi-CRF model (Sarawagi and Cohen, 2004) to allow the modeling of arbitrarily long expressions while accounting for their likely syntactic structure when modeling segment boundaries.", "label": 1}
{"sent1": "We propose a method for learning normalization rules from machine translations of a parallel corpus of microblog messages.", "sent2": "can improve performance.", "label": 1}
{"sent1": "for predicting word associations.", "sent2": "We discuss how the approach can be built into dictionary interfaces to help tip-of-the-tongue searches.", "label": 1}
{"sent1": "Only some of the automated summarization methods proposed in the literature, however, can be defined as ?languageindependent?, as they are not based on any morphological analysis of the summarized text.", "sent2": "The framework leverages features in letteralignment and letter n-gram pairs learned from available bilingual dictionaries.", "label": 0}
{"sent1": "Results using multiple assisting languages are mixed and it helps in boosting MultiPRF accuracy only in some cases.", "sent2": "In addition, we present plans for a more cognitively sound sequential model, taking into consideration a larger set of basic emotions.", "label": 0}
{"sent1": "Unlike the conventional HMM, the number of hidden states is not fixed and will be increased to fit the training data.", "sent2": "In favor of sparse distribution, the Dirichlet priors are introduced with variational inference method.", "label": 1}
{"sent1": "The average value of the representative  topic sentiment sentences is calculated  and taken as the sentiment polarity of a  review.", "sent2": "Our experiments show that a significant proportion of errors can be detected by the two methods.", "label": 0}
{"sent1": "A head-driven phrase structure grammar (HPSG) parser is used to obtain the deep syntactic information, which includes a fine-grained description of the syntactic property and a semantic representation of a sentence.", "sent2": "In this paper, we propose to use deep syntactic information for obtaining fine-grained translation rules.", "label": 1}
{"sent1": "We also test a string edit distance based method.", "sent2": "The model is trained using a parallel text of closed caption and automatic speech recognition output.", "label": 1}
{"sent1": "We demonstrate the effectiveness of the method using a CCG supertagger and parser, obtaining significant speed increases on newspaper text with no loss in accuracy.", "sent2": "Most methods extract keyphrases according to their statistical properties in the given document.", "label": 0}
{"sent1": "Experimental results show that our proposed methods improve considerably the learning curve of Japanese dependency parsing.", "sent2": "However, dealing with Swiss German in natural language processing, usually the detour through Standard German is taken.", "label": 0}
{"sent1": "We create new training sets for English and Dutch from the CELEX European lexical resource, and achieve error rates for English of less than 0.1% for correctly allowed hyphens, and less than 0.01% for Dutch.", "sent2": "Experiments show that both the Knuth/Liang method and a leading current commercial alternative have error rates several times higher for both languages.", "label": 1}
{"sent1": "We employ two algorithms which come from a family of generative probabilistic models.", "sent2": "This redundancy leads to misrepresentation of tree weight and reduced information for debugging and tuning purposes.", "label": 0}
{"sent1": "We use near state-of-the-art supervised baselines, and find that each of the three word representations improves the accuracy of these baselines.", "sent2": "We evaluate Brown clusters, Collobert and Weston (2008) embeddings, and HLBL (Mnih & Hinton, 2009) embeddings of words on both NER and chunking.", "label": 1}
{"sent1": "It has applications in text classification, text filtering, analysis of product review, analysis of responses to surveys, and mining online discussions.", "sent2": "We expect further improvement with additional data, features, and classification techniques.", "label": 0}
{"sent1": "We compare LDA-SP to several state-ofthe-art methods achieving an 85% increase in recall at 0.9 precision over mutual information (Erk, 2007).", "sent2": "We also evaluate LDA-SP?s effectiveness at filtering improper applications of inference rules, where we show substantial improvement over Pantel et al?s system (Pantel et al, 2007).", "label": 1}
{"sent1": "node, and negative training data to learn the conditional probabilities for the observed child.", "sent2": "Thus, we define syntactic and semantic structures representing the text pairs and then apply graph and tree kernels to them for automatically engineering features in Support Vector Machines.", "label": 0}
{"sent1": "This paper studies two main aspects of pseudoword creation that affect performance results.", "sent2": "(1) Pseudo-word evaluations often evaluate only a subset of the words.", "label": 1}
{"sent1": "We incrementally explore capturing various syntactic substructures as complex tags on the English side, and evaluate how our translations improve in BLEU scores.", "sent2": "Our maximal set of source and target side transformations, coupled with some additional techniques, provide an 39% relative improvement from a baseline 17.08 to 23.78 BLEU, all averaged over 10 training and test sets.", "label": 1}
{"sent1": "We use transliteration as a tool for disambiguation of Hindi homonyms which can be both translated or transliterated or transliterated differently based on different contexts.", "sent2": "Different studies have been conducted for  predicting human brain activity associated  with the semantics of nouns.", "label": 0}
{"sent1": "Most approaches report problems with overfitting.", "sent2": "In particular, FactChecker makes use of linguistic features to detect if a given source objectively states facts or is speculative and opinionated.", "label": 0}
{"sent1": "Viterbi decoding is, however, prohibitively slow when the label set is large, because its time complexity is quadratic in the number of labels.", "sent2": "The Viterbi algorithm is the conventional decoding algorithm most widely adopted for sequence labeling.", "label": 1}
{"sent1": "Even for the simple linearchain model, taking structure into account implies a number of parameters and a computational effort that grows quadratically with the cardinality of the label set.", "sent2": "Experimental results show a significant and consistent BLEU improvement of approximately 1 point for all conditions.", "label": 0}
{"sent1": "We train and test linguistic quality models on consecutive years of NIST evaluation data in order to show the generality of results.", "sent2": "Online news editors ask themselves the same question many times: what is missing in this news article to go online?", "label": 0}
{"sent1": "We model the sentences in an article and their lexical similarities as a Markov Random Field tuned to detect the patterns that context data create, and employ a Belief Propagation mechanism to detect likely context sentences.", "sent2": "In this paper, we propose a general framework based on probabilistic inference to extract such context information from scientific papers.", "label": 1}
{"sent1": "Using an integer linear programming formulation, the model learns to select and combine phrases subject to length, coverage and grammar constraints.", "sent2": "We apply a Markov random walk model to a large word relatedness graph, producing a polarity estimate for any given word.", "label": 0}
{"sent1": "The system performs a two stage graph based clustering where a cooccurrence graph is first clustered to compute similarities against contexts.", "sent2": "The algorithm outperforms the well-known Incremental Algorithm (Dale and Reiter, 1995) and the GraphBased Algorithm (Krahmer et al., 2003; Viethen et al., 2008) across a variety of images in two domains.", "label": 0}
{"sent1": "We also compare with our own prosody-based model, and show that our HBM is competitive even without the use of prosody.", "sent2": "We integrate our proposed model into a state-of-the-art translation system and demonstrate the efficacy of our proposal in a largescale Chinese-to-English translation task.", "label": 0}
{"sent1": "relational pattern discovery and ?bottom-up?", "sent2": "relation extraction.", "label": 1}
{"sent1": "We evaluate the Tag&Parse approach on a corpus of Robotic Spatial Commands as part of the SemEval Task6 exercise.", "sent2": "Each stage produces multiple hypotheses which are re-ranked using spatial validation.", "label": 1}
{"sent1": "Paraphrase acquisition is a fundamental task in the emerging area of text mining for software engineering.", "sent2": "The second measures the similarity between the source query and each target query, and then combines these fine-grained similarity values for its importance estimation.", "label": 0}
{"sent1": "Distractors are of low value and seem to be replaceable by generic noise to improve threshold calculation.", "sent2": "Furthermore, new ways to flexibly calculate thresholds could be identified.", "label": 1}
{"sent1": "Structured Vector Space (SVS) (Erk and Pad?, 2008) is a model that computes word meaning in context in order to assess the appropriateness of such paraphrases.", "sent2": "This paper investigates ?best-practice?", "label": 1}
{"sent1": "VNC tokens are classified as either idiomatic or literal.", "sent2": "We focus our study on Verb-Noun Constructions (VNC) that vary in their idiomaticity depending on context.", "label": 1}
{"sent1": "produce translations can be manually postedited with an increase in productivity.", "sent2": "Automatic post-editing (APE) systems aim at correcting the output of machine translation systems to produce better quality translations, i.e.", "label": 1}
{"sent1": "This way, our novel algorithm avoids any document-level prefiltering step.", "sent2": "A beam-search algorithm is used to abandon target sentences as non-parallel early on during classification if they fall outside the beam.", "label": 1}
{"sent1": "First, we propose a method of parse hybridization that recombines context-free productions instead of constituents, thereby preserving the structure of the output of the individual parsers to a greater extent.", "sent2": "or ?align?", "label": 0}
{"sent1": "The target application is a sign dictionary where precision is more important than recall.", "sent2": "The STD system described in this paper indexes word-level lattices produced by an LVCSR system using Weighted Finite State Transducers (WFSTs).", "label": 1}
{"sent1": "Finally the full-name and abbreviation co-occurrence information from a web search engine is utilized to further improve the performance.", "sent2": "Our model is inspired by theories of local coherence and formulated within the framework of Integer Linear Programming.", "label": 0}
{"sent1": "It also explores the trade-off between search accuracy and the speed of audio transcription.", "sent2": "Motivated by the requirement for high-quality indexes, this study explores the effect of using both word and sub-word information to find in-vocabulary and OOV query terms.", "label": 1}
{"sent1": "Experimental results show that the proposed method leads to significantly better translation quality than existing methods.", "sent2": "Our algorithm explicitly maximizes the effectiveness function with greedy search for phrase table training or synchronized grammar extraction.", "label": 1}
{"sent1": "I also describe some of the ways in which probabilistic models are starting to have a significant impact on psycholinguistics and language acquisition.", "sent2": "We show several procedures that enable evaluating the quality of a translated sentence more appropriately than using conventional methods.", "label": 0}
{"sent1": "tolerance ?", "sent2": "This paper classifies the scored dependency graphs and discusses the specific features of the ?Dependency Forest?", "label": 0}
{"sent1": "The automatically learnt mapping, which we call MapNet, can be used 1) to extend frame sets in the English FrameNet, 2) to populate frame sets in the Italian FrameNet via MultiWordNet and 3) to add frame labels to the MultiSemCor corpus.", "sent2": "Trained under a discriminative setting, our model is able to incorporate a rich set of features where certain unbounded long-distance dependencies can be captured in a principled manner.", "label": 0}
{"sent1": "The parser?s high performance indicates that its latent variables succeeded in inducing effective features.", "sent2": "In our system, we implement mention detection and coreference resolution seperately.", "label": 0}
{"sent1": "et al, 2009).", "sent2": "This paper describes our contribution to the semantic role labeling task (SRL-only) of the CoNLL-2009 shared task in the closed challenge (Hajic?", "label": 1}
{"sent1": "Our system uses rich features and incorporates various integration technologies.", "sent2": "This paper describes our system about multilingual syntactic and semantic dependency parsing for our participation in the joint task of CoNLL-2009 shared tasks.", "label": 1}
{"sent1": "The parser is coupled with an on-line averaged perceptron (Collins, 2002) as the learning method.", "sent2": "We extend their analysis to all of the ranking tasks from 2010 and 2011, and show through an extension of their reasoning that the ranking is naturally cast as an instance of finding the minimum feedback arc set in a tournament, a wellknown NP-complete problem.", "label": 0}
{"sent1": "An analysis of learning rates and of the reliance on syntactic parsing quality shows that only modest improvements could be expected for most languages given more training data; Better syntactic parsing quality, on the other hand, could greatly improve the results.", "sent2": "This work is concerned with the space of alignments searched by word alignment systems.", "label": 0}
{"sent1": "For semantic parsing and predicate classifying, we focus on finding optimized features on multiple languages.", "sent2": "For the case where the predicted sequences come from a closed set, we show that a globally conditioned model alleviates the above problems of encoder-decoder models.", "label": 0}
{"sent1": "This paper proposes a method for dependency parsing of Japanese monologues based on sentence segmentation.", "sent2": "In this method, the dependency parsing is executed in two stages: at the clause level and the sentence level.", "label": 1}
{"sent1": "The parser is an unlexicalized PCFG parser which is guaranteed to return the most probable parse.", "sent2": "The grammar is extracted from a version of the PENN treebank which was automatically annotated with features in the style of Klein and Manning (2003).", "label": 1}
{"sent1": "Models derived from data are generally more robust than hand-crafted systems since they better reflect the distribution of the phenomena being modeled.", "sent2": "Data-driven techniques have been used for many computational linguistics tasks.", "label": 1}
{"sent1": "In the standard Penn Treebank setup, our novel features improve attachment score form 91.4% to 92.9%, giving the best results so far for transitionbased parsing and rivaling the best results overall.", "sent2": "For the Chinese Treebank, they give a signficant improvement of the state of the art.", "label": 1}
{"sent1": "Our approach is based on extending the minimum entropy regularization framework to the structured prediction case, yielding a training objective that combines unlabeled conditional entropy with labeled conditional likelihood.", "sent2": "We describe new approaches for improving the accuracy of manual annotation of three discourse connectives (two English, one French) by using parallel corpora.", "label": 0}
{"sent1": "Specifically focusing on sequential segmentation tasks, i.e.", "sent2": "The results also show that the extracted paraphrases can be used to generate high-quality paraphrase patterns.", "label": 0}
{"sent1": "syntactic variety, or the use of various structures in the arrangement of phases, clauses, and sentences, (2) organization ?", "sent2": "This motivated us to work on an approach to change this manual procedure for an automatic one.", "label": 0}
{"sent1": "First, it learns decision lists from training data generated automatically to distinguish mass and count nouns.", "sent2": "This paper proposes a method for detecting errors in article usage and singular plural usage based on the mass count distinction.", "label": 1}
{"sent1": "We propose a novel unsupervised method for learning such mappings from user reviews in the target domain, and test it on restaurant reviews.", "sent2": "So we developed a system, SEGAPSITH, that acquires it automatically from text segments by using an unsupervised and incremental clustering method.", "label": 0}
{"sent1": "We present a method where such individual aspects are learned separately from data (without any hand-engineering) but optimized jointly using an integer linear programme.", "sent2": "opinions on the important aspects greatly influence their overall opinions on the product.", "label": 0}
{"sent1": "However, most of current Statistical Machine Translation (SMT) systems mainly depend on translation model and language model.", "sent2": "The proposed explanation is that the features used are more appropriate to text with strong editorial standards than the informal writing style of blogs.", "label": 0}
{"sent1": "Moreover, combining the small bi-text with the adapted bi-text outperforms the corresponding combinations with the unadapted bi-text by 1.5?", "sent2": "We first present our corpus, which has been annotated with respect to student correctness and uncertainty.", "label": 0}
{"sent1": "What will be the consequences of a new syntactic rules addition?", "sent2": "Given a dictionary of 110k lemmas, a few hundred syntactic analysis rules, 20k ngrams matrices and other resources, what will be the impact on a syntactic analyzer of adding a new possible category to a given verb?", "label": 1}
{"sent1": "While projectivity is generally taken to be too restrictive for natural language syntax, it is not clear which of the other proposals strikes the best balance between expressivity and complexity.", "sent2": "In dependency-based parsing, several constraints have been proposed that restrict the class of permissible structures, such as projectivity, planarity, multi-planarity, well-nestedness, gap degree, and edge degree.", "label": 1}
{"sent1": "Our experiments also show that current technology for extracting subcategorization frames initially designed for written texts works equally well for spoken language.", "sent2": "In this setting, the system is trained using labeled examples in a source language (e.g.", "label": 0}
{"sent1": "questions, a new class complex information needs formally introduced in TREC 2005.", "sent2": "Our experiments clearly show that CR-oriented features yield strongest performance exceeding a strong baseline.", "label": 0}
{"sent1": "We hypothesise that there exists a directly proportional relation between the frequency of POS blocks and their content salience.", "sent2": "We also hypothesise that the class membership of the parts of speech within such blocks reflects the content load of the blocks, on the basis that open class parts of speech are more content-bearing than closed class parts of speech.", "label": 1}
{"sent1": "In contrast, fluency-oriented metrics such as ROUGE-W compute longest common subsequences, but ignore words not aligned by the LCS.", "sent2": "Adequacy-oriented metrics such as BLEU measure n-gram overlap of MT outputs and their references, but do not represent sentence-level information.", "label": 1}
{"sent1": "This paper proposes a method for reinforcing countability prediction by introducing a novel concept called one countability per discourse.", "sent2": "It especially plays an important role in machine translation since it determines the range of possible determiners.", "label": 1}
{"sent1": "Based on the list of the expanded forms and their likelihood scores, the proposed algorithm determines the final acronym-definition pairs.", "sent2": "However, solving this problem exactly using an integer programming formulation is intractable for practical purposes.", "label": 0}
{"sent1": "The results obtained indicate that regardless of any additional complexity VPCs feature widely in children data following closely adult usage.", "sent2": "Studies like these can inform the development of computational models for language acquisition.", "label": 1}
{"sent1": "Thus, the selection of words to represent Chinese text is of vital importance to the success of the Chinese novelty mining.", "sent2": "Then, these objects of interest are processed in order to be labelled, and the related frames are thus annotated with the corresponding semantic content.", "label": 0}
{"sent1": "The approach relies on standard dynamic-programming algorithms as oracle solvers for sub-problems, together with a simple method for forcing agreement between the different oracles.", "sent2": "The approach provably solves a linear programming (LP) relaxation of the global inference problem.", "label": 1}
{"sent1": "We show that increasing the quality of the automatically parsed data used for self-training gives higher accuracy self-trained grammars.", "sent2": "Our generative self-trained grammars reach F scores of 91.6 on the WSJ test set and surpass even discriminative reranking systems without selftraining.", "label": 1}
{"sent1": "Using a linear-chain conditional random field, we improve parsing accuracy over the generative baseline parser on the Penn Treebank WSJ corpus, rivalling a similar model that does not make use of context.", "sent2": "We propose a novel text normalization model based on learning edit operations from labeled data while incorporating features induced from unlabeled data via character-level neural text embeddings.", "label": 0}
{"sent1": "and preliminary results suggest its metric is competitive with other standard metrics (Topic Coherence).", "sent2": "In the era of social media, a big challenge is that parsers trained on traditional newswire corpora typically suffer from the domain mismatch issue, and thus perform poorly on social media data.", "label": 0}
{"sent1": "We identify subgroups of character n-grams that correspond to linguistic aspects commonly claimed to be covered by these features: morphosyntax, thematic content and style.", "sent2": "Character n-grams have been identified as the most successful feature in both singledomain and cross-domain Authorship Attribution (AA), but the reasons for their discriminative value were not fully understood.", "label": 1}
{"sent1": "In addition to a straightforward adaptation of CNN from image to text, a simple but new variation which employs bag-ofword conversion in the convolution layer is proposed.", "sent2": "Instead of using low-dimensional word vectors as input as is often done, we directly apply CNN to high-dimensional text data, which leads to directly learning embedding of small text regions for use in classification.", "label": 1}
{"sent1": "We propose an alternative algorithm that constructs output structures from left to right using beam-search.", "sent2": "for computing the optimum dependency tree from a DF.", "label": 0}
{"sent1": "without human-labelled data.", "sent2": "This algorithm was tested using a ?leaveone-out?", "label": 0}
{"sent1": "We show wine experts are capable of describing their smell and flavor experiences in wine reviews in a sufficiently consistent manner, such that we can use their descriptions to predict properties of a wine based solely on language.", "sent2": "wine reviews.", "label": 1}
{"sent1": "These two algorithms are applied to sentence- and document-level cross lingual opinion analysis tasks, respectively.", "sent2": "Alternatively, starting only from the training data in target language, the Transfer Self-training algorithm is designed to iteratively select high quality translated examples to enrich the training data set.", "label": 1}
{"sent1": "For generating a wider variety of phrasal paraphrases in Japanese, it is necessary to paraphrase functional expressions as well as content expressions.", "sent2": "A maximum entropy classi\fer can be used to extract sentences from documents.", "label": 0}
{"sent1": "We used various methods of passage retrieval for the system.", "sent2": "We constructed a system for answering nonfactoid Japanese questions.", "label": 1}
{"sent1": "The proposed method can be considered as exploiting the SMT-based passage retrieval for CLQA task.", "sent2": "We applied our method to the English-toJapanese CLQA system and evaluated the performance by using NTCIR CLQA 1 and 2 test collections.", "label": 1}
{"sent1": "We show that allowing only grammatically related words to influence each other?s senses leads to disambiguation results on a par with the best graph-based systems, while greatly reducing the computation load.", "sent2": "We also compare two methods for computing selectional preferences between the senses of every two grammatically related words: one using a Lesk-based measure on WordNet, the other using dependency relations from the British National Corpus.", "label": 1}
{"sent1": "The best classifier (based on Maximum Entropy) yields the promising accuracy of 60.1% in classifying 204 verbs to 17 Levin (1993) classes.", "sent2": "We evaluate this feature set using a set of supervised classifiers, most of which are new to the task.", "label": 1}
{"sent1": "We test the results against classification results obtained by converting the confidence scores into discrete labels.", "sent2": "Thus, the strength of sentiment is ignored.", "label": 1}
{"sent1": "where sentences are skipped during the first pass of reading, or through ?homing?", "sent2": "This they do either through ?anticipation?", "label": 1}
{"sent1": "landscapes of perceptions of social groups.", "sent2": "Thus, the method combines the benefits of both explicit and latent topic modelling approaches.", "label": 0}
{"sent1": "However, little has been done to adjust for the sampling bias inherent in this approach.", "sent2": "These insights help us develop features for a model to solve a new prediction task of practical importance: given a biased sentence, identify the bias-inducing word.", "label": 0}
{"sent1": "effect, i.e.", "sent2": "whether receiving products for free affect how consumer reviews are written.", "label": 1}
{"sent1": "We design a unified probabilistic graphical model to capture both topic-driven words and styledriven words.", "sent2": "We compare different ways of generating senses and assess the quality of the alignments relative to the IBM HMM model, as well as the generated sense probabilities, in order to gauge the usefulness in Word Sense Disambiguation.", "label": 0}
{"sent1": "We induce a transliteration model from parallel data and use it to translate OOV words.", "sent2": "Our approach is fully unsupervised and language independent.", "label": 1}
{"sent1": "Then, we propose a transition-based dependency parser that incorporates the predictions from a CRF-based supertagger as new features.", "sent2": "On standard English Penn Treebank corpus, we show that our supertag features achieve parsing improvements of 1.3% in unlabeled attachment, 2.07% root attachment, and 3.94% in complete tree accuracy.", "label": 1}
{"sent1": "In this paper, we explore a method of incorporating this information via Combinatory Categorial Grammar (CCG) categories from a supertagger.", "sent2": "Syntactic analysis of search queries is important for a variety of information-retrieval tasks; however, the lack of annotated data makes training query analysis models difficult.", "label": 0}
{"sent1": "We evaluate this scheme on the T?uBa-D/Z treebank w.r.t.", "sent2": "several metrics and show that it improves both parsing accuracy and parsing speed considerably.", "label": 1}
{"sent1": "Our approach is based on reranking N -best outputs from a state-of-the-art CSL parser.", "sent2": "This paper presents an empirical study on using syntactic and semantic information for Concept Segmentation and Labeling (CSL), a well-known component in spoken language understanding.", "label": 1}
{"sent1": "In this paper, we propose a novel method that extends the translation based model and incorporates the temporal and personal factors.", "sent2": "Experiments in two domains showed that the contextual role knowledge improved coreference performance, especially on pronouns.", "label": 0}
{"sent1": "Furthermore, we tackle the issues of rich Czech morphology by examining different preprocessing techniques.", "sent2": "Experiments show that our language-independent approach significantly outperforms adapted state-of-the-art methods in English (F-measure 0.947) and also represents a strong baseline for further research in Czech (F-measure 0.582).", "label": 1}
{"sent1": "To tackle this challenge, we incorporate multiple graphs probabilistic factorization with two alternatively designed combination strategies into collaborative topic regression (CTR).", "sent2": "The main challenge is how to exploit the shared information among multiple social graphs in a probabilistic framework.", "label": 1}
{"sent1": "The latter dataset in not only of unprecedented size, but also created by the large community of Wiktionary editors instead of expert annotators, making it an interesting subject of study in its own right as the first crowdsourced WSA dataset.", "sent2": "Additionally, we annotate a corpus of search queries with partof-speech tags, providing a resource for future work on syntactic query analysis.", "label": 0}
{"sent1": "To verify the effectiveness of the multi-view framework, we implemented an arc-standard transition-based dependency parser and added phrase structure features produced by the phrase structure view.", "sent2": "A combination of features of different levels of complexity and from different sentence representations, coupled with task-oriented feature pruning, gives the best performance.", "label": 0}
{"sent1": "We develop a set of derivational smoothing methods and evaluate them on two lexical semantics tasks in German.", "sent2": "without requiring training data).", "label": 0}
{"sent1": "Happily, an increasing amount of information and opinion exchange occur in natural dialogue in online forums, where people share their opinions about a vast range of topics.", "sent2": "This has impacted the dialogue research community?s ability to develop better theories, as well as good off-the-shelf tools for dialogue processing.", "label": 1}
{"sent1": "intent at sentence level using its dependency parse and sentiWordNet and to build the intention structure of the post to identify its stance.", "sent2": "To aid the task of classification, we define the health of the debate structure and show that maximizing its value leads to better stance classification accuracies.", "label": 1}
{"sent1": "These are integrated to complement each other and used as the final CM.", "sent2": "We also show that for an all words WSD task this automatic method is best focussed on words that are salient to the domain, and on words with a different acquired predominant sense in that domain compared to that acquired from a balanced corpus.", "label": 0}
{"sent1": "Humans and agents will need to make extra efforts by collaborating with each other to mediate a shared perceptual basis and to come to a mutual understanding of intended referents in the environment.", "sent2": "By dynamically training the QE model for the document-specific MT model, we are able to achieve consistency and prediction quality across multiple documents, demonstrated by the higher correlation coefficient and F-scores in finding Good sentences.", "label": 0}
{"sent1": "features were slightly more informative than ?classic?", "sent2": "formula; (2) ?non-classic?", "label": 1}
{"sent1": "Here, we experiment with two very different emotion lexicons and show that even in supervised settings, an affect lexicon can provide significant gains.", "sent2": "Some prior research finds no gain over and above what is obtained with ngram features?arguably the most widely used features in text classification.", "label": 1}
{"sent1": "Our event extraction is based on the system we recently proposed for mining relations and events involving genes or proteins in the biomedical literature using a novel, approximate subgraph matching-based approach.", "sent2": "Its simple programming model hides system-level details from the developer, and its ability to run on commodity hardware puts cluster computing within the reach of many academic research groups.", "label": 0}
{"sent1": "We use  dictionary and support vector machine classifier to detect event triggers.", "sent2": "There are three main  stages in model: Pre-processing, trigger detection and biomedical  event  detection.", "label": 1}
{"sent1": "We find that this optimisation improves the performance of our approach.", "sent2": "We present three approaches for unsupervised grammar induction that are sensitive to data complexity and apply them to Klein and Manning?s Dependency Model with Valence.", "label": 0}
{"sent1": "In previous work (Ma et al., 2012), we suggested that the fine-grained assessment task can be approached using a ranking methodology, and incorporating features that correspond to the visual layout of the page improves performance.", "sent2": "For translation into English, a loss due to cross-translation is about 13% of BLEU and for the other translation direction about 15%.", "label": 0}
{"sent1": "However, in many real situations, especially in communications between humans and mobile robots, the misunderstandings manifest themselves not only through utterances but also through physical actions performed by the participants.", "sent2": "In this paper, we focus on action corrections and propose a classification of such utterances into Omission, Commission, and Degree corrections.", "label": 1}
{"sent1": "Two experimental studies are reported in this paper.", "sent2": "For the actual test case of a domain-dependent review, the review?s rating is predicted by aggregating the scores of all opinions in the review and combining it with a domaindependent unigram model.", "label": 0}
{"sent1": "We ran experiments on short video samples involving 30 signers (about 6 hours in total).", "sent2": "Using leave-one-signer-out cross-validation, our evaluation shows an average best accuracy of 84%.", "label": 1}
{"sent1": "Typically, these are annotations for non-sequential classification tasks.", "sent2": "While there has been some work on crowdsourcing named entity annotations, researchers have largely assumed that syntactic tasks such as part-of-speech (POS) tagging cannot be crowdsourced.", "label": 1}
{"sent1": "Our lexicons have a polarity agreement of 95.7% with published lexicons, while achieving an overall coverage of 45.2%.", "sent2": "We find that models using part-of-speech tags, context-free grammar production rules and function words are highly effective, achieving a maximum accuracy of 71% .", "label": 0}
{"sent1": "We address these questions in the context of a subjective semantic task.", "sent2": "What should be done with them when building supervised machine learning systems?", "label": 1}
{"sent1": "However, empirical investigations to date have focused on a small number of verbs.", "sent2": "If true, this fact would have striking implications for theories and models of language acquisition, as well as numerous applications in natural language processing.", "label": 1}
{"sent1": "a sentence or a paragraph which best describes its contents.", "sent2": "While prior work reported that log-linear interpolation yields lower perplexity than linear interpolation, normalizing at query time was impractical.", "label": 0}
{"sent1": "In this contribution we introduce a novel model which captures latent cultural dimensions through an individual?s expressions of intentionality.", "sent2": "To this end, we develop classifiers for opinion detection in these languages, and further classifying opinionated tweets into positive, negative and neutral sentiments.", "label": 0}
{"sent1": "Such tweets are relevant to a given query but do not explicitly contain the term.", "sent2": "We evaluated the performance of SVM classifiers on the task of identifying 12 types of named entities using a combination of textual and visual features.", "label": 0}
{"sent1": "For the SSTb corpus, our approach achieves state-of-the-art results for single sentence sentiment prediction in both binary positive/negative classification, with 85.7% accuracy, and fine-grained classification, with 48.3% accuracy.", "sent2": "We apply our approach for two corpora of two different domains: the Stanford Sentiment Treebank (SSTb), which contains sentences from movie reviews; and the Stanford Twitter Sentiment corpus (STS), which contains Twitter messages.", "label": 1}
{"sent1": "We derive an efficient algorithm for learning the factorization, analyze its complexity, and provide proof of convergence.", "sent2": "This paper also describes the possible applications of the parallel corpus and proposes a new framework to aid in translation.", "label": 0}
{"sent1": "In this paper we model the spatial relationships between image regions using Visual Dependency Representations, a structured image representation that makes it possible to distinguish between object co-occurrence and interaction.", "sent2": "Overall, spatial information is shown to be central to narrative discourse structure and prediction tasks.", "label": 0}
{"sent1": "A portion of these queries is not well served by the search engine because there is a mismatch between the query terms, and the terms representing the local business entity in the index.", "sent2": "Business entities are frequently represented by their name, the category of entity (whether it is a restaurant, an airport, a grocery store, etc.)", "label": 1}
{"sent1": "Particularly, we introduce the morphological knowledge as both additional input representation and auxiliary supervision to the neural network framework.", "sent2": "In this paper, we propose to leverage morphological knowledge to address this problem.", "label": 1}
{"sent1": "It is necessary to remove these disfluencies before processing downstream tasks.", "sent2": "Automatic speech recognition (ASR) outputs often contain various disfluencies.", "label": 1}
{"sent1": "a core component of tweet information extraction, which aims to identify and link name mentions to entities in a knowledge base.", "sent2": "We apply S-MART to the task of tweet entity linking ?", "label": 1}
{"sent1": "We implement the model within an interactive question answering system simulating real estate dialogue.", "sent2": "A commonly-adopted framework generates structured review summaries with aspects and opinions.", "label": 0}
{"sent1": "In terms of achieving a human-like attribute selection, the overall performance of both algorithms is fundamentally equivalent, while differing in the handling of redundancy in selected attributes.", "sent2": "Various approaches have been formalized the problem as a sequence labelling task and utilize a character-based methodology, in which character is treated as the basic classification unit.", "label": 0}
{"sent1": "We use a large-margin framework to learn convex mixtures over the set of submodular components.", "sent2": "Detecting and removing such disfluencies can substantially improve the usefulness of spontaneous speech transcripts.", "label": 0}
{"sent1": "Already after the release of the gold standard annotations of the test data, we observed that using only the similarity measures without combining them with other features would have obtained positions 6th, 7th and 8th; moreover, an arithmetic average of these similarity measures would have been 4th(mean=0.5747).", "sent2": "This paper describes both the 3 systems as they were submitted and the similarity measures that would obtained those better results.", "label": 1}
{"sent1": "Using a core set of 11 lexical features of the most basic kind, it uses a support vector regressor which uses a combination of these lexical features to train a model for predicting similarity between sentences in a two phase method, which in turn uses all combinations of the features in the feature space and trains separate models based on each combination.", "sent2": "Most coreference resolution models determine if two mentions are coreferent using a single function over a set of constraints or features.", "label": 0}
{"sent1": "Our best system was ranked 17th out of 89 participating systems.", "sent2": "Relevant information is ubiquitous in web text, but extraction deems challenging.", "label": 0}
{"sent1": "To integrate more linguistics information, an n-gram language model as well as several post processing strategies are also employed.", "sent2": "The methods were found to be almost equal in the accuracy measured by Spearman correlation between the grades given by the system and a human.", "label": 0}
{"sent1": "It is shown that we can get the results just acceptable without using dictionary.", "sent2": "Statistical phrase-based translation learns translation rules from bilingual corpora, and has traditionally only used monolingual evidence to construct features that rescore existing translation candidates.", "label": 0}
{"sent1": "However, the rapid pace of biomedical research and the lack of constraints on usage ensure that such dictionaries are incomplete.", "sent2": "In our study, we found some strong reuse cases which can be an indicator to establish a clear policy to handle text reuse for the upcoming editions of ACL.", "label": 0}
{"sent1": "Our multi-layer generative approach uses both labeled and unlabeled utterances to jointly learn aspects regarding utterance?s target domain (e.g.", "sent2": "We describe a joint model for understanding user actions in natural language utterances.", "label": 1}
{"sent1": "It involves learning uncertain commonsense knowledge (in the form of probabilistic first-order rules) from natural language text by mining a large corpus of automatically extracted facts.", "sent2": "So, this paper presents the initial ideas of our work, the steps taken so far as well as some opportunities for collaboration.", "label": 0}
{"sent1": "These trees succinctly summarize the mentions providing a highly compact, information-rich structure for reasoning about entities and coreference uncertainty at massive scales.", "sent2": "In this paper we propose a novel stopping criterion for active learning of frame assignment based on the variability of the classifier?s confidence score on the unlabeled data.", "label": 0}
{"sent1": "The Aspect Term Polarity, Aspect Category and Aspect Category Polarity detection are tackled as a classification problem where multiple kernels are linearly combined to generalize several linguistic information.", "sent2": "We show a connection between the ITG constraints and the since 1870 known Schro?der numbers.", "label": 0}
{"sent1": "The opinion words related with an aspect are obtained using dependency relations.", "sent2": "For coreference resolution, we apply SVM by exploiting multiple syntactic and semantic features.", "label": 0}
{"sent1": "This paper performs an analysis of human annotated extractive summaries using the ICSI meeting corpus with an aim to examine their consistency and the factors impacting human agreement.", "sent2": "learning phase.", "label": 0}
{"sent1": "Having had its roots in the EU-funded project GEMINI, fundamental changes were necessary to adopt it to the requirements of the application environment.", "sent2": "At the same time it is guaranteed that only well-formed and well-defined constructs are used.", "label": 1}
{"sent1": "We propose a novel method to learn a user knowledge model from a review database.", "sent2": "This paper reports progress on a complete open-source software infrastructure supporting the rapid development of tools for transcribing and annotating time-series data.", "label": 0}
{"sent1": "This paper reports an experiment for examining the assumptions made by QACIAD.", "sent2": "It assumes that users interactively collect information using a QA system for writing a report on a given topic and evaluates, among other things, the capabilities needed under such circumstances.", "label": 1}
{"sent1": "Each important term is identified and classified into a biomedical concept class.", "sent2": "Since recent work has shown that minimizing the model size in a Hidden Markov Model for part-of-speech (POS) tagging leads to higher accuracies, we test our approach by applying it to this problem.", "label": 0}
{"sent1": "This paper addresses these aspects in the framework of the deployed France Telecom 3000 Voice Agency service.", "sent2": "We conclude that HMEANT is a step in the right direction, but has some serious flaws.", "label": 0}
{"sent1": "This paper presents a statistical unsupervised system, called BioNoculars, for extracting protein-protein interactions from biomedical text.", "sent2": "We evaluate this summarization system for relevant content selection using gold standard summaries prepared on principle based guidelines.", "label": 0}
{"sent1": "In the XLE parsing model which is a hand-crafted, unification-based parsing system, most of the time is spent on unification, searching for valid f-structures (dependency attributevalue matrices) within the space of the many valid c-structures (phrase structure trees).", "sent2": "Hindi and Urdu are two standardized registers of what has been called the Hindustani language, which belongs to the IndoAryan language family.", "label": 0}
{"sent1": "presently 14.", "sent2": "We applied our algorithm to two different domains; semantic similarity of documents collected from the Web, and phenotype descriptions in genomic data.", "label": 0}
{"sent1": "test data, the 1-gram baseline is outperformed by 60%; the improvement brought by the adaptation technique using a very small amount of matched BN data ?", "sent2": "Web interfaces also sidestep issues of platform dependency in software packages, available computer lab times, etc.", "label": 0}
{"sent1": "In addition to usual features for training in word sense disambiguation, our system also uses Base Level Concepts automatically obtained from WordNet.", "sent2": "Our empirical results have shown the probabilistic labeling approach significantly outperforms a previous graphmatching approach for referential grounding.", "label": 0}
{"sent1": "Here we explore such a method: we extract the predicate of simple, manuallydetected, claims, and attempt to generate novel claims from them.", "sent2": "The latter targets the exploration steps of imitation learning towards areas which are likely to provide the most information in the context of a large action-space.", "label": 0}
{"sent1": "We report small but significant improvements in recognition accuracies on a standard voice-search data set using our discriminative reranking model.", "sent2": "We propose an efficient and scalable MapReduce framework that uses a perceptron-style distributed training strategy to handle these large amounts of data.", "label": 1}
{"sent1": "parser ?", "sent2": "As part of three systems created for the task, we explore a simple bag of words tokenization scheme, a more careful tokenization scheme which captures named entities, times, dates, monetary entities etc., and finally try to capture context around tokens using grammatical dependencies.", "label": 0}
{"sent1": "We replace this intractable intersection by a tractable relaxation which incorporates a low-order upperbound on the language model.", "sent2": "The combinatorial space of translation derivations in phrase-based statistical machine translation is given by the intersection between a translation lattice and a target language model.", "label": 1}
{"sent1": "Our model leverages insights from discourse theory to constrain latent topic assignments in a way that reflects the underlying organization of document topics.", "sent2": "We propose a global model in which both topic selection and ordering are biased to be similar across a collection of related documents.", "label": 1}
{"sent1": "A major problem in this task is the high degree of lexical variation in documents which makes it very difficult to detect stories that talk about the same event but expressed using different words.", "sent2": "First story detection (FSD) involves identifying first stories about events from a continuous stream of documents.", "label": 1}
{"sent1": "Specifically, we develop a dedicated neural architecture and integrate the sentiment information of text (e.g.", "sent2": "Evaluation results on a collected dataset show that the overall system can achieve 85% accuracy using the top-3 results.", "label": 0}
{"sent1": "To tackle this relation extraction task, we employ a basic Support Vector Machine framework.", "sent2": "We discuss our findings in constructing local and contextual features, that augment our precision with as much as 7.5%.", "label": 1}
{"sent1": "We achieve CoNLL scores of 63.33 and 62.91 on the CoNLL-2012 DEV and TEST splits of the OntoNotes 5 corpus, beating the publicly available state of the art systems.", "sent2": "Additionally, our framework naturally lends itself to rich discourse modelling, which we use to define a series of psycholinguistically motivated features.", "label": 1}
{"sent1": "Like most existing approaches it utilizes clustering of word co-occurrences.", "sent2": "This paper proposes a new methodology to improve the accuracy of a term aggregation system using each author?s text as a coherent corpus.", "label": 0}
{"sent1": "The alignment information was manually checked using a graphical tool that allows the annotator to view a pair of trees from parallel sentences.", "sent2": "Despite this, the existing body of work is dominated by conservative methods with little (if any) attention paid to providing users with control over the behavior of stopping methods.", "label": 0}
{"sent1": "Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).", "sent2": "Some rights reserved.", "label": 1}
{"sent1": "On each successive iteration the algorithm selects new strong negative samples from the unlabeled class and retrains itself.", "sent2": "Due to the absence of real negative class samples, we employ the MC algorithm, in which training can be initiated with instances only from the positive class.", "label": 1}
{"sent1": "In the log-linear model, we incorporate as feature functions both rule-based intuitions and data co-occurrence phenomena (either as an explicit or indirect definition, or through formal/informal usages occurring in free variation in a discourse).", "sent2": "The growth of digital clinical data has raised questions as to how best to leverage this data to aid the world of healthcare.", "label": 0}
{"sent1": "Once the parameters of our model have been learned on bilingual parallel data, we evaluate its performance on a held-out monolingual test set.", "sent2": "Case structure and zero anaphora relation are simultaneously determined based on probabilistic evaluation metrics.", "label": 0}
{"sent1": "We explore different approaches to exploit existing resources for both languages that range from simple heuristics, to language identification, to machine learning.", "sent2": "In this paper, we use two similar German treebanks, Tu?Ba-D/Z and NeGra, and investigate the role that different annotation decisions play for parsing.", "label": 0}
{"sent1": "Although Bikel?s parser achieves a higher accuracy for parsing written language, it achieves a higher accuracy when extracting subcategorization cues from spoken language.", "sent2": "Distant supervision has become the leading method for training large-scale relation extractors, with nearly universal adoption in recent TAC knowledge-base population competitions.", "label": 0}
{"sent1": "In this paper, we describe some statistically and linguistically motivated methods for Arabic word segmentation.", "sent2": "The BioNLP?09 Shared Task on Event Extraction is a challenge which concerns the detection of bio-molecular events from text.", "label": 0}
{"sent1": "On the training corpus composed of query items, a ranking model is learned by a widely-used tool Ranking SVM, with some useful statistical features, such as mutual information, difference of t-test, frequency and dictionary information.", "sent2": "Experimental results show that, this method is able to eliminate overlapping ambiguity much more effectively, compared to the current word segmentation methods.", "label": 1}
{"sent1": "We evaluate our approach on morphological tasks and demonstrate that latent variables can dramatically improve results, even when trained on small data sets.", "sent2": "On the task of generating morphological forms, we outperform a baseline method reducing the error rate by up to 48%.", "label": 1}
{"sent1": "The MAP semantic parse of a sentence is obtained by recursively assigning its parts to lambda-form clusters and composing them.", "sent2": "The quality of the clusters is found to be sensitive to the inclusion of information about lexical heads of the constituents in the syntactic frames, as well as parameters of the clustering algorithm .", "label": 0}
{"sent1": "We use these similarities for different semi-supervised SRL methods as additional features or to automatically expand a small training set.", "sent2": "Intuitively, our method strives to ensure that probabilistic ?round-trip?", "label": 0}
{"sent1": "This second-order semiring is essential for many interesting training paradigms such as minimum risk, deterministic annealing, active learning, and semi-supervised learning, where gradient descent optimization requires computing the gradient of entropy or risk.", "sent2": "We then introduce a novel second-order expectation semiring, which computes second-order statistics (e.g., the variance of the hypothesis length or the gradient of entropy).", "label": 1}
{"sent1": "In particular, while word level models benefit greatly from re-estimation, phrase-level models do not: the crucial difference is that distinct word alignments cannot all be correct, while distinct segmentations can.", "sent2": "The performance gap stems primarily from the addition of a hidden segmentation variable, which increases the capacity for overfitting during maximum likelihood training with EM.", "label": 1}
{"sent1": "In both simulated and real user experiments on two sequence labeling tasks we show that our active learning method outperforms passive learning with features as well as traditional active learning with instances.", "sent2": "Preliminary experiments suggest that novel interfaces which intelligently solicit labels on multiple features facilitate more efficient annotation.", "label": 1}
{"sent1": "In particular, our mining algorithm selects the most relevant features based on SVM estimated weights and uses this information to automatically infer an explicit representation of the input data.", "sent2": "Experiments conducted on a real world Q&A collection show that substantial improvements in retrieval performance can be achieved by using compact translation models.", "label": 0}
{"sent1": "SVM-CW learns from one corpus, while using other corpora for support.", "sent2": "Our setup includes a preliminary screen output planning module, which prepares several versions of possible screen output.", "label": 0}
{"sent1": "We present a conditional random field (CRF) that aligns tokens of a given DB record and its realization in text.", "sent2": "Tests on factoid questions from TREC 2004 indicate that the algorithm improved the system performance by 2.4%.", "label": 0}
{"sent1": "We present results on both newspaper and biomedical corpora which contain nested named entities.", "sent2": "We find that the improvements range from 10 to 4%, depending on both the use of phonotactic cues and, to a lesser extent, the amount of evidence available to the learner.", "label": 0}
{"sent1": "Often, however, role fillers occur in clauses that are not directly linked to an event word.", "sent2": "Experimental results show that the model?s output is comparable to human-written highlights in terms of both grammaticality and content.", "label": 0}
{"sent1": "Thus, word order is the most important problem for distant language translation.", "sent2": "The API enables a variety of n-gram models to be easily combined and used in conjunction with appropriate edge pruning strategies.", "label": 0}
{"sent1": "We show that our approach provides a reliable relative correctness information as it outperforms other alternatives in ranking label-predictions according to their error.", "sent2": "In this sense, speech and language technology may provide important support in improving the recovery process.", "label": 0}
{"sent1": "either directly or in some converted manner ?", "sent2": "The top-performing systems in the BioNLP 2009 Shared Task on Event Extraction all shared the idea to use dependency structures generated by a variety of parsers ?", "label": 1}
{"sent1": "Specifically, we have designed and implemented a high-level language NERL on top of SystemT, a general-purpose algebraic information extraction system.", "sent2": "Motivated by these results, we explore the following natural question in this paper: Are rule-based systems still a viable approach to named-entity recognition?", "label": 1}
{"sent1": "For inference we run an efficient Gibbs sampler that leads to linear time joint inference.", "sent2": "We use distant supervision to train a factor graph model for relation extraction based on an existing knowledge base (Freebase, derived in parts from Wikipedia).", "label": 1}
{"sent1": "Furthermore, we investigate the performance of our CRF-based approach and the baseline in a single- and cross-domain opinion target extraction setting.", "sent2": "As this will still yield too many hits, I suggest to cluster and label the outputs.", "label": 0}
{"sent1": "This algorithm has been tested on different tasks involving different pair of languages.", "sent2": "This generalized model outperforms the multinomial model by 3.4% for CBF and 17.4% for CF in recommending English Wikipedia articles.", "label": 0}
{"sent1": "Unlike previous joint learning methods for the task, our approach (1) does not rely on gold standard sentence-level subjectivity annotations (which may be expensive to obtain), and (2) optimizes directly for document-level performance.", "sent2": "Empirical evaluations on movie reviews and U.S. Congressional floor debates show improved performance over previous approaches.", "label": 1}
{"sent1": "Here we specifically consider surprisal, a word?s predictability in context.", "sent2": "In order to build psycholinguistic models of processing difficulty and evaluate these models against human data, we need highly accurate language models.", "label": 1}
{"sent1": "In this paper, we describe two statistical measures for identifying portions to be confirmed.", "sent2": "A relevance score represents the matching degree with the target knowledge base.", "label": 1}
{"sent1": "In this paper, we introduce efficient methods for inferring large topic hierarchies.", "sent2": "topic models like LDA have difficulty modeling sparsely expressed topics, and richer hierarchical models become computationally intractable as the number of topics increases.", "label": 1}
{"sent1": "method where the parallel corpus is lemmatized before it is aligned by a phrase aligner, and then a ?deep?", "sent2": "We enhanced the rule set used by the original DEPFIX system and measured the performance of the individual rules.", "label": 0}
{"sent1": "They are unable to handle long-range syntactic movement, but tree acceptors and transducers address this weakness (Knight and Graehl, 2005).", "sent2": "They flexibly capture many kinds of stateful left-toright substitution, simple transducers can be composed into more complex ones, and they are EM- trainable.", "label": 1}
{"sent1": "the domain-specific resources, whereby some translation evaluation metrics outperformed the results of Google Translate.", "sent2": "Our system obtained an F-score of 11.03 on the official test set using the M2 evaluation method (the official evaluation method).", "label": 0}
{"sent1": "These search engines help to resolve questions on common prepositions following verbs, common synonyms in given contexts, and word order difficulties, to name only a few.", "sent2": "We show that our system outperforms a highlyoptimized attention-based seq2seq system and other baselines on three different sequence to sequence tasks: word ordering, parsing, and machine translation.", "label": 0}
{"sent1": "In this work we present an application of statistical machine translation to SMS messages.", "sent2": "Disambiguating named entities in naturallanguage text maps mentions of ambiguous names onto canonical entities like people or places, registered in a knowledge base such as DBpedia or YAGO.", "label": 0}
{"sent1": "In monologues, the biggest problem with dependency structure analysis is that sentence boundaries are ambiguous.", "sent2": "This paper describes a project to detect dependencies between Japanese phrasal units called bunsetsus, and sentence boundaries in a spontaneous speech corpus.", "label": 1}
{"sent1": "We are particularly interested in addressing the second problem and propose a sampling approach to handle the distribution mismatch.", "sent2": "There are two main challenges with distant supervision: (1) noise generated by incorrect heuristic labeling, and (2) distribution mismatch between the target and distant supervision examples.", "label": 1}
{"sent1": "words, between-subject correlation and similarity of texts.", "sent2": "Analysing the judgements shows that by relatively careful phrase-based paraphrasing our model achieves similar simplification results to state-of-the-art systems, while generating better formed output.", "label": 0}
{"sent1": "We have performed various experiments with a wide range of variables influencing the performance.", "sent2": "Our linguistically motivated approaches yield a relative error reduction of 18% in total over a stateof-the-art baseline.", "label": 0}
{"sent1": "The first method is used to detect any type of word segments.", "sent2": "The dataset records purchases of AAC technology by the UK?s National Health Service between 2006 and 2012; giving information for each item on: make, model, price, year of purchase, and geographic area of purchase.", "label": 0}
{"sent1": "The parameters of both algorithms and the selection of features are optimized per task with iterative deepening, an efficient wrapper procedure that uses progressive sampling of training data.", "sent2": "For the disorder mention extraction (Task A), the system was trained using Conditional Random Fields with features based on words, their POS tags and semantic types, as well as features based on MetaMap matches.", "label": 0}
{"sent1": "Thus, the proposed method is primarily based on the rules, and then the residual errors are corrected by adopting a memory-based machine learning method.", "sent2": "Further, we provide evidence that the model is an effective way to guide manual annotation to find +/-effect senses that are not in the seed set.", "label": 0}
{"sent1": "The use of supertags in NP chunking gives rise to almost \t\f\u000b absolute increase (from \u0002\u0004\u0003\u0006\u0005\u000e \u0010\u000f\u0010\u000b to \u0002\u0004\u0003\u0006\u0005\u0011\u0002\u0004\u0012\u0010\u000b ) in F-score under Transformation Based Learning(TBL) frame.", "sent2": "LAMBADA is a collection of narrative passages sharing the characteristic that human subjects are able to guess their last word if they are exposed to the whole passage, but not if they only see the last sentence preceding the target word.", "label": 0}
{"sent1": "We report experiences and evaluate the annotated data from the first project stage.", "sent2": "The backbone of the annotation are semantic roles in the frame semantics paradigm.", "label": 1}
{"sent1": "We evaluate the automatically generated orderings against authored texts from our corpus and against human subjects that are asked to mimic the model?s task.", "sent2": "We also assess the appropriateness of such a model for multidocument summarization.", "label": 1}
{"sent1": "Our feature-based algorithm combines knowledge about content using a text-based algorithm as a feature and about form using linguistic and acoustic cues about topic shifts extracted from speech.", "sent2": "This segmentation algorithm uses automatically induced decision rules to combine the different features.", "label": 1}
{"sent1": "This work is part of an ongoing project for an information extraction system in the field of maritime Search And Rescue (SAR).", "sent2": "Our purpose is to automatically annotate parts of texts with concepts from a SAR ontology.", "label": 1}
{"sent1": "In this paper, we propose an efficient method for implementing ngram models based on doublearray structures.", "sent2": "First, we propose a method for representing backwards suffix trees using double-array structures and demonstrate its efficiency.", "label": 1}
{"sent1": "The tool can be used to build classifier cascades that decomposes tweet streams, and provide analysis of targeted conversations.", "sent2": "A central concern is to provide an environment in which social science researchers can rapidly develop an informed sense of what the datasets look like.", "label": 1}
{"sent1": "The system allows domain experts to customise its lexical resources and to set parameters which influence syntactic constructions in generated sentences.", "sent2": "With more than 20 million citations in PubMed, text mining provides the ideal tool for generating additional large-scale homology-based predictions.", "label": 0}
{"sent1": "We establish a one-to-one correspondence between extensional models and RDF models such that satisfaction is preserved.", "sent2": "Our translation encompasses the expressivity of the target language and supports complex linguistic constructions like relative clauses and unbounded dependencies.", "label": 1}
{"sent1": "As these applications often search across different topical domains, such as maps, weather or Wikipedia, we discuss the problem of switching focus between different domains.", "sent2": "For the second method, we experimented with moderate-scale Chinese-English translation task.", "label": 0}
{"sent1": "Our best approach achieves a roughly ?15% absolute increase in F-score over a simple but reasonable baseline.", "sent2": "The user can issue translation requests from Arabic, Chinese or Spanish into English.", "label": 0}
{"sent1": "approach, assuming that morphological information has been separately obtained.", "sent2": "In this paper, we propose the first fully generative goal-driven simulator that is fully induced from data, without hand-crafting or goal annotation.", "label": 0}
{"sent1": "It relies on morpho-syntactic and lexical source-side information (part-of-speech, morphological segmentation) while learning a morpheme segmentation over the target language.", "sent2": "The model extends Hidden Semi-Markov chain models by using factored output nodes and special structures for its conditional probability distributions.", "label": 1}
{"sent1": "We conduct an extensive evaluation for article and preposition errors using various feature sets.", "sent2": "As part of our work, we introduce the NUS Corpus of Learner English (NUCLE), a fully annotated one million words corpus of learner English available for research purposes.", "label": 1}
{"sent1": "We conduct an extensive, fair comparison of four popular learning methods for the task, reversing conclusions from earlier evaluations.", "sent2": "Our results hold for different training sets, genres, and feature sets.", "label": 1}
{"sent1": "We show how to use the EM algorithm to learn the parameters of the noise model, using only a data set of erroneous sentences, given the proper language model.", "sent2": "We introduce a novel technique, based on a noisy channel model, which can utilize the whole sentence context to determine proper corrections.", "label": 1}
{"sent1": "Geolocation can be an effective means of summarizing large document collections and it is an important component of geographic information retrieval.", "sent2": "We describe several simple supervised methods for document geolocation using only the document?s raw text as evidence.", "label": 1}
{"sent1": "We also solve the standard IE task, using the induced syntactic patterns to extract role fillers from specific documents.", "sent2": "We evaluate on the MUC-4 terrorism dataset and show that we induce template structure very similar to handcreated gold structure, and we extract role fillers with an F1 score of .40, approaching the performance of algorithms that require full knowledge of the templates.", "label": 1}
{"sent1": "Our model assumes that coherent text implicitly favors certain types of discourse relation transitions.", "sent2": "We implement this model and apply it towards the text ordering ranking task, which aims to discern an original text from a permuted ordering of its sentences.", "label": 1}
{"sent1": "We extend a syntactic surface realisation system, which can be trained to choose among word order variants, such that the candidate set includes active and passive variants.", "sent2": "Leveraging the Posterior Regularization framework, we develop an architecture for incorporating biases into representation learning.", "label": 0}
{"sent1": "Training with the LRscore leads to output which is preferred by humans.", "sent2": "Moreover, the translations incur no penalty in terms of BLEU scores.", "label": 1}
{"sent1": "In this paper, first, we explain the design of the challenge.", "sent2": "RWTH participated in the System Combination task of the Sixth Workshop on Statistical Machine Translation (WMT 2011).", "label": 0}
{"sent1": "Our guiding principle is to employ a notion of ?meaningfulness?", "sent2": "that can be quantified information-theoretically, so that plausible variants of a lexicon can be judged relative to each other.", "label": 1}
{"sent1": "In this paper, we present a substantial extension to Levin?s taxonomy which incorporates 57 novel classes for verbs not covered (comprehensively) by Levin.", "sent2": "Then we apply two unsupervised clustering procedures to form meaningful clusters of such reciprocal instances.", "label": 0}
{"sent1": "relations that readers intuit in text.", "sent2": "For less than $350, we obtained over 5000 parallel segments in five language pairs.", "label": 0}
{"sent1": "Especially designed features are extracted automatically and used in a Support Vector Machine learning model.", "sent2": "In this paper, we explore an important step toward this generation task: training an LSTM (Longshort term memory) auto-encoder to preserve and reconstruct multi-sentence paragraphs.", "label": 0}
{"sent1": "The parameters of these models are tuned jointly via MTL so that they can learn general knowledge more accurately and exploit domain knowledge better.", "sent2": "In this paper, we propose a novel multi-domain adaptation approach for SMT using Multi-Task Learning (MTL), with in-domain models tailored for each specific domain and a general-domain model shared by different domains.", "label": 1}
{"sent1": "Summarizations of narratives, however, benefit from a simpler, linear ordering of events.", "sent2": "Events described in textual narratives do not always occur in neat, chronological order but occur, for example, during or overlapping each other or as simultaneous events.", "label": 1}
{"sent1": "lexical semantic representation.", "sent2": "This level is somewhat similar to results on lexical sample tasks with open class words, indicating that significant progress has been made.", "label": 0}
{"sent1": "We provide a detailed preliminary analysis of inter-annotator agreement ?", "sent2": "both the level of agreement and the types of inter-annotator variation.", "label": 1}
{"sent1": "By varying the mathematical content of the exercise, its narrative context and the linguistic parameter settings, many different exercises can be produced.", "sent2": "We believe that the methodology proposed in the paper can be applied to other social media domains and be used to test other linguistic or social theories.", "label": 0}
{"sent1": "We examine EI for this purpose.", "sent2": "As a complementary issue, we analyze the impact of the amount of in-domain data needed to improve a system trained entirely on out-of-domain data.", "label": 0}
{"sent1": "Syntactic and lexical features are used in this process without relying on any external resource apart from the information in the document.", "sent2": "We evaluated our system on two chapters of a standard biology textbook and presented the results.", "label": 1}
{"sent1": "We are interested in discovering effective tutoring strategies, that we frame as discovering which Dialogue Act (DA) sequences correlate with learning.", "sent2": "In particular, we focus on the cooking domain, where the instructions correspond to the recipe.", "label": 0}
{"sent1": "Although these measures depict the overall competence in the usage of language, they do not provide for an analysis of the grammatical mistakes made by the child.", "sent2": "In this paper, we explore the use of existing Natural Language Processing (NLP) techniques to provide an insight into the processing of child language transcripts and challenges in automatic grammar checking.", "label": 1}
{"sent1": "Since the proportion of NS responses and the features available to the model differ according to the item type, an item type specific model was trained for each item type.", "sent2": "The data were collected from non-native speakers in two different countries, using two different item types in the proficiency assessment: items that elicit spontaneous speech and items that elicit recited speech.", "label": 1}
{"sent1": "This makes the task more challenging, as the frequent pronunciation errors of non-native speakers may weaken the phonetic and phonotactic distinction between English responses and non-English responses.", "sent2": "Distributed word representations (word embeddings) have recently contributed to competitive performance in language modeling and several NLP tasks.", "label": 0}
{"sent1": "In a comparison to a stateof-the-art approach, we demonstrate slightly better detokenization error rates, without the need for any hand-crafted rules.", "sent2": "intuitions.", "label": 0}
{"sent1": "The supporting or opposing remarks are made by directly replying to the opinion, or indirectly to other remarks (to express local agreement or disagreement), which makes the task of identifying users?", "sent2": "In the past, the four tasks have been treated independently, using a wide variety of algorithms.", "label": 0}
{"sent1": "The theme of our approach is the integration of information from alternate data sources, other than parallel corpora, into the statistical model.", "sent2": "We also provide a mathematical model to predict the performance of the system.", "label": 0}
{"sent1": "Finally, we propose a refinement of our paraphrases by classifying them into natural logic entailment relations.", "sent2": "By extending the synchronous parsing paradigm towards these entailment relations, we will enable our system to perform recognition of textual entailment.", "label": 1}
{"sent1": "We argue that these approaches place unrealistic limits on the kinds of images that can be captioned, and are unlikely to produce captions which reflect human interpretations.", "sent2": "These systems require massive amounts of hand-labeled data for training, so the number of visual classes that can be recognized is typically very small.", "label": 1}
{"sent1": "Our algorithms select sentences for extraction.", "sent2": "The best set of parameters yields an F?=1 score of 0.501, compared to a random baseline with an F?=1 score of 0.37.", "label": 0}
{"sent1": "The method is independent from the graph representation formalism chosen.", "sent2": "Experimental evaluation has been performed on translation of technical manuals in three different language pairs.", "label": 0}
{"sent1": "We place this task in the semi-supervised setting and demonstrate that considering unlabeled reviews in the learning process can improve ratinginference performance.", "sent2": "This paper presents a negation detection system based on a conditional random field modeled using features from an English dependency parser.", "label": 0}
{"sent1": "A random walk model is applied on a graph encoding words and co-occurrence dependencies, resulting in scores that represent a quantification of how a particular word feature contributes to a given context.", "sent2": "To make ontologies accessible to human domain experts, several research groups have developed ontology verbalisers using Natural Language Generation.", "label": 0}
{"sent1": "The introduced technique models the problem as a discrete optimization task in a feature-rich space.", "sent2": "In this space the global optimum can be found in polynomial time by means of dynamic programming.", "label": 1}
{"sent1": "This is an incremental learning algorithm, in which previously processed pairs and user feedback guide the process.", "sent2": "We compared a number of metrics in our experiments, and the results show that the proposed metric has a higher mean average precision than other metrics.", "label": 0}
{"sent1": "Second, given that the empirical comparison among unsupervised systems (and with respect to supervised systems) is seldom made, we used hand-tagged corpora to map the induced senses to a standard lexicon (WordNet) and a publicly available gold standard (Senseval 3 English Lexical Sample).", "sent2": "In this paper we present a novel feature to enhance current attribution methods by analyzing the grammar of authors.", "label": 0}
{"sent1": "We develop two variants of our graphical method for comparing contexts.", "sent2": "Our analysis indicates that our method performs the comparison efficiently and offers a competitive alternative to non-graphical methods.", "label": 1}
{"sent1": "We show that a novel but simple feature embedding approach provides better performance, by exploiting the feature template structure common in NLP problems.", "sent2": "Second, unsupervised domain adaptation is typically treated as a task of moving from a single source to a single target domain.", "label": 1}
{"sent1": "The first applies graph smoothing as a postprocessing step to tease the vectors of different senses apart, and is applicable to any vector space model.", "sent2": "In this paper we propose two novel and general approaches for generating sense-specific word embeddings that are grounded in an ontology.", "label": 1}
{"sent1": "We present PERSONAGE (PERSONAlity GEnerator), the first highly parametrizable language generator for extraversion, an important aspect of personality.", "sent2": "A distinct line of research has explored methods for automatically generating language that varies along personality dimensions.", "label": 1}
{"sent1": "In contrast to existing algorithms for topic segmentation of speech, our approach does not require input transcripts.", "sent2": "Our method predicts topic changes by analyzing the distribution of reoccurring acoustic patterns in the speech signal corresponding to a single speaker.", "label": 1}
{"sent1": "We also consider (i) how to include approximate frequency information efficiently within a BF and (ii) how to reduce the error rate of these models by first checking for lower-order sub-sequences in candidate ngrams.", "sent2": "Our solutions in both cases retain the one-sided error guarantees of the BF while taking advantage of the Zipf-like distribution of word frequencies to reduce the space requirements.", "label": 1}
{"sent1": "On Chinese to English speech and text translation the proposed bLSA framework successfully reduced word perplexity of the English LM by over 27% for a unigram LM and up to 13.6% for a 4-gram LM.", "sent2": "Our experiments reveal several cognitively plausible DA sequences which significantly correlate with learning outcomes.", "label": 0}
{"sent1": "The patterns, however, are designed manually and thus are not necessarily the most effective ones in terms of accuracy and breadth.", "sent2": "To deal with this problem, in this paper we propose an approach that can automatically find the effective patterns for coreference resolution.", "label": 1}
{"sent1": "To generate a coherent table-of-contents, we need to capture both global dependencies across different titles in the table and local constraints within sections.", "sent2": "We conclude that the technique is completely automatable, uncovers missing sense distinctions and other bad semantic representations, and does scale well, performing at an accuracy of 69% for identifying bad representations.", "label": 0}
{"sent1": "In our evaluation, we include previously unreported measures taking into account levels of nodes in dependency trees.", "sent2": "We pursue an edge-based approach concentrating on properties of individual edges as opposed to properties of whole trees.", "label": 1}
{"sent1": "This is the first time that self-training with small labeled datasets is applied successfully to these tasks.", "sent2": "In particular, we achieve 50% reduction in annotation cost for the in-domain case, yielding an improvement of 66% over previous work, and a 20-33% reduction for the domain adaptation case.", "label": 1}
{"sent1": "The system has over the past years been developed to provide mainly OCR error post-correction, but can just as fruitfully be employed to automatically correct texts for spelling errors, or to transcribe texts in an older spelling into the modern variant of the language.", "sent2": "Our modifications entail augmenting the basic Lesk similarity measure with more relations based on the structure of WordNet, adding SemCor examples to the basic WordNet lexical resource and finally instead of using the LCH similarity measure for computing verb verb similarity in the In-Degree algorithm, we use JCN.", "label": 0}
{"sent1": "TweetGenie was able to attract thousands of visitors.", "sent2": "We opinion predictions to represent the discussion in one of two formal representations: signed attitude network or a space of attitude vectors.", "label": 0}
{"sent1": "We \frst describe our corpus, and give details on our procedure to label corrections and aware sites.", "sent2": "Both methods result in significant improvements over a competitive in-domain baseline applied to the Arabic-to-English task of IWSLT 2013.", "label": 0}
{"sent1": "In this paper, we apply for the first time an unsupervised cross-lingual WSD method to this task.", "sent2": "The proposed sets of translations may come from external resources or be extracted from textual data.", "label": 1}
{"sent1": "The suggested framework is evaluated for the task of disambiguating names in email documents.", "sent2": "The semantic relations are detected by checking selectional constraints.", "label": 0}
{"sent1": "We focus on the graph-tograph transformation that reduces the source semantic graph into a summary graph, making use of an existing AMR parser and assuming the eventual availability of an AMR-totext generator.", "sent2": "In this framework, the source text is parsed to a set of AMR graphs, the graphs are transformed into a summary graph, and then text is generated from the summary graph.", "label": 1}
{"sent1": "This simple ?vine grammar?", "sent2": "As an additional contribution, we make available to the research community the code and the search behavior data used in this study, with the hope of encouraging further research in this area.", "label": 0}
{"sent1": "Translation, re-ordering, and language models were estimated after translating in-domain texts with the baseline.", "sent2": "Unlike other, supervised or unsupervised, methods for keyphrase extraction our proposed methods utilizes both the document?s text and label information for the task of extracting label specific keyphrases.", "label": 0}
{"sent1": "Our system uses a tree-to-tree approach, employing syntactic dependency analysis for both source and target languages in an attempt to preserve non-local structure.", "sent2": "This work was done in the context of the SemEval-2014 task on supervised semantic parsing of spatial robot commands.", "label": 0}
{"sent1": "The number of participants was larger than in any previous biomedical challenge task.", "sent2": "We describe the data production process and the evaluation measures, and give a preliminary analysis of the results.", "label": 1}
{"sent1": "We find that ChineseEnglish word alignment performance is comparable to that of IBM Model-4 even over large training bitexts.", "sent2": "The models are formulated so that alignment and parameter estimation can be performed efficiently.", "label": 1}
{"sent1": "Charts and graphics, as well as languages, are important modes of communication.", "sent2": "A methodology is proposed for taking queries and requests expressed in natural language as input and answering them in charts through organizing that interaction into felicitous dialogue.", "label": 1}
{"sent1": "We present how a perceptron (in its dual form) uses convolution kernels to learn to differentiate between two categories of objects.", "sent2": "Motivations of this work are to (1) construct a practical lexicon for dealing with alternations, paraphrases and entailment relations between predicates, and (2) provide a basic database for statistical learning system as well as a theoretical lexicon study such as Generative Lexicon and Lexical Conceptual Structure.", "label": 0}
{"sent1": "In our experiments, we saw an improvement of 0.77 Bleu points absolute in JP?EN.", "sent2": "?s anchor words algorithm for topic modeling and develop new, regularized algorithms that not only mathematically resemble Gaussian and Dirichlet priors but also improve the interpretability of topic models.", "label": 0}
{"sent1": "The Shakti Standard Format is a readable and robust representation scheme for analysis frameworks and other purposes.", "sent2": "We describe a representation scheme and an analysis engine using that scheme, both of which have been used to develop infrastructure for HLT.", "label": 1}
{"sent1": "In this paper we present new experiments to test this claim.", "sent2": "Expert physicians viewed images of dermatological conditions and provided a description while working toward a diagnosis.", "label": 0}
{"sent1": "Mean  durations  were compared  with  previous work by Gusev et al.", "sent2": "Reflexive matching is generally successful, but reveals a small number of errors in the implementation.", "label": 0}
{"sent1": "We evaluate our agreement and disagreement tagging model on two disparate online discussion corpora ?", "sent2": "We automatically construct a socially-tuned lexicon that is bootstrapped from existing general-purpose sentiment lexicons to further improve the performance.", "label": 1}
{"sent1": "This leads to tagging accuracy in the low 80?s on Biblical test material and in the 60?s on other Middle English material.", "sent2": "Finally, we train a maximum entropy tagger on the output of the bigram tagger on the target Biblical text and test it on tagged Middle English text.", "label": 1}
{"sent1": "or ?morning exercise?.", "sent2": "Although NUCLE has been available for almost two years, there has been no reference paper that describes the corpus in detail.", "label": 0}
{"sent1": "We report the highest performing monolingual unsupervised results to date on the Senseval 2 all words data set.", "sent2": "We report results on three standard data sets using three different versions of WordNet.", "label": 1}
{"sent1": "In this paper we provide background and motivation for the task and describe how the dataset will differ from a machine translation task and previous word sense disambiguation tasks based on parallel data.", "sent2": "Predicting the sense of implicit discourse relations based on these features is considerably better than a random baseline and several of the most discriminative features conform with linguistic intuitions.", "label": 0}
{"sent1": "The measures are not independent, and we show how system designers can find a desired operating point for their ASR.", "sent2": "We show that simple incremental post-processing can improve stability dramatically, at the cost of timeliness (from 90% of edits of hypotheses being spurious down to 10% at a lag of 320ms).", "label": 1}
{"sent1": "The novel aspect is that we focus on linking local semantic argument structures across sentence boundaries.", "sent2": "if they are not based on any languagespecific knowledge.", "label": 0}
{"sent1": "However, F-Score suffers from the matching problem which does not allow: (1) the assessment of the entire membership of clusters, and (2) the evaluation of all clusters in a given solution.", "sent2": "We show how information contained in the dictionary can be used as additional training data that improves accuracy in learning new nouns.", "label": 0}
{"sent1": "We find few, most of which are arguably unlikely to cause processing problems.", "sent2": "We then consider the impact of MWEs on a current RTE system.", "label": 1}
{"sent1": "This framework allows the use of paraphrasing units ranging from words to large sub-sentential fragments for which context information from the sentence can be successfully exploited.", "sent2": "We show how context can be exploited both when attempting to find pivot phrases, and when looking for the most appropriate paraphrase in the original subsentential ?envelope?.", "label": 1}
{"sent1": "The main originality of our approach is to include features originally designed to classify text according to some author?s style.", "sent2": "In this paper we describe our participation to the WMT13 Shared Task on Quality Estimation.", "label": 1}
{"sent1": "In this paper, we present a new algorithm for geo-centric language model generation for local business voice search for mobile users.", "sent2": "Previous models in syntax-based statistical machine translation usually resort to some kinds of synchronous procedures, few of these works are based on the analysis-transfer-generation methodology.", "label": 0}
{"sent1": "This requires robust modeling and understanding of the semantics of short texts.", "sent2": "Unlike previous approaches that require a predefined set of question types, we present a method for dynamically constructing a probability-based answer type model for each different question.", "label": 0}
{"sent1": "Averaged across eight previously studied Indo-European languages, our model achieves a 25% relative error reduction over the prior state of the art.", "sent2": "When word prediction is constrained to a narrow set of choices such as possible senses, it can be quite reliable, and we use these predictions either by themselves or to reinforce standard methods.", "label": 0}
{"sent1": "However, a key issue is that information extraction (IE) errors from text affect the quality of the KB, and propagate to the reasoning task.", "sent2": "A standard pipeline for statistical relational learning involves two steps: one first constructs the knowledge base (KB) from text, and then performs the learning and reasoning tasks using probabilistic first-order logics.", "label": 1}
{"sent1": "As training data, we use both labeled and unlabeled data, utilizing an expectation maximization algorithm for parameter estimation.", "sent2": "Our sentiment classification model achieves approximately 1% greater accuracy than a state-of-the-art approach based on elementary discourse units.", "label": 0}
{"sent1": "In this paper, we present a two-stage method to enable the construction of SRL models for resourcepoor languages by exploiting monolingual SRL and multilingual parallel data.", "sent2": "Experimental results show that our method outperforms existing methods.", "label": 1}
{"sent1": "According to the second observation, we use an existing context-based approach.", "sent2": "Recent work has shown that compositionaldistributional models using element-wise operations on contextual word vectors benefit from the introduction of a prior disambiguation step.", "label": 0}
{"sent1": "On this subset, the adapted version of HeidelTime achieves a precision of 92% and a recall of 66%.", "sent2": "Resource and expertise constraints, which often drive this copying behavior, can be taken advantage of by lobbyists and special interest groups.", "label": 0}
{"sent1": "The high dimensionality of vectors, however, is a barrier to the performance of methods that employ VSMs.", "sent2": "We describe a system for detecting elements of interactional style: whether a speaker is awkward, friendly, or flirtatious.", "label": 0}
{"sent1": "Each pair of words is queried to a search engine, which produces a co-occurrence matrix.", "sent2": "After that, given the topic distribution of the document, we further calculate the ranking scores of words and extract the top ranked ones as keyphrases.", "label": 0}
{"sent1": "person, location, organization, time, etc.", "sent2": "In this paper, we study the impact of a group of features extracted automatically from machine-generated parse trees on coreference resolution.", "label": 0}
{"sent1": "We also investigate compatibility functions over sets of fields, rather than simply pairs of fields, to examine how higher representational power can impact performance.", "sent2": "We apply our techniques to the task of extracting contact records from faculty and student homepages, demonstrating a 53% error reduction over baseline approaches.", "label": 1}
{"sent1": "We present a novel architecture, which models these pipelines as Bayesian networks, with each low level task corresponding to a variable in the network, and then we perform approximate inference to find the best labeling.", "sent2": "For each user, our task is to rank the comments associated with a given article according to personalized user preference (i.e., whether the user is likely to like or dislike the comment).", "label": 0}
{"sent1": "Research in many groups could be accelerated if there were a community-accessible set of outputs from running MetaMap on this document collection, cached and available on the MIMIC-II website.", "sent2": "In some systems, human behaviour is analysed, and then rules for the agent are created based on the results of that analysis; in others, the recorded behaviour is used directly as a resource for decision-making, using data-driven techniques.", "label": 0}
{"sent1": "In the task of estimating bilingual term correspondences of technical terms, it is usually rather difficult to find an existing corpus for the domain of such technical terms.", "sent2": "This paper studies issues related to the compilation of a bilingual lexicon for technical terms.", "label": 1}
{"sent1": "(2012).", "sent2": "In order to perform fast, efficient Bayesian inference in this framework, we then derive a hash sampling strategy that is inspired by the work of Ahmed et al.", "label": 1}
{"sent1": "Our dataset is composed of the comments made by the editors on the talk pages.", "sent2": "Instead of access to data, they make available decision making procedures to enable predictions on new data.", "label": 0}
{"sent1": "Instances are represented by RDF compliant URIs that are shared across different research disciplines.", "sent2": "Analyses of computer aided translation typically focus on either frontend interfaces and human effort, or backend translation and machine learnability of corrections.", "label": 0}
{"sent1": "We propose a new method that projects model expectations rather than labels, which facilities transfer of model uncertainty across language boundaries.", "sent2": "We hope that our initial work and data will encourage others to pursue this promising line of inquiry.", "label": 0}
{"sent1": "We show that enabling a current state-of-the-art Bayesian word segmentation model to take advantage of stress cues noticeably improves its performance.", "sent2": "Stress has long been established as a major cue in word segmentation for English infants.", "label": 1}
{"sent1": "In contrast to previous approaches that rely on manually specified and multi-step heuristics for model minimization, our approach is a simple greedy approximation algorithm DMLC (DISTRIBUTEDMINIMUM-LABEL-COVER) that solves this objective in a single step.", "sent2": "The combinatorial preferences of nouns with one (or more) light verb is useful for predicting an instance of a CP.", "label": 0}
{"sent1": "The joint model performed better on both tasks, with a parse accuracy of 90.5% and 84.0% accuracy at disfluency detection.", "sent2": "This work empirically studies the performance of these two classes of alignment algorithms and explores strategies to combine them to improve overall system performance.", "label": 0}
{"sent1": "Unlike previous work, we formulate this extraction task as a structured prediction problem and design the corresponding inference as an integer linear program.", "sent2": "This paper introduces an unsupervised graph-based method that selects textual labels for automatically generated topics.", "label": 0}
{"sent1": "A tradeoff must be found for segment sizes.", "sent2": "We create new training sets for English and Dutch from the CELEX European lexical resource, and achieve error rates for English of less than 0.1% for correctly allowed hyphens, and less than 0.01% for Dutch.", "label": 0}
{"sent1": "1 Based on this resource, we show that available gene recognition tools such as conditional random fields (CRF) trained on BioCreative 2 NER data or GNAT tend to underperform on this phenomenon.", "sent2": "We propose to extend existing gene recognition approaches by combining a CRF and a support vector machine.", "label": 1}
{"sent1": "We learn our model in an efficient online fashion that is scalable for large, streaming data.", "sent2": "In this paper, we propose a variant of annotation scheme for uncertainty identification and construct the first uncertainty corpus based on tweets.", "label": 0}
{"sent1": "DT-RNNs outperform other recursive and recurrent neural networks, kernelized CCA and a bag-of-words baseline on the tasks of finding an image that fits a sentence description and vice versa.", "sent2": "They also give more similar representations to sentences that describe the same image.", "label": 1}
{"sent1": "Our framework leverages on both labeled and unlabeled data in the target domain.", "sent2": "Automatically identifying related specialist terms is a difficult and important task required to understand the lexical structure of language.", "label": 0}
{"sent1": "We exploit two kinds of clues to generate constraints which can capture the implicit type and cardinality requirements of a relation.", "sent2": "word strings that phrase-based decoders manipulate complicate the use of most recursive syntactic tools.", "label": 0}
{"sent1": "Our model is built upon a medical corpus containing 80M sentences (11 gigabyte text) and designed to accurately and efficiently detect the key medical relations that can facilitate clinical decision making.", "sent2": "This approach is compared to both a stopword-list and POS-tagging approach and our method demonstrates improved coverage on the DUC 2006 and TAC 2010 datasets using the ROUGE metric.", "label": 0}
{"sent1": "To tackle the sparsity and noise challenges, we propose solving the classification problem using matrix completion on factorized matrix of minimized rank.", "sent2": "We formulate relation classification as completing the unknown labels of testing items (entity pairs) in a sparse matrix that concatenates training and testing textual features with training labels.", "label": 1}
{"sent1": "The method can be applied to any language pair where the source language is unsegmented and the target language segmentation is known.", "sent2": "Detecting disagreement in this domain is a considerable challenge.", "label": 0}
{"sent1": "The nonterminals are placeholders of embedded clauses, by which we reduce complicated clause-level reordering into simple wordlevel reordering.", "sent2": "Automatic discourse causality recognition can further improve their workload by suggesting possible causal connections and aiding in the curation of pathway models.", "label": 0}
{"sent1": "Treating the target string as a label, we examine each source string to find inconsistencies in alignment.", "sent2": "In the first method, applicable to any aligned corpus, we consider alignment as a string-to-string mapping.", "label": 1}
{"sent1": "However, at least in English, retrieving such subtrees does not always guarantee retrieval of the correct phrase boundaries.", "sent2": "Unlike phrase structure, in which arguments are annotated at the phrase level, dependency structure does not have phrases so the argument labels are associated with head words instead: the subtree of each head word is assumed to include the same set of words as the annotated phrase does in phrase structure.", "label": 1}
{"sent1": "In order to use entailment recognition technologies for real-world applications, a large-scale entailment knowledge base is indispensable.", "sent2": "Textual entailment recognition plays a fundamental role in tasks that require indepth natural language understanding.", "label": 1}
{"sent1": "Our experiments are conducted on the large-scale Chinese?English and Arabic?English NIST translation tasks.", "sent2": "The second method examines phrase nodes which are predicted to be aligned, based on the alignment of their yields.", "label": 0}
{"sent1": "We present experiments on German-English and GermanFrench translation.", "sent2": "The learned models can also be used discriminatively as semantic role labelers, and when evaluated relative to the PropBank annotation, the best learned model reduces 28% of the error between an informed baseline and an oracle upper bound.", "label": 0}
{"sent1": "Previous approaches have relied on incrementally building larger rules by chunking smaller rules bottomup; we introduce a complementary top-down model that incrementally builds shorter rules by segmenting larger rules.", "sent2": "We show that combining both bottom-up rule chunking and top-down rule segmentation search strategies in purely unsupervised learning of phrasal inversion transduction grammars yields significantly better translation accuracy than either strategy alone.", "label": 1}
{"sent1": "As part of our investigations concerning the minimal k that is required for inducing manual alignments, we present a hierarchical aligner in form of a deduction system.", "sent2": "Such discontinuous constituents are required for inducing certain alignment configurations that occur relatively frequently in manually annotated parallel corpora and that cannot be generated with less expressive grammar formalisms.", "label": 1}
{"sent1": "The goal of this paper is to see what the success or failure of these systems can tell us about the essential properties of metaphorin-language.", "sent2": "Each of the identification systems is based, explicitly or implicitly, on a theory of metaphor which hypothesizes that certain properties are essential to metaphor-inlanguage.", "label": 1}
{"sent1": "We found a moderate-to-strong correlation (r=0.51-0.57) between the percentage of metaphorically used words in an essay and the writing quality score.", "sent2": "The reliability of the protocol is ?=0.58, on a set of 116 essays (the total of about 30K content-word tokens).", "label": 1}
{"sent1": "We have adopted entropy-based uncertainty measures to select new instances to be added to our training data.", "sent2": "In this paper we present our experiments with active learning to improve the performance of our probabilistic anaphora resolution system.", "label": 1}
{"sent1": "This paper extends the Direct Translation Model 2 (DTM2) with syntax while maintaining linear-time decoding.", "sent2": "We employ a linear-time parsing algorithm based on an eager, incremental interpretation of Combinatory Categorial Grammar (CCG).", "label": 1}
{"sent1": "Active learning is one way of easing the burden of annotation.", "sent2": "To obtain high-quality annotated data constitutes a bottleneck in machine learning for NLP today.", "label": 1}
{"sent1": "We show how interleaving queries for both documents and words significantly reduces human effort ?", "sent2": "Notably, our semantic relatedness function exploits the structure of the text by making use of a semantic-role-labeling based representation of an event.", "label": 0}
{"sent1": "For these reasons, it becomes very important for an MT system to make best use of its resources, both labeled and unlabeled, in building a quality system.", "sent2": "Preliminary  surveys  show  that  the  lan?", "label": 0}
{"sent1": "We specifically investigate the Haiku poetic genre, which is characterized by heavy reliance on lexical associations.", "sent2": "The ITG constraint is also compatible with word alignments that are not covered by ITG parse trees.", "label": 0}
{"sent1": "for ?", "sent2": "lyrics ?", "label": 1}
{"sent1": "Like previous learned approaches to language generation, our model uses a simple featuredriven architecture (here a pair of neural ?listener?", "sent2": "Nonetheless, our final system1 outperforms the Stanford system (Lee et al.", "label": 0}
{"sent1": "This is even more so for morphologically rich languages such as Arabic.", "sent2": "As a result, there is a wide range of possible preprocessing choices for data used in statistical machine translation.", "label": 1}
{"sent1": "The model simulates dialogues between two virtual agents, using policy gradient methods to reward sequences that display three useful conversational properties: informativity, coherence, and ease of answering (related to forward-looking function).", "sent2": "In this paper, we show how to integrate these goals, applying deep reinforcement learning to model future reward in chatbot dialogue.", "label": 1}
{"sent1": "To deal with the large vocabulary, we extend these models to mix a fixed vocabulary with copy actions that transfer sample-specific words from the input database to the generated output sentence.", "sent2": "Our combination methods rely on predominant senses which are derived automatically from raw text.", "label": 0}
{"sent1": "Our set of construction actions generalize better than the previous approach, and can be learned with a simple classifier.", "sent2": "We present for the first time a computational model for the reduplication of the Vietnamese language.", "label": 0}
{"sent1": "Our semantic parsing model jointly reasons about the text, logical forms, and environment over multi-stage instruction sequences.", "sent2": "In addition, it models such aspects of child acquisition as ?fast mapping,?", "label": 0}
{"sent1": "We carry out an extensive comparative analysis of stateof-the-art models for this type of relational learning.", "sent2": "The first evaluations show improvements in parsing speed, coverage, and robustness in comparison to earlier GF grammars.", "label": 0}
{"sent1": "In this paper, we address this issue by incorporating user- and product- level information into a neural network approach for document level sentiment classification.", "sent2": "The system also achieved 7.8% better F 1 score (harmonic mean of average precision and recall) than the previous state of the art.", "label": 0}
{"sent1": "LP tools allow us to uncover inconsistencies efficiently, paving the way to building SL debugging tools.", "sent2": "Their automatic disambiguation, i.e.", "label": 0}
{"sent1": "We make use of the original and antonymous views in pairs, in the training, bootstrapping and testing process, all based on a joint observation of two views.", "sent2": "The experimental results demonstrate the advantages of our approach, in meeting the two co-training requirements, addressing the negation problem, and enhancing the semi-supervised sentiment classification efficiency.", "label": 1}
{"sent1": "We then evaluate proposed improvements to the syntax-based extraction techniques in light of phrase pairs captured.", "sent2": "As a result most research has either ignored negative links or was limited to the few domains where such relations are explicitly expressed (e.g.", "label": 0}
{"sent1": "Traditionally in text categorization, the same scoring or ranking criterion is adopted for all target dimensionalities, which considers both the discriminability and the coverage of a term, such as ?2 or IG.", "sent2": "In this paper, the poor accuracy at a low dimensionality is imputed to the small average vector length of the documents.", "label": 1}
{"sent1": "Recent efforts have tried to overcome this issue by using statistics from speech lattices instead of only the 1best transcripts; however, these efforts have invariably used the classical vector space retrieval model.", "sent2": "We describe a novel approach to combining lexicalized, POS-based and syntactic treebased word reordering in a phrase-based machine translation system.", "label": 0}
{"sent1": "Identification of these query segments can potentially improve both document-retrieval precision, by first returning pages which contain the exact query segments, and document-retrieval recall, by allowing query expansion or substitution via the segmented units.", "sent2": "We propose an alignment matrix model as a correction algorithm to an underlying sequencebased aligner.", "label": 0}
{"sent1": "The new dataset includes many real world terms such as acronyms and named entities, and further handles term ambiguity by providing topical context for all term pairs.", "sent2": "BAYESUM leverages the common case in which multiple documents are relevant to a single query.", "label": 0}
{"sent1": "We demonstrate the frequency and productivity of these sequences in social media such as Twitter.", "sent2": "Moreover, this still holds when ROSE is trained on human judgements of translations into a different language compared with that use in testing.", "label": 0}
{"sent1": "Automatic language identification (LID) can be used to extract language-specific data from Twitter, but it is unclear how well LID performs on short, informal texts in low-resource languages.", "sent2": "We address this question by annotating and releasing a large collection of tweets in nine languages, focusing on confusable languages using the Cyrillic, Arabic, and Devanagari scripts.", "label": 1}
{"sent1": "In this work, we convert informal, romanized Urdu messages into the native Arabic script and normalize non-standard SMS language.", "sent2": "This paper investigates incorporating task features into an unsupervised dialogue act model trained on a corpus of human tutoring in introductory computer science.", "label": 0}
{"sent1": "This paper presents the first study towards Turkish paraphrase alignment.", "sent2": "We perform an analysis of different types of paraphrases on a modest Turkish paraphrase corpus and present preliminary results on that analysis from different standpoints.", "label": 1}
{"sent1": "In this paper, we demonstrate how the frame-to-frame relations described in the FrameNet ontology can be used to improve the performance of a FrameNet-based semantic role classifier for Swedish, a low-resource language.", "sent2": "Semantic role classification accuracy for most languages other than English is constrained by the small amount of annotated data.", "label": 1}
{"sent1": "We first generate potential positive interpretations manipulating syntactic dependencies.", "sent2": "Then, we score them according to their likelihood.", "label": 1}
{"sent1": "We propose a distantly supervised model to identify AAE-like language from demographics associated with geo-located messages, and we verify that this language follows well-known AAE linguistic phenomena.", "sent2": "In addition, we analyze the quality of existing language identification and dependency parsing tools on AAE-like text, demonstrating that they perform poorly on such text compared to text associated with white speakers.", "label": 1}
{"sent1": "To this end, we develop classifiers for opinion detection in these languages, and further classifying opinionated tweets into positive, negative and neutral sentiments.", "sent2": "Our novel contributions include random projection that reduces dimensionality and a new objective function that regularizes intra-class and inter-class distances to handle a large number of classes.", "label": 0}
{"sent1": "Analysts, including historians, political scientists, and journalists, commonly read large quantities of text to construct an accurate picture of when and where an event happened, who was involved, and in what ways.", "sent2": "We instead use forward-backward recurrent neural networks (FBRNNs) to detect events that can be either words or phrases.", "label": 0}
{"sent1": "In this work, we study the application of CNNs to language modeling, a dynamic, sequential prediction task that needs models to capture local as well as long-range dependency information.", "sent2": "Their application to language has received much less attention, and it has mainly focused on static classification tasks, such as sentence classification for Sentiment Analysis or relation extraction.", "label": 1}
{"sent1": "a timeaware hierarchical Bayesian model for event detection, and a learning-to-rank model to select the salient events to construct the final chronicle.", "sent2": "Experimental results demonstrate our approach is promising to tackle this new problem.", "label": 1}
{"sent1": "Our approach achieved significant improvement over the state-of-the-art method (Huang et al., 2013), which used a large amount of training data.", "sent2": "We design a semi-supervised collective inference framework for morph mention extraction, and compare various deep learning based approaches for morph resolution.", "label": 1}
{"sent1": "We further show how keyphrases can be placed into a semantically-meaningful ?phylogenetic?", "sent2": "We demonstrate how these keyphrases/concepts can be extracted, and their viability as a database in relation to existing collections.", "label": 1}
{"sent1": "In this work, we want to verify how this hybrid approach would improve with better classifiers.", "sent2": "Specifically, we propose methods for understanding user queries about specific target buildings in their surroundings.", "label": 0}
{"sent1": "Our work added semantic labels into a basic feature set for measuring the efficiency of those for aspect extraction.", "sent2": "We used the semantic roles and the highest verb frame as features for the machine learning.", "label": 1}
{"sent1": "These systems build on our SemEval-2013 sentiment analysis systems (Mohammad et al., 2013) which ranked first in both the termand message-level subtasks in 2013.", "sent2": "The vectors were obtained by Latent Semantic Analysis (LSA) applied to the ukWaC corpus.", "label": 0}
{"sent1": "The correlations are further incorporated into a Maximum Entropy-based ranking model which estimates path weights from training.", "sent2": "Different from previous studies, we propose an approximate phrase mapping algorithm and incorporate the mapping score into the correlation measure.", "label": 1}
{"sent1": "In order to increase the coverage, a larger set of verb senses were automatically associated with the existing patterns from VerbNet.", "sent2": "The algorithm creates verb argument structures using VerbNet syntactic patterns.", "label": 1}
{"sent1": "It successfully excludes phrases which are different from the target semantics, but which look superficially similar.", "sent2": "Our method uses components of the cue phrase itself, rather than external context, to bootstrap.", "label": 1}
{"sent1": "The FrameNet corpus contains the examples annotated with semantic roles whereas the VerbNet lexicon provides the knowledge about the syntactic behavior of the verbs.", "sent2": "This article describes a robust semantic parser that uses a broad knowledge base created by interconnecting three major resources: FrameNet, VerbNet and PropBank.", "label": 1}
{"sent1": "(Papillon?s web server development platform) for the LexALP1 project.", "sent2": "LexALP?s goal is to harmonise the terminology on spatial planning and sustainable development used within the Alpine Convention2, so that the member states are able to cooperate and communicate efficiently in the four official languages (French, German, Italian and Slovene).", "label": 1}
{"sent1": "Second, we propose probability estimates and a training procedure for weighting these rules.", "sent2": "In this paper, we take the framework for acquiring multi-level syntactic translation rules of (Galley et al, 2004) from aligned tree-string pairs, and present two main extensions of their approach: first, instead of merely computing a single derivation that minimally explains a sentence pair, we construct a large number of derivations that include contextually richer rules, and account for multiple interpretations of unaligned words.", "label": 1}
{"sent1": "We quantify redundancy among source types by the similarity of their distributions over target types.", "sent2": "We present a novel method to identify effective surface text patterns using an internet search engine.", "label": 0}
{"sent1": "This framework was applied to a text retrieval system for MEDLINE.", "sent2": "We describe the system built by the National Research Council Canada for the ?Discriminating between similar languages?", "label": 0}
{"sent1": "This paper presents a second challenge, which continues this tradition and introduces some additional features ?", "sent2": "We propose a method that formulates the problem of exploring such signals on unannotated bilingual text as a simple Integer Linear Program, which encourages entity tags to agree via bilingual constraints.", "label": 0}
{"sent1": "Our corpus consists of child sentences with corrected adult forms.", "sent2": "Recent works for extracting taxonomic relations from text focused on collecting lexical-syntactic patterns to extract the taxonomic relations by matching the patterns to text.", "label": 0}
{"sent1": "We investigate the needs of an important task yet to be tackled by TM ?", "sent2": "One of the most neglected areas of biomedical Text Mining (TM) is the development of systems based on carefully assessed user needs.", "label": 1}
{"sent1": "First, we explain how state tracking is structurally similar to web-style ranking, enabling mature, powerful ranking algorithms to be applied.", "sent2": "In this paper we present the task of unsupervised prediction of speakers?", "label": 0}
{"sent1": "We introduce a framework for incorporating prior knowledge into any factfinding algorithm, expressing both general ?common-sense?", "sent2": "reasoning and specific facts already known to the user as first-order logic and translating this into a tractable linear program.", "label": 1}
{"sent1": "Performance scales log-linearly with the number of parameters in the model (the number of unique N-grams).", "sent2": "This paper proposes a definition for lexical reference which captures the common goals of lexical matching.", "label": 0}
{"sent1": "For the actual test case of a domain-dependent review, the review?s rating is predicted by aggregating the scores of all opinions in the review and combining it with a domaindependent unigram model.", "sent2": "Many of these systems rely heavily on the availability of dialogue corpora that have been annotated with Dialogue Act labels.", "label": 0}
{"sent1": "After that, ?word emotion components?", "sent2": "The experimental results demonstrate the effectiveness of using semantic feature for word emotion recognition.", "label": 1}
{"sent1": "We propose a novel two-stage greedy approximation scheme to replace the IP.", "sent2": "However, solving this problem exactly using an integer programming formulation is intractable for practical purposes.", "label": 1}
{"sent1": "Once stems have been extracted, an improved unsupervised segmentation algorithm GBUMS (GraphBased Unsupervised Morpheme Segmentation) is used to segment suffix or prefix sequences into individual suffixes and prefixes.", "sent2": "In the first stage we introduce a new Supervised Stem Extraction algorithm (SSE).", "label": 1}
{"sent1": "We show that four well-known summarization tasks including generic, query-focused, update, and comparative summarization can be modeled as different variations derived from the proposed framework.", "sent2": "In this paper, we propose a new principled and versatile framework for multi-document summarization using the minimum dominating set.", "label": 1}
{"sent1": "Further, the annotation process is described and all single resources are explained.", "sent2": "We describe the agglutinating morphology of Zulu with its multiple prefixation and suffixation, and also introduce our labeling scheme.", "label": 1}
{"sent1": "Across 3 languages, EMMA scores of 14 systems have a substantially greater positive correlation with mean average precision in an information retrieval (IR) task than do scores from the metric currently used by the Morpho Challenge (MC) competition series.", "sent2": "We compute EMMA and MC metric scores for 93 separate system-language pairs from the 2007, 2008, and 2009 MC competitions, demonstrating that EMMA is not susceptible to two types of gaming that have plagued recent MC competitions: Ambiguity Hijacking and Shared Morpheme Padding.", "label": 1}
{"sent1": "a language for which no such experiment has been conducted yet.", "sent2": "Results are particularly striking for discontinuous parsing of German, where we surpass the current state of the art by a wide margin.", "label": 0}
{"sent1": "The paper shows how triads of stacked dependency parsers described in Martins et al (2008) can label unlabeled data for each other in a way similar to co-training and produce end parsers that are significantly better than any of the stacked input parsers.", "sent2": "Martins et al (2008) presented what to the best of our knowledge still ranks as the best overall result on the CONLLX Shared Task datasets.", "label": 1}
{"sent1": "We present Chinese CCGbank, a 760,000 word corpus annotated with Combinatory Categorial Grammar (CCG) derivations, induced automatically from the Penn Chinese Treebank (PCTB).", "sent2": "We design parsimonious CCG analyses for a range of Chinese syntactic constructions, and transform the PCTB trees to produce them.", "label": 1}
{"sent1": "However, existing end-to-end solutions typically require substantial amount of human efforts (e.g., labeled data and/or manual engineering), and are not well poised for Web-scale knowledge acquisition.", "sent2": "multiple source parser adaptation.", "label": 0}
{"sent1": "But this is not the case.", "sent2": "This would be no problem if the different lexical items fell into clearly definable and easy to represent classes.", "label": 1}
{"sent1": "Our main focus has been on building the infrastructure and gathering the data.", "sent2": "Specifically, we describe what kind of information is collected in PRISMATIC and how it compares with existing lexical resources.", "label": 1}
{"sent1": "Error classification includes mistakes in preposition and article usage, errors in grammar, word order, and word choice.", "sent2": "The annotation was performed at the sentence level and involved correcting all errors in the sentence.", "label": 1}
{"sent1": "Such a checker needs to interpret and generate sentences containing quantifiers and negation.", "sent2": "To handle quantifier and negation scope, we systematically simulate continuation grammars using record structures in the Grammatical Framework.", "label": 1}
{"sent1": "Among these features, the IPC shows the highest correlation with holistic scores (r = ?0.344).", "sent2": "For instance, unvoiced consonants are the most likely first consonants and liquids and glides are preferred as second consonants in two-consonantal onsets.", "label": 0}
{"sent1": "We propose two methods to enable better comparison of prompt and essay text.", "sent2": "We automatically expand short prompts before comparison, with words likely to appear in an essay to that prompt.", "label": 1}
{"sent1": "In this paper, we present an interpolated DCLM (IDCLM) by using different distanced n-grams.", "sent2": "Most existing systems for subcategorization frame (SCF) acquisition rely on supervised parsing and infer SCF distributions at type, rather than instance level.", "label": 0}
{"sent1": "Finally, we evaluate an existing surface realiser on the resulting dataset.", "sent2": "We evaluate a lexicon derived from English documents, both qualitatively and quantitatively, and show that it provides superior performance to previously studied lexicons, including one derived from WordNet.", "label": 0}
{"sent1": "We find that using NEL for argument identification boosts performance over the traditional approach (named entity recognition with string match), and there is further improvement from using argument types.", "sent2": "Through both synthetic grammar induction and statistical machine translation experiments, we show that our model learns complex translational correspondences?", "label": 0}
{"sent1": "This paper investigates this question empirically, using machine-learning techniques on a new corpus of dialogues involving multimodal references to objects.", "sent2": "Experiments are reported with a high performing baseline, trained on the Chinese-English NIST 2006 Evaluation task and running on a standard Linux 64-bit PC architecture.", "label": 0}
{"sent1": "We applied an existing monolingual sentence alignment algorithm.", "sent2": "To incorporate dependencies between word senses, we introduce a set of features on tree edges, in combination with coarse-grained tagsets, and show that these contribute to an improvement in WSD accuracy.", "label": 0}
{"sent1": "In this research, we attempt to improve the readability of text by optimizing comma placements through integration of linguistic features of text and gaze features of readers.", "sent2": "We design a comma predictor for general Chinese text based on conditional random field models with linguistic features.", "label": 1}
{"sent1": "At the same time, documents at a wide range of reading levels are identified and even among the Top-10 search results one finds documents at the lower levels, supporting the potential usefulness of readability ranking for the web.", "sent2": "Finally, we report on generalization experiments showing that the features we used generalize well across different web sources.", "label": 1}
{"sent1": "a statistical learning method with extensive feature engineering.", "sent2": "Our model first builds a hierarchical LSTM model to generate sentence and document representations.", "label": 0}
{"sent1": "Although reading time is known to be a good metric for predicting readability, previous work has mainly focused on annotating the training data with subjective readability scores usually on a 1 to 5 scale.", "sent2": "Key to our approach is a novel dependency-based model for opinion mining, which we show, as a byproduct, to be on par with the current state of the art for English, while avoiding the need for integer programming or reranking.", "label": 0}
{"sent1": "Our setup includes a preliminary screen output planning module, which prepares several versions of possible screen output.", "sent2": "The wizards were free to speak, and/or to select a screen output.", "label": 1}
{"sent1": "The projects centered around the idea of ?overgeneration?, i.e.", "sent2": "English, Finnish and Greenlandic ?", "label": 0}
{"sent1": "This task is interesting since the abbreviation process for Chinese compound words seems to be ?compositional?", "sent2": "; in other words, one can often decode an abbreviated word, such as ????", "label": 1}
{"sent1": "Based on the Sentence Degeneration model of HNC theory, a garden-path can arise from two types of ambiguities: SD type ambiguity and NP allocated ambiguity.", "sent2": "which yields a significant improvement over the best published result in the literature.", "label": 0}
{"sent1": "The paper shows that incorporating several latent features into the tense classifier boosts the tense classifier?s performance, and a tense classifier using only the latent features outperforms one using only the surface features.", "sent2": "We evaluate our results on six corpora representing a variety of disambiguation tasks.", "label": 0}
{"sent1": "We further measure the confidence of the extracted triples by looking at the details of the complete extraction process.", "sent2": "In this paper, we propose a novel joint inference framework to allow interactions between the two subtasks and find an optimal assignment by addressing the coherence among preliminary local predictions: whether the types of entities meet the expectations of relations explicitly or implicitly, and whether the local predictions are globally compatible.", "label": 1}
{"sent1": "In order to correct inconsistently results, we perform the postprocessing procedure according to n-best results given by the CRFs model.", "sent2": "An important challenge to statistical machine translation (SMT) is the lack of parallel data for many language pairs.", "label": 0}
{"sent1": "The presented method discovers a mapping between morphemes and linguistically relevant features.", "sent2": "Toward this goal, we present a method for analyzing the morphosyntactic content of language from an Elicitation Corpus such as the one included in the LDC?s upcoming LCTL language packs.", "label": 1}
{"sent1": "Next, we extract all aligned sub-sentential syntactic constituents from the parallel sentences, and create a syntax-based phrase-table.", "sent2": "We first apply a newly developed algorithm for aligning parse-tree nodes between the two parallel trees.", "label": 1}
{"sent1": "Using zymake improves repeatability and scalability of running experiments, and provides a clean, simple interface for assembling components.", "sent2": "Our models consider both transliteration and translation when translating a particular Hindi word given the context whereas in previous work transliteration is only used for translating OOV (out-of-vocabulary) words.", "label": 0}
{"sent1": "As a result, traditional text-based approaches to information extraction (IE) could underperform.", "sent2": "Our best combination of features outperforms the baseline from data intensive approaches by 4% for comparison and 16% for contingency.", "label": 0}
{"sent1": "The scope of the system is restricted to controlled natural language, and this allows the generator to work within a tightly restricted domain of locality.", "sent2": "and in fact contains slang, misspellings, multiword expressions, etc.", "label": 0}
{"sent1": "Surprisingly, none of those works have systematically investigated the impact of the many parameters controlling their approach.", "sent2": "(Fung, 1998; Rapp, 1999).", "label": 1}
{"sent1": "Given inverted lists retrieved for a query, the algorithm collects fewer candidate strings and prunes unlikely candidates to efficiently find strings that satisfy the constraint of the ?", "sent2": "-overlap join.", "label": 1}
{"sent1": "We first develop a multi-task learning method based on logistic regression (MTL-LR), which can boost the learning for a task by sharing the knowledge contained in the training signals of other related tasks.", "sent2": "Our experiments reveal that the prediction accuracy of the models is marred by serious overfitting problems, due to violations of the random sampling assumption in corpus data.", "label": 0}
{"sent1": "We give an efficient labeling algorithm that is analogous to parsing using dynamic programming.", "sent2": "We compare these results with those obtained in recent work on Open Information Extraction, indicating with some examples the quite different kinds of output obtained by the two approaches.", "label": 0}
{"sent1": "In statistical machine translation (SMT), different forms of class-based LMs have been shown to improve baseline translation quality when used in combination with standard word-level LMs but no published work has systematically compared different kinds of classes, model forms and LM combination methods in a unified SMT setting.", "sent2": "Class-based language modeling (LM) is a long-studied and effective approach to overcome data sparsity in the context of n-gram model training.", "label": 1}
{"sent1": "We present a new dataset, TVRecap, for text recap extraction on TV shows.", "sent2": "We evaluate the algorithm by using an unsupervised POS tagger and an unsupervised parser, selecting high quality parsed sentences from English (WSJ) and German (NEGRA) corpora.", "label": 0}
{"sent1": "With the help of unlabeled sentences and a lexicon of 3,000 words, we obtain 33% error reduction in target-domain tagging.", "sent2": "We report similar findings using a novel approach for joint Chinese segmentation and POS-tagging, under a cross-domain setting.", "label": 1}
{"sent1": "By examining morphologically rich subsets of an input lexicon, the search identifies highly productive paradigms.", "sent2": "The system is composed of a generative probability model and a novel search algorithm.", "label": 1}
{"sent1": "In this paper, to supplement N-gram based splitting methods, we introduce another clue using sentence similarity based on edit-distance.", "sent2": "In our splitting method, we generate candidates for sentence splitting based on N-grams, and select the best one by measuring sentence similarity.", "label": 1}
{"sent1": "Most notably, it shows how individual agents can bene\ft from following di\u000berent discourse strategies.", "sent2": "A central concern is to provide an environment in which social science researchers can rapidly develop an informed sense of what the datasets look like.", "label": 0}
{"sent1": "This paper discusses our investigation into the effectiveness of lexicalization in dependency parsing.", "sent2": "We conclude that emotion classification according to the Interpersonal Circumplex is a challenging task for both humans and machine learners.", "label": 0}
{"sent1": "IR views language as an open-ended set of mostly stable signs with which texts can be indexed and retrieved, focusing more on a text?s potential relevance than its potential meaning.", "sent2": "which agents are hypothesized to employ when making and receiving utterances.1", "label": 0}
{"sent1": "Beyond that, the edit history of Wikipedia articles has been shown to be a valuable knowledge source for NLP, but access is severely impeded by the lack of efficient tools for managing the huge amount of provided data.", "sent2": "In particular, we focus on identifying and employing semantic classes of nouns and verbs with high tendency to encode cause or non-cause relations.", "label": 0}
{"sent1": "Finally, we present a general purpose system for identifying redundant tweets.", "sent2": "The experimental results on a domain specific corpus show that the method performs better than other approaches.", "label": 0}
{"sent1": "This paper presents a method that shares similarities with both spell checking and machine translation approaches.", "sent2": "Different well-defined approaches have been proposed, but the problem remains far from being solved: best systems achieve a 11% Word Error Rate.", "label": 1}
{"sent1": "We propose a faster framework of dynamic feature selection, where features are added sequentially as needed, edges are pruned early, and decisions are made online for each sentence.", "sent2": "Violence risk assessment is an important and challenging task undertaken by mental health professionals and others, in both clinical and nonclinical settings.", "label": 0}
{"sent1": "This measure achieves a correlation of 0.450 (Pearson?s R, p <0.01) with an experimental measure of metaphoricity involving human participants.", "sent2": "We collected scores of 23 metrics from 12 research groups.", "label": 0}
{"sent1": "The second method restricts the successor words that are looked at, for each hypothesis.", "sent2": "We also present an analysis of the impact that semantic information and text summarization have in the clustering process.", "label": 0}
{"sent1": "(2013) to syntax-based MT by generalizing their latent variable ?violation-fixing?", "sent2": "perceptron from graphs to hypergraphs.", "label": 1}
{"sent1": "In this work, we propose an alternative approach to addressing punctuation in dependency parsing.", "sent2": "Punctuation parsing errors lead to low parsing accuracy on words.", "label": 1}
{"sent1": "In this work we devise a novel crowdsourcing annotation methodology, and an accompanying large scale corpus.", "sent2": "In this paper, we compare two approaches to modeling subtask structure in dialog: a chunk-based model of subdialog sequences, and a parse-based, or hierarchical, model.", "label": 0}
{"sent1": "In this work, we analyze the deficiency of traditional attention based RNN models quantitatively and qualitatively.", "sent2": "Despite the improvement over nonattentive models, the attention mechanism under RNN is not well studied.", "label": 1}
{"sent1": "This paper proposes a novel multi-task learning framework for PRA, referred to as coupled PRA (CPRA).", "sent2": "It first devises an agglomerative clustering strategy to automatically discover relations that are highly correlated to each other, and then employs a multi-task learning strategy to effectively couple the prediction of such relations.", "label": 1}
{"sent1": "By analyzing the trained larger-context language model, we discover that content words, including nouns, adjectives and verbs, benefit most from an increasing number of context sentences.", "sent2": "However, there have been few attempts to explain skipping behavior with computational models, as most existing work has focused on predicting reading times (e.g., using surprisal).", "label": 0}
{"sent1": "Building on recent work by (Wang et al., 2015), the interpretable logical forms, which are structured objects obeying certain constraints, are enumerated by an underlying grammar and are paired with their canonical realizations.", "sent2": "Going forward, to improve accuracy on the QA task, systems will need greater coordination between text retrieval and answer extraction modules.", "label": 0}
{"sent1": "The resultant bilingual corpus, 10.4M English words and 18.3M Chinese characters, is an authoritative and comprehensive text collection covering the specific and special domain of HK laws.", "sent2": "The Xenotext Experiment implants poetry into an extremophile?s DNA, and uses that DNA to generate new poetry in a protein form.", "label": 0}
{"sent1": "Our results show that MT evaluation techniques are able to produce useful features for paraphrase classification and to a lesser extent entailment.", "sent2": "We also introduce a novel classification method based on PER which leverages part of speech information of the words contributing to the word matches and non-matches in the sentence.", "label": 1}
{"sent1": "This model is tested for compositionality detection and it is found to outperform existing prototype-based models.", "sent2": "This exacerbates the out-of-vocabulary (OOV) problem.", "label": 0}
{"sent1": "Since the speaking content is not known prior to the assessment, a two-stage method is developed to first recognize the speaking content based on non-native speech acoustic properties and then forced-align the recognition results with a reference acoustic model reflecting native and near-native speech properties.", "sent2": "This paper describes research on automatic assessment of the pronunciation quality of spontaneous non-native adult speech.", "label": 1}
{"sent1": "Content selection consists of finding the relevant part in text to frame question from while question formation involves sense disambiguation of the discourse connectives, identification of question type and applying syntactic transformations on the content.", "sent2": "Our work divides the QG task into content selection and question formation.", "label": 1}
{"sent1": "However, to the best of our knowledge, there is no systematic attempt in the literature to build such a resource.", "sent2": "This paper deals with contextual aspects of locative preposition processing.", "label": 0}
{"sent1": "The resulting word vectors, when combined with the per-perspective linear transformation, approximately recreate while also regularizing and generalizing, each word similarity perspective.", "sent2": "At feature extraction stage, multiple specifications are clustered to extend the vocabulary of product features.", "label": 0}
{"sent1": "The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task.", "sent2": "The first evaluations show improvements in parsing speed, coverage, and robustness in comparison to earlier GF grammars.", "label": 0}
{"sent1": "We build models over varying domains, data set sizes, and n-gram orders, and perform linear regression to see whether we can model test set performance as a simple function of training set performance and various model statistics.", "sent2": "Remarkably, we find a simple relationship that predicts test set performance with a correlation of 0.9997.", "label": 1}
{"sent1": "In this paper, to further improve other downstream NLP applications, we argue that other normalization operations should also be performed, e.g., missing word recovery and punctuation correction.", "sent2": "A character-based measure of similarity is an important component of many natural language processing systems, including approaches to transliteration, coreference, word alignment, spelling correction, and the identification of cognates in related vocabularies.", "label": 0}
{"sent1": "We evaluate our model on a novel comment prediction task where the models are used to predict which blog users will leave comments on a given post.", "sent2": "Our models jointly describe the generation of the primary documents (posts) as well as the authorship and, optionally, the contents of the blog community?s verbal reactions to each post (comments).", "label": 1}
{"sent1": "These worst-case bounds on processing are demonstrated to be achieved without reducing the parsing accuracy, in fact in some cases improving the accuracy.", "sent2": "The new methods achieve observed performance comparable to the previously published quadratic complexity method.", "label": 1}
{"sent1": "Here, we propose Tied-Mixture Language Model (TMLM), which does not have the model parameter estimation problems that GMLM has.", "sent2": "In a previous work we introduced Gaussian-Mixture Language Model (GMLM) and presented some initial experiments.", "label": 1}
{"sent1": "We collect a corpus of human judgements to evaluate our system.", "sent2": "This model allows us to evaluate the effectiveness of AL sampling methods in terms of time spent in annotation.", "label": 0}
{"sent1": "On the other hand, when more resources extracted from morphologically segmented data become available, models built with Arabic TreeBank style segmentation yield to better results.", "sent2": "We also show additional improvement by combining different segmentation schemes.", "label": 1}
{"sent1": "They are investigated in a formal setting and compared to a competitor that is at least as expressive.", "sent2": "However, while these graph-based approaches perform effectively when the agent has perfect knowledge or perception of the environment (e.g., 84%), they perform rather poorly when the agent has imperfect perception of the environment (e.g., 45%).", "label": 0}
{"sent1": "We propose to minimize ramp loss directly and present a training algorithm that is easy to implement and that performs comparably to others.", "sent2": "Most notably, our structured ramp loss minimization algorithm, RAMPION, is less sensitive to initialization and random seeds than standard approaches.", "label": 1}
{"sent1": "In particular, a comparison with a stateof-the-art system on the first story detection task shows that we achieve over an order of magnitude speedup in processing time, while retaining comparable performance.", "sent2": "To make event detection feasible on web-scale corpora, we present an algorithm based on locality-sensitive hashing which is able overcome the limitations of traditional approaches, while maintaining competitive results.", "label": 1}
{"sent1": "Our method is based on entropy which has been used previously as a regularizer in semi-supervised learning.", "sent2": "This technique includes another term which measures the stability of posteriors w.r.t model parameters, in addition to conditional entropy.", "label": 1}
{"sent1": "The higher disagreement of nonprofessional transcribers does not have a significant effect on system performance.", "sent2": "Genre classification has been found to improve performance in many applications of statistical NLP, including language modeling for spoken language, domain adaptation of statistical parsers, and machine translation.", "label": 0}
{"sent1": "The detection of OOV regions in the output of a LVCSR system is typically addressed as a binary classification task, where each region is independently classified using local information.", "sent2": "These words cause recognition failures, which propagate through pipeline systems impacting the performance of downstream applications.", "label": 1}
{"sent1": "An unsupervised model selection technique based on this observation is shown to reduce extraction and type-checking error by 26% over previous results, in experiments with Hidden Markov Models.", "sent2": "The results suggest that optimizing statistical language models over unlabeled data is a promising direction for improving weakly supervised and unsupervised information extraction.", "label": 1}
{"sent1": "However, existing approaches that use in-memory search, or relational or XML database technologies, do not scale up.", "sent2": "In the BPC experiments, we vary the feature set alng two factors: the POS tag set and a set of explicitly encoded morphological features.", "label": 0}
{"sent1": "reviews from several sources to predict opening weekend revenue.", "sent2": "In our experiments, the proposed kernel used with Support Vector Machines outperformed the linear kernel and the Fisher kernel based on the Probabilistic Latent Semantic Indexing model.", "label": 0}
{"sent1": "summarization to interactive summarization.", "sent2": "On the target side (Turkish), we only perform morphological analysis and disambiguation but treat the complete complex morphological tag as a factor, instead of separating morphemes.", "label": 0}
{"sent1": "Second, we adopted an adaptive method where we train classifiers from review data and incorporate their hypothesis as features.", "sent2": "Our participation is reduced to task 1.2 on System Selection.", "label": 0}
{"sent1": "We evaluate the results using a novel technique for automatically selecting a representative sentence from multiple responses.", "sent2": "In this paper, we present a methodology for collecting fusions of similar sentence pairs using Amazon?s Mechanical Turk, selecting the input pairs in a semiautomated fashion.", "label": 1}
{"sent1": "However most of this work has been concentrated on English and other European languages.", "sent2": "Hence, building a named entity  recognition (NER) system for South Asian  Languages (SAL) is still an open problem because they exhibit characteristics different from English.", "label": 1}
{"sent1": "We also show the effect of the training data on the performance of the system.", "sent2": "In this paper, we present a technique for unsupervised solution post identification leveraging a so far unexplored textual feature, that of lexical correlations between problems and solutions.", "label": 0}
{"sent1": "These latent cross-lingual concepts are induced from a comparable corpus without any additional lexical resources.", "sent2": "Word meaning is represented as a probability distribution over the latent concepts, and a change in meaning is represented as a change in the distribution over these latent concepts.", "label": 1}
{"sent1": "and pose it as a challenge to scalable information extraction and retrieval.", "sent2": "Existing approaches to relation recognition do not address well problems with an open set of relations and a need for high recall: supervised methods are not easily scaled, while unsupervised and semi-supervised methods address a limited aspect of the problem, as they are restricted to frequent, explicit, highly localized patterns.", "label": 1}
{"sent1": "By adding noun phrases as candidate arguments that are not only in the sentence of the target predicate but also outside of the sentence, our analyzer identifies arguments regardless of whether they appear in the sentence or not.", "sent2": "The treebased reranking model allows us to explicitly model global syntactic phenomena.", "label": 0}
{"sent1": "ASR accuracy per user on the basis of responses following the system?s explicit confirmations.", "sent2": "We define ?implicitly-supervised?", "label": 1}
{"sent1": "In this paper, we prove that different predicates in a sentence could help each other during SRL.", "sent2": "The linguistically motivated functional model of Baroni and Zamparelli (2010) and Coecke et al.", "label": 0}
{"sent1": "Key ideas of our model are (i) a new reordering approach which better restricts the position to which a word or phrase can be moved, and is able to handle short and long distance reorderings in a unified way, and (ii) a joint sequence model for the translation and reordering probabilities which is more flexible than standard phrase-based MT.", "sent2": "We observe statistically significant improvements in BLEU over Moses for German-to-English and Spanish-to-English tasks, and comparable results for a French-to-English task.", "label": 1}
{"sent1": "The idea is illustrated through a comparative study of auxiliary structures in HPSG-based grammars for German and Dutch.", "sent2": "Moreover, we directly apply our generator to perform a very different task from tradition, the abbreviation recognition.", "label": 0}
{"sent1": "We show that a large number of paraphrases can be automatically extracted with high precision by regarding the sentences that define the same concept as parallel corpora.", "sent2": "Using the CRAG 2 language generation system we examine how accurately judges can perceive character personality from short, automatically generated dialogues, and how alignment (similarity between speakers) alters judge perceptions of the characters?", "label": 0}
{"sent1": "Finally, we present a ranker that employs distributional similarities to build a network of words, and captures the diversity of perspectives by detecting communities in this network.", "sent2": "We show how different summaries use various phrasal information units (i.e., nuggets) to express the same atomic semantic units, called factoids.", "label": 1}
{"sent1": "By combining role induction with a rule-based component for argument identification we obtain an unsupervised end-to-end semantic role labeling system.", "sent2": "We use the corpora to analyze how nurses perform their nursing duties and how they express the perform ance of their tasks.", "label": 0}
{"sent1": "Our extraction model includes a document genre classifier to recognize event narratives, two types of sentence classifiers, and noun phrase classifiers to extract role fillers.", "sent2": "on relevant information.", "label": 1}
{"sent1": "Our framework first identifies multi-word expressions based on the syntactic structure of the sentence; this allows us to recognize both contiguous and non-contiguous phrases.", "sent2": "In this paper, we propose a method for learning a classifier which combines outputs of more than one Japanese named entity extractors.", "label": 0}
{"sent1": "Developing models that learn multiple levels simultaneously can provide important insights into how these levels might interact synergistically during learning.", "sent2": "Here, we present a model that jointly induces syntactic categories and morphological segmentations by combining two well-known models for the individual tasks.", "label": 1}
{"sent1": "We define the model as a Bayesian noisy channel; we sample segmentations and word forms simultaneously from the posterior, using beam sampling to control the size of the search space.", "sent2": "Compared to a pipelined approach in which segmentation is performed first, our model is qualitatively more similar to human learners.", "label": 1}
{"sent1": "This model is implemented in a normalization system called UNLOL, which achieves the best known results on two normalization datasets, outperforming more complex systems.", "sent2": "We use the output of UNLOL to automatically normalize a large corpus of social media text, revealing a set of coherent orthographic styles that underlie online language variation.", "label": 1}
{"sent1": "In this paper, we characterize two prose genres syntactically: chick lit (humorous novels on the challenges of being a modern-day urban female) and high literature.", "sent2": "Since the models used are typically black boxes, they give little insight into the stylistic differences they detect.", "label": 1}
{"sent1": "Sampling methods become more and more important with larger and larger collections.", "sent2": "The focus we provide yields significant savings in annotation efforts by presenting only informative items to the annotator.", "label": 0}
{"sent1": "Flexible, parametrized models can be learned from past data and automatically optimized to correlate well with human judgments for different criteria (e.g.", "sent2": "We introduce BLANC, a family of dynamic, trainable evaluation metrics for machine translation.", "label": 1}
{"sent1": "Therefore, we want to transfer learning from the old, generalpurpose subtask to a more specific new task, for which there is often less data.", "sent2": "We design three different Human Intelligence Task (HIT) strategies and report high inter-annotator agreement between non-experts and expert annotators.", "label": 0}
{"sent1": "phrases with gaps.", "sent2": "This paper presents a phrase-based statistical machine translation method, based on non-contiguous phrases, i.e.", "label": 1}
{"sent1": "It is, thus, applicable to any kind of machine translation system.", "sent2": "In this paper, we propose a method to support learners in the information seeking process which consists in answering their questions by retrieving question paraphrases and their corresponding answers from social Q&A sites.", "label": 0}
{"sent1": "We present algorithms for solving the word translation problem and demonstrate a significant improvement over a baseline system.", "sent2": "We then show that the word-translation system can be used to improve performance on a simplified machinetranslation task and can effectively and accurately prune the set of candidate translations for a word.", "label": 1}
{"sent1": "Using a community-wide curated biomedical terminology system as an evaluation gold standard, we show that our algorithm significantly outperforms a variety of standard term identification measures.", "sent2": "We also provide empirical evidence that our methodolgy is essentially domain- and corpus-size-independent.", "label": 1}
{"sent1": "We compare the proposed approach with other bootstrapping methods in the context of training a Chinese Part-of-Speech tagger.", "sent2": "We propose a number of techniques to address the noisy data problem.", "label": 0}
{"sent1": "in particular, as questions.", "sent2": "Restarts are time-intensive, and most constraint-based approaches require serious re-engineering or external solvers.", "label": 0}
{"sent1": "semantic relations on a large corpus.", "sent2": "A learning model is introduced based on the statistical analysis of the distribution of genitives?", "label": 1}
{"sent1": "However, annotation guidelines often make linguistically debatable and even somewhat arbitrary decisions, and interannotator agreement is often less than perfect.", "sent2": "While annotation projects usually specify how to deal with linguistically debatable phenomena, annotator disagreements typically still stem from these ?hard?", "label": 1}
{"sent1": "It aims at lowering the barriers of using NLP technology both for research purposes and for small industrial developers and SMEs by offering robust and efficient linguistic annotation to both researchers and non-NLP experts.", "sent2": "IXA pipeline can be used ?as is?", "label": 1}
{"sent1": "These analyzers are provided as web services following a lightweigth SOA architecture approach, and they are publically accessible and shared through META-SHARE.", "sent2": "The services cover seven major and minor languages: English, German, Spanish, Chinese, Catalan, Slovenian, and Croatian.", "label": 1}
{"sent1": "Despite its relative simplicity, model combination improves translation quality over a pipelined approach of first applying consensus decoding to individual systems, and then applying system combination to their output.", "sent2": "Having a standard test set and standard evaluation parameters, all based on a resource that provides multiple integrated annotation layers (syntactic parses, semantic roles, word senses, named entities and coreference) and in multiple languages could support joint modeling and help ground and energize ongoing research in the task of entity and event coreference.", "label": 0}
{"sent1": "To make use of the incomplete projected syntactic structures, we adopt a new learning technique based on ambiguous labelings.", "sent2": "When tuned to attain the same accuracy, our algorithm is 4.0?7.7 times as fast as the Moses decoder with cube pruning.", "label": 0}
{"sent1": "Experimental results show that we achieve high classification performance.", "sent2": "Previously proposed clickthrough-based metrics of query ambiguity tend to conflate informational and ambiguous queries.", "label": 0}
{"sent1": "To mediate perceptual differences, this paper presents a new approach using probabilistic labeling for referential grounding.", "sent2": "This approach aims to integrate different types of evidence from the collaborative referential discourse into a unified scheme.", "label": 1}
{"sent1": "Several variations have been proposed that manipulate either, or both, the key and predicted mentions in order to get a one-to-one mapping.", "sent2": "On the other hand, the metric BLANC was, until recently, limited to scoring partitions of key mentions.", "label": 1}
{"sent1": "The problem is compounded by the fact that typical emails contain extraneous material that makes it difficult to isolate the content that is directed to the recipient of the email message.", "sent2": "Moreover, including this model as a component in an existing system yields significant performance gains on the Recognizing Textual Entailment challenge.", "label": 0}
{"sent1": "Our proposed metric is called Sentiment Annotation Complexity (SAC).", "sent2": "We aim to predict a score that quantifies this effort, using linguistic properties of the text.", "label": 1}
{"sent1": "In this paper, we propose a pragmatic approach to Chinese word segmentation on patents where we train a sequence labeling model based on a group of novel document-level features.", "sent2": "Experiments show that the accuracy of our model reached 96.3% (F 1 score) on the development set and 95.0% on a held-out test set.", "label": 1}
{"sent1": "We assume that microblogs share the same topics with external knowledge.", "sent2": "In this paper, we propose a novel model for enriching the content of microblogs by exploiting external knowledge, thus improving the data sparseness problem in short text classification.", "label": 1}
{"sent1": "We will describe and evaluate two approaches to this compilation problem.", "sent2": "Our methods find trends in the field including the rise of probabilistic methods starting in 1988, a steady increase in applications, and a sharp decline of research in semantics and understanding between 1978 and 2001, possibly rising again after 2001.", "label": 0}
{"sent1": "We present the first algorithm polynomial-time in sentence length for obtaining the minimal-length linearization of a dependency tree subject to constraints of mild context sensitivity.", "sent2": "For the minimally contextsensitive case of gap-degree 1 dependency trees, we prove several properties of minimallength linearizations which allow us to improve the efficiency of our algorithm to the point that it can be used on most naturallyoccurring sentences.", "label": 1}
{"sent1": "Our proposed methodology was evaluated two?fold: the learning and generalization capabilities were quantitatively evaluated using cross validation obtaining a level of accuracy of 89%.", "sent2": "Verb classes which integrate a wide range of linguistic properties (Levin, 1993) have proved useful for natural language processing (NLP) applications.", "label": 0}
{"sent1": "We first search the Web for pages containing a term in question.", "sent2": "We advocate hypergraphs as compact representations for sets of utterances describing the same event or object.", "label": 0}
{"sent1": "We show that it is possible to significantly decrease training and test corpus perplexity of the translation models.", "sent2": "In addition, we perform a rescoring of \u0002 -Best lists using our maximum entropy model and thereby yield an improvement in translation quality.", "label": 1}
{"sent1": "The NiuParser system runs fast and shows state-of-the-art performance on several benchmarks.", "sent2": "It turns out that weighted alignment according to the Needleman-Wunsch algorithm yields best results.", "label": 0}
{"sent1": "Abstract meaning representation (AMR) is a recent example of one such semantic formalism which, similar to a dependency parse, utilizes a graph to represent relationships between concepts (Banarescu et al., 2013).", "sent2": "Semantic parsers map natural language statements into meaning representations, and must abstract over syntactic phenomena, resolve anaphora, and identify word senses to eliminate ambiguous interpretations.", "label": 1}
{"sent1": "In this paper, we introduce data recombination, a novel framework for injecting such prior knowledge into a model.", "sent2": "We propose a number of solutions to this problem.", "label": 0}
{"sent1": "In this paper, we consider a much more expressive class of logical forms, and show how to use dynamic programming to efficiently represent the complete set of consistent logical forms.", "sent2": "We identify the different elements in a coordination phrase and label each element with its function.", "label": 0}
{"sent1": "We encode input utterances into vector representations, and generate their logical forms by conditioning the output sequences or trees on the encoding vectors.", "sent2": "The list is automatically compared and evaluated against a similarly ranked list of paraphrases proposed by human annotators, recruited and managed through Amazon?s Mechanical Turk.", "label": 0}
{"sent1": "In this analysis we present a crowd-sourced annotated corpus for topic level disagreement detection in Slashdot, showing that disagreement detection in this domain is difficult even for humans.", "sent2": "Many topics are unique to the conversation on the forum, and the appearance of disagreement may be much more subtle than on political blogs or social media sites such as twitter.", "label": 1}
{"sent1": "Due to significant sense ambiguity, our goal is to develop a sense-level rather than word-level lexicon.", "sent2": "To maximize the effectiveness of different types of information, we combine a graph-based method using WordNet 1 relations and a standard classifier using gloss information.", "label": 1}
{"sent1": "Emotion phrases are also extracted from the learned hashtags and used to create phrase-based emotion classifiers.", "sent2": "The toolkit is efficient, accurate and currently supports a range of features including EM sequence alignment and several decoding techniques novel in the context of G2P.", "label": 0}
{"sent1": "We present the first holistic, quantitative evaluation of these issues by contrasting two assistive modes: postediting and interactive machine translation (MT).", "sent2": "dialog system.", "label": 0}
{"sent1": "First of all, our approach is adapted for the specific translation task at hand by taking the corresponding source (target) language into account.", "sent2": "The use of A* search can dramatically reduce the time required to find a best parse by conservatively estimating the probabilities of parse completions.", "label": 0}
{"sent1": "We propose system- and application-independent evaluation and analysis methodologies for resources?", "sent2": "Simplification of complex sentences into simple structures is also applied for the extraction of the features.", "label": 0}
{"sent1": "This study is an attempt to analyze the structure of languages via a purely structural technique, namely spectral analysis, which is ideally suited for discovering the global correlations in a network.", "sent2": "Application of this technique to PhoNet, the co-occurrence network of consonants, not only reveals several natural linguistic principles governing the structure of the consonant inventories, but is also able to quantify their relative importance.", "label": 1}
{"sent1": "Even in domain, errors are often made where syntactic information does not provide sufficient cues.", "sent2": "In this paper, we mitigate both of these problems by employing distributional word representations gathered from unlabelled data.", "label": 1}
{"sent1": "In this paper, we will investigate the performance of these two types of models and that of a new approach based on compounding.", "sent2": "By applying an advanced entity linking system and a deep convolutional neural network model that matches questions and predicate sequences, our system outperforms previous methods substantially, and achieves an F 1 measure of 52.5% on the WEBQUESTIONS dataset.", "label": 0}
{"sent1": "This redundancy leads to misrepresentation of tree weight and reduced information for debugging and tuning purposes.", "sent2": "The error detection algorithm identified spuriously deleted content words with high precision.", "label": 0}
{"sent1": "The algorithm treats aggregation as a set partitioning problem and uses a global inference procedure to find an optimal solution.", "sent2": "Our experiments show that this approach yields substantial improvements over a clustering-based model which relies exclusively on local information.", "label": 1}
{"sent1": "While human evaluation is the most accurate way to compare systems, approximate automatic evaluation becomes critical during system development.", "sent2": "Human evaluators provide informal descriptions of each nugget, and judgements (assignments of nuggets to responses) for each response submitted by participants.", "label": 1}
{"sent1": "We demonstrate on TREC 2003, 2004, and 2005 data that our ?nugget pyramids?", "sent2": "In this work, we introduce a scoring model based on judgments from multiple assessors that captures a more refined notion of nugget importance.", "label": 1}
{"sent1": "Using a comparable corpus, a supervised method and two unsupervised methods have been assessed.", "sent2": "Furthermore, a list of Spanish opinion words is presented as a valuable resource.", "label": 1}
{"sent1": "This leads to smaller pools than traditional round robin pooling, thus reduces significantly the manual assessment workload.", "sent2": "Data-driven systems for natural language processing have the advantage that they can easily be ported to any language or domain for which appropriate training data can be found.", "label": 0}
{"sent1": "The expanded document provides a more accurate estimation of the document model, thus improves retrieval accuracy.", "sent2": "We construct a probabilistic neighborhood for each document, and expand the document with its neighborhood information.", "label": 1}
{"sent1": "The linear text representation is suboptimal for audio search, where accuracy can be significantly improved if the search includes alternate recognition candidates, commonly represented as word lattices.", "sent2": "This paper proposes a method for indexing word lattices that is suitable for large-scale web-search engines, requiring only limited code changes.", "label": 1}
{"sent1": "In this paper we report results of SRL experiments on nominalized predicates in Chinese, using a newly completed corpus, the Chinese Nombank.", "sent2": "Most notably, nouns that are nominalized forms of verbs and relational nouns generally are also considered to have their own predicate-argument structure.", "label": 1}
{"sent1": "Our experiments show that the use of a paraphrased synthetic reference refines the accuracy of automatic evaluation.", "sent2": "We apply our paraphrasing method in the context of machine translation evaluation.", "label": 1}
{"sent1": "Inspired by the recent graph-based NLP methods, we reinforce the generation probabilities by iterating random walks on the underlying graph representation.", "sent2": "The value at each dimension of the vector is closely related to the generation probability based on the language model of the corresponding document.", "label": 1}
{"sent1": "We show that this system with a fully automated transfer process performs better than the system with a hand-crafted bilingual dictionary.", "sent2": "More importantly, this has enabled us to create in less than one day a new language pair, French-Spanish, which, for a technical domain, surpasses the quality bar of the commercial system chosen for comparison.", "label": 1}
{"sent1": "Statistical information, obtained from a corpus, is then used to rank the paraphrases.", "sent2": "A distinctive feature is that CQA services usually organize questions into a hierarchy of natural categories.", "label": 0}
{"sent1": "First we identify two structural factors that contribute to the complexity of scenarios: the scattering of events in text, and inclusion relationships between events.", "sent2": "While most previous work accesses web text through search engine hit counts, we created a Web Corpus by downloading web pages to create a topic-diverse collection of 10 billion words of English.", "label": 0}
{"sent1": "This does not necessarily reflect the ?quality?", "sent2": "This can be very expensive, especially when skilled annotators are required.", "label": 0}
{"sent1": "by comparing estimated error reduction over observed error reduction on held-out datasets ?", "sent2": "In the evaluation using Formal Run and Reference Run data, there were several cases which our algorithm could not handle ellipsis correctly.", "label": 0}
{"sent1": "In a second step, the estimated model is used to re-rank the outputs of a number of surface realisers to produce stylistically adaptive output.", "sent2": "Crucially, we do not assume a pre-existing entity list (knowledge base), so entity characteristics are unknown.", "label": 0}
{"sent1": "In some cases, however, morphosyntactic evidence seems to be in conflict with semantic evidence.", "sent2": "For this reason dependency grammar theories, annotation guidelines and tree-to-dependency conversion schemes often differ in how they analyze various syntactic constructions.", "label": 1}
{"sent1": "Our approach combines machine learning with linguistic constraints and electronic resources.", "sent2": "We evaluate our system both intrinsically through a human judgment experiment, and extrinsically by passing its output to a letterto-phoneme converter.", "label": 1}
{"sent1": "Training the model is consistently ten times faster than Model 4.", "sent2": "The mega-word British component has been constructed, grammatically tagged, and syntactically parsed.", "label": 0}
{"sent1": "The first uses an expertcrafted but limited-coverage lexicon, Arabic WordNet, and heuristics.", "sent2": "We use opinion mining techniques to identify opinion expressions and determine their polarities and their targets.", "label": 0}
{"sent1": "Such a process of acquisition of translation rules is like a linked chain.", "sent2": "From the results of evaluation experiments, we confirmed the effectiveness of Recursive Chain-link-type Learning.", "label": 1}
{"sent1": "We propose a method which explicitly takes into account such interdependencies during the EM training of the statistical alignment models.", "sent2": "Existing statistical translation systems usually treat different derivations of the same base form as they were independent of each other.", "label": 1}
{"sent1": "Our method yields up to 16.3% error reduction compared to state-of-the-art systems, being the first to report successful semi-supervised domain adaptation.", "sent2": "We focus on the semi-supervised domain adaptation scenario, where we train on the source corpus and test on the target corpus, and try to improve results using unlabeled data.", "label": 1}
{"sent1": "topology of wordnets to cut down on time-expensive calculations performed by algorithms to solve the all-pairs shortest path problem in general graphs.", "sent2": "The algorithm was applied to two wordnets of two different languages: Princeton WordNet (Fellbaum, 1998) for English, and GermaNet (Kunze and Lemnitzer, 2002), the German language wordnet.", "label": 1}
{"sent1": "The method handles several languages at once, and avoids the complexity explosion due to the usual pair-bypair processing.", "sent2": "We introduce the problem of aspect aggregation at multiple granularities.", "label": 0}
{"sent1": "The higher level of abstraction afforded by dependency representations allows for a linguistically sound treatment of complex constructs requiring reordering and morphological change, such as conversion of passive voice to active.", "sent2": "We present a synchronous grammar formalism in which it is easy to write rules by hand and also acquire them automatically from dependency parses of aligned English and Simple English sentences.", "label": 1}
{"sent1": "Here, we introduce results on dependency parsing of Hungarian that employ a 80K, multi-domain, fully manually annotated corpus, the Szeged Dependency Treebank.", "sent2": "Generated summaries are less redundant and more coherent based upon manual quality evaluations.", "label": 0}
{"sent1": "the first such attempt using a deep learning approach.", "sent2": "Our intuition is to restrict distributional semantics to articles about the same event, thus promoting referential match.", "label": 0}
{"sent1": "Siamese CBOW handles this problem by training word embeddings directly for the purpose of being averaged.", "sent2": "The underlying neural network learns word embeddings by predicting, from a sentence representation, its surrounding sentences.", "label": 1}
{"sent1": "Specifically, we focus on the problem of lexical choice and investigate it in the context of three typologically diverse languages: Russian, Spanish and English.", "sent2": "We show that a statistical semantic model learned from L1 data improves automatic error detection in L2 for the speakers of the respective L1.", "label": 1}
{"sent1": "We show that the quality of machine-generated items approaches that of human-crafted ones.", "sent2": "Together these dimensions provide a summary of an utterance?s propositional content and how it may change the underlying information state of the conversation.", "label": 0}
{"sent1": "However, for relational network classification, DeepWalk can be suboptimal as it lacks a mechanism to optimize the objective of the target task.", "sent2": "To this end, we propose a cross language naive Bayes algorithm.", "label": 0}
{"sent1": "The proposed kernel outperforms the exiting state-of-the-art approaches on the BioInfer corpus, the largest PPI benchmark corpus available.", "sent2": "We deploy the framework on a CNN for sentiment analysis, and an RNN for named entity recognition.", "label": 0}
{"sent1": "In this method, dual decomposition is used as a framework to take advantage of both HPSG parsing and coordinate structure analysis with alignment-based local features.", "sent2": "The proposed approach yields improvements over state-of-the-art systems on a benchmark dataset.", "label": 0}
{"sent1": "Modeling the style of this genre can be very challenging given the shortage of available in-domain training data.", "sent2": "The key innovations provided by the toolkit are computeraided translation, including post-editing and interactive SMT, incremental learning and robust generation of alignments at phrase level.", "label": 0}
{"sent1": "We show that standard intrinsic metrics such as F-score alone do not predict the outcomes well.", "sent2": "However, we can build predictive performance functions that account for up to 50% of the variance in learning gain by combining features based on standard evaluation scores and on the confusion matrix entries.", "label": 1}
{"sent1": "The first approach employs the self-learning algorithm to generate the synthetic large-scale parallel data for NMT training.", "sent2": "The second approach applies the multi-task learning framework using two NMTs to predict the translation and the reordered source-side monolingual sentences simultaneously.", "label": 1}
{"sent1": "In this work, we argue that generating data can compensate for this need.", "sent2": "While defining generic data generators is difficult, we propose to allow generators to be ?weakly?", "label": 1}
{"sent1": "It is designed to support requirement engineers in the elicitation process on detecting and analyzing requirements in user-generated content.", "sent2": "We therefore present REaCT1, an automated approach for identifying and semantically annotating the on-topic parts of requirement descriptions.", "label": 1}
{"sent1": "An active-set outer loop allows the feature set to grow as far as needed.", "sent2": "Compositional Distributional Semantics Models (CDSMs) are traditionally seen as an entire different world with respect to Tree Kernels (TKs).", "label": 0}
{"sent1": "More importantly, we use the challenging task of politeness prediction as a testbed to next present a much-needed understanding of what these successful networks are actually learning.", "sent2": "For this, we present several network visualizations based on activation clusters, first derivative saliency, and embedding space transformations, helping us automatically identify several subtle linguistics markers of politeness theories.", "label": 1}
{"sent1": "The parser model follows up previous approach based on using tokenlevel (local) features with conditional random fields for shallow discourse parsing, which is lacking in structural knowledge of discourse.", "sent2": "Incorporating Discriminative Term Frequency and Inverse Document Frequency (DTFIDF), lexical affect scoring, and low and high level prosodic and acoustic features, our experiments outperform the published results of all systems participating in the 2010 Interspeech Paralinguistic Affect Subchallenge.", "label": 0}
{"sent1": "However, such models are ill-suited to probabilistic reasoning about spatial relationships between entities.", "sent2": "We demonstrate that it outperforms applicable baselines by a considerable margin.", "label": 0}
{"sent1": "In this paper, we show how to capture the underlying structure of a dialogue domain in terms of probabilistic rules operating on the dialogue state.", "sent2": "One central limitation is that the state space of such models grows exponentially with the problem size, which makes parameter estimation increasingly difficult, especially for domains where only limited training data is available.", "label": 1}
{"sent1": "The proposed method adopts a dynamic Bayesian network to learn the user action model directly from a machine-transcribed dialog corpus.", "sent2": "This paper proposes the use of unsupervised approaches to improve components of partition-based belief tracking systems.", "label": 1}
{"sent1": "It also provides a post-edition service which captures user post-editing data that can be used to incrementally improve the translations engines.", "sent2": "The key is to identify groups of objects that are naturally recognized by humans.", "label": 0}
{"sent1": "To help scholars identify and correct potential writing problems, we introduce SWAN (Scientific Writing AssistaNt) tool.", "sent2": "3LB annotation scheme has been developed for three languages (Spanish, Catalan and Basque).", "label": 0}
{"sent1": "The aim of such application is to attribute a title for a given text.", "sent2": "So, our application relies on three very different automatic titling methods.", "label": 1}
{"sent1": "We contrast two parameter estimation methods: the perceptron algorithm, and a method based on conditional random fields (CRFs).", "sent2": "Extracting biomedical events from literature has attracted much recent attention.", "label": 0}
{"sent1": "We show how a parser can be trained with a discriminative learning method while still parameterizing the problem according to a generative probability model.", "sent2": "One problem is that much of the work on discriminative methods conflates changes to the learning method with changes to the parameterization of the problem.", "label": 1}
{"sent1": "We also develop a new efficient parsing algorithm for CCG which maximises expected recall of dependencies.", "sent2": "The empirical evaluation shows that our approach significantly outperforms stateof-the-art systems across domains (cameras and movies) and across genres (reviews and forum posts).", "label": 0}
{"sent1": "To enable the proposed method to be executed efficiently, it is embedded into an original kernel calculation process by using sub-structure mining algorithms.", "sent2": "Reliance on syntactic ordering, however, may not be appropriate for individuals with limited or emerging literacy skills.", "label": 0}
{"sent1": "To accomplish this, the listener must parse the sentence, find constituents that are candidate arguments, and assign semantic roles to those constituents.", "sent2": "A fundamental step in sentence comprehension involves assigning semantic roles to sentence constituents.", "label": 1}
{"sent1": "The current paper attempts to address this deficiency by first proposing a framework for computing turn-taking model perplexity, and then by evaluating several multi-participant modeling approaches.", "sent2": "The set was generated by using an N-gram language model to generate a long list of likely words, given the immediate context.", "label": 0}
{"sent1": "The RL policies perform especially well in more complex scenarios.", "sent2": "We find their performance to be competitive with near state-of-art methods in English, Danish and Swedish.", "label": 0}
{"sent1": "On the task of identifying cognates in a dataset of Romance words, our model significantly outperforms a baseline approach, increasing accuracy by as much as 80%.", "sent2": "We also present a novel method for simplifying complex weighted automata created during inference to counteract the otherwise exponential growth of message sizes.", "label": 1}
{"sent1": "It is a problem that can occur in a number of practical applications, such as in the problem of determining the encodings of electronic documents in which the language is known, but the encoding standard is not.", "sent2": "Sparse alignments with high precision on the link level, for translation units, and on the subset of crossing links, like intersected HMM models, are preferred.", "label": 0}
{"sent1": "Empirically, our algorithm yields up to a five-fold speedup over a state-of-the-art shift-reduce dependency parser with no loss in accuracy.", "sent2": "We deployed six different kinds of terminology extraction methods, and participated in three different tasks: FR?EN and EN?", "label": 0}
{"sent1": "We augment a statistical classifier with an integer linear program imposing hard linguistic constraints on the solution space output by the classifier, capturing global distributional restrictions.", "sent2": "per clause.", "label": 1}
{"sent1": "We require only simple, deterministic grammar symbol refinement, in contrast to recent work on latent symbol refinement.", "sent2": "In this work we intend to use the knowledge represented in two ConceptNets, one in Brazilian Portuguese and another in English, to fix/filter translations built automatically.", "label": 0}
{"sent1": "In this paper, we propose a method to detect errors in corpora using support vector machines (SVMs).", "sent2": "In this paper, we present a compilation procedure to convert the rules resulting from an AdaBoost classifier into an WFST.", "label": 0}
{"sent1": "Specifically, we propose a new topic model called Probabilistic Cross-Lingual Latent Semantic Analysis (PCLSA) which extends the Probabilistic Latent Semantic Analysis (PLSA) model by regularizing its likelihood function with soft constraints defined based on a bilingual dictionary.", "sent2": "In this paper, we propose a way to incorporate a bilingual dictionary into a probabilistic topic model so that we can apply topic models to extract shared latent topics in text data of different languages.", "label": 1}
{"sent1": "We use a topic model to decompose this conditional probability into two conditional probabilities with latent variables.", "sent2": "This paper presents a probabilistic model for sense disambiguation which chooses the best sense based on the conditional probability of sense paraphrases given a context.", "label": 1}
{"sent1": "The paper begins by showing that LDA topic models can be viewed as a special kind of PCFG, so Bayesian inference for PCFGs can be used to infer Topic Models as well.", "sent2": "The results contribute to finding the proper contexts for extrinsic evalution in dynamic domains.", "label": 0}
{"sent1": "As experimental conditions we investigate different forms of textual context and linguistic complexity classes relative to syntax and semantics.", "sent2": "A novel method is introduced that utilizes the ICD-10 codes attached to care episodes to better induce domain-specificity in the semantic model.", "label": 0}
{"sent1": "In this paper, we extend these results by asking to what extent reading is well-modeled as rational behavior at a finer level of analysis, predicting not aggregate measures, but the duration and location of each fixation.", "sent2": "Many times, these hypotheses have been tested in reading by linking predictions about relative word difficulty to word-aggregated eye tracking measures such as go-past time.", "label": 1}
{"sent1": "These rules can be used to categorize student responses to short-answer questions.", "sent2": "The system is trained on written responses captured by an online assessment system that poses multiple choice questions and asks the student to justify their answers with textual explanations of their reasoning.", "label": 1}
{"sent1": "PLASER employs hidden Markov models to represent position-dependent English phonemes.", "sent2": "They are discriminatively trained using the standard American English TIMIT corpus together with a set of TIMIT utterances collected from ?good?", "label": 1}
{"sent1": "In both cases, students interact with the tutor through a web interface.", "sent2": "We present here a comparison between the two on a number of features of dialogue that have been demonstrated to correlate reliably with learning gains with students interacting with the tutor using the text based interface (Rose?", "label": 1}
{"sent1": "However, this paper focuses on a general-purpose system that allows arbitrary input.", "sent2": "Thus the architecture can be used for controlled-language-like translators that deliver very high quality, which is the traditional strength of GF.", "label": 1}
{"sent1": "In addition to this, the toolkit also provides standard SMT features such as fully-automatic translation, scalable and parallel algorithms for model training, client-server implementation of the translation functionality, etc.", "sent2": "We present a first step towards such a model, based on WordNet augmented with ontological classes provided by CoreLex.", "label": 0}
{"sent1": "Our hope is that a wide variety of annotation will be undertaken on the same corpora, which would facilitate: (1) the comparison of annotation schemes; (2) the merging of information represented by various annotation schemes; (3) the emergence of NLP systems that use information in multiple annotation schemes; and (4) the adoption of various types of best practice in corpus annotation.", "sent2": "We seek to identify a limited amount of representative corpora, suitable for annotation by the computational linguistics annotation community.", "label": 1}
{"sent1": "This implementation includes the creation of a substantial set of corpus annotations for dataintensive named entity recognition.", "sent2": "We construct a probabilistic neighborhood for each document, and expand the document with its neighborhood information.", "label": 0}
{"sent1": "The procedure of building the gold standard and the guidelines which were given to six human judges are described.", "sent2": "Our technique relies on an HMM to align the recipe steps to the (automatically generated) speech transcript.", "label": 0}
{"sent1": "Users can create formal propositions to represent spans of text, as well as temporal relations and other aspects of narrative.", "sent2": "It uses a phrase-based alignment representation, exploits external lexical resources, and capitalizes on a new set of supervised training data.", "label": 0}
{"sent1": "Joshua implements all of the algorithms required for translation via synchronous context free grammars (SCFGs): chart-parsing, n-gram language model integration, beam- and cubepruning, and k-best extraction.", "sent2": "We study three densification mechanisms that involve aligning sparse representation via many-to-many, many-to-one, and oneto-one mappings.", "label": 0}
{"sent1": "The system achieves an F-score of 0.834 in identifying sentences which describe interactions between biological entities.", "sent2": "Defining the reordering search space is a crucial issue in phrase-based SMT between distant languages.", "label": 0}
{"sent1": "An extra treatment of negative uses of projective prepositions (e.g.", "sent2": "We evaluate LEM on a Twitter corpus.", "label": 0}
{"sent1": "Our method, thus, requires gold standard trees only on the source side of a bilingual corpus in the training phase, unlike the joint parsing model, which requires gold standard trees on the both sides.", "sent2": "Dependency parsing has been shown to improve NLP systems in certain languages and in many cases helps achieve state of the art results in NLP applications, in particular applications for free word order languages.", "label": 0}
{"sent1": "The inference system is especially useful in the linguistic modules dealing with reference resolution and generation and we show how we use it to rank different readings in the case of referential and syntactic ambiguities.", "sent2": "Consequently, PUPA allows obtaining high quality parses without any human involvement.", "label": 0}
{"sent1": "whether it is perceived as point-like, linelike or area-like.", "sent2": "In this paper I present a Master?s thesis proposal in syntax-based Statistical Machine Translation.", "label": 0}
{"sent1": "Evaluation is performed against manual and semiautomatic methods using a fixed set of answer labels.", "sent2": "These models being language independent are improved with the use of language-dependent technique on the example  of  the  English  corpus.", "label": 0}
{"sent1": "In this paper, we propose a method based on importance sampling that allows us to use a very large target vocabulary without increasing training complexity.", "sent2": "We show that decoding can be efficiently done even with the model having a very large target vocabulary by selecting only a small subset of the whole target vocabulary.", "label": 1}
{"sent1": "A significant weakness in conventional NMT systems is their inability to correctly translate very rare words: end-to-end NMTs tend to have relatively small vocabularies with a single unk symbol that represents every possible out-of-vocabulary (OOV) word.", "sent2": "In this paper, we propose and implement an effective technique to address this problem.", "label": 1}
{"sent1": "With different guiding signals during decoding, our specifically designed convolution+gating architectures can pinpoint the parts of a source sentence that are relevant to predicting a target word, and fuse them with the context of entire source sentence to form a unified representation.", "sent2": "In this paper, we give a more systematic treatment by summarizing the relevant source information through a convolutional architecture guided by the target information.", "label": 1}
{"sent1": "Third, we apply multitask learning to estimate the neural network parameters jointly.", "sent2": "To measure relational similarity we employed lexical patterns that can match against word pairs within a large corpus of 12 million documents.", "label": 0}
{"sent1": "CCA is first used to derive low-dimensional gazetteer embeddings from domain-specific search logs.", "sent2": "We propose to improve word embeddings by incorporating morphological information, capturing shared sub-word features.", "label": 0}
{"sent1": "movements in a virtual environment.", "sent2": "Particularly, in complex referential scenes, where more objects next to the target are possible referents, gaze turns out to be beneficial and helps deciphering listeners?", "label": 1}
{"sent1": "All the three topics progress in terms of the scope of data in question.", "sent2": "We propose a novel subgroup detection method that combines linguistic signals and signed network analysis for dynamic clustering.", "label": 0}
{"sent1": "We argue that to devise an effective way to measure the similarity between languages one should build a probabilistic model that tries to capture as much regular correspondence between the languages as possible.", "sent2": "This approach yields two benefits.", "label": 1}
{"sent1": "Our three LDA-based approaches outperform two knowledge-based state-of-the art methods to lexical chaining by a large margin, which can be attributed to lacking coverage of the knowledge resource.", "sent2": "Also, we propose a new measure for direct evaluation of lexical chains.", "label": 1}
{"sent1": "The efficacy of these clusters is then evaluated on a diverse set of classification tasks that predict hidden users properties such as ethnicity, geographic location, gender, language, and race, using only profile names and locations when appropriate.", "sent2": "We separately cluster millions of unique first names, last names, and userprovided locations.", "label": 1}
{"sent1": "In this paper, we propose a novel latent variable model for viewpoint discovery from threaded forum posts.", "sent2": "Lately, this tendency has changed and recent works concentrate on data selection.", "label": 0}
{"sent1": "We show that the cooperative principle and the associated maxims of relevance, quality, and quantity emerge from multi-agent decision theory.", "sent2": "Grice characterized communication in terms of the cooperative principle, which enjoins speakers to make only contributions that serve the evolving conversational goals.", "label": 1}
{"sent1": "In this paper we describe a syntagmatic, corpus-based approach to redefining WordNet?s categories in a functional, gradable and context-sensitive fashion.", "sent2": "We describe how the diagnostic properties for these definitions are automatically acquired from the web, and how the increased flexibility in categorization that arises from these redefinitions offers a robust account of metaphor comprehension in the mold of Glucksberg?s (2001) theory of category-inclusion.", "label": 1}
{"sent1": "These implications state facts about the range of extant languages, such as ?if objects come after verbs, then adjectives come after nouns.?", "sent2": "Experimental results on web sentences indicate the effectiveness of our approach.", "label": 0}
{"sent1": "However, this approach requires prohibitive computational cost if we are dealing with quite a few features and training samples.", "sent2": "We tackle the problem by estimating the latent information in sentences using a semiMarkov class model, and then extracting features from them.", "label": 1}
{"sent1": "Comparisons are performed utilizing large models of 60000 lexical items and smaller vocabularies of 5000 items.", "sent2": "This paper compares various vocabulary decomposition approaches to open vocabulary speech recognition, using Estonian speech recognition as a benchmark.", "label": 1}
{"sent1": "Further, we present a technique for reconstructing the target language sentence from the selected words.", "sent2": "We compare the results of this approach against those obtained from a finite-state based statistical machine translation system which relies on local lexical associations.", "label": 1}
{"sent1": "These ambiguities can still be found when language is restricted to a particular domain, such as biomedicine.", "sent2": "A prior study has shown that a linkbased method, which completely ignores the content of the remarks, can achieve higher accuracy for the identification task than methods based solely on the contents of the remarks.", "label": 0}
{"sent1": "The user can manage topics, filter documents by topic and summarize views with metadata and topic graphs.", "sent2": "In this paper, we present a new web-based tool that integrates topics learned from an unsupervised topic model in a faceted browsing experience.", "label": 1}
{"sent1": "To achieve faster input, users only have to input consonant, which is then converted directly to Kanji sequences by direct consonant decoding.", "sent2": "The ASR confidence feature indicates whether each word has been correctly recognized.", "label": 0}
{"sent1": "We characterize the types of errors that occur using the word count approach, and find lexical ambiguity to be the most prevalent.", "sent2": "Temporal evidence classification, i.e., finding associations between temporal expressions and relations expressed in text, is an important part of temporal relation extraction.", "label": 0}
{"sent1": "We argue that more data of this kind would be helpful to improve existing approaches to linking implicit arguments in discourse and to enable more in-depth studies of the phenomenon itself.", "sent2": "One reason for this lies in the scarce amount of annotated data sets available.", "label": 1}
{"sent1": "Our approach can facilitate the construction of SRL models for resource-poor languages, while preserving the annotation schemes designed for the target language and making use of the limited resources available for it.", "sent2": "In this paper, we introduce a flexible notion of paths that describe chains of words on a dependency path.", "label": 0}
{"sent1": "In this paper, we describe the participants?", "sent2": "in each task and in general.", "label": 1}
{"sent1": "The ultimate purpose of produced summaries is defined as helping a reader to determine whether she would be interested in reading a particular story.", "sent2": "To this end, the summary aims to provide a reader with an idea about the settings of a story (such as characters, time and place) without revealing the plot.", "label": 1}
{"sent1": "The resulting data set is of importance for our research and it will contribute to and stimulate other research in the field of why-QA.", "sent2": "We developed a question analysis method for why-questions, based on syntactic categorization and answer type determination.", "label": 1}
{"sent1": "To cope with this challenge, we perform successive projections of the full model onto simpler models that operate over equivalence classes of logical forms.", "sent2": "The data is used for automatically learning phonological similarities between the two language pairs via EMbased clustering.", "label": 0}
{"sent1": "This paper will relieve this complexity in two ways.", "sent2": "Our corpus consists of child sentences with corrected adult forms.", "label": 0}
{"sent1": "We combine DAL scores with syntactic constituents and then extract ngrams of constituents from all sentences.", "sent2": "In this paper, we propose a method to transform traditional dialogue systems into incremental ones.", "label": 0}
{"sent1": "over other tree-structured models, and its integrated parser can operate on unparsed data with little loss in accuracy.", "sent2": "We evaluate it on the Stanford NLI entailment task and show that it significantly outperforms other sentence-encoding models.", "label": 1}
{"sent1": "We optimized the feature sets for the three languages: We carried out an extensive evaluation of pairs of features and we complemented the single features with associations that improved the CoNLL score.", "sent2": "We obtained the respective scores of 59.57, 56.62, and 48.25 on English, Chinese, and Arabic on the development set, 59.36, 56.85, and 49.43 on the test set, and the combined official score of 55.21.", "label": 1}
{"sent1": "We develop a learned graph matching approach to approximate entailment using the amount of the sentence?s semantic content which is contained in the text.", "sent2": "We present results on the Recognizing Textual Entailment dataset (Dagan et al, 2005), and show that our approach outperforms Bag-Of-Words and TF-IDF models.", "label": 1}
{"sent1": "We participated in the translation task for the following translation directions: French?English and English?French, in which we employed our multi-engine architecture to translate.", "sent2": "Word sense disambiguation aims to identify which meaning of a word is present in a given usage.", "label": 0}
{"sent1": "These methods were studied in the context of a system that uses compound processing, a morphological sequence model for German, and a partof-speech sequence model for English.", "sent2": "We focus on two methods to improve the word alignment: (i) by applying Giza++ in a second phase to a reordered training corpus, where reordering is based on the alignments from the first phase, and (ii) by adding lexical data obtained as highprecision alignments from a different word aligner.", "label": 1}
{"sent1": "The toolkit also implements suffix-array grammar extraction and minimum error rate training.", "sent2": "We explicitly model the longest span of such chunks, referred to as Maximal Orientation Span, to serve as a global parameter that constrains underlying local decisions.", "label": 0}
{"sent1": "As these languages fall out of use, we lose important sources of data that contribute to our understanding of human language.", "sent2": "Most of the world?s languages are under-resourced, and most under-resourced languages lack a writing system and literary tradition.", "label": 1}
{"sent1": "Most of the function words of a language are adpositions, and we show that function words can be effectively separated from content words by leveraging differences in their distributional properties in a corpus.", "sent2": "This task is often performed by a number of human judges.", "label": 0}
{"sent1": "We call this the answer-entailing structure; given the structure, the correctness of the answer is evident.", "sent2": "For this task, we posit that there is a hidden (latent) structure that explains the relation between the question, correct answer, and text.", "label": 1}
{"sent1": "Question retrieval in cQA archives aims to find the existing questions that are semantically equivalent or relevant to the queried questions.", "sent2": "Using feature analysis, contextual features are shown to be useful across languages and connectives.", "label": 0}
{"sent1": "In this paper, we introduce multi-column convolutional neural networks (MCCNNs) to understand questions from three different aspects (namely, answer path, answer context, and answer type) and learn their distributed representations.", "sent2": "Most of existing systems typically rely on hand-crafted features and rules to conduct question understanding and/or answer ranking.", "label": 1}
{"sent1": "First of all, we carry out a largescale evaluation, comparing different composition methods within the distributional framework for the cases of both adjectivenoun and noun-noun composition, making use of a newly developed dataset.", "sent2": "Secondly, we propose a novel method for composition, which generalises the approach by Baroni and Zamparelli (2010).", "label": 1}
{"sent1": "in that it computes meanings word-by-word.", "sent2": "We present an account of word and phrase meaning that is perceptually grounded, trainable, compositional, and ?dialogueplausible?", "label": 1}
{"sent1": "Using only dense features, our neural CRF already exceeds a strong baseline CRF model (Hall et al., 2014).", "sent2": "Hindi is an Indian language which is relatively rich in morphology.", "label": 0}
{"sent1": "Our model can automatically learn high-order feature combinations using only atomic features by exploiting a novel activation function tanhcube.", "sent2": "Moreover, we propose a simple yet effective way to utilize phrase-level information that is expensive to use in conventional graph-based parsers.", "label": 1}
{"sent1": "Given this fixed network representation, we learn a final layer using the structured perceptron with beam-search decoding.", "sent2": "Furthermore,  we  show  how  the  use  of  hard constraints and soft constraints helps  us  build  an  efficient  and  robust  hybrid  parser.", "label": 0}
{"sent1": "Dawborn and Curran (2014) have developed a declarative description and storage for structured annotation, on top of which we have built generic command-line utilities.", "sent2": "To overcome this limitation, this paper proposes a method utilizing the perceptual groups of objects and n-ary relations among them.", "label": 0}
{"sent1": "Like the conventional stack data structures used in transitionbased parsing, elements can be pushed to or popped from the top of the stack in constant time, but, in addition, an LSTM maintains a continuous space embedding of the stack contents.", "sent2": "This lets us formulate an efficient parsing model that captures three facets of a parser?s state: (i) unbounded look-ahead into the buffer of incoming words, (ii) the complete history of actions taken by the parser, and (iii) the complete contents of the stack of partially built tree fragments, including their internal structures.", "label": 1}
{"sent1": "We replace this large pattern set with a few patterns for canonically structured sentences, and shift the focus to a classifier which learns to extract self-contained clauses from longer sentences.", "sent2": "Traditionally these are extracted using a large set of patterns; however, this approach is brittle on out-of-domain text and long-range dependencies, and gives no insight into the substructure of the arguments.", "label": 1}
{"sent1": "We create several baselines and experiment with various parameter settings for three algorithms, i.e., Conditional Random Fields (CRF), Support Vector Machines (SVM) and Random Forests (RF).", "sent2": "We here describe an approach to the automatic identification of discourse causality triggers in the biomedical domain using machine learning.", "label": 1}
{"sent1": "We further add weights to the reordering automata.", "sent2": "We show how to compute reordering automata on-demand using IBM or ITG constraints, and also introduce two new types of reordering constraints.", "label": 1}
{"sent1": "Obtaining their training and test data for English?French, we carry out a number of experiments using the Pharaoh SMT Decoder.", "sent2": "Occurence patterns of words in documents can be expressed as binary vectors.", "label": 0}
{"sent1": "We will evaluate the quality of the word graphs using the well-known graph word error rate.", "sent2": "We will use these word graph to provide an analysis of the search process.", "label": 1}
{"sent1": "Each of the parts is translated by a recursive application of the model and the resulting translation are then concatenated.", "sent2": "The generative process begins by splitting the input sentence in two parts.", "label": 1}
{"sent1": "We use a richer framework that allows for probabilistic generalization, with a word represented as a probability distribution over a space of generalized classes: lemmas, clusters, or synsets.", "sent2": "The standard approach for lexical generalization in parsing is to map a word to a single generalized class, either replacing the word with the class or adding a new feature for the class.", "label": 1}
{"sent1": "If the existing lexicon has only one half of the alternation, then our method constructs the other half.", "sent2": "The new entries have detailed information about argument structure and selectional restrictions.", "label": 1}
{"sent1": "In this framework, parallel translations whose source language sentence is similar to a given sentence can be semiautomatically generated.", "sent2": "We integrate a variety of linguistic resources to produce an immense knowledge graph.", "label": 0}
{"sent1": "The generic aspect of our platform allows its use for the development of other lexical databases.", "sent2": "For this, we developed a generic community website originally dedicated to the diffusion and the development of a particular acception based multilingual lexical database.", "label": 1}
{"sent1": "Then, they are assembled (CPXM.dtd) to visualize them in parallel through the web.", "sent2": "This is the first large-scale experimentation with automatic algorithms for this task.", "label": 0}
{"sent1": "To make matters worse, the resources are typically specific to the domain in question and not portable to new tasks.", "sent2": "By exploiting semantic regularities between hyponyms and hypernyms in embeddings spaces, and integrating a domain clustering algorithm, our model becomes sensitive to the target data.", "label": 0}
{"sent1": "In this system, the performance of the heuristics is optimized for specific dialogues using genetic algorithms, which relieves the programmer of hand-crafting the weights of these heuristics.", "sent2": "These extracted terms become the candidates for the final step.", "label": 0}
{"sent1": "Unlike in controlled and restricted dialogue systems a simple oneto-one mapping from words to meanings is no longer feasible here.", "sent2": "A ?serial architecture?", "label": 0}
{"sent1": "Then, several types of features are defined for automatic disambiguation of like: collocations, part-of-speech tags and duration-based features.", "sent2": "Linguistic research on multilingual societies has indicated that there is usually a preferred language for expression of emotion and sentiment (Dewaele, 2010).", "label": 0}
{"sent1": "We present in this paper a novel computational model capable to detect sarcasm in the social network Twitter (a popular microblogging service which allows users to post short messages).", "sent2": "Our model is easy to implement and, unlike previous systems, it does not include patterns of words as features.", "label": 1}
{"sent1": "In the classification we use a novel unsupervised learning algorithm based on the idea of language combinatorics.", "sent2": "This paper assumes that the DIH sometimes fails, and investigates other ways of quantifying the relationship between the cooccurrence contexts of two terms.", "label": 0}
{"sent1": "With this aim we make preliminary filtering of subjective tweets using general domain-independent lexicons in each language.", "sent2": "Then the subjective tweets are used for extraction of domain-specific sentiment words.", "label": 1}
{"sent1": "In this paper we compare two sentiment lexicon approaches to classify the sentiment of sentences from political discussions.", "sent2": "The first approach is based on applying the number of words between the target and the sentiment words to weight the sentence sentiment score.", "label": 1}
{"sent1": "We proceeded incrementally, starting from a minimal system put on a toll-free telephone number to collect speech data.", "sent2": "We describe our experience with bootstrapping a dialogue system for public transit and weather information in real-word deployment under public use.", "label": 1}
{"sent1": "As a result, they have to be implemented from scratch.", "sent2": "In this paper, we propose a method to transform traditional dialogue systems into incremental ones.", "label": 1}
{"sent1": "This paper investigates incorporating task features into an unsupervised dialogue act model trained on a corpus of human tutoring in introductory computer science.", "sent2": "Cue  detection  is  performed  using  regular  expression  rules  extracted  from  the  training  data.", "label": 0}
{"sent1": "Because the words relevant to short- and medium-term interest rates differ, we apply a supervised approach to learn distinct sets of topics for each dependent variable being examined.", "sent2": "Remarkable is the fact that precision drops to 52% without lexicalization.", "label": 0}
{"sent1": "We evaluate the approach on recommending Wikipedia descriptions of ingredients to their associated product categories.", "sent2": "As neural models require substantial training time, we introduce a sequential component so as to quickly adjust the learned metric over objects as additional evidence accrues.", "label": 1}
{"sent1": "Finally, we show that GEC metrics are much more reliable when they are calculated at the sentence level instead of the corpus level.", "sent2": "We have set up a CodaLab site for benchmarking GEC output using a common dataset and different evaluation metrics.", "label": 1}
{"sent1": "In this work, we tackle addressee and response selection for multi-party conversation, in which systems are expected to select whom they address as well as what they say.", "sent2": "To create conversational systems working in actual situations, it is crucial to assume that they interact with multiple agents.", "label": 1}
{"sent1": "In this paper, we explore how a regression-based approach might offer such insights into modeling predictive relationships between speaker behaviors and addressee backchannels in a storytelling scenario.", "sent2": "Our results reveal speaker eye contact as a significant predictor of verbal, nonverbal, and bimodal backchannels and utterance boundaries as predictors of nonverbal and bimodal backchannels.", "label": 1}
{"sent1": "Such type of understanding is required in conversational systems that need to act immediately on language input, such as multi-modal systems or dialogue systems for robots.", "sent2": "Search support provided by the tool fosters this aspect and is helpful for building natural language processing modules in general.", "label": 0}
{"sent1": "The final tracker is a combination of a rulebased model, a maximum entropy and a deep neural network model.", "sent2": "Sparse representations of text such as bag-ofwords models or extended explicit semantic analysis (ESA) representations are commonly used in many NLP applications.", "label": 0}
{"sent1": "features, which can lead to more efficiency and flexibility in tracking user goal changes.", "sent2": "Syntax is derived from constituent and dependency parse trees whereas semantics concerns to entity types and lexical sequences.", "label": 0}
{"sent1": "Supervised hierarchical topic modeling makes heavy use of the information from observed hierarchical labels, but cannot explore new topics; while unsupervised hierarchical topic modeling is able to detect automatically new topics in the data space, but does not make use of any information from hierarchical labels.", "sent2": "Supervised hierarchical topic modeling and unsupervised hierarchical topic modeling are usually used to obtain hierarchical topics, such as hLLDA and hLDA.", "label": 1}
{"sent1": "At both training and test time we marginalize over this hidden structure, learning the optimal latent representations for the problem.", "sent2": "Results show that this approach provides significant gains over a syntactically uninformed baseline, outperforming models that observe syntax on an English relation extraction task, and performing comparably to them in semantic role labeling.", "label": 1}
{"sent1": "We also define a simple HMM emission initialization that takes advantage of the tag dictionary and raw data to capture both the openness of a given tag and its estimated prevalence in the raw data.", "sent2": "Paraphrase criteria especially the paraphrase rate is not able to be ensured in that way.", "label": 0}
{"sent1": "We explore the feature space in this task and argue that collecting person specific evidences from a corpus level can provide a more reasonable and robust estimation for evaluating a feature?s importance in a given web page.", "sent2": "In order to evaluate the method, we applied the results of topic detection to extractive multi-document summarization.", "label": 0}
{"sent1": "For example, our model learns that someone is unlikely to start a job at age two or to marry someone who hasn?t been born yet.", "sent2": "With this in mind, the SemEval-2014 Analysis of Clinical Text task aimed at assessing and improving current methods for identification and normalization of concepts occurring in clinical narrative.", "label": 0}
{"sent1": "We describe a simple technique for reducing out-of-vocabulary rate after phrase extraction.", "sent2": "We discuss the benefits of tuning towards multiple reference translations for English-Czech language pair.", "label": 1}
{"sent1": "Until now, most SMT approaches are only able to model local reorderings.", "sent2": "In this paper we describe a new approach to model long-range word reorderings in statistical machine translation (SMT).", "label": 1}
{"sent1": "We use the DE classifier to preprocess MT data by explicitly labeling { (DE) constructions, as well as reordering phrases, and show that our approach provides significant BLEU point gains on MT02 (+1.24), MT03 (+0.88) and MT05 (+1.49) on a phrasedbased system.", "sent2": "The proliferation of user-generated web content such as blogs, discussion forums and online review sites has made it possible to perform large-scale mining of public opinion.", "label": 0}
{"sent1": "However, these metrics suffer a significant decrease at the sentence level.", "sent2": "This leads to the routine use of approximate inference such as beam search but there is not much theory behind it.", "label": 0}
{"sent1": "We explore these differences through the use of a new tunable MT metric: TER-Plus, which extends the Translation Edit Rate evaluation metric with tunable parameters and the incorporation of morphology, synonymy and paraphrases.", "sent2": "Different types of human judgments, such as Fluency, Adequacy, and HTER, measure varying aspects of MT performance that can be captured by automatic MT metrics.", "label": 1}
{"sent1": "This approach leads to a representation of requests based on the inclusion of a semantic level under a pragmatic level via a structural level.", "sent2": "We suggest a model which is confined to simple lexical information, but is formulated as a principled generative probabilistic model.", "label": 0}
{"sent1": "Afterwards, text segments and their topic are identified in the output of automatic speech recognition.", "sent2": "First, we employ SVM classification to assign whole reports to coarse work-type categories.", "label": 1}
{"sent1": "We describe some experiments with judgments of the House of Lords where we have performed automatic linguistic annotation of a small sample set in order to explore correlations between linguistic features and argumentative roles.", "sent2": "We first present a neural network based relation extractor to retrieve the candidate answers from Freebase, and then infer over Wikipedia to validate these answers.", "label": 0}
{"sent1": "In this paper, we describe and analyze the human annotation process of rich semantic structures in order to train semantic statistical parsers.", "sent2": "We have annotated spoken conversations from both a human-machine and a human-human spoken dialog corpus.", "label": 1}
{"sent1": "In this paper, we propose a concept-specific language model adaptation strategy where the language model (LM) is adapted to the concept type(s) actually present in the user?s post-confirmation utterance.", "sent2": "We evaluate concept type classification and LM adaptation for post-confirmation utterances in the Let?s Go!", "label": 1}
{"sent1": "Furthermore, speech recognition is known to be a highly error-prone task, especially for complex, open-ended discourse domains.", "sent2": "Systems were presented with pairs of sentences and were evaluated on their ability to predict human judgments on (i) semantic relatedness and (ii) entailment.", "label": 0}
{"sent1": "along with the linking relation that exists between them.", "sent2": "We then show that a simpler particle filter implementation performs just as well, and that the quality of the initialization dominates other factors of performance.", "label": 0}
{"sent1": "In this paper, we use a subsumption hierarchy to formally define different types of lexical features and their relationship to one another, both in terms of representational coverage and performance.", "sent2": "This paper reports preliminary experiments on part-whole extraction from a corpus of anatomy definitions, using a fully automatic iterative algorithm to learn simple lexico-syntactic patterns from multiword terms.", "label": 0}
{"sent1": "We first introduce a multinomial model that combines CF and CBF in a language modeling framework.", "sent2": "We present a generative probabilistic modeling approach to building content distributions for use with statistical multi-document summarization where the syntax words are learned directly from the data with a Hidden Markov Model and are thereby deemphasized in the term frequency statistics.", "label": 0}
{"sent1": "At the same time, we make an extensive study on users?", "sent2": "This statistical component is augmented by a knowledge-driven hub-page identifier that retrieves a hub-page for the most salient noun phrase in the question, if possible.", "label": 0}
{"sent1": "We propose a hybrid model that is capable of representing both types of features, and describe efficient algorithms for its training and inference.", "sent2": "Yet the availability of clean training data for the former is still a severe challenge.", "label": 0}
{"sent1": "Performance is compared with two corresponding probabilistic approaches based on Markov chains.", "sent2": "Knowledge bases (KBs) are often greatly incomplete, necessitating a demand for KB completion.", "label": 0}
{"sent1": "to a sequence of tokens in a document.", "sent2": "This paper presents results of using belief functions to rank the list of candidate information provided in a noisy dialogue input.", "label": 0}
{"sent1": "Then we propose to bound the relaxed objective function by the supermodular binary quadratic programming problem, which can be solved efficiently using graph max-flow/min-cut.", "sent2": "Evaluation demonstrates BLEU scores competitive with state-of-the-art SMT systems such as Moses.", "label": 0}
{"sent1": "Content plans are represented intuitively by a set of grammar rules that operate on the document level and are acquired automatically from training data.", "sent2": "In this paper we focus on the problem of generating text from a database and present a trainable end-to-end generation system that includes both content selection and ordering.", "label": 1}
{"sent1": "Most of the existing work on IMT uses batch learning paradigm which does not allow translation systems to make use of the new input instantaneously.", "sent2": "But their limited ability to model long-distance information presents a bottleneck to make further improvements.", "label": 0}
{"sent1": "While we agree that ultimately a combination of shallow and deep features is needed to balance the preciseness of exemplars with the usefulness of generalizations to avoid data sparsity, in this paper we explore the limits of a purely surfacebased prediction of prepositions.", "sent2": "Fully unsupervised pattern-based methods for discovery of word categories have been proven to be useful in several languages.", "label": 0}
{"sent1": "Entity-density (a discourse feature) and POS-features, in particular nouns, are individually very useful but highly correlated.", "sent2": "We find that features based on in-domain language models have the highest predictive power.", "label": 1}
{"sent1": "In this paper, we present a shift-reduce decoding algorithm that can generate ITG-legal translation from left to right in linear time.", "sent2": "We describe Joshua, an open source toolkit for statistical machine translation.", "label": 0}
{"sent1": "Past approaches have suggested using stems or synonyms for OOV words.", "sent2": "We propose combining these two approaches, thus allowing a formal specification of the dialogue behavior, and allowing hand-crafted preconditions, with remaining ones determined via reinforcement learning so as to minimize dialogue cost.", "label": 0}
{"sent1": "Spreading activation is then used on this network in order to judge the strengths of all relationships connecting the terms.", "sent2": "This paper proposes a new approach, whereby relationships are derived from natural language text by using existing nlp tools, then integrated into a large scale semantic network.", "label": 1}
{"sent1": "The average readers of these two newspapers are middle-aged (55 and 47 years old, respectively), and the annotated articles are more than 20 years old by now.", "sent2": "parser compiler, which allows to generate a robust shallow?parser for any language, even in the absence of training data, by resorting to a very limited number of rules which aim at identifying constituent boundaries.", "label": 0}
{"sent1": "However, many phrase reorderings are arbitrary because the models are weak on determining phrase boundaries for patternmatching.", "sent2": "Hierarchical phrase-based models provide a powerful mechanism to capture non-local phrase reorderings for statistical machine translation (SMT).", "label": 1}
{"sent1": "Our approach reveals some of the structure of model summaries and identifies topics that are good approximations of the Summary Content Units (SCU) used in the Pyramid method.", "sent2": "In this paper, we present an unsupervised, probabilistic topic modeling approach for automatically identifying such semantically similar text spans.", "label": 1}
{"sent1": "We apply the algorithm over a large data set of extracted predicate instances, from which a resource of typed entailment rules has been recently released (Schoenmackers et al, 2010).", "sent2": "Our results show that using global transitivity information substantially improves performance over this resource and several baselines, and that our scaling methods allow us to increase the scope of global learning of entailment-rule graphs.", "label": 1}
{"sent1": "Incremental syntactic language models score sentences in a similar left-to-right fashion, and are therefore a good mechanism for incorporating syntax into phrase-based translation.", "sent2": "This requirement makes it difficult to incorporate them into phrase-based translation, which generates partial hypothesized translations from left-to-right.", "label": 1}
{"sent1": "However, two aspects of BTM may restrict its performance: 1) user individualities are ignored to obtain the corpus level words co-occurrence patterns; and 2) the strong assumptions that two co-occurring words will be assigned the same topic label could not distinguish background words from topical words.", "sent2": "Biterm Topic Model (BTM) is designed to model the generative process of the word co-occurrence patterns in short texts such as tweets.", "label": 1}
{"sent1": "In this paper, we propose a novel phrase-based translation model for question retrieval.", "sent2": "We evaluated distributions of the CMs by average errors from the reference.", "label": 0}
{"sent1": "We show that for three leading unsupervised parsers (Klein and Manning, 2004; Cohen and Smith, 2009; Spitkovsky et al, 2010a), a small set of parameters can be found whose modification yields a significant improvement in standard evaluation measures.", "sent2": "The proposed method requires only a monolingual corpus of the source language to find candidate replacements.", "label": 0}
{"sent1": "In this paper, we develop a shift-reduce CCG parser using a discriminative model and beam search, and compare its strengths and weaknesses with the chart-based C&C parser.", "sent2": "or ?morning exercise?.", "label": 0}
{"sent1": "These features encode both surface evidence of lexical affinities as well as paraphrase-based cues to syntactic structure.", "sent2": "A common form of sarcasm on Twitter consists of a positive sentiment contrasted with a negative situation.", "label": 0}
{"sent1": "Our approach uses a log-linear reranker, operating on the top n analyses of a noisy channel model.", "sent2": "The model uses an affective lexicon automatically generated from a very large corpus of raw web data.", "label": 0}
{"sent1": "We consider the task of out of vocabulary (OOV) word detection, which relies on output from a hybrid model.", "sent2": "We consider two main approaches: (1) deriving simplification probabilities via an edit model that accounts for a mixture of different operations, and (2) using metadata to focus on edits that are more likely to be simplification operations.", "label": 0}
{"sent1": "Our experimental results demonstrate that our approach is able to reduce word error rate relatively by about 3%.", "sent2": "This gain is consistent across the two different tests, showing promising future directions of incorporating prosodic information to improve speech recognition.", "label": 1}
{"sent1": "Next, a discriminative HMM selects the best subset of codes to assign to the document by tagging candidates as present or absent.", "sent2": "Some are shallow while others operate over syntactic structure, rely on parameter learning, or require access to very large corpora.", "label": 0}
{"sent1": "Specifically, we parse sentences into dependency trees and represent them as a graph, and assume the topic assignment of a word is influenced by its adjacent words and distance-2 words.", "sent2": "Due to errors in the hypothesis alignment, decoding may result in ungrammatical combination outputs.", "label": 0}
{"sent1": "Through experimentation with a range of years, we found that the birth dates of students in college at the time when social media such as AIM, SMS text messaging, MySpace and Facebook first became popular, enable accurate age prediction.", "sent2": "Automatic post-editing (APE) systems aim at correcting the output of machine translation systems to produce better quality translations, i.e.", "label": 0}
{"sent1": "Association information has so far not been used in CoRe because it is sparse and difficult to learn from small labeled corpora.", "sent2": "We apply the machine learning based Turku Event Extraction System to both tasks.", "label": 0}
{"sent1": "In this paper we show how we can improve the performance of the recurrent neural network (RNN) language model by incorporating the syntactic dependencies of a sentence, which have the effect of bringing relevant contexts closer to the word being predicted.", "sent2": "Our main focus is the interaction between the political scientists and the natural language processing groups to ensure a beneficial assistance for the political scientists and new application challenges for NLP.", "label": 0}
{"sent1": "This approach takes advantage of phrase alignments and source-side parse trees for pattern extraction, and then filters out those patterns without functional words.", "sent2": "Here, a new method based on using a statistical machine translation system has been introduced to mitigate the effects of data sparsity for training classifiers.", "label": 0}
{"sent1": "A discriminative approach for learning lexical selection and reordering utilizes a large set of feature functions (thereby providing the power to incorporate greater contextual and linguistic information), which leads to an effective training of these models.", "sent2": "Our results suggest that the averaged context DBN model and the Pair HMM achieve the highest accuracy given a large training set of positive examples.", "label": 0}
{"sent1": "We conducted experiments on an EnglishHindi parallel corpora.", "sent2": "In this paper, we propose a dependency based statistical system that uses discriminative techniques to train its parameters.", "label": 1}
{"sent1": "We present a novel discriminative, probabilistic tree transduction model, and contribute a set of empirical upperbounds on translation performance for Englishto-Dutch source string permutation under sequence and parse tree constraints.", "sent2": "The experimental results on a domain specific corpus show that the method performs better than other approaches.", "label": 0}
{"sent1": "Our system uses a trainable classifier to predict ?edit scripts?", "sent2": "that are then used to transform lemmas into inflected word forms.", "label": 1}
{"sent1": "The maximum entropy classifier is trained to identify and classify the predicates?", "sent2": "Our model consists of two sub-models: an anchor word alignment model which aims to find a set of high-precision anchor links and a syntaxenhanced word alignment model which focuses on aligning the remaining words relying on dependency information invoked by the acquired anchor links.", "label": 0}
{"sent1": "For an input sentence, syntactic constituent structure parses are generated by a Charniak parser and a Collins parser.", "sent2": "Phrase-based decoding produces state-of-theart translations with no regard for syntax.", "label": 0}
{"sent1": "In particular, some probability distributions expressible in terms of a context-free grammar cannot be expressed in terms of the LR parser constructed from that grammar, under the restrictions of the existing approaches to training of LR parsers.", "sent2": "Information graphics (bar charts, line graphs, etc.)", "label": 0}
{"sent1": "We report on the performance of the morphological analyzer and part-of-speech tagger.", "sent2": "Similar words have better chance to be put into the same topic due to the regularization of MRF, hence the coherence of topics can be boosted.", "label": 0}
{"sent1": "We show that a model whose terminal symbols are word segments (=morphemes), is advantageous over a word-level model for the task of POS tagging.", "sent2": "We evaluate our training method with Noun Phrase Chunking, Text Chunking and Extended Named Entity Recognition.", "label": 0}
{"sent1": "We adopt a minimally supervised approach that only requires raw text data from several varieties of Arabic and a morphological analyzer for Modern Standard Arabic.", "sent2": "No dialect-specific tools are used.", "label": 1}
{"sent1": "Experiments on a clearly stated partition of the ACE 2004 data show that stem-based features can significantly improve the performance of the EDT system by 2 absolute F-measure points.", "sent2": "Developing natural language processing tools for low-resource languages often requires creating resources from scratch.", "label": 0}
{"sent1": "Amharic is the language for countrywide communication in Ethiopia and has its own writing system containing extensive systematic redundancy.", "sent2": "Particularly, we introduce the morphological knowledge as both additional input representation and auxiliary supervision to the neural network framework.", "label": 0}
{"sent1": "English and Italian).", "sent2": "In this paper, we identify the semantic relations essential to this task and discuss how to efficiently collect valid examples from Web documents by splitting complex sentences into fundamental units of meaning called ?statements?", "label": 0}
{"sent1": "with increased polarity over the adjective alone.", "sent2": "produces a phrase (?very good?)", "label": 1}
{"sent1": "These induced parses are used to preorder source sentences.", "sent2": "We demonstrate that our induced parser is effective: it not only improves a state-of-the-art phrase-based system with integrated reordering, but also approaches the performance of a recent preordering method based on a supervised parser.", "label": 1}
{"sent1": "Our best classifier based on the combination of active learning and selftraining outperforms our best supervised classifier, yielding a high accuracy of 81% when using just 10% of the labeled data.", "sent2": "We investigate the performance of four weakly-supervised classifiers on scientific abstract data annotated for multiple AZ classes.", "label": 1}
{"sent1": "APS scales linearly for realistic segmentation tasks.", "sent2": "Based on this corpus, we conducted a preliminary experiment on cohesion evaluation, obtaining encouraging results.", "label": 0}
{"sent1": "We define a universal morphological feature space in which every language and its morphological analysis reside.", "sent2": "We develop a novel structured nearest neighbor prediction method which seeks to find the morphological analysis for each unlabeled language which lies as close as possible in the feature space to a training language.", "label": 1}
{"sent1": "We use softmaxmargin to optimise a log-linear CCG parser for a variety of loss functions, and demonstrate a novel dynamic programming algorithm that enables us to use it with F-measure, leading to substantial gains in accuracy on CCGBank.", "sent2": "In this work we revisit this issue and present a multi-task learning based system which can effectively use synthetic data for implicit discourse relation recognition.", "label": 0}
{"sent1": "These sentences may be selected with simple cross-entropy based methods, of which we present three.", "sent2": "In this paper, we propose a novel approach for translating agglutinative languages by treating stems and affixes differently.", "label": 0}
{"sent1": "It has long been the hope that by tuning machine translation systems against these new generation metrics, advances in automatic machine translation evaluation can lead directly to advances in automatic machine translation.", "sent2": "Many machine translation evaluation metrics have been proposed after the seminal BLEU metric, and many among them have been found to consistently outperform BLEU, demonstrated by their better correlations with human judgment.", "label": 1}
{"sent1": "number of clusters based on the similarity of their contexts.", "sent2": "This paper presents an unsupervised word sense learning algorithm, which induces senses of target word by grouping its occurrences into a ?natural?", "label": 1}
{"sent1": "Most previous work simplifies sentences using handcrafted rules aimed at splitting long sentences, or substitutes difficult words using a predefined dictionary.", "sent2": "This paper presents a datadriven model based on quasi-synchronous grammar, a formalism that can naturally capture structural mismatches and complex rewrite operations.", "label": 1}
{"sent1": "When something goes wrong, a system can ask for clarification, rewording, or otherwise redirect the interaction to achieve its goals.", "sent2": "We propose a new probabilistic graphical model called MCTA which can cope with the language gap and capture the common semantics in different languages.", "label": 0}
{"sent1": "We provide a method for identifying such terms.", "sent2": "Our method is based on the notion of in-domain terms which can be thought of as the most important contextually relevant words.", "label": 1}
{"sent1": "We show the benefit of our incongruity features for two text forms - tweets and discussion forum posts.", "sent2": "Our system also outperforms two past works (with Fscore improvement of 10-20%).", "label": 1}
{"sent1": "using linear transformations over the parameters of a generic model ?", "sent2": "Results show that accounting for multiple derivations does indeed improve performance.", "label": 0}
{"sent1": "Local features are first collected by bi-directional long short term memory network, then combined and refined to long distance dependencies via gated recursive neural network.", "sent2": "Our system produces two versions of summaries for each document: generic summary without considering annotations and annotation-based summary.", "label": 0}
{"sent1": "Historically, syntactic parsing has been mainly tackled using generative models.", "sent2": "Morphologically rich languages (MRL) are languages in which much of the structural information is contained at the wordlevel, leading to high level word-form variation.", "label": 1}
{"sent1": "In this work, we bring these two ideas together and show that given raw text, a dictionary, and eyetracking data obtained from naive participants reading text, we can train a weakly supervised PoS tagger using a secondorder HMM with maximum entropy emissions.", "sent2": "The best model use type-level aggregates of eye-tracking data and significantly outperforms a baseline that does not have access to eye-tracking data.", "label": 1}
{"sent1": "As NLP becomes increasingly wide-spread and uses more data from social media, however, the situation has changed: the outcome of NLP experiments and applications can now have a direct effect on individual users?", "sent2": "This paper suggests two ways of improving semantic role labeling (SRL).", "label": 0}
{"sent1": "In addition, most of these datasets do not allow ties and integrate simplification ranking from all the annotators without considering the quality.", "sent2": "All of them substitute only a single target word, and some of them extract sentences only from newswire corpus.", "label": 1}
{"sent1": "We present how k-best alignments are constructed over target-side dependency forests.", "sent2": "This paper introduces a dependency forest based word alignment model, which utilizes target dependency forests in an attempt to minimize the impact on limitations attributable to 1-best parse trees.", "label": 1}
{"sent1": "First, we propose a novel method for choosing which terms to present to a user to aid in the task of topic interpretation, in which we define the relevance of a term to a topic.", "sent2": "Second, we present results from a user study that suggest that ranking terms purely by their probability under a topic is suboptimal for topic interpretation.", "label": 1}
{"sent1": "Tools based on topic modeling become increasingly complex as the number of topics required to best represent the collection increases.", "sent2": "In this work, we present Hi?erarchie, an interactive visualization that adds structure to large topic models, making them approachable and useful to an end user.", "label": 1}
{"sent1": "Our model jointly learns to predict precondition relations from text and to perform high-level planning guided by those relations.", "sent2": "Each noisy sentence/relation pair is presented to multiple turkers, who are asked whether the sentence expresses the relation.", "label": 0}
{"sent1": "Only then can the decoder take advantage of relevant data.", "sent2": "Optimization procedures need to be customized, task-specific features should be introduced.", "label": 1}
{"sent1": "For English-to-Arabic translation, our model yields a +1.04 BLEU average improvement over a state-of-the-art baseline.", "sent2": "score, based on the probability distribution of unigrams in human summaries.", "label": 0}
{"sent1": "On the task shown in (Ravi and Knight, 2011) we obtain better results with only 5% of the computational effort when running our method with an n-gram language model.", "sent2": "Then the content of microblogs is further enriched by relevant words from external knowledge.", "label": 0}
{"sent1": "treating MT as a problem of transformation between character strings.", "sent2": "We achieve this result by applying phrasal inversion transduction grammar alignment techniques to character strings to train a character-based translation model, and using this in the phrase-based MT framework.", "label": 1}
{"sent1": "However, these language models can be difficult to use in practice because of the time required to generate features for rescoring a large hypothesis set.", "sent2": "Long-span features, such as syntax, can improve language models for tasks such as speech recognition and machine translation.", "label": 1}
{"sent1": "The latter includes annotation visualisers and editors, as well as serialisation to RDF format, which enables flexible querying in addition to data manipulation thanks to the semantic query language SPARQL.", "sent2": "The distributed development feature allows users to seamlessly connect their tools to workflows running in Argo, and thus take advantage of both the available library of components (without the need of installing them locally) and the analytical tools.", "label": 1}
{"sent1": "Within such a multi-level type hierarchy with several hundreds of types at different levels, many entities naturally belong to multiple types.", "sent2": "We provide empirical evidence that our approach is robust, by showing good performance on three different data sets.", "label": 0}
{"sent1": "The core of the system is based on the University of Illinois model that placed first in the CoNLL-2013 shared task.", "sent2": "This baseline model has been improved and expanded for this year?s competition in several respects.", "label": 1}
{"sent1": "Our experiments show that using this combination not only improves the search accuracy of the N-gram model but that it also improves the BLEU scores.", "sent2": "In this paper we combine N-grambased modeling with phrase-based decoding, and obtain the benefits of both approaches.", "label": 1}
{"sent1": "This enables us to find optimal weights efficiently without enumerating all combination features.", "sent2": "As empirically demonstrated by the last SensEval exercises, assigning the appropriate meaning to words in context has resisted all attempts to be successfully addressed.", "label": 0}
{"sent1": "Experimental results on data obtained from a commercially deployed Voice Search system show that the combination of the proposed features leads to a substantial sentence error rate reduction.", "sent2": "Personalization is carried out from three different angles: short-term, long-term and Web-based, and a large variety of features are proposed for use in a log-linear classification framework.", "label": 1}
{"sent1": "Our experimental results show that by using ILP we can improve the performance of our models with negligible cost in processing time.", "sent2": "During testing each model proposes possible disfluency labels which are then assessed in the presence of local and global constraints using ILP.", "label": 1}
{"sent1": "Finally, confidence values for the candidate codes are estimated using features derived from concept confidence scores.", "sent2": "We evaluate our model on its ability to simulate similarity judgments and concept categorization.", "label": 0}
{"sent1": "This paper investigates how a speech-to-speech translation system can adapt day-to-day from collected data on day one to improve performance on day two.", "sent2": "As with all speech systems, it is important to allow the system to adapt to the actual usage situations.", "label": 1}
{"sent1": "Our method, which is based on feedback control theory, uses ranking errors to adjust the search engine behavior.", "sent2": "For this purpose, we use a simple but effective method to extract year qualified queries by mining query logs and a time-stamp recognition method that considers titles and urls of web documents.", "label": 1}
{"sent1": "We show that in deployed dialog systems with real users, as in laboratory experiments, users adapt to the system?s lexical and syntactic choices.", "sent2": "dialog system.", "label": 1}
{"sent1": "Experiments on the task of named entity recognition show that each of the proposed approaches can better utilize the word embedding features, among which the distributional prototype approach performs the best.", "sent2": "This paper shows that incorporating linguistically motivated features to ensure correct animacy and number agreement in an averaged perceptron ranking model for CCG realization helps improve a state-ofthe-art baseline even further.", "label": 0}
{"sent1": "In this work 1 , we compare various methods for combining punctuation prediction (PU) and disfluency prediction (DF) on the Switchboard corpus.", "sent2": "We compare an isolated prediction approach with a cascade approach, a rescoring approach, and three joint model approaches.", "label": 1}
{"sent1": "We present a new class of submodular functions designed specifically for SMT and evaluate them on two different translation tasks.", "sent2": "By explicitly formulating data selection as a submodular program, we obtain fast scalable selection algorithms with mathematical performance guarantees, resulting in a unified framework that clarifies existing approaches and also makes both new and many previous approaches easily accessible.", "label": 1}
{"sent1": "Despite bilingual embedding?s success, the contextual information, which is of critical importance to translation quality, was ignored in previous work.", "sent2": "327 328 Callaway", "label": 0}
{"sent1": "entity popularity.", "sent2": "Furthermore, we show that two well known models for these respective tasks (DMV and the IBM models) share common modeling assumptions.", "label": 0}
{"sent1": "However, current kernel methods such as subset tree kernel and partial tree kernel understate the similarity of very similar tree structures.", "sent2": "Although soft-matching approaches can improve the similarity scores, they are corpusdependent and match relaxations may be task-specific.", "label": 1}
{"sent1": "including conversations, it will be important to provide users with the ability to seek informational content, rather than socially motivated small talk that appears in many conversational sources.", "sent2": "For each word we computed a Net Overlap Score by subtracting the total number of runs assigning this word a negative sentiment from the total of the runs that consider it positive.", "label": 0}
{"sent1": "To perform this task, we build decision tree classifiers that use a combination of simple speech features (speech lengths and spoken keywords) extracted from the participants?", "sent2": "Our goal is to automatically detect the functional roles that meeting participants play, as well as the expertise they bring to meetings.", "label": 1}
{"sent1": "We demonstrate that exploiting the contextual information in the messages can noticeably improve email-act classification.", "sent2": "or ?commit to a task?.", "label": 1}
{"sent1": "This means its ?world model?", "sent2": "it becomes obsolete and/or incomplete.", "label": 1}
{"sent1": "One surprising finding was that over 90% of annotated targets from these frames are used metaphorically, underscoring the importance of processing figurative language.", "sent2": "Using the Wall Street Journal (WSJ) corpus, we annotated all the verbal targets associated with a set of frames which includes frames of spatial motion, manipulation, and health.", "label": 1}
{"sent1": "It focused on two subtasks: (i) identification (Task A) and (ii) normalization (Task B) of diseases and disorders in clinical reports as annotated in the Shared Annotated Resources (ShARe) 1 corpus.", "sent2": "This task was a follow-up to the ShARe/CLEF eHealth 2013 shared task, subtasks 1a and 1b, 2 but using a larger test set.", "label": 1}
{"sent1": "This year, we introduced three new test sets: (i) regular tweets, (ii) sarcastic tweets, and (iii) LiveJournal sentences.", "sent2": "As in 2013, this was the most popular SemEval task; a total of 46 teams contributed 27 submissions for subtask A (21 teams) and 50 submissions for subtask B (44 teams).", "label": 1}
{"sent1": "lexical and syntactic ?", "sent2": "in order to provide our models with lexical and syntactic features such as word clusters, lemmas and tree fragments of different types.", "label": 1}
{"sent1": "My conclusion, intended to provoke discussion, will be that we currently lack a clear motivation or ?mission?", "sent2": "In this presentation, I will look back at 10 years of CoNLL conferences and the state of the art of machine learning of language that is evident from this decade of research.", "label": 1}
{"sent1": "To demonstrate the benefits of our approach, we consider the problem of parsing Chinese treebank data using only lexical features, that is, without part-of-speech tags or grammatical categories.", "sent2": "Second, to cope with sparse data, we smooth the lexical parameters according to their underlying word similarities using Laplacian Regularization.", "label": 1}
{"sent1": "(MWEs) in an annotated corpus.", "sent2": "In this approach, MWEs have no special status, but emerge in a general procedure for finding the best statistical grammar to describe the training corpus.", "label": 1}
{"sent1": "We extend the kernels on marked ordered labeled trees (Kazama and Torisawa, 2005) so that the mark can be weighted according to its importance.", "sent2": "We present a method for recognizing semantic role arguments using a kernel on weighted marked ordered labeled trees (the WMOLT kernel).", "label": 1}
{"sent1": "Then, various clusterings of the same verbs are performed on the basis of standard corpus-based types, and evaluated against the association-based clustering as well as GermaNet and FrameNet classes.", "sent2": "We address the modeling, parameter estimation and search challenges that arise from the introduction of reordering models that capture non-local reordering in alignment modeling.", "label": 0}
{"sent1": "we benefit from training examples for other problems (e.g., disambiguation of ?bar?, ?canal?, and so forth).", "sent2": "Since different models are obtained for each subject it becomes hard to perform an analysis on the group level.", "label": 0}
{"sent1": "This is because acquiring a large number of labeled data is expensive.", "sent2": "This paper describes a learning method that exploits unlabeled data to tackle data sparseness problem.", "label": 1}
{"sent1": "Our method is based on the n-gram distribution i.e.", "sent2": "We observe that the distribution of occurrence as well as cooccurrence of the consonants across languages follow a power-law behavior.", "label": 0}
{"sent1": "type features) do not exploit this information optimally.", "sent2": "We describe a novel approach for automatically predicting the hidden demographic properties of social media users.", "label": 0}
{"sent1": "Audio indexation must take into account the specificities of audio data, such as needing to deal with the continuous data stream and an imperfect word transcription.", "sent2": "At LIMSI, broadcast news transcription systems have been developed for English, French, German, Mandarin and Portuguese, and systems for other languages are under development.", "label": 1}
{"sent1": "Further, in their optimum configuration, bag-of-words methods are shown to be equivalent to segment ordersensitive methods in terms of retrieval accuracy, but much faster.", "sent2": "We also provide evidence that our findings are scalable.", "label": 1}
{"sent1": "Can computers learn to identify the perspective of a document?", "sent2": "By perspective we mean a point of view, for example, from the perspective of Democrats or Republicans.", "label": 1}
{"sent1": "It supports several different measures for automatically determining the number of clusters in which a collection of contexts should be grouped.", "sent2": "We also obtained the same conclusion with F 1 = 81.27 on CoNLL2012 shared task.", "label": 0}
{"sent1": "The prototype speech interface is based around a VoiceXML application running on the Voxeo developer platform.", "sent2": "Recognition of the user?s question is performed on a separate speech recognition server dedicated to recognizing questions.", "label": 1}
{"sent1": "We also introduce a model of the diversity of ideas, topic entropy, using it to show that COLING is a more diverse conference than ACL, but that both conferences as well as EMNLP are becoming broader over time.", "sent2": "Finally, we apply Jensen-Shannon divergence of topic distributions to show that all three conferences are converging in the topics they cover.", "label": 1}
{"sent1": "The proposed system automatically extracts sets of words related to a conversation topic set freely by a user.", "sent2": "The annotations are evaluated in several ways.", "label": 0}
{"sent1": "It overcomes some of the difficulties encountered by syntactic tree kernels as well.", "sent2": "Experimental results demonstrate the advantage of this kernel over word subsequence and syntactic tree kernels.", "label": 1}
{"sent1": "This paper investigates a number of empirical methods for eliminating unimportant words in order to construct compact translation models for retrieval purposes.", "sent2": "However, since it is possible for unimportant words (e.g., non-topical words, common words) to be included in the translation models, a lack of noise control on the models can cause degradation of retrieval performance.", "label": 1}
{"sent1": "This paper illustrates these points with a case study in building word cooccurrence matrices from large corpora.", "sent2": "The first is the impossibility to capitalize on lessons learned over the different datasets available, due to the changing nature of traditional RTE evaluation settings.", "label": 0}
{"sent1": "Every time a sentence is analyzed, it detects unknown morphemes, enumerates candidates and selects the best candidates by comparing multiple examples kept in the storage.", "sent2": "When a morpheme is unambiguously selected, the lexicon acquirer updates the dictionary of the analyzer, and it will be used in subsequent analysis.", "label": 1}
{"sent1": "We show that this new, but simple, approach outperforms all existing state-of-the-art ML models, with statistically significant gains.", "sent2": "Based on the intuition gained from our experiments, we also developed a simple propositional logic based classifier using hand-labeled features, that addresses both types of errors simultaneously.", "label": 1}
{"sent1": "the senses, of the words.", "sent2": "The system works for a given language-pair, either English-Dutch or English-Spanish in the current implementation, and takes a word-aligned parallel corpus as its input.", "label": 1}
{"sent1": "This task has a strict relation with the task of automatic machine translation, but there are some differences: Cross-lingual lexical substitution targets one word at a time and the main goal is to find as many good translations as possible for the given target word.", "sent2": "The goal of the task is to substitute a word in a language L s , which occurs in a particular context, by providing the best synonyms in a different language L t which fit in that context.", "label": 1}
{"sent1": "Bagged decision trees appeared to be the most efficient machine learning algorithm for generating a list of ranked key term candidates.", "sent2": "When integrated into English-toCzech dependency-based translation scenario implemented in the TectoMT framework, the new translation model significantly outperforms the baseline model (MLE) in terms of BLEU.", "label": 0}
{"sent1": "The second approach leverages automatically extracted semantic parse information from a large corpus to identify similar arguments by the predicates that select them.", "sent2": "We evaluated the knowledge by measuring the performance of an idiom recognizer that exploits the knowledge.", "label": 0}
{"sent1": "Then a relation typespecific classifier determines the relation direction.", "sent2": "First, the type of semantic relation is classified.", "label": 1}
{"sent1": "Performance is evaluated on the task data with and without gold-standard overt arguments.", "sent2": "The extended system models null instantiations, including non-local argument reference.", "label": 1}
{"sent1": "Our system incorporated two dependency parsers, one semantic role labeler, and a deep parser based on hand-crafted grammars.", "sent2": "The shortest path algorithm is applied on the graph representation of the parser outputs.", "label": 1}
{"sent1": "For Spanish, TIPSem achieved the best F1 score in all the tasks.", "sent2": "These systems are principally based on evaluating the substitutability of potential synonyms in the context of the target word.", "label": 0}
{"sent1": "We investigate deep learning methods for unsupervised feature learning for NLP tasks.", "sent2": "First, we use term frequencies to predict demographic attributes; our method identifies a compact set of words that are strongly associated with author demographics.", "label": 0}
{"sent1": "We will use semi-supervised classifiers on a dataset of humorous tweets driven from different Twitter humor groups or funny tweet sites.", "sent2": "We apply different similarity metrics to compare different domains and investigate the correlation between similarity and accuracy loss of NLP tool.", "label": 0}
{"sent1": "The amount of code available makes necessary to develop systems supporting education that could address the problem of detection of source code re-use.", "sent2": "This model includes the background information necessary to understand a natural language architectural description.", "label": 0}
{"sent1": "abstracts  are shown.", "sent2": "Finally, the results of an initial experiment judging the relevance of MEDLINE?", "label": 1}
{"sent1": "We select the most important information from diabetic patients?", "sent2": "records.", "label": 1}
{"sent1": "As an initial step in creating this experience, we constructed a prototype of an online shopping interface which combines product ontology information with topic model results to allow users to explore items from the food and kitchen domain.", "sent2": "Both methods exploit multiple hypotheses from ASR, in the form of word confusion networks, in order to achieve tighter coupling between ASR and query parsing and improved accuracy of the query parser.", "label": 0}
{"sent1": "Our system uses a hierarchy of reinforcement learning dialogue agents, which support transitions across sub-dialogues in order to relax the strictness of hierarchical control and therefore support flexible interactions.", "sent2": "When two vectors are similar, the two words corresponding to the vectors may have some implicit relationship with each other.", "label": 0}
{"sent1": "The algorithm is based on a k-best version of the standard cubictime search algorithm for projective dependency parsing, which is used as the backbone of a beam search procedure.", "sent2": "Our experiments used different feature configurations to train the model.", "label": 0}
{"sent1": "First, we use a baseline parser to parse large-scale unannotated data.", "sent2": "Then we extract subtrees from dependency parse trees in the auto-parsed data.", "label": 1}
{"sent1": "This distinguishes our method from existing ones, which typically require a large amount of effort on the part of humans in the form of document annotation or interactive construction of the feature space.", "sent2": "To address this problem, we propose a novel way of incorporating user feedback into a clustering algorithm, which allows a user to easily specify the dimension along which she wants the data points to be clustered via inspecting only a small number of words.", "label": 1}
{"sent1": "There are a number of such lexical resources available, but it is often suboptimal to use them as is, because general purpose lexical resources do not reflect domain-specific lexical usage.", "sent2": "Polarity lexicons have been a valuable resource for sentiment analysis and opinion mining.", "label": 1}
{"sent1": "Most of these methods use WordNet.", "sent2": "Term expansion for IR may also depend on statistics, or use some other, non-metric method based on a lexical resource.", "label": 0}
{"sent1": "We tested our method using smart phone user manuals, and compared its performance against the state-ofthe-art methods in a related area.", "sent2": "Different features are extracted and integrated by applying a machine learning classification method.", "label": 1}
{"sent1": "Frame-based systems currently make use of the FrameNet database but fail to show suitable generalization capabilities in out-of-domain scenarios.", "sent2": "Current Semantic Role Labeling technologies are based on inductive algorithms trained over large scale repositories of annotated examples.", "label": 1}
{"sent1": "context profiles obtained from a limited amount of data.", "sent2": "Existing word similarity measures are not robust to data sparseness since they rely only on the point estimation of words?", "label": 1}
{"sent1": "When incorporating user comments, we consider structural, semantic, and authority information carried by them.", "sent2": "Yet, an important factor that is often overlooked is the source translatability with respect to the specific translation system and the specific model that are being used.", "label": 0}
{"sent1": "We also explore a one-semantic-class-per-discourse heuristic, and use the classifiers to dynamically create semantic features.", "sent2": "We investigated of the characteristics of in-text causal relations.", "label": 0}
{"sent1": "with an average F1 score of 61%.", "sent2": "more than an order of magnitude greater than any previous approach ?", "label": 1}
{"sent1": "OntoUSP builds on the USP unsupervised semantic parser by jointly forming ISA and IS-PART hierarchies of lambda-form clusters.", "sent2": "We present OntoUSP, a system that induces and populates a probabilistic ontology using only dependency-parsed text as input.", "label": 1}
{"sent1": "In the first step, we generate a few high-confidence sentiment and topic seeds in the target domain.", "sent2": "We present a new domain with denser references?quiz bowl questions?that is challenging and enjoyable to humans, and we use the quiz bowl community to develop a new coreference dataset, together with an annotation framework that can tag any text data with coreferences and named entities.", "label": 0}
{"sent1": "We present a novel probabilistic SR-TSG model based on the hierarchical Pitman-Yor Process to encode backoff smoothing from a fine-grained SR-TSG to simpler CFG rules, and develop an efficient training method based on Markov Chain Monte Carlo (MCMC) sampling.", "sent2": "We aim to provide a unified model where TSG rules and symbol refinement are learned from training data in a fully automatic and consistent fashion.", "label": 1}
{"sent1": "Finally we encode these reorderings by modifying selected entries of the distortion cost matrix, on a per-sentence basis.", "sent2": "In our analyses we examine a set of selected principles which (i) are general and (ii) verifiable by applying text mining and natural language processing techniques.", "label": 0}
{"sent1": "Comput.", "sent2": "Linguist., 2012) that finitely ambiguous tree adjoining grammars cannot be transformed into a normal form (preserving the generated tree language), in which each production contains a lexical symbol.", "label": 1}
{"sent1": "It is amenable to inspection, allowing us to explore inferences about the persuasiveness of different amici and influenceability of different justices; these are consistent with earlier findings.", "sent2": "?Language is the central tool of our trade.?", "label": 1}
{"sent1": "We cast this approach as minimum Bayes risk decoding (under the Hamming cost) and argue that weaker consensus within the ensemble is a useful signal of difficulty or ambiguity.", "sent2": "The first is a consensus parser built from an ensemble of independently trained greedy LSTM transition-based parsers with different random initializations.", "label": 1}
{"sent1": "We train by transferring a model from a computationally expensive loglinear CKY parser.", "sent2": "Joshua implements all of the algorithms required for translation via synchronous context free grammars (SCFGs): chart-parsing, n-gram language model integration, beam- and cubepruning, and k-best extraction.", "label": 0}
{"sent1": "In this paper, we focus on a query?s clicked sentence, i.e., a well-formed sentence that i) contains all the tokens of the query, and ii) appears in the query?s top clicked web pages.", "sent2": "We argue such sentences are semantically consistent with the query.", "label": 1}
{"sent1": "We characterize these operations and the representations on which they operate.", "sent2": "We show that this goes beyond standard techniques used in anaphora and ellipsis resolution and requires operations on highly structured, linguistically heterogeneous representations.", "label": 1}
{"sent1": "We then show that this knowledge can be used in the analysis of first-person communication; knowledge of distinguishing attributes allows us to both classify users and to bootstrap new training examples.", "sent2": "Our novel approach enables substantial improvements on the widelystudied task of user gender prediction, obtaining a 20% relative error reduction over the current state-of-the-art.", "label": 1}
{"sent1": "?, for the user to answer.", "sent2": "One motivating example of its application is for increasing user engagement around news articles by suggesting relevant comparable questions, such as ?is Beyonce a better singer than Madonna?", "label": 1}
{"sent1": "The translation results for the Xerox and Canadian Hansards task are very promising.", "sent2": "Significance tests are generally not used to establish whether improvements over existing methods such as BLEU are statistically significant or have occurred simply by chance, however.", "label": 0}
{"sent1": "In this paper, we propose an unsupervised alternative ?", "sent2": "The creation of a pronunciation lexicon remains the most inefficient process in developing an Automatic Speech Recognizer (ASR).", "label": 1}
{"sent1": "The error detection algorithm identified spuriously deleted content words with high precision.", "sent2": "However, retranslation was not an effective approach for correcting them, which indicates the need for a more targeted approach to error correction in the future.", "label": 1}
{"sent1": "These knowledge sources determine whether the contexts surrounding an anaphor and antecedent are compatible.", "sent2": "BABAR applies a Dempster-Shafer probabilistic model to make resolutions based on evidence from the contextual role knowledge sources as well as general knowledge sources.", "label": 1}
{"sent1": "Exponential priors also lead to a simpler learning algorithm and to easier to understand behavior.", "sent2": "This paper presents a maximum entropy machine translation system using a minimal set of translation blocks (phrase-pairs).", "label": 0}
{"sent1": "This paper presents a method for improving the performance of a link detection system by using a variety of similarity measures and using source-pair specific statistical information.", "sent2": "The utility of a number of different similarity measures, including cosine, Hellinger, Tanimoto, and clarity, both alone and in combination, was investigated.", "label": 1}
{"sent1": "The basic theory of CRFs is becoming well-understood, but best-practices for applying them to real-world data requires additional exploration.", "sent2": "SPIED is the first publicly available tool to visualize diagnostic information of multiple pattern learning systems to the best of our knowledge.", "label": 0}
{"sent1": "First, Association Rule principles are suggested to guide MaxEnt feature selections.", "sent2": "This paper proposes a method for automatically inserting commas into Japanese texts.", "label": 0}
{"sent1": "of lexical entries to other morphemes not typically taken to bear semantic content.", "sent2": "Our state-of-the-art semantic role labeling system, while performing well on WSJ test data, shows significant performance degradation when applied to data from the Brown corpus.", "label": 0}
{"sent1": "We first show that the model yields competitive results in article generation.", "sent2": "We apply the log-linear model to automatically restore missing articles based on features of the noun phrase.", "label": 1}
{"sent1": "New terms, technical terminology, and nonstandard orthography, all common in bioscience text, contribute to this difficulty.", "sent2": "In this paper, we demonstrate that it is possible to efficiently mine algebra problems and their numerical solutions with little to no manual effort.", "label": 0}
{"sent1": "In this paper we present a system for temporal scoping of relational facts, which is trained on distant supervision based on the largest semi-structured resource available: Wikipedia.", "sent2": "Less attention has been paid given to extracting the temporal scope for relations between named entities; for example, the relation president-Of(John F. Kennedy, USA) is true only in the time-frame (January 20, 1961 - November 22, 1963).", "label": 1}
{"sent1": "We then use the induced interlingual word representation as augmenting features to train a delexicalized dependency parser on labeled sentences in the source language and apply it to the target sentences.", "sent2": "Summarisation of the comments allows interaction at a higher level and can lead to an understanding of the overall discussion.", "label": 0}
{"sent1": "Our approach draws on annotation projection but avoids the use of noisy source-side annotation of an unrelated parallel corpus and instead relies on manual treebank annotation in combination with statistical machine translation, which makes it possible to train fully lexicalized parsers.", "sent2": "The performance of the approach is evaluated on a small manually annotated test set.", "label": 0}
{"sent1": "The inference of grammars from natural language causes the models to become larger when a less restrictive task is involved; even more if a bilingual modelling is being considered.", "sent2": "Although finding the ?minimal?", "label": 0}
{"sent1": "Our strategy is to characterize all possible versions of the gold treebank that UNTS grammars can produce and to find the one that optimizes a metric we define.", "sent2": "We show a way to translate this score into an upper bound for the F1.", "label": 1}
{"sent1": "Our proposed method employs statistical machine translation to improve question retrieval and enriches the question representation with the translated words from other languages via matrix factorization.", "sent2": "Machine comprehension tests the system?s ability to understand a piece of text through a reading comprehension task.", "label": 0}
{"sent1": "We show how to utilize Determinantal Point Processes (DPPs), elegant probabilistic models that are defined over the possible subsets of a given dataset and give higher probability mass to high quality and diverse subsets, for clustering.", "sent2": "We present the first unified framework for unsupervised learning of these three types of information.", "label": 1}
{"sent1": "beliefs in Discourse Representation Theory (DRT) and presents a viable solution in the form of a dialogue-based DRT representation of beliefs.", "sent2": "Building machine translation (MT) for many minority languages in the world is a serious challenge.", "label": 0}
{"sent1": "Semantic frames help to generalize from specific sentences to scenarios, and to detect the (positive or negative) roles of specific companies.", "sent2": "We address a task to predict change in stock price from financial news.", "label": 1}
{"sent1": "Amortized inference has been proposed as a way to accomplish this.", "sent2": "In this paper, first, we introduce a new amortized inference algorithm called the Margin-based Amortized Inference, which uses the notion of structured margin to identify inference problems for which previous solutions are provably optimal.", "label": 1}
{"sent1": "However, a largely under-explored case is tapping into highly dynamic sources like news streams and social media, where new entities are continuously emerging.", "sent2": "In this paper, we present a method for discovering and semantically typing newly emerging out-ofKB entities, thus improving the freshness and recall of ontology-based IE and improving the precision and semantic rigor of open IE.", "label": 1}
{"sent1": "These insights help us develop features for a model to solve a new prediction task of practical importance: given a biased sentence, identify the bias-inducing word.", "sent2": "Our linguistically-informed model performs almost as well as humans tested on the same task.", "label": 1}
{"sent1": "It is a linked structure of wordnets of 18 different Indian languages, Universal Word dictionary and the Suggested Upper Merged Ontology (SUMO).", "sent2": "The emergence of domain languages is simulated using an empirically evaluated ACTR-based cognitive model of agents in a naming game played within communities.", "label": 0}
{"sent1": "We provide standard splits of the dataset into training and testing, for both polarity and rating classification, in both balanced and unbalanced settings.", "sent2": "We run baseline experiments on the dataset to establish a benchmark.", "label": 1}
{"sent1": "In the dialogue case, engineering work can infer a precise state of the user by taking into account the uncertainty provided by the spoken understanding language module.", "sent2": "However, similarly to other human-machine interaction systems such as spoken dialogue systems, ITSs suffer from a partial knowledge of the interlocutor?s intentions.", "label": 1}
{"sent1": "In doing so, it draws attention to the need to account for agent presupposition (i.e.", "sent2": "In this paper, we present a statistical language-independent framework for identifying and tracking named, nominal and pronominal references to entities within unrestricted text documents, and chaining them into clusters corresponding to each logical entity present in the text.", "label": 0}
{"sent1": "Different versions of these SNs interact with each other to generate corpora for Reinforcement Learning (RL) of argumentation dialogue policies for each of the two agents.", "sent2": "They may also make irrational moves, i.e., moves not consistent with their goals, to generate a variety of negotiation patterns.", "label": 1}
{"sent1": "Moreover, we further extend CSE models by utilizing a local attention-based model that select relevant words within the context to make more efficient prediction.", "sent2": "In the experiments, we evaluate the CSE models on two tasks, text classification and information retrieval.", "label": 1}
{"sent1": "Furthermore, we find that discourse acts modulate alignment substantially.", "sent2": "We build on the work by Mitchell et al.", "label": 0}
{"sent1": "We introduce the concept of fairness that operationalize an equal and adequate, i.e.", "sent2": "The system is initially designed to process a single sequence but we also demonstrate how to integrate it with an encoder-decoder architecture.", "label": 0}
{"sent1": "Here we aim to combine the two.", "sent2": "We focus on distributed, ?mini-batch?", "label": 1}
{"sent1": "Our selection algorithm is as accurate as and much more efficient than those proposed in previous work.", "sent2": "This study explores a method to build a high-performance NER without a manually annotated corpus, but using a comprehensible lexical database that stores numerous expressions of semantic types and with huge amount of unannotated texts.", "label": 0}
{"sent1": "Firstly, a conditional random field (CRF) model and a large margin-based model are trained respectively.", "sent2": "Our results show that a knowledge-light, direct method for scoring potential replacements is viable.", "label": 0}
{"sent1": "In both tasks, we use a Bayesian logistic regression classifier incorporating a sparsity-enforcing Laplace prior.", "sent2": "Overall, the performance achieved is 85.21% F-score and 44.11% F-score in Task1 and Task2, respectively.", "label": 1}
{"sent1": "automatically detecting historical text reuse is much more difficult.", "sent2": "Focusing on Italian MWEs containing at least one adjective, we set out to explore how candidate POS-patterns listed in relevant literature and lexicographic sources compare with POS sequences exhibited by statistically significant n-grams including an adjective position extracted from a large corpus of Italian.", "label": 0}
{"sent1": "However, another supervised CRF classifier was used to refine these predictions.", "sent2": "As a final step, scopes were constructed from the classifier output using a small set of post-processing rules.", "label": 1}
{"sent1": "For Task 1B, we tuned our categorization and weighting scheme to recognize hedging in biological text.", "sent2": "All knowledge sources are treated as feature functions, which depend on the source langauge sentence, the target language sentence and possible additional variables.", "label": 0}
{"sent1": "A greedy forward selection strategy is used in exploring the large set of potential features.", "sent2": "Our official results for Task 1 for the biological domain are 85.2 F1-score, for the Wikipedia set 55.4 F1-score.", "label": 1}
{"sent1": "In this work, we organize microblog posts as conversation trees based on reposting and replying relations, which enrich context information to alleviate data sparseness.", "sent2": "We propose an approach for incorporating both of these signals in a unified framework based on natural logic.", "label": 0}
{"sent1": "Our model achieves significant and consistent improvements on relation extraction as compared with baselines.", "sent2": "We demonstrate how textual readymades can be identified and harvested on a large scale, and used to drive a modest form of linguistic creativity.", "label": 0}
{"sent1": "Further, based on the detected results, we analyze possible mappings from frames to event-types.", "sent2": "In this paper, we propose a global inference approach to detect events in FN.", "label": 1}
{"sent1": "An equation is then generated from the formal description of the formula.", "sent2": "(3) The extracted paraphrase patterns can be classified into 5 types, which are useful in various applications.", "label": 0}
{"sent1": "Our approach is based on phonological and other features proposed in prior theoretical studies of fictional names.", "sent2": "These features are used to construct a predictive model over a manually annotated corpus of characters from motion pictures.", "label": 1}
{"sent1": "In this paper, we propose a new psychometric-inspired evaluation metric for Chinese word segmentation, which addresses to balance the very skewed word distribution at different levels of difficulty1.", "sent2": "The performance on a real evaluation shows that the proposed metric gives more reasonable and distinguishable scores and correlates well with human judgement.", "label": 1}
{"sent1": "One problem is that the number of possible TLINKs grows quadratic with the number of event mentions, therefore most annotation studies concentrate on links for mentions in the same or in adjacent sentences.", "sent2": "In order to find a use of the domain-independent research achievements for TM, we aim at linking classes of the two types of semantics.", "label": 0}
{"sent1": "We propose a neural reordering model that conditions reordering probabilities on the words of both the current and previous phrase pairs.", "sent2": "Reading comprehension activities are an authentic task including a rich, language-based context, which makes them an interesting reallife challenge for research into automatic content analysis.", "label": 0}
{"sent1": "It, however, has severe data sparsity problem due to the large tuple vocabulary coupled with the limited bilingual training data.", "sent2": "Our RNNTSM can potentially capture arbitrary long contextual information during estimating probabilities of tuples in continuous space.", "label": 1}
{"sent1": "In this extended abstract, we propose an active learning framework that interactively and iteratively acquires user feedback to improve the quality of learned topics.", "sent2": "We conduct experiments to demonstrate its effectiveness with simulated user input on a benchmark dataset.", "label": 1}
{"sent1": "A metaphor detecting classifier is trained on English samples and then applied to the target language.", "sent2": "The representation of lexically  motivated knowledge is realized as an enhancement to Pustejovsky's Generative Lexicon, and  the process of building logical forms takes into  account overwriting of default information and  mismatch of cardinality requirements.", "label": 0}
{"sent1": "Metaphors are ubiquitous and they present NLP with a range of challenges for WSD, IE, etc.", "sent2": "We propose in this paper a new multi-span architecture, which separately models the short and long context information while it dynamically merges them to perform the language modeling task.", "label": 0}
{"sent1": "In order to navigate a citation index in this more-sophisticated manner, the citation index must provide not only the citation-link information, but also must indicate the function of the citation.", "sent2": "We describe a semantic role labeling system that makes primary use of CCG-based features.", "label": 0}
{"sent1": "We have applied the ?WordNet monosemous relatives?", "sent2": "method to construct automatically a web corpus that we have used to train disambiguation systems.", "label": 1}
{"sent1": "Accordingly, many NLP applications would benefit from high coverage knowledge bases of paraphrases.", "sent2": "However, the scalability of state-of-the-art paraphrase acquisition approaches is still limited.", "label": 1}
{"sent1": "Since patterns are interpretable to humans, it is possible to identify sources of errors, such as patterns responsible for extracting incorrect entities and vice-versa, and correct them.", "sent2": "Furthermore, the recognizers built with the automatically induced lexicon consistently outperform grapheme-based recognizers and even approach the performance of recognition systems trained using conventional supervised procedures.", "label": 0}
{"sent1": "Both models combine lexical, syntactic, and prosodic information.", "sent2": "We describe a CNN model to extract emotion from raw speech input without feature engineering.", "label": 0}
{"sent1": "In this paper we give a detailed evaluation of a CCG parser on object extraction dependencies found in WSJ text.", "sent2": "With the proliferation of user-generated articles over the web, it becomes imperative to develop automated methods that are aware of the ideological-bias implicit in a document collection.", "label": 0}
{"sent1": "In the story rewriting task, an exemplar story is read to the pupils and the pupils rewrite the story in their own words.", "sent2": "Abbreviations are common in biomedical documents and many are ambiguous in the sense that they have several potential expansions.", "label": 0}
{"sent1": "The equivalence classes can also be used in order to automatically adapt the language model, the understanding module and the dialogue strategy to better fit the kind of interaction detected.", "sent2": "When considering a social media corpus, we often have access to structural information about how messages are flowing between people or organizations.", "label": 0}
{"sent1": "In the course of this analysis, we have paid particular attention to parameters that include bilexical dependencies.", "sent2": "Consequently, it is beneficial for the consumers of Twitter to know the origin of a tweet, as it affects how they view and interpret this information.", "label": 0}
{"sent1": "In addition, a partial entailment task was piloted.", "sent2": "Our system targets a set of semantic relations that have been inspired by CST but that have been generalized and broadened to facilitate application to mixed fact and opinion data from the Internet.", "label": 0}
{"sent1": "Our system performed competitively, obtaining 3rd place in the Infectious Diseases track (50.6% f-score), 5th place in Epigenetics and Post-translational Modifications (31.2%), and 7th place in Genia (50.0%).", "sent2": "The vast majority of our domain-specific knowledge comes from the conversion to and from dependency graphs.", "label": 1}
{"sent1": "Our results are very competitive: With minimal adaptation of our model we come in second for two of the tasks?right behind a version of the system presented here that includes predictions of the Stanford event extractor as features.", "sent2": "For efficient decoding we employ dual decomposition.", "label": 1}
{"sent1": "Four teams submitted final results for the REL task, with the highest-performing system achieving 57.7% F-score.", "sent2": "The task concerns the extraction of two types of part-of relations between a gene/protein and an associated entity.", "label": 1}
{"sent1": "We also perform coreference resolution to deal with events having a large textual scope, which may span over several sentences (or even paragraphs).", "sent2": "The system performs semi-supervised named entity recognition by leveraging additional information derived from external resources including a large amount of raw text.", "label": 1}
{"sent1": "The task consists in extracting gene renaming acts and gene synonymy reminders in scientific texts about bacteria.", "sent2": "Our objective is to train a sequence labelling system to detect the segment boundaries.", "label": 0}
{"sent1": "In this paper, we propose a multi-view response selection model that integrates information from two different views, i.e., word sequence view and utterance sequence view.", "sent2": "It is an adaptation of Affinity Propagation, a state-of-the-art clustering algorithm in the framework of factor graphs.", "label": 0}
{"sent1": "We show that our approach to event detection is competitive with the top supervised methods.", "sent2": "Notably, our semantic relatedness function exploits the structure of the text by making use of a semantic-role-labeling based representation of an event.", "label": 1}
{"sent1": "We then apply such embeddings as features to identify taxonomic relations using a supervised method.", "sent2": "We  estimate the degree of correlation by using comparable corpora based on  these assumptions: ?parallel word associations?", "label": 0}
{"sent1": "By incorporating a mixture of labeled and unlabeled data, we are able to improve relation classification accuracy, reduce the need for annotated data, while still retaining the capacity to use labeled data to ensure that specific desired relations are learned.", "sent2": "On this basis, we discuss the problems of vagueness and ambiguity in semantic annotation.", "label": 0}
{"sent1": "SICTF factorizes Open Information Extraction (OpenIE) triples extracted from a domain corpus along with additional side information in a principled way to induce relation schemas.", "sent2": "In this paper we show that despite the unorthodox organisation of SFG, adapting existing resources remains the most practical way to create an annotated corpus.", "label": 0}
{"sent1": "By exploiting semantic regularities between hyponyms and hypernyms in embeddings spaces, and integrating a domain clustering algorithm, our model becomes sensitive to the target data.", "sent2": "In this paper, we propose a supervised distributional framework for hypernym discovery which operates at the sense level, enabling large-scale automatic acquisition of disambiguated taxonomies.", "label": 1}
{"sent1": "We combine LTLM with 4-gram Modified Kneser-Ney language model via linear interpolation.", "sent2": "We introduce our incremental coreference resolution system for the BioNLP 2011 Shared Task on Protein/Gene interaction.", "label": 0}
{"sent1": "Deep visual representations, learned using convolutional neural networks, have been shown to achieve particularly high performance.", "sent2": "We present a server which identifies biological facts in scientific text and presents the annotation to the curator.", "label": 0}
{"sent1": "The paper shows that in the context of Gaussian process POMDP optimisation, a domain can be extended through a simple expansion of the kernel and then rapidly adapted.", "sent2": "The methods focus on the completeness of the semantic structures of the translations, as well as the order of the translated semantic roles.", "label": 0}
{"sent1": "The SSE is modelled as two connected Markov Decision Processes (MDPs) with action selection policies that are jointly optimised in interaction with a Multi-User Simulation Environment (MUSE).", "sent2": "Our investigation concentrates on the association between discourse relations and properties of the referring expressions that appear in the related sentences.", "label": 0}
{"sent1": "For both experiments, the resulting semantic predictions are then used to select parses.", "sent2": "Whereas in English, Chinese, or Spanish this field has a long history and evaluation datasets for various domains are widely available, in case of Czech language there has not yet been any systematical research conducted.", "label": 0}
{"sent1": "This paper presents an unsupervised method for inferring the hierarchical grouping of the senses of a polysemous word.", "sent2": "The inferred hierarchical structures are applied to the problem of word sense disambiguation, where we show that our method performs significantly better than traditional graph-based methods and agglomerative clustering yielding improvements over state-of-the-art WSD systems based on sense induction.", "label": 1}
{"sent1": "For each of these levels, we further explore two ways of capturing long distance relations between language constituents: implicit modeling based on the length of distance and explicit modeling based on actual patterns of relations.", "sent2": "Our framework simplifies a previously proposed ?instance-based evaluation?", "label": 0}
{"sent1": "There has been continuing work trying to find general purpose algorithms to alleviate this problem.", "sent2": "In this paper we argue that existing general purpose approaches usually only focus on one of two issues related to the difficulties faced by adaptation: 1) difference in base feature statistics or 2) task differences that can be detected with labeled data.", "label": 1}
{"sent1": "However, training such models for large vocabulary tasks is computationally challenging which does not scale easily to the huge corpora that are nowadays available.", "sent2": "In this work, we study the performance and behavior of two neural statistical language models so as to highlight some important caveats of the classical training algorithms.", "label": 1}
{"sent1": "We explore the performance of models with varying amounts of training data and find that with about 34,500 labeled tokens, we can outperform a reasonable baseline trained on over 99,000 tokens and achieve an accuracy of just over 80%.", "sent2": "The model is a class of synchronous-CFG with a Greibach Normal Form-like structure for the projected production rule: The paired target-side of a production rule takes a phrase prefixed form.", "label": 0}
{"sent1": "However, in existing systems, this expansion come with a steep increase in model complexity.", "sent2": "Given a certain domain, DRE distinguishes between relevant and non-relevant texts by means of a Gaussian Mixture model that describes the frequency distribution of domain words inside a large-scale corpus.", "label": 0}
{"sent1": "We categorized the usages of commas and investigated the appearance tendency of each category.", "sent2": "Each model considers a different training corpus: SemCor (SC), examples from monosemous words extracted automatically from background data (BG), and both SC and BG (SCBG).", "label": 0}
{"sent1": "We describe the preparation of the corpus, and compare the profile of the data with other existing temporally annotated corpora.", "sent2": "We present how a perceptron (in its dual form) uses convolution kernels to learn to differentiate between two categories of objects.", "label": 0}
{"sent1": "Moreover, when an article is composed of text and graphics, the intended message of the information graphic (its discourse intention) must be integrated into the discourse structure of the surrounding text and contributes to the overall discourse intention of the article.", "sent2": "The good results of our experiments give an indication of the potentiality of the proposed approach.", "label": 0}
{"sent1": "In this work we present a chance-corrected metric based on Krippendorff?s ?, adapted to the structure of syntactic annotations and applicable both to phrase structure and dependency annotation without any modifications.", "sent2": "With this in mind, it is striking that virtually all evaluations of syntactic annotation efforts use uncorrected parser evaluation metrics such as bracket F 1 (for phrase structure) and accuracy scores (for dependencies).", "label": 1}
{"sent1": "We translate questions to answers based on CYK parsing.", "sent2": "Unlike previous methods which treat them in a cascaded manner, we present a translation-based approach to solve these two tasks in one unified framework.", "label": 1}
{"sent1": "We experimentally demonstrate that the discourse structure of nonfactoid answers provides information that is complementary to lexical semantic similarity between question and answer, improving performance up to 24% (relative) over a state-of-the-art model that exploits lexical semantic similarity alone.", "sent2": "Machine Translation has evolved tremendously in the recent time and stood as center of research interest for many computer scientists.", "label": 0}
{"sent1": "We examined how conversants switch from the ongoing task to a real-time task.", "sent2": "In this study, we devise a model, Co-Simmate, to speed up the retrieval of all pairs of Co-Simranks to O(log 2 (log(1/?", "label": 0}
{"sent1": "The MLNs model entity relations in a unified undirected graph collectively using multiple features, including contextual, morphological, syntactic, semantic as well as Wikipedia characteristic features which can capture the essential characteristics of relation extraction task.", "sent2": "Despite the successes of these systems, accuracy will always be imperfect.", "label": 0}
{"sent1": "The software we have  developed based on this platform has been  shown to handle large data sets.", "sent2": "An unsupervised model selection technique based on this observation is shown to reduce extraction and type-checking error by 26% over previous results, in experiments with Hidden Markov Models.", "label": 0}
{"sent1": "Our scheme, inspired by the Penn Discourse TreeBank (PDTB), adopts the lexically grounded approach; at the same time, it makes adaptations based on the linguistic and statistical characteristics of Chinese text.", "sent2": "Six different feature extraction strategies were applied to this corpus and combined in various parametrizations in different classifiers.", "label": 0}
{"sent1": "The most confident semantic parsing results are selected to generate a fully-annotated corpus which is used to train the HM-SVMs.", "sent2": "We identify subgroups of character n-grams that correspond to linguistic aspects commonly claimed to be covered by these features: morphosyntax, thematic content and style.", "label": 0}
{"sent1": "Improvements are even greater when combined with existing language and alignment model approaches.", "sent2": "For this task SenseClusters was configured to construct representations of the instances to be clustered using the centroid of word cooccurrence vectors that replace the words in an instance.", "label": 0}
{"sent1": "However, dealing with metaphor properly is ultimately crucial for any automated language technology that is to be truly human-friendly or able to properly appreciate utterances by humans.", "sent2": "This paper proposes to bring metaphor into the Recognizing Textual Entailment task.", "label": 1}
{"sent1": "By applying TCRFs to a sentence described as a dependency tree structure, we conduct WSD as a labeling problem on tree structures.", "sent2": "number of clusters based on the similarity of their contexts.", "label": 0}
{"sent1": "dependency structures bridge the gap between the surface-syntactic structures as produced by state-of-the-art dependency parsers and semantic logical forms in that they abstract away from surfacesyntactic idiosyncrasies, but still keep the linguistic structure of a sentence.", "sent2": "The modeling makes use of several LSTM networks.", "label": 0}
{"sent1": "Thus we turned this task into slot-filling for <question topic, relation, answer> tuples: predicting relations to get answers given a question?s topic.", "sent2": "For the task of question answering (QA) over Freebase on the WEBQUESTIONS dataset (Berant et al., 2013), we found that 85% of all questions (in the training set) can be directly answered via a single binary relation.", "label": 1}
{"sent1": "We are releasing the source code at https://github.com/pilehvar/adw/.", "sent2": "These services are generally organized as pipelines, using dedicated APIs and different taxonomy for extracting, classifying and disambiguating named entities.", "label": 0}
{"sent1": "Languages which do not have parallel corpora are supported by transliteration through a bridge language.", "sent2": "Our script conversion system supports conversion between all Brahmi-derived scripts as well as ITRANS romanization scheme.", "label": 1}
{"sent1": "Additionally, we integrate a tool for visualizing these annotations as well as allowing for the manual annotation of new data.", "sent2": "Our pipeline includes data ingest, word segmentation, part of speech tagging, parsing, named entity recognition, relation extraction and cross document coreference resolution.", "label": 1}
{"sent1": "Much of the information in such grammars is encoded in the signature, and hence the key is facilitating a modularized development of type signatures.", "sent2": "We also use the cascade models to generate an n-best list, use the bi-directional cascade models to perform rescoring, and compare that with the results of the cascade models.", "label": 0}
{"sent1": "Recent deep learning approaches alleviate this problem by automatic feature engineering.", "sent2": "We present a shift-reduce CCG semantic parser.", "label": 0}
{"sent1": "To robustly infer topics in such contexts, we propose a latent concept topic model (LCTM).", "sent2": "This hinders effective topic inference of traditional LDA because it infers topics based on document-level co-occurrence of words.", "label": 1}
{"sent1": "We then compare the ability of linguistic and extra-linguistic features to predict readers?", "sent2": "Experimental results show that the combination results achieve a relative word error reduction of up to 39 % against the best performing single model and that of up to 23 % against ROVER.", "label": 0}
{"sent1": "a highcoverage and high-precision lexicon of roughly 37 thousand terms annotated with emotion scores, called DepecheMood.", "sent2": "In particular, prosodic boundaries have been shown to help infants with sentence and wordlevel segmentation.", "label": 0}
{"sent1": "We first establish a state-of-the-art baseline with a rich feature set.", "sent2": "Then we build a topic-based sentiment mixture model with topic-specific data in a semi-supervised training framework.", "label": 1}
{"sent1": "We use reservoir sampling to reduce the storage complexity of a previously-studied online algorithm, namely the particle filter, to constant.", "sent2": "allowing only one pass over the data and constant storage complexity?is not as well explored.", "label": 1}
{"sent1": "We estimate the correlation of unigram and Smoothed BLEU, TER, ROUGE-SU4, and Meteor against human judgements on two data sets.", "sent2": "The main finding is that unigram BLEU has a weak correlation, and Meteor has the strongest correlation with human judgements.", "label": 1}
{"sent1": "Intuitively, an incremental parser that has access to semantic information should be able to reduce ambiguity by ruling out semantically implausible analyses, even for incomplete input.", "sent2": "In this paper, we test this hypothesis by combining an incremental TAG parser with an incremental semantic role labeler in a discriminative framework.", "label": 1}
{"sent1": "Cross-category test further shows the models trained with semantic features are easier to be generalized to reviews of different product categories.", "sent2": "Experimental results show that the two semantic features can accurately predict helpfulness scores and greatly improve the performance compared with using features previously used.", "label": 1}
{"sent1": "Translators?", "sent2": "However, by using an SVM ranker to combine the realizer?s model score together with features from multiple parsers, including ones designed to make the ranker more robust to parsing mistakes, we show that significant increases in BLEU scores can be achieved.", "label": 0}
{"sent1": "We experiment with tweets labeled using hashtags as distant supervision.", "sent2": "We introduce automatic drunk-texting prediction as the task of identifying whether a text was written when under the influence of alcohol.", "label": 1}
{"sent1": "Each model considers a different training corpus: SemCor (SC), examples from monosemous words extracted automatically from background data (BG), and both SC and BG (SCBG).", "sent2": "Our system explodes the monosemous words appearing as members of a particular WordNet semantic class to automatically acquire class-based annotated examples from the domain text.", "label": 1}
{"sent1": "We describe several experiments that involve a variety of supplemental data and two state-of-the-art transduction systems, yielding error rate reductions ranging from 12% to 43%.", "sent2": "Our algorithm substantially outperforms other lexicon generation methods.", "label": 0}
{"sent1": "The model is essentially an infinite HMM that infers the number of states from data.", "sent2": "In this paper we present a fully unsupervised nonparametric Bayesian model that jointly induces POS tags and morphological segmentations.", "label": 1}
{"sent1": "In this paper, we introduce a novel method using forced decoding to confirm the validity of this constraint, and we demonstrate that it can be exploited in order to improve machine translation quality.", "sent2": "constraint is operative in bilingual contexts as well.", "label": 1}
{"sent1": "In this work, we address the problem of incremental speech-to-speech translation (S2S) that enables cross-lingual communication between two remote participants over a telephone.", "sent2": "The key strength of our model is that we use existing structure predictors as black boxes.", "label": 0}
{"sent1": "To address these challenges, we have developed an application called CourseMIRROR (Mobile Insitu Reflections and Review with Optimized Rubrics).", "sent2": "CourseMIRROR uses a mobile interface to administer prompts and collect reflective responses for a set of instructorassigned course lectures.", "label": 1}
{"sent1": "However, this work has been limited to bag-of-words models where the main signals being used are word overlap, character level edit distance and word level edit distance.", "sent2": "We propose a solution based on similarity-based smoothing, where the probability of new PPs is estimated with information from similar examples generated using a thesaurus.", "label": 0}
{"sent1": "Because AMR annotations are not designed for human readability, we present AMRICA, a visual aid for exploration of AMR annotations.", "sent2": "LVCs pose challenges for natural language understanding, as their semantics differ from usual predicate structures.", "label": 0}
{"sent1": "Ckylark introduces three new techniques that prevent possible causes for parsing failure: outputting intermediate results when coarse-to-fine analysis fails, smoothing lexicon probabilities, and scaling probabilities to avoid underflow.", "sent2": "It is designed to decrease the translation ambiguities and efficiently search for an optimal hypothesis by reducing the hypothesis search space.", "label": 0}
{"sent1": "The query language allows arbitrary tree queries, including negated branches, and is suitable for querying analyses with rich morphological annotation.", "sent2": "Treebanks of over a million words can be comfortably queried on a low-end netbook, and a parsebank with over 100M words on a single consumer-grade server.", "label": 1}
{"sent1": "We explore a rich set of discourse and lexical constraints which we incorporate through the Generalized Expectation (GE) criterion.", "sent2": "Our idea is to guide feature-based models with declarative domain knowledge encoded as posterior distribution constraints.", "label": 1}
{"sent1": "Pareto-optimality is a natural way to think about multi-metric optimization (MMO) and our methods can effectively combine several Pareto-optimal solutions, obviating the need to choose one.", "sent2": "Results will be presented for different machine translation systems to show that the new approach is independent of the underlying machine translation system which generated the translations.", "label": 0}
{"sent1": "In the popular cube pruning algorithm, every hypothesis is annotated with boundary words and permitted to recombine only if all boundary words are equal.", "sent2": "We propose a new algorithm to approximately extract top-scoring hypotheses from a hypergraph when the score includes an N?gram language model.", "label": 1}
{"sent1": "In this paper we build upon this venerable base by recasting these models in the non-parametric Bayesian framework.", "sent2": "We develop self-disclosure topic model (SDTM), a variant of latent Dirichlet allocation (LDA) for automatically classifying the level of self-disclosure for each tweet.", "label": 0}
{"sent1": "Specifically, we exploit detailed examination data, such as mouse cursor movements and scrolling, to infer the parts of the document the searcher found interesting, and then incorporate this signal into passage retrieval for QA.", "sent2": "In this paper we develop a methodology that combines label propagation with constraint reasoning for temporal fact extraction.", "label": 0}
{"sent1": "Our system first performs hierarchical graph factorization clustering (HGFC) of nouns and then searches the resulting graph for metaphorical connections between concepts.", "sent2": "It then makes use of the salient features of the metaphorically connected clusters to identify the actual metaphorical expressions.", "label": 1}
{"sent1": "Our best approach required 13 machine translation metrics + explicit semantic analysis and ranked 65 in the competition.", "sent2": "A severe challenge in applying such an approach to full syntactic parsing is the efficiency of the parsing algorithms involved.", "label": 0}
{"sent1": "In addition, we investigated the use of two different learning strategies exploiting both syntactic and semantic features.", "sent2": "The proposed framework is evaluated with several experiments run in Arabic, Chinese and English texts; a system based on the approach described here and submitted to the latest Automatic Content Extraction (ACE) evaluation achieved top-tier results in all three evaluation languages.", "label": 0}
{"sent1": "Previous work has exposed dependencies between user behavior towards systems and user belief about whether the system is automated or human-controlled.", "sent2": "This work examines whether user behavior changes when user belief is held constant and the system?s operator is varied.", "label": 1}
{"sent1": "creators.", "sent2": "This makes the model a good match with the commonly used phrase extraction heuristics.", "label": 0}
{"sent1": "The second concern is to specify an appropriate range of lexical entries classes within the JLP-O.", "sent2": "Both concerns have far-reaching implications for effectively capturing the rich patterns of interconnections among lexical entries and lexical properties and thus for realizing a multifunctional LR.", "label": 1}
{"sent1": "We argue that this is primarily due to a lack of logical expressivity in the underlying ontology languages.", "sent2": "We will show significant improvements on the Chinese-English NIST task.", "label": 0}
{"sent1": "Since it is unreasonable to perform search in the entire lexicon, I suggest to start by reducing this space (step-1) and to present then the remaining candidates in a clustered and labeled form, i.e.", "sent2": "categorial tree (step-2).", "label": 1}
{"sent1": "We present a new citation sentiment corpus which has been annotated to take the dominant sentiment in the entire citation context into account.", "sent2": "Speaker- and tone-normalized pitch reset is a good story boundary indicator.", "label": 0}
{"sent1": "We propose a discriminative model for predicting the likelihood of a response or a retweet on the Twitter network.", "sent2": "Predicting whether a message will elicit a user response opens the possibility of maximizing the virality, reach and effectiveness of messages and ad campaigns on these networks.", "label": 1}
{"sent1": "On a modest cluster, our scalable end-to-end processing pipeline was able to automatically gather 5.8m parallel sentence pairs from English and German Wikipedia.", "sent2": "Augmenting existing bitext with these data yielded significant improvements over a state-of-the-art baseline (2.39 BLEU points in the best case).", "label": 1}
{"sent1": "We find that these representations are surprisingly good at capturing syntactic and semantic regularities in language, and that each relationship is characterized by a relation-specific vector offset.", "sent2": "Our system is evaluated on the CoNLL2012 Shared Task closed track, which comprises three languages: Arabic, Chinese and English.", "label": 0}
{"sent1": "We first demonstrate that delexicalized parsers can be directly transferred between languages, producing significantly higher accuracies than unsupervised parsers.", "sent2": "We then use a constraint driven learning algorithm where constraints are drawn from parallel corpora to project the final parser.", "label": 1}
{"sent1": "The experimental results show that our new parsers significantly outperform state-of-theart baselines.", "sent2": "We present ongoing work on two approaches to the automatic construction of ontologies from a flat database of records, and compare them to a manually constructed ontology.", "label": 0}
{"sent1": "This criterion allows us to work with a relatively small but representative set of fragments, which can be employed as the symbolic backbone of several probabilistic generative models.", "sent2": "These constraints may include a semantic classification of the sought after answer and may even suggest using different strategies when looking for and verifying a candidate answer.", "label": 0}
{"sent1": "The candidates are generated by applying existing paraphrasing rules extracted from parallel corpora.", "sent2": "The full  negation  F1 score  obtained  for  the  task  evaluation is 48.09% (P=74.02%, R=35.61%)  which ranks this system fourth among the six  submitted for the closed track.", "label": 0}
{"sent1": "We propose two graph-theoretic methods (centrality and regularization), which start with a small set of labeled class-instance pairs and use the instance-instance network to extend the class labels to all instances in the network.", "sent2": "The set was generated by using an N-gram language model to generate a long list of likely words, given the immediate context.", "label": 0}
{"sent1": "Existing approaches independently analyze relations expressed by verb predicates or those expressed as nominalizations.", "sent2": "This paper presents a model that extends semantic role labeling.", "label": 1}
{"sent1": "Based on the derived hierarchy, we generate a hierarchical organization of consumer reviews on various product aspects and aggregate consumer opinions on these aspects.", "sent2": "Different techniques are employed, including a simple unsupervised dictionary-based approach, supervised word-level classification with and without contextual clues, and sequence labelling using Conditional Random Fields.", "label": 0}
{"sent1": "Our method learns vector space representations for multi-word phrases.", "sent2": "Part-of-speech tagging is carried out by a bi-modular tagger that has a subtagger for known words and one for unknown words.", "label": 0}
{"sent1": "We discuss the rationale behind the main decisions of the collection, the methodology used to generate the multilingual corpus, as well as challenges and problems faced per language.", "sent2": "We describe how the Data Contributors of MultiLing collected and generated a multilingual multi-document summarization corpus on 10 different languages: Arabic, Chinese, Czech, English, French, Greek, Hebrew, Hindi, Romanian and Spanish.", "label": 1}
{"sent1": "An automatic evaluation task was also added to this year?s set of tasks.", "sent2": "The participating systems submitted over 15 runs, some providing summaries across all languages.", "label": 1}
{"sent1": "The generated summaries were ranked first in several languages based on various metrics.", "sent2": "We compiled NOAH?s Corpus of Swiss German Dialects consisting of various text genres, manually annotated with Part-ofSpeech tags.", "label": 0}
{"sent1": "However, tasks such as visual question answering require combining these vector representations with each other.", "sent2": "Modeling textual or visual information with vector representations trained from large language or visual datasets has been successfully explored in recent years.", "label": 1}
{"sent1": "We prove the convergence of SWVP for linearly separable training sets, provide mistake and generalization bounds, and show that in the general case these bounds are tighter than those of the CSP special case.", "sent2": "In synthetic data experiments with data drawn from an HMM, various variants of SWVP substantially outperform its CSP special case.", "label": 1}
{"sent1": "and relational (?on?)", "sent2": "In contrast, our approach allows structured modeling of sentiment while taking into account both local and global contextual information.", "label": 0}
{"sent1": "The challenge focused on the identification of semantic relations between pairs of nominals in sentences collected from the web.", "sent2": "We also propose a new path-constrained graph walk method, in which the graph walk process is guided by high-level knowledge about meaningful edge sequences (paths).", "label": 0}
{"sent1": "As a result, the meanings of expressions are more specific than those derived by using primitives.", "sent2": "Similar to LSA, a lowrank approximation of the tensor is derived using a tensor decomposition.", "label": 0}
{"sent1": "Our work also includes a supervised pronoun aligner that outperforms a GIZA++ baseline in terms of both intrinsic evaluation and evaluation on CR.", "sent2": "Maximum entropy model is preferred because of its novel approach of smoothing.", "label": 0}
{"sent1": "Due to the novelty of this task, we construct a large-scale dataset and design an automatic evaluation methodology.", "sent2": "Our knowledge base completion method uses information within the existing KB and external information from Wikipedia.", "label": 1}
{"sent1": "To date, concept modeling techniques have in the main based their representation either on lexicographic resources, such as WordNet, or on encyclopedic resources, such as Wikipedia.", "sent2": "The semantic representation of individual word senses and concepts is of fundamental importance to several applications in Natural Language Processing.", "label": 1}
{"sent1": "This is comparable to results (0.72 F-score) with a set of 85 manual features.", "sent2": "Finally, evaluating against DepBank demonstrates the effectiveness of our modified corpus and novel features, with an increase in parser performance of 1.51%.", "label": 0}
{"sent1": "To satisfy special characteristics of couplets, we incorporate the attention mechanism and polishing schema into the encoding-decoding process.", "sent2": "There are few computational models of second language acquisition (SLA).", "label": 0}
{"sent1": "We present a sentence-compression-based framework for the task, and design a series of learning-based compression models built on parse trees.", "sent2": "Dyslexia  is  considered  as  an cognitive  impairment  arising  from  visual similarity  of  letters,  therefore  we  focus  on Czech  language  which  uses  special characters.", "label": 0}
{"sent1": "The computer initially knows nothing about language and therefore must learn it from scratch through interaction, while the human adapts to the computer?s capabilities.", "sent2": "We present a web-based algorithm for the task of POS tagging of unknown words (words appearing only a small number of times in the training data of a supervised POS tagger).", "label": 0}
{"sent1": "We deploy the framework on a CNN for sentiment analysis, and an RNN for named entity recognition.", "sent2": "We annotate the top of the ranked list of tweets most likely to be sarcastic that do not have the explicit hashtag.", "label": 0}
{"sent1": "The proposed scheme utilizes the textual entailment relation between statements as the basis of the exploration process.", "sent2": "We present a novel text exploration model, which extends the scope of state-of-the-art technologies by moving from standard concept-based exploration to statement-based exploration.", "label": 1}
{"sent1": "In this demonstration, we present WizIE, an IE development environment intended to reduce the development life cycle and enable developers with little or no linguistic background to write high quality IE rules.", "sent2": "Experimental results show that, this method is able to eliminate overlapping ambiguity much more effectively, compared to the current word segmentation methods.", "label": 0}
{"sent1": "Our main innovations are (i) the usage of outputs from NLP tools, viz.", "sent2": "We participated in the English-Hindi (EN-HI) and Hindi-English (HI-EN) language pair and achieved 0.792 for the Translation Error Rate (TER) score 2 for EN-HI, the lowest among the competing systems.", "label": 1}
{"sent1": "We try to avoid task-specific feature engineering, and use deep layers of neural networks to discover relevant features to the tasks.", "sent2": "This study explores the feasibility of performing Chinese word segmentation (CWS) and POS tagging by deep learning.", "label": 1}
{"sent1": "Moreover, this algorithm can work on large grammars and datasets and infers correctly even from small samples.", "sent2": "Both entity and relation extraction can benefit from being performed jointly, allowing each task to correct the errors of the other.", "label": 0}
{"sent1": "The empirical results obtained in all the experiments conducted in this work indicate that the proposed approach achieves state of the art performance in native language identification, reaching an accuracy that is 1.7% above the top scoring system of the 2013 NLI Shared Task.", "sent2": "Furthermore, the proposed approach has an important advantage in that it is language independent and linguistic theory neutral.", "label": 1}
{"sent1": "In this study, we propose a novel framework for this sampling method.", "sent2": "In the QA task our best model achieves 37.3% P@1, significantly outperforming a strong baseline by 7.7% (relative).", "label": 0}
{"sent1": "In this paper we develop and present a methodology for deriving ranked lists of such features.", "sent2": "and up to three ?arguments?", "label": 0}
{"sent1": "Our experimental results show that each device has its own readability characteristics, and thus different weights should be imposed on readability factors according to the device type.", "sent2": "This paper explores a range of methods for adapting a system for adding links to Wikipedia to cultural heritage items.", "label": 0}
{"sent1": "To solve the ?character duplication?", "sent2": "problem in Chinese abbreviation prediction, we also use a substring tagging strategy to generate local substring tagging candidates.", "label": 1}
{"sent1": "Recent advances in Open Information Extraction (Open IE) techniques enable the extraction of structured events from web-scale data.", "sent2": "Both learners perform well, yielding similar success rates of approx 90%.", "label": 0}
{"sent1": "The key problem in defining the task is to agree on a scoring system which is acceptable both to medical professionals and to the speech and language community.", "sent2": "A specific effort is also made on the detection of reactions to a particular event.", "label": 0}
{"sent1": "This paper presents a detailed description of a parametrization mechanism used for building multilingual grammar rules.", "sent2": "We show how these rules, which had originally been designed and developed for typologically different languages (English, Japanese and Finnish) are applied to a new language (Greek).", "label": 1}
{"sent1": "We describe a system of passage-query pairs divided into three types of phenomenon-based testsuites (sanity, query, basic correct).", "sent2": "This presence of incongruity- implicit or explicit- affects the way readers eyes move through the text.", "label": 0}
{"sent1": "Conventional wisdom suggests that, the higher the quality of the retrieval results used as input to the answer extraction module, the better the extracted answers, and hence system accuracy, will be.", "sent2": "Much of this work has focussed on initial reference to objects in visual scenes.", "label": 0}
{"sent1": "Therefore, performance of an information retrieval subsystem serves as an upper bound for the performance of a QA system.", "sent2": "Much  of the previous work in this area has used automated  queries to commercial web search engines.", "label": 0}
{"sent1": "In particular we look at semantically motivated approaches (using coreference chains and discourse clues) compared with simple window-based techniques.", "sent2": "In this paper we investigate several ways of dividing documents into passages.", "label": 1}
{"sent1": "A second recognition pass determines the name by combining information from the spoken and spelled part of the waveform, augmented with language model constraints.", "sent2": "The procedure is integrated into a spoken dialogue system where users are asked to enroll their names for the first time.", "label": 1}
{"sent1": "We characterize the kind of ?well-behaved?", "sent2": "Natural language generation of coherent long texts like paragraphs or longer documents is a challenging problem for recurrent networks models.", "label": 0}
{"sent1": "generated by a chart parsing decoder operating on phrase tables augmented and generalized with target language syntactic categories.", "sent2": "Feature analyses suggest that Brown cluster pairs and coreference patterns can reveal many key linguistic characteristics of each type of discourse relation.", "label": 0}
{"sent1": "This paper presents a method and its results for learning semantic constraints to detect part-whole relations.", "sent2": "We design a dual decomposition inference algorithm to perform joint decoding over the combined alignment and NER output space.", "label": 0}
{"sent1": "We learn this correspondence with a reinforcement learning algorithm, using the deviation of the route we follow from the intended path as a reward signal.", "sent2": "We demonstrate that our system successfully grounds the meaning of spatial terms like above and south into geometric properties of paths.", "label": 1}
{"sent1": "In this paper, we formulate extractive summarization as a two step learning problem building a generative model for pattern discovery and a regression model for inference.", "sent2": "We calculate scores for sentences in document clusters based on their latent characteristics using a hierarchical topic model.", "label": 1}
{"sent1": "We then present an algorithm with provable properties that uses linear programming and a region growing technique to tackle this challenge.", "sent2": "We present a recently released corpus of Czech sentences with manually annotated named entities, in which a rich two-level classification scheme was used.", "label": 0}
{"sent1": "probability distributions to search for the minimum risk translation among all the finite-length strings over the output vocabulary.", "sent2": "While significant progress has been made in this area for text sources and for English audio sources, little work has been done in automatic segmentation of other languages using both text and acoustic information.", "label": 0}
{"sent1": "Automatically prototyping full-fledged dialogue systems from corpora is far from being a reality nowadays.", "sent2": "This paper presents a novel framework called error case frames for correcting preposition errors.", "label": 0}
{"sent1": "It is a good indicator for phrase boundaries and dependency relations but mostly does not appear in the text.", "sent2": "Ezafe construction is an idiosyncratic phenomenon in the Persian language.", "label": 1}
{"sent1": ".", "sent2": "However, in most cases these evaluations take the parsers independently (intrinsic evaluations), and only in a few cases has the effect of different parsers in real applications been measured (extrinsic evaluations).", "label": 0}
{"sent1": "Whilst the tree structure is sufficient to represent the surface relations, deep dependencies which may result to multi-headed relations require more general dependency structures, namely Directed Acyclic Graphs (DAGs).", "sent2": "This study proposes a new dependency DAG parsing approach which uses a dynamic oracle within a shift-reduce transitionbased parsing framework.", "label": 1}
{"sent1": "However, using text information from social media poses challenges for event detection because of the unreliable nature of user-generated texts, which often include counter-factual statements.", "sent2": "Probabilistic lexical information is introduced into parser feature vectors by modifying the weights of lexical features.", "label": 0}
{"sent1": "These corpora provide valuable data for computational tasks like sense-based machine translation and word sense disambiguation, but also to contrastive linguistics and translation studies.", "sent2": "In this paper we present the ongoing development of a web-based corpus semantic annotation environment that uses the Open Multilingual Wordnet (Bond and Foster, 2013) as a sense inventory.", "label": 1}
{"sent1": "First, we used monolingual syntactic paraphrases to provide syntactic variety to the source training set sentences.", "sent2": "We compare the RL-based strategy against a supervised strategy which mimics the wizards?", "label": 0}
{"sent1": "On each word of 205 experimental sentences, surprisal was estimated by three types of language model: Markov models, probabilistic phrasestructure grammars, and recurrent neural networks.", "sent2": "Semantic networks have been used successfully to explain access to the mental lexicon.", "label": 0}
{"sent1": "for one minute.", "sent2": "Test responses are typically subjected to manual phonetic clustering analysis that is labor-intensive and subject to inter-rater variability.", "label": 1}
{"sent1": "This suggests that human perceptions of relatedness are less strictly constrained than perceptions of similarity and establishes a clearer expectation for what constitutes human-like performance by a computational measure of semantic relatedness.", "sent2": "The best system achieves an accuracy of 90.69%, which is a 44.73% improvement over the baseline (62.66%).", "label": 0}
{"sent1": "The paper discusses the importance and background of these subtasks and their structure.", "sent2": "The second one addresses deciding the compositionality of phrases in a given context.", "label": 1}
{"sent1": "The identification phase combines the use of conditional random fields along with a post-processing identification pipeline, whereas the normalization phase is carried out using NorMA, an open-source rule-based temporal normalizer.", "sent2": "Medical Entity Recognition is a crucial step towards efficient medical texts analysis.", "label": 0}
{"sent1": "We describe an approach to the identification of the question focus from questions asked to a Question Answering system over Topic Maps by extracting the asking point and falling back to the expected answer type when necessary.", "sent2": "We use known machine learning techniques for expected answer type extraction and we implement a novel approach to the asking point extraction.", "label": 1}
{"sent1": "When humans are employed, the whole process becomes time consuming and expensive.", "sent2": "on features rather than instances.", "label": 0}
{"sent1": "We show that this method of combining judgments of nugget importance from multiple assessors increases the stability and discriminative power of the evaluation while introducing only a small additional burden in terms of manual assessment.", "sent2": "We also consider an alternative method for combining assessor opinions, which yields a distinction similar to micro- and macro-averaging in the context of classification tasks.", "label": 1}
{"sent1": "(2006a) presented an approximation which significantly reduces the storage and computation overhead, but we show here that their formulation was incorrect and, even after correction, is grossly inaccurate.", "sent2": "We present an alternative formulation which is exact and can be computed easily.", "label": 1}
{"sent1": "LOUDS succinctly represents a trie with M nodes as a 2M + 1 bit string.", "sent2": "This paper proposes lossless compression of N gram language models based on LOUDS, a succinct data structure.", "label": 1}
{"sent1": "Our approach originates from that of Lapata and Lascarides (2003), which generates a list of nondisambiguated interpretations with their likelihood derived from a corpus.", "sent2": "We propose a novel sense-based representation of the interpretation of logical metonymy and a more thorough evaluation method than that of Lapata and Lascarides (2003).", "label": 1}
{"sent1": "In this work, we look at non-projectivity in Hyderabad Dependency Treebank (HyDT) for Hindi.", "sent2": "Hindi, being a morphologically rich, flexible word order language, brings challenges such as handling non-projectivity in parsing.", "label": 1}
{"sent1": "This work introduces a new genre of text which are not well-written, noise prone, ungrammatical and with much cryptic content.", "sent2": "We quantitatively study how earnings calls are correlated with the financial risks, with a special focus on the financial crisis of 2009.", "label": 0}
{"sent1": "We experiment with a twotask annotation scenario that includes named entity and syntactic parse tree annotations on three different corpora.", "sent2": "MTAL outperforms random selection and a stronger baseline, onesided example selection, in which one task is pursued using AL and the selected examples are provided also to the other task.", "label": 1}
{"sent1": "Perhaps surprisingly, recent attempts to incorporate automatically acquired anaphoricity information into coreference systems, however, have led to the degradation in resolution performance.", "sent2": "This paper examines several key issues in computing and using anaphoricity information to improve learning-based coreference systems.", "label": 1}
{"sent1": "We show that significant improvements in the alignment and translation quality of such models can be achieved by additionally including wordaligned data during training.", "sent2": "Two common-ground input representations were developed and for the first time several independently developed surface realisers produced realisations from the same shared inputs.", "label": 0}
{"sent1": "To support the static analysis, we introduce a new classification of the instances of variables used in TFSGs, based on what type of structure sharing they create.", "sent2": "Also, we evaluate the impact of lexical, syntactic and semantic features on each of the algorithms and look at errors.", "label": 0}
{"sent1": "In approaching this problem, a model builder often has three sources of information available: a small collection of labeled documents, a large collection of unlabeled documents, and human understanding of language.", "sent2": "We present a Bayesian classifier for discriminating between documents with a preponderance of opinions such as editorials from regular news stories, and describe three unsupervised, statistical techniques for the significantly harder task of detecting opinions at the sentence level.", "label": 0}
{"sent1": "In particular, we discuss some issues with TimeML motivated by error analysis on annotated TLINKs in TimeBank.", "sent2": "chart cells, which has focused on multi-word constituents, leaving span-1 chart cells unpruned.", "label": 0}
{"sent1": "We evaluate this summarization system for relevant content selection using gold standard summaries prepared on principle based guidelines.", "sent2": "We present a system called SciSumm that embodies this approach and apply it to the 2008 ACL Anthology.", "label": 1}
{"sent1": "The Guided Summarization task introduced at the Text Analysis Conference 2010 attempts to neutralize both of these problems by introducing topic categories and lists of aspects that a responsive summary should address.", "sent2": "This design results in more similar human models, giving the automatic summarizers a more focused target to pursue, and also provides detailed diagnostics of summary content, which can can help build better meaningoriented summarization systems.", "label": 1}
{"sent1": "In this paper we approach Label Propagation as solution to a system of linear equations which can be implemented as a scalable parallel algorithm using the map-reduce framework.", "sent2": "In addition to semi-supervised classification, this approach to Label Propagation allows us to adapt the algorithm to make it usable for ranking on graphs and derive the theoretical connection between Label Propagation and PageRank.", "label": 1}
{"sent1": "In this machine learning framework, as features of machine learning, information such as the model IDs which output the hypothesized word are useful for improving the word recognition rate.", "sent2": "Training efficient statistical approaches for natural language understanding generally requires data with segmental semantic annotations.", "label": 0}
{"sent1": "Our analysis of cross-corpus performance on WG shows that Wikipedia text may be a harder NER domain than newswire.", "sent2": "We present the first NER evaluation on a Wikipedia gold standard (WG) corpus.", "label": 1}
{"sent1": "We provide an in-depth study of these synonymy networks and compare them to those extracted from traditional resources.", "sent2": "Finally, we describe two methods for semiautomatically improving this network by adding missing relations: (i) using a kind of semantic proximity measure; (ii) using translation relations of Wiktionary itself.", "label": 1}
{"sent1": "has attracted less attention so far.", "sent2": "Our method is realized by learning translation rules that have acoustic correspondence between two languages inductively.", "label": 0}
{"sent1": "Wikipedia is an interesting domain for parsing that has so far been underexplored.", "sent2": "However, previous work mixed review helpfulness prediction with those outer layer tasks.", "label": 0}
{"sent1": "Using the committees, an ambiguous tag is identified as one which belongs to more than one committee.", "sent2": "Named entity disambiguation concerns linking a potentially ambiguous mention of named entity in text to an unambiguous identifier in a standard database.", "label": 0}
{"sent1": "We then make use of optimal finite-state devices, in particular minimal sequential string-to string transducers to build a computational model for very efficient recognition and production of those words.", "sent2": "We first give a systematical study of Vietnamese reduplicative words, bringing into focus clear principles for the formation of a large class of bi-syllabic reduplicative words.", "label": 1}
{"sent1": "To mimic the repeated reading strategy, we propose the neural networks with multi-level attention (NNMA), combining the attention mechanism and external memories to gradually fix the attention on some specific words helpful to judging the discourse relations.", "sent2": "Experiments on the PDTB dataset show that our proposed method achieves the state-ofart results.", "label": 1}
{"sent1": "We also define features that describe the relation of the content of the antecedent and the sluice type.", "sent2": "We argue that both syntactic and discourse relationships are important in antecedent selection, and we construct linguistically sophisticated features that describe the relevant relationships.", "label": 1}
{"sent1": "Motivated by Centering Theory and other previous works, we exploit as clues both the surface word sequence and the dependency tree of a target sentence in our MCNN.", "sent2": "This paper explores techniques to quickly derive task-specific taxonomies supporting browsing in arbitrary document collections.", "label": 0}
{"sent1": "We present a model that combines Dyer et al.", "sent2": "A first step towards making use of such data would be to automatically align spoken words with their translations.", "label": 1}
{"sent1": "We present a novel human semantic evaluation measure, Human UCCA-based MT Evaluation (HUME), building on the UCCA semantic representation scheme.", "sent2": "HUME covers a wider range of semantic phenomena than previous methods and does not rely on semantic annotation of the potentially garbled MT output.", "label": 1}
{"sent1": "These mappings are built from weakly annotated data and can be extended to new languages with no human annotation or language-dependent knowledge involved.", "sent2": "Since parallel corpus is limited, many words are not translated.", "label": 0}
{"sent1": "We measure entrainment on eight acoustic features extracted from the speech of subjects playing a cooperative computer game and associate the degree of entrainment with a number of manually-labeled social variables acquired using Amazon Mechanical Turk, as well as objective measures of dialogue success.", "sent2": "We find that male-female pairs entrain on all features, while male-male pairs entrain only on particular acoustic features (intensity mean, intensity maximum and syllables per second).", "label": 1}
{"sent1": "We explore the use of Amazon?s Mechanical Turk system, a significantly cheaper and faster method for collecting annotations from a broad base of paid non-expert contributors over the Web.", "sent2": "We investigate five tasks: affect recognition, word similarity, recognizing textual entailment, event temporal ordering, and word sense disambiguation.", "label": 1}
{"sent1": "We then consider a more flexible, non-ITG matching constraint which is less efficient for exact inference but more efficient for BP.", "sent2": "We first show that their model can be approximated using structured belief propagation, with a gain in alignment quality stemming from the use of marginals in decoding.", "label": 1}
{"sent1": "We use this data to build Dialectal Arabic MT systems, and find that small amounts of dialectal data have a dramatic impact on translation quality.", "sent2": "It is shown that text line detection can be accurately solved using a formal methodology, as opposed to most of the proposed heuristic approaches found in the literature.", "label": 0}
{"sent1": "When co-referent text mentions appear in different languages, these techniques cannot be easily applied.", "sent2": "A first perception study in which minimal pairs of truthful and deceptive utterances were shown (vision-only) to adult observers revealed that the correct detection of deceptive utterances is dependent on whether the stimuli were produced by a child alone or together with another child (both being visible).", "label": 0}
{"sent1": "While the model contains high-order potentials, efficient approximate inference can be performed with dualdecomposition.", "sent2": "We experiment with two data sets that consist of newspaper articles describing multiple terrorism events, and show that our model substantially outperforms traditional pipeline models.", "label": 1}
{"sent1": "For example, they have been used in scientific paper summarization, automatic survey generation, paraphrase identification, and citation function classification.", "sent2": "In this paper, a stochastic dependency parsing scheme based on A* admissible search is formally presented.", "label": 0}
{"sent1": "Correlation analyses show crucially that our automatic disengagement labels correlate with system performance in the same way as the gold standard (manual) labels, while regression analyses show that detecting user disengagement adds value over and above detecting only user uncertainty when modeling performance.", "sent2": "However, since our goal is immediate implementation in a system that already detects and adapts to user uncertainty, we go further than prior work and present an extrinsic evaluation of our model (i.e., with respect to the real-world task).", "label": 1}
{"sent1": "In this paper, we explore features representing the accuracy of the content of a spoken response.", "sent2": "For automated scoring of unrestricted spontaneous speech, speech proficiency has been evaluated primarily on aspects of pronunciation, fluency, vocabulary and language usage but not on aspects of content and topicality.", "label": 1}
{"sent1": "Second, a conditional random field is trained to segment the components into clauses.", "sent2": "An alternative approach would have been to modify the claim content which is, however, prone to also changing the meaning of this legal text.", "label": 1}
{"sent1": "Most email-based customer care management systems provide a method to include template texts in order to reduce the handling time for a customer?s email.", "sent2": "The other of these decisions is the choice of sentences, or EI test items, to be repeated.", "label": 0}
{"sent1": "In this work we motivate the need to construct a large, accessible corpus of everyday documents along with their simplifications for the development and evaluation of simplification systems that make everyday documents more accessible.", "sent2": "In this paper, we present an integrated model of the two central tasks of dialog management: interpreting user actions and generating system actions.", "label": 0}
{"sent1": "We apply the method to radiology reports and medical journal texts, and compare the results to general Swedish.", "sent2": "The results show that the correct expansion of the abbreviation can be found in 40% of the cases, an improvement by 24 percentage points compared to the baseline (0.16), and an increase by 22 percentage points compared to using word space models alone (0.18).", "label": 1}
{"sent1": "The best models can be trained to decide if a text is easy to read or not with very high accuracy, e.g.", "sent2": "a model using 117 parameters from shallow, lexical, morphological and syntactic analyses achieves 98,9% accuracy.", "label": 1}
{"sent1": "We then built machine learning models to attempt to automatically classify segments based on such transformations.", "sent2": "To learn meanings from data, we therefore need to link underlying representations of meaning to models of speaker judgment and speaker choice.", "label": 0}
{"sent1": "Both metrics have been shown to align with human evaluations and provide a balance between internal measures of information gain and comparisons to human ratings of coherent topics.", "sent2": "In addition, RBPB uses a regularization method to take advantage of the relationship between arguments.", "label": 0}
{"sent1": "In this work, we propose a relative entropy model for translation models, that measures how likely a phrase pair encodes a translation event that is derivable using smaller translation events with similar probabilities.", "sent2": "However, many phrase pairs do not encode any relevant context, which means that the translation event encoded in that phrase pair is led by smaller translation events that are independent from each other, and can be found on smaller phrase pairs, with little or no loss in translation accuracy.", "label": 1}
{"sent1": "In this paper, we investigate the impact of using different sets of features in two discriminative machine learning frameworks, namely, Support Vector Machines and Conditional Random Fields using Arabic data.", "sent2": "Automatic topic segmentation, separation of a discourse stream into its constituent stories or topics, is a necessary preprocessing step for applications such as information retrieval, anaphora resolution, and summarization.", "label": 0}
{"sent1": "While there has been some research on temporal relations, the aspect of causality between events from a Natural Language Processing (NLP) perspective has hardly been touched.", "sent2": "The Aspect Term Polarity, Aspect Category and Aspect Category Polarity detection are tackled as a classification problem where multiple kernels are linearly combined to generalize several linguistic information.", "label": 0}
{"sent1": "This thesis proposal describes ongoing work on bilingual discourse annotation and plans towards incorporating discourse relation knowledge to a ChineseEnglish SMT system with consideration of implicit discourse relations.", "sent2": "The final goal is a discourse-unit-based translation model unbounded by the traditional assumption of sentence-to-sentence translation.", "label": 1}
{"sent1": "Discriminatively trained models based on local character features are used to make the tagging decisions, with Viterbi decoding finding the highest scoring segmentation.", "sent2": "Standard approaches to Chinese word segmentation treat the problem as a tagging task, assigning labels to the characters in the sequence indicating whether the character marks a word boundary.", "label": 1}
{"sent1": "The approach builds on earlier work based on the idea of matching specific lexico-syntactic patterns conveying a certain semantic relation on the World Wide Web using standard search engines.", "sent2": "This paper presents an approach for the automatic acquisition of qualia structures for nouns from the Web and thus opens the possibility to explore the impact of qualia structures for natural language processing at a larger scale.", "label": 1}
{"sent1": "SE classification is important for discourse mode identification and for tracking the temporal progression of a discourse.", "sent2": "We show that (a) linguistically-motivated cooccurrence features and grammatical relation information from deep syntactic analysis improve classification accuracy and (b) using a sequencing model provides improvements over assigning labels based on the utterance alone.", "label": 1}
{"sent1": "Our experiments reveal that the prediction accuracy of the models is marred by serious overfitting problems, due to violations of the random sampling assumption in corpus data.", "sent2": "In this paper, we propose a novel approach for translating agglutinative languages by treating stems and affixes differently.", "label": 0}
{"sent1": "We also propose a method for detecting variation within stems in an unsupervised fashion.", "sent2": "The segmentation quality reached with the new algorithm is good enough to improve grapheme-to-phoneme conversion.", "label": 1}
{"sent1": "Human error analysis clarifies advantages and disadvantages of the systems under consideration.", "sent2": "artificial words to the training documents to identify topics in accordance with the underlying class structure of the corpus based on the higher order word associations.", "label": 0}
{"sent1": "Studies have shown that both the informational and affective aspects of news text affect the markets in profound ways, impacting on volumes of trades, stock prices, volatility and even future firm earnings.", "sent2": "Research in the domain of finance strongly suggests that it can.", "label": 1}
{"sent1": "We detect and classify all entities (persons and objects) in the text after which we determine the salience (the importance of an entity in a text) and visualness (the extent to which an entity can be perceived visually) of these entities.", "sent2": "We combine these measures to compute the probability that an entity is present in the image.", "label": 1}
{"sent1": "We evaluate our system on the FraCaS test suite, and achieve a 27% reduction in error from previous work.", "sent2": "The fact that web mark-up strongly correlates with syntactic structure may have broad applicability in NLP.", "label": 0}
{"sent1": "The identified terms are then transliterated.", "sent2": "We present an SMTbased transliteration model trained with a parallel corpus extracted from Wikipedia using a fairly simple method which requires minimal knowledge.", "label": 1}
{"sent1": "The use of such a shallow representation as a common format has the advantage of reduced noise introduced by the conversion in comparison with the noise produced by the conversion to deeper representations.", "sent2": "We first convert the parsing result to a shallow CFG analysis by using an automatic tree converter based on synchronous grammars.", "label": 1}
{"sent1": "There are many practical settings where computational humor will add value.", "sent2": "Computational humor will be needed in interfaces, no less than other cognitive capabilities.", "label": 1}
{"sent1": "We used a specialized vocabulary for an English certification test as the target vocabulary and used English Wikipedia, a free-content encyclopedia, as the target corpus.", "sent2": "The organized reading materials would enable learners not only to study the target vocabulary efficiently but also to gain a variety of knowledge through reading.", "label": 1}
{"sent1": "We find a significant increase in motivation for users who most frequently received the disengagement adaptation.", "sent2": "Our analysis investigates how iteratively adding new affect adaptation to an existing affect-adaptive system impacts global and local performance.", "label": 1}
{"sent1": "The system consists  of four main stages: topic classification,  named entity recognition (NER),  disease/location detection and visualization.", "sent2": "Evaluation of the system shows  that it achieved high accuracy on a gold  standard corpus.", "label": 1}
{"sent1": "This system allows the user to input a Sinhala word with a key sequence that highly matches his/her intuition from its pronunciation.", "sent2": "A key to this scenario is a pre-compiled table that lists conceivable roman character sequences utilized by a wide range of users for representing a consonant, a consonant sign, and a vowel.", "label": 1}
{"sent1": "Reduplication can also be classified as either bounded or unbounded reduplication.", "sent2": "Experiments with up to 3600 features show that these extensions of MERT yield results comparable to PRO, a learner often used with large feature sets.", "label": 0}
{"sent1": "As such, it presents challenges that are not to be taken lightly.", "sent2": "Although existing technology covers each of the steps in the process, from speech recognition to synthesis, deriving a model of translation that is effective in the domain of spoken language is an interesting and challenging task.", "label": 1}
{"sent1": "By well representing the parse state and appropriately designing the cost and heuristic functions, dependency parsing can be modeled as an A* search problem, and solved with a generic algorithm of state space search.", "sent2": "In this paper, a stochastic dependency parsing scheme based on A* admissible search is formally presented.", "label": 1}
{"sent1": "We compute the compositionality of a phrase through substituting the constituent words with their ?neighbours?", "sent2": "These features were extracted from a 23M word WSJ corpus based on part-of-speech tags and phrasal chunks alone.", "label": 0}
{"sent1": "Although VerbNet?s predicates are theoretically well-motivated, systematic empirical data is scarce.", "sent2": "For example, the verb spray (of the Spray class), involves the predicates MOTION, NOT, and LOCATION, where the event can be decomposed into an AGENT causing a THEME that was originally not in a particular location to now be in that location.", "label": 1}
{"sent1": "The learned model achieves over 82% accuracy in discriminating severe offenders from places with no violation, and provides insights into salient cues in reviews that are indicative of the restaurant?s sanitary conditions.", "sent2": "We evaluate the model using small, widely used sentiment and subjectivity corpora and find it out-performs several previously introduced methods for sentiment classification.", "label": 0}
{"sent1": "We introduce a framework which apply summarisation algorithms to generate topic labels.", "sent2": "These algorithms are independent of external sources and only rely on the identification of dominant terms in documents related to the latent topic.", "label": 1}
{"sent1": "Both grammars are evaluated qualitatively showing that probabilistic context-free grammars can contribute linguistic knowledge to phonology.", "sent2": "We focus especially on abstract concepts and emotions to show that even though they cannot be physically visualized, they too tend to have strong colour associations.", "label": 0}
{"sent1": "An ?integrated architecture?, on the other hand, would integrate all the models in a single network where the search process takes place.", "sent2": "The output of this search process is the target word sequence associated to the optimal path.", "label": 1}
{"sent1": "This speech translation method can be utilized for any language because the system has no processing dependent on an individual character of a specific language.", "sent2": "We focus only on acoustic characteristics of speech waveforms of source and target languages without obtaining character strings from utterances.", "label": 1}
{"sent1": "Free-style sentence translation accepts natural language sentences and translates them by machine translation.", "sent2": "Parallel text based translation provides a proper translation for a sentence in the parallel text by referring to a corresponding translation of the sentence and supplements free-style sentence translation.", "label": 1}
{"sent1": "During summarization, we use multiple compressed sentences in the integer linear programming framework to select salient summary sentences.", "sent2": "Using this corpus, we train a supervised sentence compression model using a set of word-, syntax-, and documentlevel features.", "label": 1}
{"sent1": "(AG) model where we use a graph structure to model global contextual information that is crucial for reordering.", "sent2": "Taking the MINGREEDY algorithm (Ravi et al., 2010) as a starting point, we improve it with several intuitive heuristics.", "label": 0}
{"sent1": "We obtain improvements of up to 1.4 BLEU on language pairs in the WMT 2010 shared task.", "sent2": "This information is also added to the tokens themselves to achieve better precision.", "label": 0}
{"sent1": "Ristad and Yianilos (1998) defined stochastic edit distance?a probability distribution p(y | x) whose parameters can be trained from data.", "sent2": "String similarity is most often measured by weighted or unweighted edit distance d(x, y).", "label": 1}
{"sent1": "However, these information may be heterogeneous, so the widely-used Viterbi algorithm for searching the best alignment may not apply here.", "sent2": "Type-token generalization was applied, but also reduced performance.", "label": 0}
{"sent1": "We introduce features controlling the interactions between the two systems and explore three interaction schemes of hiero and forest-to-string models?specification, generalization, and interchange.", "sent2": "We propose flexible interaction of hypergraphs as a novel technique combining different translation models within one decoder.", "label": 1}
{"sent1": "We apply pattern mining to automatically labeled edits in the revision histories of different Wikipedia articles.", "sent2": "A model trained on the same data achieves state-of-the-art performance on the related task of fluency edit classification.", "label": 1}
{"sent1": "These languages are not learnable under traditional distribution free criteria.", "sent2": "We claim that an appropriate learning framework is PAC learning where the distributions are constrained to be generated by a class of stochastic automata with support equal to the target concept.", "label": 1}
{"sent1": "Example-based MT sometimes generates invalid translations because it selects similar examples to the input sentence based only on source language similarity.", "sent2": "We present an extensible API for integrating language modeling and realization, describing its design and efficient implementation in the OpenCCG surface realizer.", "label": 0}
{"sent1": "Properly understanding the information filtering structures that govern the interpretation of these facts, then, is critical to appropriately analyzing them.", "sent2": "Experimental results show that our approach achieves higher accuracy than previous approaches.", "label": 0}
{"sent1": "Recently, new approaches based on factored language models have been developed to address this problem.", "sent2": "We describe the submission of the team of the Sofia University to SemEval-2014 Task 9 on Sentiment Analysis in Twitter.", "label": 0}
{"sent1": "In order to test the effect of our title revision wizard, we conducted a questionnaire survey on the effect of the titles with or without using the wizard on the interest of lay readers.", "sent2": "The wizard provides a guidance on revising draft title to compose a title meeting three key points, and support tools for coming up with and elaborating on comprehensible or appealing phrases.", "label": 1}
{"sent1": "They may also be objects of interest in their own right, that is, as the output of a knowledge discovery process.", "sent2": "Despite the many initiatives in recent years aimed at creating Language Engineering standards, it is often the case that di\u000berent projects use di\u000berent approaches and often de\fne their own standards.", "label": 0}
{"sent1": "We investigate different reordering constraints for phrase-based statistical machine translation, namely the IBM constraints and the ITG constraints.", "sent2": "Our results suggest that our bootstrapping methods have considerable potential, and could be used to semi-automate an approach based on incremental manual annotation.", "label": 0}
{"sent1": "We show statistically significant improvements of the alignment quality compared to the best results reported so far.", "sent2": "We evaluate the automatic alignments created in this way on the German?English Verbmobil task and the French?English Canadian Hansards task.", "label": 1}
{"sent1": "In this paper, we propose a supervised learning-based approach which does coreference resolution by exploring the relationships between NPs and coreferential clusters.", "sent2": "Predicates such as thinks, claims, and admits offer a range of options for framing quoted content according to the author?s own perceptions of its credibility.", "label": 0}
{"sent1": "The extended dar-algorithm accounts for differences in the resolution mechanisms of different types of Danish pronouns.", "sent2": "The partners are now also working on English, Chinese, Lao, Malay, Thai and Vietnamese.", "label": 0}
{"sent1": "We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset, and run two different machine learning algorithms: SLIPPER, a rule-based learning algorithm, and TiMBL, a memory-based system.", "sent2": "This paper attempts to bridge work in psycholinguistics and natural language processing by proposing sentence processing complexity as a feature for automated essay scoring, in the context of English as a Foreign Language (EFL).", "label": 0}
{"sent1": "Although such an English word dependency analyzer was proposed by Yamada and Matsumoto, its accuracy is lower than state-of-the-art phrase structure parsers because of the lack of top-down information given by phrase labels.", "sent2": "Therefore, we expect an accurate dependency analyzer trainable without using phrase labels is useful.", "label": 1}
{"sent1": "We show that large increases in speed can be obtained by tightly integrating the supertagger with the CCG grammar and parser.", "sent2": "This is the first work we are aware of to successfully integrate a supertagger with a full parser which uses an automatically extracted grammar.", "label": 1}
{"sent1": "We use a Partially Observable Markov Decision Process (POMDP)-style approach to generate dialogue strategies by inverting the notion of dialogue state; the state represents the user?s intentions, rather than the system state.", "sent2": "We demonstrate that under the same noisy conditions, a POMDP dialogue manager makes fewer mistakes than an MDP dialogue manager.", "label": 1}
{"sent1": "Our model also integrates lexical information.", "sent2": "This huge amount of data, available only because Twitter blurs the line between chatting and publishing, highlights the need to be able to adapt quickly to a new medium.", "label": 0}
{"sent1": "We extract Chinese?Japanese parallel sentences from quasi?comparable corpora, which are available in far larger quantities.", "sent2": "Many studies have been conducted on extracting parallel sentences from noisy parallel or comparable corpora.", "label": 1}
{"sent1": "There is an abundance of event-centered texts (e.g., breaking news) and event-oriented information needs that often involve structure that cannot be expressed using keywords.", "sent2": "Our proposed methodology treats content selection as a multi-label (ML) classification problem, which takes as input time-series data and outputs a set of templates, while capturing the dependencies between selected templates.", "label": 0}
{"sent1": "sentences.", "sent2": "We prove the conditions to identify the treatment effects of texts and introduce the supervised Indian Buffet process to discover those treatments.", "label": 0}
{"sent1": "In this work, we address this important question and characterise the constituents of news article editorial quality.", "sent2": "This is not an easy question to be answered by computational linguistic methods.", "label": 1}
{"sent1": "In this paper, we perform a case study for metric evaluation by measuring the effect that systematic sentence transformations (e.g.", "sent2": "active to passive voice) have on the automatic metric scores.", "label": 1}
{"sent1": "We induce bilingual labels into the SAMT grammar, use them for category coarsening, then project back to monolingual labeling as in standard SAMT.", "sent2": "The result is a ?collapsed?", "label": 1}
{"sent1": "Compression candidates generated by a word graph-based MSC approach are reranked according to the number and relevance of keyphrases they contain.", "sent2": "Both manual and automatic evaluations were performed using a dataset made of clusters of newswire sentences.", "label": 1}
{"sent1": "This model learns the cost of putting a word immediately before another word and finds the best reordering by solving an instance of the Traveling Salesman Problem (TSP).", "sent2": "However, for efficiently solving the TSP, the model is restricted to pairwise features which examine only a pair of words and their neighborhood.", "label": 1}
{"sent1": "The unambiguity bias favors a grammar that leads to unambiguous parses, which is motivated by the observation that natural language is remarkably unambiguous in the sense that the number of plausible parses of a natural language sentence is very small.", "sent2": "On an English-to-Iraqi CSLT task, the proposed approach gives significant improvements over a baseline system as measured by BLEU, TER, and NIST.", "label": 0}
{"sent1": "The experimental results highlight the important factors in modeling the questioning process.", "sent2": "Our method projects opinion frames from the source to the target language, and then trains a system on the target language using the automatic annotations.", "label": 0}
{"sent1": "Using the outputs of five different English ASR systems as input, we find consistent and significant improvements in translation quality.", "sent2": "We participated in ?task B?, where the objective was to build models which classify tweets into three classes (positive, negative or neutral) by their contents.", "label": 0}
{"sent1": "We evaluate intrinsically using held-out probability and perplexity, and find a substantial reduction in uncertainty brought by our spatial representation.", "sent2": "It is shown how the new integrated model gives insights and stimulates new ideas for IR algorithms.", "label": 0}
{"sent1": "We present a simple aspect detection algorithm, a co-occurrence based method for category detection and a dictionary based sentiment classification algorithm.", "sent2": "The dictionary for the latter is based on co-occurrences as well.", "label": 1}
{"sent1": "To evaluate our approach, we compile a data set from the top 500 Baidu Baike articles and their corresponding English Wiki articles.", "sent2": "In this paper, we propose a cross-language article linking method using a mixed-language topic model and hypernym translation features based on an SVM model to link English Wikipedia and Chinese Baidu Baike, the most widely used Wiki-like encyclopedia in China.", "label": 1}
{"sent1": "Among the 45 submitted systems including the SemEval 2013 participants, our system (Coooolll) is ranked 2nd on the Twitter2014 test set of SemEval 2014 Task 9.", "sent2": "To robustly infer topics in such contexts, we propose a latent concept topic model (LCTM).", "label": 0}
{"sent1": "The main purpose was to robustly provide uniform access to sentences in ACL Anthology papers from the past 46 years, ranging from scanned, typewriter-written conference and workshop proceedings papers, up to recent high-quality typeset, born-digital journal articles, with varying layouts.", "sent2": "PaperXML markup includes information on page and paragraph breaks, section headings, footnotes, tables, captions, boldface and italics character styles as well as bibliographic and publication metadata.", "label": 1}
{"sent1": "We use Parscit, to process the Bibliography of each paper.", "sent2": "We contribute to the goal of enriching the textual content of ACL Anthology by identifying the citation contexts in a paper and linking them to their corresponding references in the bibliography section.", "label": 1}
{"sent1": "80%) for nominals and high precision (?", "sent2": "70%) for verbals.", "label": 1}
{"sent1": "I propose that there are different types of power relations and they are different in the ways they are expressed and revealed in dialog and across different languages, genres and domains.", "sent2": "In my thesis I propose a data-oriented study on how social power relations between participants manifest in the language and structure of online written dialogs.", "label": 1}
{"sent1": "Our work addresses this challenge by estimating a word frequency representation of the visual content of a query image.", "sent2": "Experimental evaluation shows that the proposed method achieves improvement over the best known results with Japanese named entity extractors based on maximum entropy models.", "label": 0}
{"sent1": "We take as a case study queries asked to a search engine of an art, cultural and history library and classify them against the library cataloguing categories.", "sent2": "However, how to use them to improve performance of statistical machine translation (SMT) is not well studied.", "label": 0}
{"sent1": "Our techniques make use of (1) a training set of 1791 disambiguated entries, representing 1442 verb entries from 167 classes; (2) word sense probabilities, from frequency counts in a tagged corpus; (3) semantic similarity of WordNet senses for verbs within the same class; (4) probabilistic correlations between WordNet data and attributes of the verb classes.", "sent2": "The best results achieved 72% precision and 58% recall, versus a lower bound of 62% precision and 38% recall for assigning the most frequently occurring WordNet sense, and an upper bound of 87% precision and 75% recall for human judgment.", "label": 1}
{"sent1": "Hand-crafted grammars inevitably lack coverage but many coverage failures are due to inadequacies of their lexicons.", "sent2": "We describe a method of gaining a degree of robustness by interfacing POS tag information with the existing lexicon.", "label": 1}
{"sent1": "which can be written in a lightweight language such as JavaScript.", "sent2": "(e.g., semantic role labeling?SRL).", "label": 0}
{"sent1": "We present an inter-cluster ranking algorithm that takes events from multiple clusters as input and that selects the most salient and relevant events.", "sent2": "Empirical results in two benchmark domains demonstrate consistently strong performance on both mention detection and template filling tasks.", "label": 0}
{"sent1": "We use state-of-the-art visual recognition systems to obtain confidences on entities, activities, and scenes present in the video.", "sent2": "Our factor graph model combines these detection confidences with probabilistic knowledge mined from text corpora to estimate the most likely subject, verb, object, and place.", "label": 1}
{"sent1": "Our proposed idea is to build a predictive model for one topic using documents from all other available topics.", "sent2": "In this paper, we offer broad insight into the underperformance of Arabic constituency parsing by analyzing the interplay of linguistic phenomena, annotation choices, and model design.", "label": 0}
{"sent1": "The verbs in PreDic are categorized into three groups, enabling applications to target precision-oriented, recall-oriented, or harmony-oriented results as needed.", "sent2": "systems identified and, if appropriate, replaced references to people in texts.", "label": 0}
{"sent1": "However, when compared to professional translation, naive collection of translations from non-professionals yields low-quality results.", "sent2": "It provides a low cost, fast turnaround way of processing large volumes of data.", "label": 1}
{"sent1": "By performing probability integral transform, our approach moves beyond the standard count-based bag-ofwords models in NLP, and improves previous work on text regression by incorporating the correlation among local features in the form of semiparametric Gaussian copula.", "sent2": "In experiments, we show that our model significantly outperforms strong linear and non-linear discriminative baselines on three datasets under various settings.", "label": 1}
{"sent1": "Our best models obtain competitive results in the high-resource setting and state-ofthe-art results in the low resource setting, reaching 72.48% F1 averaged across languages.", "sent2": "We release our code for this work along with a larger toolkit for specifying arbitrary graphical structure.", "label": 1}
{"sent1": "The trained parser produces a full syntactic parse of any sentence, while simultaneously producing logical forms for portions of the sentence that have a semantic representation within the parser?s predicate vocabulary.", "sent2": "We present an approach to training a joint syntactic and semantic parser that combines syntactic training information from CCGbank with semantic training information from a knowledge base via distant supervision.", "label": 1}
{"sent1": "A major challenge for this task is the automatic discovery of such relations.", "sent2": "We present here a novel method for improving distributional paraphrasing by filtering out such candidates.", "label": 0}
{"sent1": "This simplifies semisupervised training considerably.", "sent2": "Our model jointly learns word representations and their composition functions using bagof-words and dependency-based contexts.", "label": 0}
{"sent1": "This paper presents the first results for the normalization of Turkish and tries to shed light on the different challenges in this area.", "sent2": "We empirically measure a systematic improvement in the BLEU scores compared to training using N-best lists, without suffering the increase in computational complexity associated with operating with the whole lattice.", "label": 0}
{"sent1": "In these experiments, starting with a baseline named entity recognition system, we adapt its recognition rules and resources to better fit Twitter language by relaxing its capitalization constraint and by diacritics-based expansion of its lexical resources, and we employ a simplistic normalization scheme on tweets to observe the effects of these on the overall named entity recognition performance on Turkish tweets.", "sent2": "The final vector representations of words are used in the LSTM language model which predicts the next word given all the preceding words.", "label": 0}
{"sent1": "Equipped with a probabilistic model and a large lexicon, the grammar has also been tested in widecoverage machine translation.", "sent2": "The grammar is implemented for Chinese, English, Finnish, and Swedish, sharing the maximum of code to identify similarities and differences between the languages.", "label": 1}
{"sent1": "values and ?simple?", "sent2": "functions into a more complex value space, in a canonical way.", "label": 1}
{"sent1": "This is exemplified via the formalisation of various linguistic examples, including conjoined NPs, comparatives, adjectives as well as various linguistic coercions.", "sent2": "In our submission we use the features from the shared task baseline system and our own features.", "label": 0}
{"sent1": "This lends support to theories of discourse salience that appeal to latent topic representations and suggests that topic models can capture aspects of speakers?", "sent2": "Our scheme, inspired by the Penn Discourse TreeBank (PDTB), adopts the lexically grounded approach; at the same time, it makes adaptations based on the linguistic and statistical characteristics of Chinese text.", "label": 0}
{"sent1": "In a 10-fold cross-validation, we report an overall Fscore of 97% with Na?", "sent2": "The corpus is annotated for all of the rhetorical categories except Introduction without involving domain experts.", "label": 1}
{"sent1": "1 This is especially the case for online user comments, which often consist of arguments lacking proper substantiation and reasoning.", "sent2": "Thus, we develop a framework for automatically classifying each proposition as UNVERIFIABLE, VERIFIABLE NONEXPERIENTIAL, or VERIFIABLE EXPERIENTIAL 2 , where the appropriate type of support is reason, evidence, and optional evidence, respectively 3 .", "label": 1}
{"sent1": "Our experimental results show that our model significantly outperforms a PageRank-based approach.", "sent2": "The algorithm increases the number of extracted parallel sentence pairs significantly, which leads to a BLEU improvement of about 1 % on our SpanishEnglish data.", "label": 0}
{"sent1": "To identify active region of arguments, this paper models Maximal Projection (MP), which is a concept in Dstructure from the projection principle of the Principle and Parameters theory.", "sent2": "We report retrieval and clustering experiments in the case where the word-embeddings are computed from standard topic models showing significant improvements with respect to the original topic models.", "label": 0}
{"sent1": "It outperforms two existing inference algorithms.", "sent2": "With the BLP inference, the LDCRF model significantly outperforms CRF models on word features, and achieves comparable performance of the most successful shallow parsers on the CoNLL data when further using part-ofspeech features.", "label": 1}
{"sent1": "Our objective is to train a sequence labelling system to detect the segment boundaries.", "sent2": "The originality of the proposed approach is to avoid manually annotating the training data and instead exploit the human computational efforts dedicated to message reply formatting when the writer replies to a message by inserting his response just after the quoted text appropriate to his intervention.", "label": 1}
{"sent1": "provide inconsistent results for the same text.", "sent2": "We present a simple semi-supervised learning algorithm for named entity recognition (NER) using conditional random fields (CRFs).", "label": 0}
{"sent1": "diagnostic descriptions, the model improved on the baseline by over 30%.", "sent2": "The introduced computational model provides construct validity for decision styles, as well as insights into the linguistic expression of decision-making.", "label": 1}
{"sent1": "We take a feature-driven approach to annotation, with the result that each clause is also annotated with fundamental aspectual class, whether the main NP referent is specific or generic, and whether the situation evoked is episodic or habitual.", "sent2": "parsing makes 1-best search efficient by suppressing unlikely 1-best items.", "label": 0}
{"sent1": "On the one hand, it is based on a task-based corpus providing more explicit context.", "sent2": "The annotation study is based on the CREG corpus (Ott et al., 2012), which consists of answers to explicitly given reading comprehension questions.", "label": 1}
{"sent1": "A new Multilayer Search Mechanism (MSM) which integrates and quantifies these components into a uniform multilayer treelike architecture is presented in this paper.", "sent2": "A classical Chinese Natural Language Understanding (NLU) architecture usually includes several NLU components which are executed with some mechanism.", "label": 1}
{"sent1": "We explore here the relationship between protein/gene names and expressions used to characterize protein/gene function.", "sent2": "First, we try to define more precisely the context within which a figurative expression may occur, by parsing a corpus annotated for metaphor.", "label": 0}
{"sent1": "Curation is timeconsuming and can be supported by information extraction methods.", "sent2": "We present a server which identifies biological facts in scientific text and presents the annotation to the curator.", "label": 1}
{"sent1": "It offers a wide range of state-of-the-art keyphrase experiments approaches.", "sent2": "First, it did not allow for including lexical properties of tokens in the search.", "label": 0}
{"sent1": "The claim is made that ?logical?", "sent2": "We empirically show effective domain shift detection on a variety of data sets and shift conditions.", "label": 0}
{"sent1": "It robustly identifies a grammar rule that a user intends to utter, even when some important words are missed from the ASR result.", "sent2": "We demonstrate the utility of this measure for  estimating text complexity as measured by US  school grade level designations of texts.", "label": 0}
{"sent1": "The manual annotation of dialogue corpora is both tedious and expensive.", "sent2": "Already after the release of the gold standard annotations of the test data, we observed that using only the similarity measures without combining them with other features would have obtained positions 6th, 7th and 8th; moreover, an arithmetic average of these similarity measures would have been 4th(mean=0.5747).", "label": 0}
{"sent1": "Since it is an iterative task, it should be stopped at some point which is optimum or near-optimum.", "sent2": "As such they represent a valuable resource even though linguists tend to disagree about the role and the methods by which data should influence linguistic exploration (Lehmann, 2004).", "label": 0}
{"sent1": "Semi-supervised word alignment aims to improve the accuracy of automatic word alignment by incorporating full or partial alignments acquired from humans.", "sent2": "Such dedicated elicitation effort is often expensive and depends on availability of bilingual speakers for the language-pair.", "label": 1}
{"sent1": "However, these techniques assume that the labeled examples cover all the classes to learn which might not stand.", "sent2": "In the presence of an imbalanced class distribution getting labeled examples from minority classes might be very costly if queries are randomly selected.", "label": 1}
{"sent1": "These are built using the SDEWAC corpus and evaluated against a dataset from a self-paced reading and a probe recognition study for their sensitivity to thematic fit effects via their accuracy in predicting the correct covert event in a metonymical context.", "sent2": "In this paper we investigate the problem of identifying the perspective from which a document was written.", "label": 0}
{"sent1": "Still, dialog systems are limited by the scale, complexity of the task and coverage of knowledge required by problemsolving machines or mobile personal assistants.", "sent2": "This work is done in the context of an annotation project wherewe construct a parallel treebank by doingword and phrase alignments simultaneously.", "label": 0}
{"sent1": "In this position paper, we focus on statistical methods for user simulation, their main advantages and drawbacks.", "sent2": "We initiate a reflection about the utility of such methods and give some insights of what their future should be.", "label": 1}
{"sent1": "Additionally, it uses innovative features, such as the answer position in the rank and aggregated information such as the min, max and average clue reranking scores.", "sent2": "SACRY uses a database (DB) containing previously solved CPs in order to generate the list of candidate answers.", "label": 1}
{"sent1": "It covers all major stages of the process and allows for easy benchmarking of various approaches.", "sent2": "We present a method which, given a few words defining a concept in some language, retrieves, disambiguates and extends corresponding terms that define a similar concept in another specified language.", "label": 0}
{"sent1": "We introduce tools supporting this approach and apply it to several existing annotation clients and servers, demonstrating direct interoperability between tools and resources that were previously unable to exchange information.", "sent2": "The specification and tools are available from http://restoa.github.io/.", "label": 1}
{"sent1": "QUEST++ allows the extraction of a variety of features, and provides machine learning algorithms to build and test quality estimation models.", "sent2": "These global features are combined with local features using the averaged perceptron algorithm over N-best candidate word segmentations.", "label": 0}
{"sent1": "Worse still, progress on machine learning approaches to named entity recognition for many of these languages is currently hampered by the scarcity of annotated data and the lack of an accurate part-of-speech tagger.", "sent2": "Supplemental representations offer valuable additional information, but incorporating that information is not straightforward.", "label": 0}
{"sent1": "We identify two challenging cases of this problem: when the verb is unseen in training data, and when the verb is ambiguous for aspectual class.", "sent2": "A semi-supervised approach using linguistically-motivated features and a novel set of distributional features based on representative verb types allows us to predict classes accurately, even for unseen verbs.", "label": 1}
{"sent1": "We analyse the (dis)agreements between annotators for two different cases in a multimodal annotated corpus and explicitly relate the results to the way machinelearning algorithms perform on the annotated data.", "sent2": "we focus on computing a semantic distance on field author which has the highest potential to benefit from the domain knowledge.", "label": 0}
{"sent1": "This information comes from the results obtained by the judges, as well as from their personal impressions after passing the test.", "sent2": "Compared to a state-ofthe-art approach, we achieve more than 20% relative error reduction.", "label": 0}
{"sent1": "English and French?English, in which we employed our hybrid EBMT-SMT architecture to translate.", "sent2": "We also participated in the Czech?", "label": 1}
{"sent1": "Our model consists of two sub-models: an anchor word alignment model which aims to find a set of high-precision anchor links and a syntaxenhanced word alignment model which focuses on aligning the remaining words relying on dependency information invoked by the acquired anchor links.", "sent2": "We introduce a word alignment framework that facilitates the incorporation of syntax encoded in bilingual dependency tree pairs.", "label": 1}
{"sent1": "We describe the results from an initial user survey that revealed the power of reordering on the users?", "sent2": "Recently, deep learning-based sequential models of sentence, such as recurrent neural network, have proved to be effective in dealing with the non-sequential properties of human language.", "label": 0}
{"sent1": "Data driven extension words were found to help in over 70% of difficult questions.", "sent2": "These words can be used to improve and evaluate query expansion methods.", "label": 1}
{"sent1": "Evaluation through manual assessment shows that well-formed propositions of reasonable quality, representing general world knowledge, given in a logical form potentially usable for inference, may be extracted in high volume from arbitrary input sentences.", "sent2": "We compare these results with those obtained in recent work on Open Information Extraction, indicating with some examples the quite different kinds of output obtained by the two approaches.", "label": 1}
{"sent1": "Using part of speech information, candidate words are determined among possible translation options, which in turn are estimated through a precomputed word alignment.", "sent2": "This paper constitutes an attempt to find out how subjective annotations with a low level of agreement can profitably be used for machine learning purposes.", "label": 0}
{"sent1": "Chunks correspond to sense units, and end-of-sentence detection is done incrementally based on a notion of semantic/pragmatic completeness.", "sent2": "We here propose a new method which sets apart domain-specific terminology from common non-specific noun phrases.", "label": 0}
{"sent1": "The phonotactic approach we use proves to be effective in identifying these dialects with considerable overall accuracy ?", "sent2": "As clusters are built, information flows between entity and event clusters through features that model semantic role dependencies.", "label": 0}
{"sent1": "The first approach uses Page-Rank (PR) to rank all nodes and selects a candidate based on PR score combined with local confidence score.", "sent2": "This paper presents a novel approach for multi-instance learning with overlapping relations that combines a sentence-level extraction model with a simple, corpus-level component for aggregating the individual facts.", "label": 0}
{"sent1": "In addition, this system introduces a target language model, based on linguistic classes (Part-of-Speech), morphology reduction for an inflectional language (Spanish) and an improved optimization procedure.", "sent2": "Our corpus consists of child sentences with corrected adult forms.", "label": 0}
{"sent1": "In this paper we present a machine learning system that finds the scope of hedge cues in biomedical texts.", "sent2": "Integrated solutions, which may also be used by designers and researchers without technical background, are missing.", "label": 0}
{"sent1": "Finally, we experiment with different tokenization and recasing rules, achieving 35.09% Bleu score on the WMT?07 news test data when translating from English to Spanish, which is a sizable improvement over the highest Bleu score achieved on that dataset at WMT?07: 33.10% (in fact, by our system).", "sent2": "We further add a third phrase translation model trained on a version of the news bi-text augmented with monolingual sentencelevel syntactic paraphrases on the sourcelanguage side, and we combine all models in a log-linear model using minimum error rate training.", "label": 1}
{"sent1": "The algorithm \frst detects the thematic hierarchy of a source text with lexical cohesion measured by term repetitions.", "sent2": "This distinguishes our method from existing ones, which typically require a large amount of effort on the part of humans in the form of document annotation or interactive construction of the feature space.", "label": 0}
{"sent1": "An ideal summarization system would understand each document and generate an appropriate summary directly from the results of that understanding.", "sent2": "A more practical approach to this problem results in the use of an approximation: viewing summarization as a problem analogous to statistical machine translation.", "label": 1}
{"sent1": "This limits the use of WSD in other applications, especially for researchers whose research interests are not in WSD.", "sent2": "In particular, five basic kernel functions are linearly combined and weighted under different conditions.", "label": 0}
{"sent1": "We show that directly optimizing cross-lingual rankings rivals and complements machine translation-based cross-language information retrieval (CLIR).", "sent2": "Large-scale discriminative training has become promising for statistical machine translation by leveraging the huge training corpus; for example the recent effort in phrase-based MT (Yu et al., 2013) significantly outperforms mainstream methods that only train on small tuning sets.", "label": 0}
{"sent1": "We discuss experimentation and analysis in initial and secondary pilot studies.", "sent2": "In both cases, we experimented with computational modeling using features from the acoustic-prosodic and lexical-structural linguistic modalities.", "label": 1}
{"sent1": "Secondly, we show that they are remarkably sensitive to the word order, syntax, and meaning of the source sentence despite lacking alignments.", "sent2": "This paper presents a method for unsupervised discovery of semantic patterns.", "label": 0}
{"sent1": "and ?Why??", "sent2": "questions.", "label": 1}
{"sent1": "We compare the results against a baseline system that always assigns f(ocus) and against a rule-based system.", "sent2": "We present the performance of decision trees (C4.5), maximum entropy, and rule induction (RIPPER) classifiers on all tectogrammatical nodes.", "label": 1}
{"sent1": "Comparative experiments are conducted to show that the widelyknown MUC F-measure has serious flaws in evaluating a coreference system.", "sent2": "Since an annotator?s behaviour during annotation can be seen as reflecting her/his cognitive process during her/his attempt to understand the text for annotation, analysing the process of text annotation has potential to reveal useful information for NLP tasks, in particular semantic and discourse processing that require deeper language understanding.", "label": 0}
{"sent1": "Further, the use of multiple machine translation systems provides yet more redundancy, yielding different ways to realize that information in English.", "sent2": "Typically, information that makes it to a summary appears in many different lexical-syntactic forms in the input documents.", "label": 1}
{"sent1": "Based on the observation that recognition errors may result in ungrammatical sentences, especially in dictation application where an acceptable level of accuracy of generated documents is indispensable, we propose to incorporate two kinds of linguistic features into error detection: lexical features of words, and syntactic features from a robust lexicalized parser.", "sent2": "Recognition errors hinder the proliferation of speech recognition (SR) systems.", "label": 1}
{"sent1": "In this paper, we present methods for recovering automatically from errors committed in the pipeline processing.", "sent2": "By experiments, we show that the proposed model outperforms the bigram Hidden Markov model (HMM)-based tagging model.", "label": 0}
{"sent1": "The probabilistic model used in the alignment directly models the link decisions.", "sent2": "We present a biomedical anaphora resolution system, BioAR, in order to address the variations of protein names and to further associate them with Swiss-Prot entries as the actual entities in the world.", "label": 0}
{"sent1": "In contrast, by modeling both aspects of the EDT task simultaneously, we are able to learn using highly complex, non-local features.", "sent2": "We develop a new joint EDT model and explore the utility of many features, demonstrating their effectiveness on this task.", "label": 1}
{"sent1": "In the TREC novelty track, the task was to highlight sentences containing relevant and new information in a short, topical document stream.", "sent2": "Input Nominal compound is first paraphrased automatically with the 8 prepositions as proposed by Lauer (1995) for the task.", "label": 0}
{"sent1": "Unsupervised induction of grammatical gender is performed via global modeling of contextwindow feature agreement.", "sent2": "It handles irregular, regular and semi-regular morphology through a robust generative model using weighted Levenshtein alignments.", "label": 1}
{"sent1": "When using one billion words, as expected, we do find that many of our estimates do converge to their eventual value.", "sent2": "Our study shows that simple, unsupervised cues can indeed significantly tell unattested but acceptable ANs apart from impossible, or deviant, ANs, and that the simple additive and multiplicative models are the most effective in this task.", "label": 0}
{"sent1": "Our approach relies on a combination of probabilistic models, which we use to model the generation of entities and their context, and kernel machines, which implement powerful categorisers based on a similarity measure and some labelled data.", "sent2": "(ISU) dialogue systems.", "label": 0}
{"sent1": "The Khmer word segmentation tool  (Chea et  al., 2007) is also implemented into the system to improve the accuracy of indexing as well as searching.", "sent2": "The system is built  on top of the popular open source information retrieval software library Lucene 1 .", "label": 1}
{"sent1": "We are currently investigating a method to clarify terms in patent claims and to find the explanatory portions from the detailed description part of the patent specifications.", "sent2": "Through both approaches, we believe we can improve readability of patent claims.", "label": 1}
{"sent1": "We compare the results of machine learning experiments using these features alone or in combination to predict various categorizations of the annotated student emotions.", "sent2": "We characterize the various readings and make an initial proposal about how to create the lexical classes that will allow us to draw the correct inferences in the different cases.", "label": 0}
{"sent1": "Our approach does not predefine frames, associates probabilities with frames conditional on the lemma, distinguishes between active and passive frames, and fully reflects the effects of long-distance dependencies in the source data structures.", "sent2": "We extract abstract syntactic function-based subcategorisation frames (LFG semantic forms), traditional CFG categorybased subcategorisation frames as well as mixed function/category-based frames, with or without preposition information for obliques and particle information for particle verbs.", "label": 1}
{"sent1": "When compared to the handcrafted FrameNet, SemFrame achieves its best recall-precision balance with 83.2% recall (based on SemFrame's coverage of FrameNet frames) and 73.8% precision (based on SemFrame verbs?", "sent2": "Semantic frames are thought to have significant potential in resolving the paraphrase problem challenging many languagebased applications.", "label": 1}
{"sent1": "Existing algorithms work at the semantic level and assume the availability of a classification for attributes, which is only feasible for restricted domains.", "sent2": "We then model the different types of IQAPs using Markov logic networks, which combine first-order logic with probabilities, emphasizing the ways in which this approach allows us to model inferential uncertainty about both the context of utterance and intended meanings.", "label": 0}
{"sent1": "We propose an unsupervised method for relation discovery from large corpora.", "sent2": "The key idea is clustering pairs of named entities according to the similarity of context words intervening between the named entities.", "label": 1}
{"sent1": "Recent work in the biomedical domain has applied distant supervision for proteinprotein interaction (PPI) with reasonable results making use of the IntAct database.", "sent2": "Such data is typically noisy and heuristics to filter the data are commonly applied.", "label": 1}
{"sent1": "and ?disease?", "sent2": "We identify a subproblem ?", "label": 0}
{"sent1": "One is based on n-grams, the other on minimization of the Kullback-Leibler divergence.", "sent2": "We compare two approaches for inducing such languages.", "label": 1}
{"sent1": "We describe deterministic annealing (Rose et al, 1990) as an appealing alternative to the ExpectationMaximization algorithm (Dempster et al, 1977).", "sent2": "Seeking to avoid search error, DA begins by globally maximizing an easy concave function and maintains a local maximum as it gradually morphs the function into the desired non-concave likelihood function.", "label": 1}
{"sent1": "In brief, we use languagedependent hyponym patterns to find a noisy set of initial seeds, and then use a state-of-the-art language-independent set expansion system to expand these seeds.", "sent2": "particle filters, are well suited to approximating such models, resolving their multi-modal nature at the cost of generating additional samples.", "label": 0}
{"sent1": "We employ a generative model that generates a paraphrase of a given sentence, and we use probabilistic inference to reason about whether two sentences share the paraphrase relationship.", "sent2": "Some topics appear to carry a ?focus marker?, indicating that they are particularly salient.", "label": 0}
{"sent1": "We test the efficacy of this method in the context of Chinese word segmentation and part-of-speech tagging, where no segmentation and POS tagging standards are widely accepted due to the lack of morphology in Chinese.", "sent2": "Most state-of-the-art evaluation measures for machine translation assign high costs to movements of word blocks.", "label": 0}
{"sent1": "In addition, we examine various informative sample selection methods.", "sent2": "They suggest areas for future research.", "label": 0}
{"sent1": "The decoder finds ways of decomposing trees in the source forest into elementary trees using the source projection of STSG while building target forest in parallel.", "sent2": "The model is based on a probabilistic synchronous tree substitution grammar (STSG), which can be learned from aligned forest pairs automatically.", "label": 1}
{"sent1": "However, MBR targeting BLEU is prohibitively slow to optimize over k-best lists for large k. In this paper, we introduce and analyze an alternative to MBR that is equally effective at improving performance, yet is asymptotically faster ?", "sent2": "We evaluate these models on two cross-lingual document classification tasks, outperforming the prior state of the art.", "label": 0}
{"sent1": "We instead propose joint decoding, a method that combines multiple translation models in one decoder.", "sent2": "The gold standards additionally narrow the scope of deficiencies in a word prediction system.", "label": 0}
{"sent1": "Our particular variational distributions are parameterized as n-gram models.", "sent2": "Instead, we develop a variational approximation, which considers all the derivations but still allows tractable decoding.", "label": 1}
{"sent1": "Verbs may be ambiguous, in that some meanings may be benefactive and others may be malefactive or neither.", "sent2": "Thus, we use WordNet to create a sense-level lexicon.", "label": 1}
{"sent1": "We compared the performance of CRFs with a set of hand-written rules.", "sent2": "We present a low-resource, languageindependent system for text difficulty assessment.", "label": 0}
{"sent1": "We confirmed that it significantly outperforms previous reported results in both phonetic transcripts and standard datasets for Chinese and Japanese word segmentation.", "sent2": "Our model is also considered as a way to construct an accurate word n-gram language model directly from characters of arbitrary language, without any ?word?", "label": 1}
{"sent1": "Our system advances the current state-of-the-art, predicting primary stress in English, German, and Dutch with up to 98% word accuracy on phonemes, and 96% on letters.", "sent2": "The system is also highly accurate in predicting secondary stress.", "label": 1}
{"sent1": "In this paper, we confront the challenge of building an accurate L2P classifier with a minimal amount of training data by combining several diverse techniques: context ordering, letter clustering, active learning, and phonetic L2P alignment.", "sent2": "Experiments on six languages show up to 75% reduction in annotation effort.", "label": 1}
{"sent1": "The experiments show that better alignment consistently leads to more accurate transliteration.", "sent2": "evaluation, and good performance are achieved.", "label": 0}
{"sent1": "Then we employ a hybrid method combining RBMT and SMT systems to fill up the data gap for pivot translation, where the sourcepivot and pivot-target corpora are independent.", "sent2": "Our results are based on a user study for Spanish native speakers through a group of twenty three dyslexic users and a control group of similar size.", "label": 0}
{"sent1": "These algorithms are more efficient than the lattice-based versions presented earlier.", "sent2": "The proposed method can be considered as exploiting the SMT-based passage retrieval for CLQA task.", "label": 0}
{"sent1": "We examine a number of variations of the method, including the addition of WordNet, partial matching, or removing relation labels from the dependencies.", "sent2": "Most works on relation extraction assume considerable human effort for making an annotated corpus or for knowledge engineering.", "label": 0}
{"sent1": "A typical tweet contains word variations, emoticons, hashtags etc.", "sent2": "We analyze the performance of several parsers as well as the effect on different types of translation models.", "label": 0}
{"sent1": "We explore how to generate a series of summaries with various lengths based on them.", "sent2": "By leveraging syntax-based context, resulting clusters are better when evaluated against a wordnet for Dutch.", "label": 0}
{"sent1": "We use the high-level structure of human-authored texts to automatically induce a domainspecific template for the topic structure of a new overview.", "sent2": "The algorithmic innovation of our work is a method to learn topicspecific extractors for content selection jointly for the entire template.", "label": 1}
{"sent1": "In this paper we propose a data-driven approach for generating short children?s stories that does not require extensive manual involvement.", "sent2": "?ve Bayes, and Conditional Random Field extraction models for fact extraction from individual Web pages.", "label": 0}
{"sent1": "In this paper, we consider the problem of learning high-quality sentiment models with minimal manual supervision.", "sent2": "We use multiple views for cross-domain document classification.", "label": 0}
{"sent1": "In addition, it is presupposed that a single semantic role is assigned to each syntactic argument.", "sent2": "We propose a robust answer reranking model for non-factoid questions that integrates lexical semantics with discourse information, driven by two representations of discourse: a shallow representation centered around discourse markers, and a deep one based on Rhetorical Structure Theory.", "label": 0}
{"sent1": "Like the distillation algorithm of Danescu-Niculescu-Mizil et al.", "sent2": "In particular, the word alignment quality of this new convex model is significantly above that of the standard IBM Models 2 and 3, as well as the popular (and still non-convex) IBM Model 2 variant of (Dyer et al., 2013).", "label": 0}
{"sent1": "We implement this as a bi-class classification problem (i.e.", "sent2": "The models in many of these studies have assumed that arguments are independent of each other.", "label": 0}
{"sent1": "This is a difficult problem, as German verbal elements can appear in different positions within a clause (in contrast with English verbal elements, whose positions do not vary as much).", "sent2": "We obtain a significant improvement in translation performance.", "label": 1}
{"sent1": "microblog) specific improvements including text preprocessing and feature engineering.", "sent2": "Beyond the supervised setting we also introduce some early results employing a huge, automatically annotated tweet dataset.", "label": 1}
{"sent1": "We utilise the original phrases from the input sentence and the corresponding paraphrases to build a lattice with estimated weights for each edge to improve translation quality.", "sent2": "The first algorithm is exact and requires O(n 6 ) running time.", "label": 0}
{"sent1": "Our problem is then abstracted as finding correct mappings across two graphs.", "sent2": "To achieve this goal, we propose a holistic approach, of exploiting both transliteration similarity and monolingual co-occurrences.", "label": 1}
{"sent1": "judgments of text readability.", "sent2": "We combine lexical, syntactic, and discourse features to produce a highly predictive model of human readers?", "label": 1}
{"sent1": "Moreover, connecting black boxes in series tends to multiply errors, especially when the key terms are out-ofvocabulary (OOV).", "sent2": "This paper studies the impact of written language variations and the way it affects the capitalization task over time.", "label": 0}
{"sent1": "Further, our model propagates global information by sharing attributes (e.g., gender and number) across mentions in the same cluster.", "sent2": "Each tier builds on the previous tier?s entity cluster output.", "label": 1}
{"sent1": "Selection preferences for individual phrases are learned discriminatively, while a quasi-synchronous grammar (Smith and Eisner, 2006) captures rendering preferences such as paraphrases and compressions.", "sent2": "Based on an integer linear programming formulation, the model learns to generate summaries that satisfy both types of preferences, while ensuring that length, topic coverage and grammar constraints are met.", "label": 1}
{"sent1": "To address the search challenge, we devise an iterative local search algorithm that stochastically explores reordering possibilities.", "sent2": "By capturing non-local reordering phenomena, our proposed alignment model bears a closer resemblance to stateof-the-art translation model.", "label": 1}
{"sent1": "We classify translation rules into several reordering patterns, and build a MaxEnt model for each pattern based on various contextual features.", "sent2": "The single biggest factor in this improvement has been the accumulation of ever larger stores of data.", "label": 0}
{"sent1": "Our method uses Adistance, a metric for detecting shifts in data streams, combined with classification margins to detect domain shifts.", "sent2": "We empirically show effective domain shift detection on a variety of data sets and shift conditions.", "label": 1}
{"sent1": "Using word fertility features has been shown to be useful in building word alignment models for statistical machine translation.", "sent2": "These dialogs can provide a data source for a more careful analysis of the source of errors.", "label": 0}
{"sent1": "Recent work has been done to extend the algorithm to use the entire translation lattice built by the decoder, instead of N-best lists.", "sent2": "We propose here a third, intermediate way, consisting in growing the translation pool using samples randomly drawn from the translation lattice.", "label": 1}
{"sent1": "This approach not only results in space and efficiency issues, but also suffers from the sparse data problem.", "sent2": "By augmenting the Persian WordNet with the  un-ambiguous words, the total accuracy  of automatically extracted Persian WordNet is about 82.6% which outperforms  the previously semi-automated generated  Persian WordNet by about 12.6%.", "label": 0}
{"sent1": "Active sample selection aims to reduce the labor, time, and expense incurred in producing such resources, attaining a given performance benchmark with the smallest possible training corpus by choosing informative, nonredundant source sentences from an available candidate pool for manual translation.", "sent2": "Experiments with k-means and hierarchical clustering algorithms show significant improvements over the alternative \u0001\u0002 \u0003\u0004\u0005\u0002 vector representation.", "label": 0}
{"sent1": "We expand the experiment by automatically inserting these elements into a larger data set using various methods and training on the modified corpus.", "sent2": "It also enables the visualization of the structure of the regular expression components, providing a bird?s eye view of the overall system, enabling a user to easily understand and track the structural and functional relationships among the components involved.", "label": 0}
{"sent1": "We use a pipeline approach, in which syntactic dependency parsing, word sense disambiguation, and semantic role labeling are performed separately: Syntactic dependency parsing is performed by a tournament model with a support vector machine; word sense disambiguation is performed by a nearest neighbour method in a compressed feature space by probabilistic latent semantic indexing; and semantic role labeling is performed by a an online passive-aggressive algorithm.", "sent2": "This paper describes our system for syntactic and semantic dependency parsing to participate the shared task of CoNLL2008.", "label": 1}
{"sent1": "So we propose a novel approach which extracts rules from a packed forest that compactly encodes exponentially many parses.", "sent2": "Moreover, the proposed semantic similarity measure significantly improves the accuracy (F measure of 0.78) in a named entity clustering task, proving the capability of the proposed measure to capture semantic similarity using web content.", "label": 0}
{"sent1": "The remaining three modules are implemented by using maximum entropy classifiers.", "sent2": "Most of the Internet data for Indian languages exist in various encodings, causing difficulties in searching for the information through search engines.", "label": 0}
{"sent1": "as a feature on the syntax-semantics interface to handle phenomena associated with definiteness.", "sent2": "Biterm Topic Model (BTM) is designed to model the generative process of the word co-occurrence patterns in short texts such as tweets.", "label": 0}
{"sent1": "Our recurrent neural network based model captures both word sequence and dependency tree substructure information by stacking bidirectional treestructured LSTM-RNNs on bidirectional sequential LSTM-RNNs.", "sent2": "This allows our model to jointly represent both entities and relations with shared parameters in a single model.", "label": 1}
{"sent1": "This differs from phone-based models in that pronunciation variation is viewed as the result of feature asynchrony and changes in feature values, rather than phone substitutions, insertions, and deletions.", "sent2": "We present experiments with a dependency parsing model defined on rich factors.", "label": 0}
{"sent1": "This question highlights the tension that sometimes appears in the development of corpora between linguistic considerations and the aim for perfection on the one hand and practical applications and the aim for efficiency on the other.", "sent2": "The dataset is freely available at https://stanford-qa.com.", "label": 0}
{"sent1": "Intuitively, prosodic cues would seem to provide much the same information in speech as punctuation does in text, so we tried to incorporate them into our parser in much the same way as punctuation is.", "sent2": "This paper investigates the usefulness of sentence-internal prosodic cues in syntactic parsing of transcribed speech.", "label": 1}
{"sent1": "It is one of the reasons why speech synthesis applications are prone to produce unnatural speech.", "sent2": "This paper represents a method of paraphrasing unsuitable expressions for spoken language into suitable ones.", "label": 1}
{"sent1": "The problem is that words are generally built by concatenating several prefixes and suffixes to the word roots.", "sent2": "We introduce a methodology to elicit novel templates from the crowd based on a dialogue seed corpus, and investigate the effect that the amount of surrounding dialogue context has on the generation task.", "label": 0}
{"sent1": "We suggest here that appraisal expression extraction should be viewed as a fundamental task in sentiment analysis.", "sent2": "We also describe our contribution to the CogALex 2014 shared task.", "label": 0}
{"sent1": "In this paper, we propose a novel framework for discriminative training of alignment models with automated translation metrics as maximization criterion.", "sent2": "In this approach, alignments are optimized for the translation task.", "label": 1}
{"sent1": "the name of an event or person, etc.).", "sent2": "We present an approach for detecting salient (important) dates in texts in order to automatically build event timelines from a search query (e.g.", "label": 1}
{"sent1": "Because this is a longitudinal data set, we are also interested in understanding how these opinions change over the course of decades.", "sent2": "We study the language use in these legal cases, with a special focus on shifts in opinions on controversial topics across different regions.", "label": 1}
{"sent1": "We therefore propose a topic similarity model to exploit topic information at the synchronous rule level for hierarchical phrase-based translation.", "sent2": "To acquire this knowledge, relationships between nouns are retrieved by using search phrases with automatically filled constituents.", "label": 0}
{"sent1": "The core of MAISE?s codebase was used for the manual evaluation of WMT10, and the completed package is being used again in the current evaluation for WMT11.", "sent2": "We divide the task into independent steps which we approach as machine learning problems.", "label": 0}
{"sent1": "on TER.", "sent2": "Novel techniques compared with RWTH?s submission to WMT 2010 include two additional system combination engines, an additional word alignment technique, meta combination, and additional optimization techniques.", "label": 1}
{"sent1": "The expected BLEU tuning described in this paper naturally generalizes to hypergraphs and can be used to optimize thousands of weights.", "sent2": "The combination gained about 0.5-4.0 BLEU points over the best individual systems on the official WMT11 language pairs.", "label": 1}
{"sent1": "TYPED, on the other hand, is novel and tries to characterize why two items are deemed similar, using cultural heritage items which are described with metadata such as title, author or description.", "sent2": "Several types of similarity have been defined, including similar author, similar time period or similar location.", "label": 1}
{"sent1": "We participated in the system combination task for the translation directions DE?EN and EN?DE.", "sent2": "The system uses Moses as a backbone, with the outputs of the 2?3 best individual systems being integrated through additional phrase tables.", "label": 1}
{"sent1": "We analyzed the effect of bilingual language models and show where they could help to better model the translation process.", "sent2": "Recent years?", "label": 0}
{"sent1": "techniques which allow the translation system to select among a range of possible S?V re-orderings.", "sent2": "With this approach, we demonstrate a 0.3-point improvement in BLEU score (69% of the maximum possible using gold parses), and a corresponding improvement in the percentage of syntactically well-formed subjects under a manual evaluation.", "label": 1}
{"sent1": "et al., 2012), and the 2013 STS task focused more on predicting similarity for text pairs from new domains.", "sent2": "However, approaches including word and n-gram features also performed well (Ba?r et al., 2012; S?aric?", "label": 1}
{"sent1": "The goal is to evaluate the degree of semantic similarity between semi-structured records.", "sent2": "The work described in this paper particularly shows effects of the mentioned processes in the context of the *SEM 2013 pilot task on typed-similarity, a part of the Semantic Textual Similarity shared task.", "label": 1}
{"sent1": "Our third system with different training data and different feature sets for each test data set performs the best and ranks 35 out of 90 runs.", "sent2": "We submitted three Support Vector Regression (SVR) systems in core task, using 6 types of similarity measures, i.e., string similarity, number similarity, knowledge-based similarity, corpus-based similarity, syntactic dependency similarity and machine translation similarity.", "label": 1}
{"sent1": "This discrepancy is a source of difficulty when translating between these languages because there are words in one language that correspond to empty categories in the other, and these words must either be inserted or deleted?depending on translation direction.", "sent2": "In this paper, we propose a novel framework for discriminative training of alignment models with automated translation metrics as maximization criterion.", "label": 0}
{"sent1": "The initial translation equivalents can be extracted with the help of the techniques and tools developed for the phrase-table construction in statistical machine translation.", "sent2": "Third, we integrate the relation topics in a kernel function, and use it together with SVM to construct detectors for new relations.", "label": 0}
{"sent1": "To identify salient events in a given history article, we exploit lexical cues about the article?s subject area, as well as time expressions that are syntactically attached to an event word.", "sent2": "This scenario is in contrast to existing works on timeline generation, which require the presence of a large corpus of news articles.", "label": 1}
{"sent1": "We use both text-based and image-based features, which depict complementary improvements.", "sent2": "We present multiple approaches, via unary (position) and pairwise (order) predictions, and their ensemble-based combinations, achieving strong results on this task.", "label": 1}
{"sent1": "Annotators annotate the email content type and email importance for three levels of hierarchy (senior manager, middle manager and employee).", "sent2": "Each email is annotated by 5 turkers.", "label": 1}
{"sent1": "The unique challenges include: (1) Chinese verbs do not have explicit lexical or grammatical forms to indicate tense; (2) Tense information is often implicitly hidden outside of the target sentence.", "sent2": "stance (PRO or CON) towards discussion topics in domains such as politics or news is an important problem, and is of utility to researchers, government organizations, and companies.", "label": 0}
{"sent1": "No complex or hierarchical structure is assumed or used in the input dictionaries: each is initially parsed into the ?lowest common denominator?", "sent2": "Further, we show that the models learned from crowdsourced annotations fare as well as the models learned from expert annotations in downstream tasks.", "label": 0}
{"sent1": "The proposed model is based on the observation that when there exist words (surface forms) that share the same lexical forms, the probabilities to appear are different from each other.", "sent2": "This causes an inaccurate calculation of the probability.", "label": 1}
{"sent1": "We present experimental results under variable resource conditions.", "sent2": "We argue for the benefits of using rich morphosyntactic tagsets in cross-lingual parsing and empirically support the claim by showing large improvements over an impoverished common feature representation in form of a reduced part-of-speech tagset.", "label": 0}
{"sent1": "We propose to use predicate-argument structures (PASs), which are outputs of a full parser, to obtain verbs and their arguments.", "sent2": "In this paper, we evaluated PAS method by comparing it to a method using part of speech (POSs) pattern matching.", "label": 1}
{"sent1": "in Visual Question Answering (VQA) to understand where humans choose to look to answer questions about images.", "sent2": "The discovery of semantic relations from text becomes increasingly important for applications such as Question Answering, Information Extraction, Text Summarization, Text Understanding, and others.", "label": 0}
{"sent1": "We develop two novel learning algorithms capable of predicting complex structures which only rely on a binary feedback signal based on the context of an external world.", "sent2": "Factorization lowers the rank of a production but may increase its fan-out.", "label": 0}
{"sent1": "Our system is designed to function as a baseline, to see what we can accomplish with well-understood and purely data-driven lexical features, simple generalizations as well as standard machine learning techniques: We use one-against-one Support Vector Machines with asymmetric cost factors and linear ?kernels?", "sent2": "This paper describes University of Leipzig?s approach to SemEval-2013 task 2B on Sentiment Analysis in Twitter: message polarity classification.", "label": 1}
{"sent1": "The main goal was to evaluate the best settings for a sentiment analysis component to be added to the online news monitoring system.", "sent2": "We propose an innovative way to apply a fast adaptation scheme at a semantic level, providing recommendations and arguments in phase with the very recent past.", "label": 0}
{"sent1": "Multilingual Semantic Textual Similarity.", "sent2": "We propose to model Semantic Textual Similarity in the context of Multi-task Learning in order to deal with inherent challenges of the task such as unbalanced performance across domains and the lack of training data for some domains (i.e.", "label": 1}
{"sent1": "ambiguities, namely those where the intended interpretation fails to be considerably more likely than alternative ones.", "sent2": "The goal of this article is to present our work about a combination of several syntactic parsers to produce a more robust parser.", "label": 0}
{"sent1": "Second, it combines a simplification model for splitting and deletion with a monolingual translation model for phrase substitution and reordering.", "sent2": "An alternative method we propose is to use trigger pairs that are automatically extracted by a feature induction algorithm.", "label": 0}
{"sent1": "The key idea is to introduce a new type of transition that reorders top k elements in the memory module.", "sent2": "Machine learning techniques inadequately solve the stated problem because automatic speakerindependent speech transcription is inaccurate.", "label": 0}
{"sent1": "The resulting relations are often noisy or difficult to interpret in general.", "sent2": "To the best of our knowledge, this online learning capability has never been provided by previous IMT systems.", "label": 0}
{"sent1": "signature.", "sent2": "In accordance, they extend the vector space paradigm by structuring elements with relational information that decompose distributional signatures over discrete relation dimensions.", "label": 1}
{"sent1": "Secondly, we focus more specifically on improving the obtained thesaurus, seen as a graph of k-nearest neighbors.", "sent2": "We propose a sentence generation strategy that describes images by predicting the most likely nouns, verbs, scenes and prepositions that make up the core sentence structure.", "label": 0}
{"sent1": "In this paper, we show that under a suitable regime these two approaches can be regarded as the same and, thus, structural information and distributional semantics can successfully cooperate in CSDMs for NLP tasks.", "sent2": "We illustrate with examples of output, and briefly note results from user studies with the earlier CRAG-1, indicating how CRAG-2 will be further evaluated.", "label": 0}
{"sent1": "Manifold DSM are constructed starting from a pairwise word-level semantic similarity matrix.", "sent2": "The proposed model is evaluated on semantic similarity estimation task significantly improving on the state-of-the-art.", "label": 1}
{"sent1": "(2005) in two ways to adjust it for the parsing of MT outputs.", "sent2": "We show that our system is able to improve the quality of the state-of-the-art MT systems.", "label": 1}
{"sent1": "We conclude with qualitative feedback from researchers who have used DOCREP for their own projects.", "sent2": "We transform the OntoNotes 5 corpus using DOCREP and UIMA, providing a quantitative comparison, as well as discussing modelling trade-offs.", "label": 1}
{"sent1": "For sentiment classification we use Random Forest classifier.", "sent2": "The algorithms are informed by linguistic and sentiment-based features computed from full documents and summaries.", "label": 0}
{"sent1": "This is the first time we attempt for this task, and our submissions are based on supervised machine learning algorithm.", "sent2": "This paper develops a novel joint learning algorithm for both tasks, that uses the final prediction to guide the selection of the best intermediate representation.", "label": 0}
{"sent1": "We implement the features for sentiment analysis without using deep domain-specific resources and/or tools.", "sent2": "More specifically, we identify 14 aspects related to the content of news articles.", "label": 0}
{"sent1": "We use a supervised learning approach, evaluate various features and report accuracies which are much higher than the provided baselines.", "sent2": "A detailed evaluation analysis is presented.", "label": 0}
{"sent1": "We conducted several annotation experiments and showed that human annotators can reliably differentiate between semantically coherent and incoherent speech recognition hypotheses (both with and without discourse context).", "sent2": "We apply the contextually enhanced system to the task of scoring alternative speech recognition hypotheses (SRH) in terms of their semantic coherence.", "label": 1}
{"sent1": "The parsing systems, despite both being dependency-based, return different types of dependencies, making a direct comparison impossible.", "sent2": "We address the problem of learning a morphological automaton directly from a monolingual text corpus without recourse to additional resources.", "label": 0}
{"sent1": "These are stored and retrieved from a construction inventory based on the constellation of closed class items uniquely identifying each construction.", "sent2": "Sentence to meaning mappings are learned and stored as grammatical constructions.", "label": 1}
{"sent1": "We propose a novel approach for bootstrapping spoken dialog systems based on reuse of existing transcribed and labeled data, common reusable dialog templates and patterns, generic language and understanding models, and a consistent design process.", "sent2": "The visualization displays a regularized training objective; it supports gradient ascent by optionally displaying gradients on the sliders and providing ?Step?", "label": 0}
{"sent1": "However, in many applications, it may be informative to compare the overall sense distributions for two different contexts.", "sent2": "We propose a new method for comparing two probability distributions over WordNet, which captures in a single measure the aggregate semantic distance of the component nodes, weighted by their probability.", "label": 1}
{"sent1": "Speaking styles vary and depend on type of task and dialog state.", "sent2": "Experimental results show that the proposed method achieves higher accuracy.", "label": 0}
{"sent1": "At the same time term recognition must be performed in realistic times.", "sent2": "A complex sentence, divided into clauses, can be analyzed more easily than the complex sentence itself.", "label": 0}
{"sent1": "Methods like Maximum Entropy and Conditional Random Fields make use of features for the training purpose.", "sent2": "Despite their flat, semantics-free structure, ontology identifiers are often given names or labels corresponding to natural language words or phrases which are very dense with information as to their intended referents.", "label": 0}
{"sent1": "Similes are a convenient vehicle for this kind of knowledge, insofar as they mark out the most salient aspects of the most frequently evoked concepts.", "sent2": "Second, it progresses from easier to harder sentences, to minimize any hindrance on preposition learning that might be posed by difficult vocabulary.", "label": 0}
{"sent1": "We focus on the problem of lexical representation, introducing features that incorporate word clusters derived from a large unannotated corpus.", "sent2": "The task of machine translation (MT) evaluation is closely related to the task of sentence-level semantic equivalence classification.", "label": 0}
{"sent1": "However, STAG parsing is known to be NP-hard due to the potential for intertwined correspondences between the linked nonterminal symbols in the elementary structures.", "sent2": "Our findings are compared to the theoretical models and based on this we deduce which models best describe learning and forgetting in our automotive environment.", "label": 0}
{"sent1": "To evaluate the proposed method, a spoken dialog system for a building guidance robot was developed.", "sent2": "Preliminary evaluation shows this approach would be effective to improve the robustness of example-based dialog modeling.", "label": 1}
{"sent1": "from small amounts of Wizard-of-Oz (WOZ) data.", "sent2": "This use of WOZ data allows development of optimal strategies for domains where no working prototype is available.", "label": 1}
{"sent1": "In this work, we apply the ETL framework to four phrase chunking tasks: Portuguese noun phrase chunking, English base noun phrase chunking, English text chunking and Hindi text chunking.", "sent2": "In all four tasks, ETL shows better results than Decision Trees and also than TBL with hand-crafted templates.", "label": 1}
{"sent1": "At its heart, our approach is an EM algorithm that seeks a model which maximizes the regularized marginal likelihood of the bagof-words documents.", "sent2": "This paper is an analysis of the claim that a universal ban on certain (?anti-markedness?)", "label": 0}
{"sent1": "We incorporate up to 1G-words (one billion tokens) of unlabeled data, which is the largest amount of unlabeled data ever used for these tasks, to investigate the performance improvement.", "sent2": "Then, we describe experiments performed on widely used test collections, namely, PTB III data, CoNLL?00 and ?03 shared task data for the above three NLP tasks, respectively.", "label": 1}
{"sent1": "We present a method for obtaining surface paraphrases, using a 150GB (25 billion words) monolingual corpus.", "sent2": "Our method achieves an accuracy of around 70% on the paraphrase acquisition task.", "label": 1}
{"sent1": "Heuristic methods are designed to extract question focus and generate proper condition patterns from question.", "sent2": "To validate an answer candidate, the approach calculates the conditional information distance between the question focus and the candidate under certain condition pattern set.", "label": 1}
{"sent1": "Models for assessing fluency, meaning preservation and lexical divergence are used to rank possible rephrasings, and their relative weight can be tuned by the user so as to better address her needs.", "sent2": "Our results surpass the current state-of-the-art on six publicly available data sets representing four different languages.", "label": 0}
{"sent1": "However, an open issue is which semantic relations are cognitively most salient, and should therefore be used for dictionary construction.", "sent2": "In this paper, we present a concept description elicitation experiment conducted with German and Italian speakers.", "label": 1}
{"sent1": "Compression by Partial Match (PPM) is an adaptive statistical modelling technique that is widely used in the field of text compression.", "sent2": "We examine several basic concerns in modeling contrasting meaning to provide detailed analysis, with the aim to shed some light on the future directions for this basic semantics modeling problem.", "label": 0}
{"sent1": "We present a web-based concept extension algorithm.", "sent2": "This paper proposes an approach to improve graph-based dependency parsing by using decision history.", "label": 0}
{"sent1": "We create a graph for labeled and unlabeled data using match-scores of textual entailment features as similarity weights between data points.", "sent2": "We present an algorithm for calculating the expected frequencies of arbitrary subtrees given the parameters of an STSG, and a method for estimating the parameters of an STSG given observed frequencies in a tree bank.", "label": 0}
{"sent1": "They can be obtained by training statistical translation models on parallel monolingual corpora, such as question-answer pairs, where answers act as the ?source?", "sent2": "language and questions as the ?target?", "label": 1}
{"sent1": "In this paper, we propose an Opinion PageRank model and an Opinion HITS model to fully explore the information from different relations among questions and answers, answers and answers, and topics and opinions.", "sent2": "Moreover, the evidence suggests that curcumin may have a beneficial and therapeutic role in the context of these diseases.", "label": 0}
{"sent1": "Recently, McDonald et al (2005b) formalized dependency parsing as a maximum spanning tree (MST) problem, which can be solved in quadratic time relative to the length of the sentence.", "sent2": "We provide a detailed preliminary analysis of inter-annotator agreement ?", "label": 0}
{"sent1": "Unlike previous approaches, we do not resort to heuristics or constraints from a word-alignment model, but instead directly induce a synchronous grammar from parallel sentence-aligned corpora.", "sent2": "I explore the given manually annotated data using word features such as the length, endings and character trigrams.", "label": 0}
{"sent1": "We propose using source-language monolingual models and resources to paraphrase the source text prior to translation.", "sent2": "Contrary to previous work our system does not follow a generate-and-rank architecture.", "label": 0}
{"sent1": "Our studies of correspondences in the two languages show that case markers and suffixes in Hindi are predominantly determined by the combination of suffixes and semantic relations on the English side.", "sent2": "We, therefore, augment the aligned corpus of the two languages, with the correspondence of English suffixes and semantic relations with Hindi suffixes and case markers.", "label": 1}
{"sent1": "In this paper, we propose a novel method for statistical paraphrase generation (SPG), which can (1) achieve various applications based on a uniform statistical model, and (2) naturally combine multiple resources to enhance the PG performance.", "sent2": "In our experiments, we use the proposed method to generate paraphrases for three different applications.", "label": 1}
{"sent1": "We present an efficient search algorithm that does not require any training data or SMS normalization and can handle semantic variations in question formulation.", "sent2": "We demonstrate the effectiveness of our approach on two reallife datasets.", "label": 1}
{"sent1": "opinions of the system, we used a method based on the PARADISE evaluation framework (Walker et al, 1997) to derive a performance function from our data.", "sent2": "The tool was designed to build the NTU-Multilingual Corpus (Tan and Bond, 2012).", "label": 0}
{"sent1": "However, when building a new dialog system, usually no data or only a small amount of data is available.", "sent2": "The t-test results showed that there is no significant difference between BlogSum-generated summaries and OList summaries.", "label": 0}
{"sent1": "In this  experiment, segmentation was done on a  level of analysis similar to adjacency pairs.", "sent2": "We interpret the variation in performance achieved by different settings of the model parameters as an indication of which aspects of distributional patterns characterize these types of relations.", "label": 0}
{"sent1": "First, in order to incorporate non-local information into abbreviation generation tasks, we present both implicit and explicit solutions: the latent variable model, or alternatively, the label encoding approach with global information.", "sent2": "The present paper describes a robust approach for abbreviating terms.", "label": 1}
{"sent1": "We develop an algorithm that maintains explicit, lambda-calculus representations of salient discourse entities and uses a context-dependent analysis pipeline to recover logical forms.", "sent2": "This is the first study to take into account such a variety of linguistic factors and the first to empirically demonstrate that discourse relations are strongly associated with the perceived quality of text.", "label": 0}
{"sent1": "Summary sentences are ranked by a regression SVM.", "sent2": "Like other DOP models, our parser utilizes syntactic fragments of arbitrary size from a treebank to analyze new sentences, but, crucially, it uses only those which are encountered at least twice.", "label": 0}
{"sent1": "We evaluate an existing Penn-treebank-trained parser on the ungrammatical treebank to see how it reacts to noise in the form of grammatical errors.", "sent2": "We re-train this parser on the training section of the ungrammatical treebank, leading to an significantly improved performance on the ungrammatical test sets.", "label": 1}
{"sent1": "Each weighted edge encodes a relation that exists between two words.", "sent2": "We first show how a structural locality bias can improve the accuracy of state-of-the-art dependency grammar induction models trained by EM from unannotated examples (Klein and Manning, 2004).", "label": 0}
{"sent1": "We set these trade-offs by analysing existing MATCH data.", "sent2": "We then train a NLG policy using Reinforcement Learning (RL), which adapts its behaviour to noisy feedback from the current generation context.", "label": 1}
{"sent1": "We evaluate algorithms based on the match with gold standard head-annotations, and the comparative parsing accuracy of the lexicalized grammars they give rise to.", "sent2": "On the first task, we approach the accuracy of handdesigned heuristics for English and interannotation-standard agreement for German.", "label": 1}
{"sent1": "Thus, we present a supervised machine learning approach to image annotation utilizing non-lexical features1 extracted from image-related text to select useful terms.", "sent2": "Unfortunately, this problem is generally domainspecific because indexing terms that are useful in one domain can be ineffective in others.", "label": 1}
{"sent1": "Furthermore, we describe a straightforward solution on approximating the LDI, and show that the approximated LDI performs as well as the exact LDI, while the speed is much faster.", "sent2": "In this paper, we describe the latent-dynamic inference (LDI), which is able to produce the optimal label sequence on latent conditional models by using efficient search strategy and dynamic programming.", "label": 1}
{"sent1": "The probability of an entire parse tree is computed as the product of the probabilities of individual chunking results.", "sent2": "We convert the task of full parsing into a series of chunking tasks and apply a conditional random field (CRF) model to each level of chunking.", "label": 1}
{"sent1": "Its predictions correlate significantly with the human judgments.", "sent2": "We illustrate with examples of output, and briefly note results from user studies with the earlier CRAG-1, indicating how CRAG-2 will be further evaluated.", "label": 0}
{"sent1": "These questions are then ranked by a logistic regression model trained on a small, tailored dataset consisting of labeled output from our system.", "sent2": "In response to a reading input, we calculate the plausibility of each dictionary entry corresponding to the reading and display a list of candidates for the user to choose from.", "label": 0}
{"sent1": "The evaluation set of multiword expressions is derived from WordNet and the textual data are downloaded from the web.", "sent2": "Our system is superior to vector-space ranking techniques from IR, and its accuracy approaches that of the top contenders at the TREC QA tasks in recent years.", "label": 0}
{"sent1": "In this paper, we modeled this long-distance information in dependency formalism and integrated it into the process of HPSG supertagging.", "sent2": "Knowledge graphs are useful resources for numerous AI applications, but they are far from completeness.", "label": 0}
{"sent1": "Combing a semantic dictionary, it uses multiple semantic codes to represent a paraphrase template.", "sent2": "We achieve CoNLL scores of 63.33 and 62.91 on the CoNLL-2012 DEV and TEST splits of the OntoNotes 5 corpus, beating the publicly available state of the art systems.", "label": 0}
{"sent1": "We assume that the context of a sentence is indicated by a latent variable of the model as a topic and that the likelihood of each variable can be inferred.", "sent2": "In addition to its own functionality, it provides interfaces to external software and corpora.", "label": 0}
{"sent1": "They may be made up of recycled fragments of text taken from important sentences in an input document.", "sent2": "When integrated into the treebanking environment, the model brings a significant annotation speed-up with improved inter-annotator agreement.", "label": 0}
{"sent1": "The viability of the proposed method was tested on a Japanese verb (X-ga Y -wo) osou (roughly meaning ?X attack(s) Y ,?", "sent2": "?X hit(s) Y ,?", "label": 1}
{"sent1": "We use the corpora to analyze how nurses perform their nursing duties and how they express the perform ance of their tasks.", "sent2": "Our method uses automatically extracted features such as phrases and dependency trees, called subtree features, for semi-supervised learning.", "label": 0}
{"sent1": "The mega-word British component has been constructed, grammatically tagged, and syntactically parsed.", "sent2": "This article is a description of work that aims at the automatic induction of a wide-coverage grammar from this corpus as well as an empirical evaluation of the grammar.", "label": 1}
{"sent1": "The system uses uses syntactic information from Penn Treebank parse trees.", "sent2": "Our experiments confirm that in movies that fail the test, women are in fact portrayed as less-central and less-important characters.", "label": 0}
{"sent1": "We argue that a more sophisticated and fine-grained annotation in the treebank would have very positve effects on stochastic parsers trained on the treebank and on grammars induced from the treebank, and it would make the treebank more valuable as a source of data for theoretical linguistic investigations.", "sent2": "The information gained from corpus research and the analyses that are proposed are realized in the framework of SILVA, a parsing and extraction tool for German text corpora.", "label": 1}
{"sent1": "Honorifics are used extensively in Japanese, reflecting the social relationship (e.g.", "sent2": "Verb-particle combinations (VPCs) consist of a verbal and a preposition/particle component, which often have some additional meaning compared to the meaning of their parts.", "label": 0}
{"sent1": "Such an approach, especially the corpus-driven nature of it, yields several advantages over more traditional approaches.", "sent2": "Previous experiments have proven that bilingual lexicons can be created by applying word alignment on parallel corpora.", "label": 1}
{"sent1": "Experiments show that MaltOptimizer can improve parsing accuracy by up to 9 percent absolute (labeled attachment score) compared to default settings.", "sent2": "During the demo session, we will run MaltOptimizer on different data sets (user-supplied if possible) and show how the user can interact with the system and track the improvement in parsing accuracy.", "label": 1}
{"sent1": "This demonstration shows how Fluid Construction Grammar (FCG), a fully operational and bidirectional unification-based grammar formalism, caters for this increasing demand.", "sent2": "FCG features many of the tools that were pioneered in computational linguistics in the 70s-90s, but combines them in an innovative way.", "label": 1}
{"sent1": "To avoid ungrammatical sentences, the tool also makes use of a number of rules.", "sent2": "These probabilities were estimated from a parallel transcript/subtitle corpus.", "label": 1}
{"sent1": "Integrating one of these services in a particular application requires to implement an appropriate driver.", "sent2": "Furthermore, the results of these services are not comparable due to different formats.", "label": 1}
{"sent1": "The network of actors and their relations can be mined for insights about the structure of the narration, including the identification of the key players, of the network of political support of each of them, a representation of the similarity of their political positions, and other information concerning their role in the media narration of events.", "sent2": "(one example of a triplet of this kind is ?Romney Criticised Obama?).", "label": 1}
{"sent1": "The data collected in this work is freely available to the research community.", "sent2": "The paper presents four experiments that aim at improving parsing performance of coordinate structure: 1) reranking the n-best parses of a PCFG parser, 2) enriching the input to a PCFG parser by gold scopes for any conjunct, 3) reranking the parser output for all possible scopes for conjuncts that are permissible with regard to clause structure.", "label": 0}
{"sent1": "Our method is domain-independent and can be adapted to other speech and language processing areas where domain adaptation is expensive to perform.", "sent2": "The performance bottleneck of a discourse parser comes from implicit discourse relations, whose discourse connectives are not overtly present.", "label": 0}
{"sent1": "?", "sent2": "as an orthogonal notion to ?depth in time?", "label": 1}
{"sent1": "This architecture allows information to flow not only bottom-up, as in traditional recursive neural networks, but also topdown.", "sent2": "The Smoothed Partial Tree Kernel is applied, i.e.", "label": 0}
{"sent1": "In this work, we propose a novel way of learning a neural network classifier for use in a greedy, transition-based dependency parser.", "sent2": "Our evaluation on the nouns of SemEval-2007 WSI task (SWSI) shows that: (1) all GCM estimate a set of parameters which significantly outperform the worst performing parameter setting in both SWSI evaluation schemes, (2) all GCM estimate a set of parameters which outperform the Most Frequent Sense (MFS) baseline by a statistically significant amount in the supervised evaluation scheme, and (3) two of the measures estimate a set of parameters that performs closely to a set of parameters estimated in supervised manner.", "label": 0}
{"sent1": "We have observed that incorrect parses often result in wildly implausible semantic interpretations of sentences, which can be detected automatically using semantic information obtained from the Web.", "sent2": "The two grid constructions can also be combined to produce consistently strong results across all training sets.", "label": 0}
{"sent1": "We also introduce a novel metric to measure translation adequacy based on predicate-argument structure match using word alignments.", "sent2": "In this paper we present a method for unsupervised semantic role induction which we formalize as a graph partitioning problem.", "label": 0}
{"sent1": "The decision tree model achieves an overall accuracy of 79.5%, significantly outperforming the hand-crafted algorithm (64.4%).", "sent2": "We use statistical approach for tagging, parsing, and reference resolution stages.", "label": 0}
{"sent1": "acknowledgement of the use of the cited method).", "sent2": "Citation function is defined as the author?s reason for citing a given paper (e.g.", "label": 1}
{"sent1": "Parser performance for the models trained on Tu?Ba-D/Z are comparable to parsing results for English with the Stanford parser, when trained on the Penn treebank.", "sent2": "The experiments also show that there is a big difference in parsing performance, when trained on the Negra and on the Tu?BaD/Z treebanks.", "label": 1}
{"sent1": "In such cases, we seek to adapt existing models from a resourcerich source domain to a resource-poor target domain.", "sent2": "We introduce structural correspondence learning to automatically induce correspondences among features from different domains.", "label": 1}
{"sent1": "Extensive experimental evaluation in the CoNLL2005 shared task framework supports our previous claims.", "sent2": "This combination scheme is also very flexible since the individual systems are not required to provide any information other than their solution.", "label": 1}
{"sent1": "The syntactic features improve the Arabic and English systems significantly, but play a limited role in the Chinese one.", "sent2": "Detailed analyses are done to understand the syntactic features?", "label": 1}
{"sent1": "With a highly inflected language such as Czech, this problem can be particularly severe.", "sent2": "In statistical machine translation, estimating word-to-word alignment probabilities for the translation model can be difficult due to the problem of sparse data: most words in a given corpus occur at most a handful of times.", "label": 1}
{"sent1": "The experimental results demonstrate that our learning algorithm is more effective than the ones commonly used in the literature for distant supervision of information extraction models.", "sent2": "On several data conditions, we show that our method outperforms the baseline and results in up to 8.5% improvement in the F 1 -score.", "label": 1}
{"sent1": "Moreover, our approach can incorporate external synonymy information (increasing its pairwise accuracy to 78%) and extends easily to new languages.", "sent2": "We then lay out a research agenda in advancing the state-of-theart in rule-based IE systems which we believe has the potential to bridge the gap between academic research and industry practice.", "label": 0}
{"sent1": "Compared to linguistic grammars learned from rich phrase-structure treebanks, well designed pseudo grammars achieve similar parsing accuracy and have equivalent contributions to parser ensemble.", "sent2": "Based on the structured perceptron, we propose a general framework of ?violation-fixing?", "label": 0}
{"sent1": "In most work on this topic, however, utterances in a conversation are treated independently and discourse structure information is largely ignored.", "sent2": "Experimental results demonstrate its advantage over existing algorithms.", "label": 0}
{"sent1": "The space defined by loose reordering constraints is dynamically pruned through a binary classifier that predicts whether a given input word should be translated right after another.", "sent2": "We propose a method to dynamically shape such space and, thus, capture long-range word movements without hurting translation quality nor decoding time.", "label": 1}
{"sent1": "To address the lack of training data, we pretrain the network in a novel way using a language modeling task.", "sent2": "Results on the MSRP corpus surpass that of previous NN competitors.", "label": 1}
{"sent1": "Experimental evidence suggests that this is a promising approach, given evaluations performed on three distinct news article sets against the baseline of assigning the publication date.", "sent2": "Automatic paraphrasing is a transformation of expressions into semantically equivalent expressions within one language.", "label": 0}
{"sent1": "Test set words are more likely to be unknown, limiting the effectiveness of the model.", "sent2": "The goal of this study is to use the regularities of Arabic inflectional morphology to reduce the OOV problem in that language.", "label": 1}
{"sent1": "We applied the system to a large newspaper corpus (consisting of 10 years of the French newspaper ?Le Monde?)", "sent2": "We conclude that user comments pose a significant natural language processing challenge, but do contain useful extractable information which merits further exploration.", "label": 0}
{"sent1": "Specifically, we extend the method recently proposed by Ta?ckstro?m et al (2012), which is based on cross-lingual word cluster features.", "sent2": "Parsing speed is 177 words per second for English and 97 words per second for Chinese.", "label": 0}
{"sent1": "Considering that the number of documents is quickly growing every day, the availability of these keywords is very important.", "sent2": "Improved results are obtained by inverting a semantic parser that uses SMT methods to map sentences into meaning representations.", "label": 0}
{"sent1": "We propose novel features to improve the accuracy of extraction.", "sent2": "Experiment results show that we can obtain an accuracy of up to 75%.", "label": 1}
{"sent1": "A Bootstrap Aggregating model is proposed.", "sent2": "By letting multiple segmenters vote, our model improves segmentation consistently on the four different data sets from the second SIGHAN bakeoff.", "label": 1}
{"sent1": "the time it takes to manually label selected annotation examples.", "sent2": "We here propose three different approaches to incorporate costs into the AL selection mechanism and evaluate them on the MUC7T corpus, an extension of the MUC7 newspaper corpus that contains such annotation time information.", "label": 1}
{"sent1": "We then use a large monolingual corpus to rank and filter the results.", "sent2": "Evaluation of the quality of the extraction algorithm reveals significant improvements over na?", "label": 1}
{"sent1": "For example, Michael Collins would be one of the top names retrieved given the query Syntactic Parsing.", "sent2": "Our system targets a set of semantic relations that have been inspired by CST but that have been generalized and broadened to facilitate application to mixed fact and opinion data from the Internet.", "label": 0}
{"sent1": "When a sentence s containing an unknown word u is to be tagged by a trained POS tagger, our algorithm collects from the web contexts that are partially similar to the context of u in s, which are then used to compute new tag assignment probabilities for u.", "sent2": "Our algorithm enables fast multi-domain unknown word tagging, since, unlike previous work, it does not require a corpus from the new domain.", "label": 1}
{"sent1": "In this paper we show that we can get reasonable quality translations (we estimated the Translation Error rate at 18%) between the two languages even in absence of a parallel corpus.", "sent2": "These annotations allow us to build a significantly more comprehensive model of language generation and allow us to study what visual information is required to generate human-like descriptions.", "label": 0}
{"sent1": "In addition to that we computed scores of 6 standard metrics (BLEU, NIST, WER, PER, TER and CDER) as baselines.", "sent2": "This paper addresses the problem of building concise, diverse and relevant lists of documents, which can be recommended to the participants of a conversation to fulfill their information needs without distracting them.", "label": 0}
{"sent1": "RTMs achieve top performance in automatic, accurate, and language independent prediction of sentence-level and word-level statistical machine translation (SMT) quality.", "sent2": "While substantial work has been done on identifying and automatically recognizing the textual and prosodic correlates of discourse structure in monologue, comparable cues for dialogue or multiparty conversation, and in particular humancomputer dialogue remain relatively less studied.", "label": 0}
{"sent1": "Novel features related to the availability of multiple systems output (new point of this year) are also proposed and experimented along with baseline set.", "sent2": "We report how we overcome this challenge to retain most of the important features which performed well last year in our system.", "label": 1}
{"sent1": "Second, our parser, being type-driven instead of syntax-driven, uses type-checking to decide the direction of reduction, which eliminates the need for a syntactic grammar such as CCG.", "sent2": "Third, to fully exploit the power of type-driven semantic parsing beyond simple types (such as entities and truth values), we borrow from programming language theory the concepts of subtype polymorphism and parametric polymorphism to enrich the type system in order to better guide the parsing.", "label": 1}
{"sent1": "The templates define which properties of a part should combine to create features.", "sent2": "Many NLP applications rely on type systems to represent higher-level classes.", "label": 0}
{"sent1": "This method allows us to model the sequential nature of the problem and to incorporate features of a whole paragraph, such as paragraph coherence which cannot be used in previous models.", "sent2": "Experimental evaluation on four text corpora shows improvement over the previous state-of-the art method on this task.", "label": 1}
{"sent1": "We propose a method with Conditional Random Fields (CRFs) to categorize the nodes on the graph.", "sent2": "We present a new automatic and empirical measure of antonymy that combines corpus statistics with the structure of a published thesaurus.", "label": 0}
{"sent1": "The translation dictionaries are created with unsupervised lexicon induction techniques that rely only on raw textual data.", "sent2": "When humans and artificial agents (e.g.", "label": 0}
{"sent1": "An instancebased transfer learning method is utilized to overcome the problems of topic drift and translation errors.", "sent2": "Experiments on the NIST Chinese-English datasets show that our neural reordering model achieves significant improvements over state-of-the-art lexicalized reordering models.", "label": 0}
{"sent1": "The results show not only statistically significant, but a large improvement ?", "sent2": "Since information retrieval is often an integral component of many question answering strategies, it is important to understand the impact of different termbased techniques.", "label": 0}
{"sent1": "is an important challenging problem, which has been of great interest to the research community.", "sent2": "In this paper we present a system CLL which aims to learn natural language syntax in a way that is both computationally effective and psychologically plausible.", "label": 0}
{"sent1": "Though these phenomena have been  addressed by plenty of computational methods,  the impacts of cardinalities of metonymically  related items have been widely ignored in all of  them.", "sent2": "However, in most cases, web-based models fail to outperform more sophisticated state-of-theart models trained on small corpora.", "label": 0}
{"sent1": "We asked participants of this task to score the outputs of the MT systems involved in WMT13 Shared Translation Task.", "sent2": "We collected scores of 16 metrics from 8 research groups.", "label": 1}
{"sent1": "A family of measures called MEANT has been proposed which uses semantic role labels (SRL) to overcome this problem.", "sent2": "Specifically we explore the combination of citation information and summarization techniques.", "label": 0}
{"sent1": "We show significant improvements over state of the art segmentation algorithms on two standard datasets.", "sent2": "As an additional benefit, TopicTiling performs the segmentation in linear time and thus is computationally less expensive than other LDA-based segmentation methods.", "label": 1}
{"sent1": "Two versions of the probabilistic model are tested: unweighted and weighted.", "sent2": "The model is based on a new measure of semantic relatedness between terms.", "label": 0}
{"sent1": "Among the 14 participants in the subtask to identify the best translation, our systems were ranked 2nd and 4th in terms of recall, 3rd and 4th in terms of precision.", "sent2": "This paper describes the Sanskrit characteristics that make text comparisons different from other languages, and will present different methods of comparison of Sanskrit texts which can be used for the elaboration of computer assisted critical edition of Sanskrit texts.", "label": 0}
{"sent1": "The first system, SWAT-E, finds Spanish substitutions by first finding English substitutions in the English sentence and then translating these substitutions into Spanish using an English-Spanish dictionary.", "sent2": "The second system, SWAT-S, translates each English sentence into Spanish and then finds the Spanish substitutions in the Spanish sentence.", "label": 1}
{"sent1": "Both of our systems that participated in Task 2 achieve a decent ranking among the participating systems.", "sent2": "For Task 3 (Lefever & Hoste, 2009), we apply an unsupervised approach to the training and test data.", "label": 1}
{"sent1": "Our approach relies on identifying the nearest neighbors of the test sentence from the training data using a pairwise similarity measure.", "sent2": "Our model substantially outperforms a stateof-the-art semantic parsing baseline, yielding a 29% absolute improvement in accuracy.1", "label": 0}
{"sent1": "We evaluated the obtained results by using micro-averaged precision, recall and Fscores with respect to two different gold standards: 1) reader?s keyphrases, and 2) a combined set of author?s and reader?s keyphrases.", "sent2": "We show that our approach scales to at least an order of magnitude larger data than previous reported methods.", "label": 0}
{"sent1": "Even though general-purpose term extractors along with linguistically-motivated analysis allow us to extract elaborated morphosyntactic variation forms of terms, a na?", "sent2": "We describe our method for extracting keyphrases from scientific articles which we participate in the shared task of SemEval-2 Evaluation Exercise.", "label": 1}
{"sent1": "Random Forest, a supervised ensemble classifier, is then used to select the top keyphrases from the candidate set.", "sent2": "SEERLAB achieved a 0.24 F-score in generating the top 15 keyphrases, which places it sixth among 19 participating systems.", "label": 1}
{"sent1": "The system adopts a lightweight approach, based on training a Bayesian Network classifier using large sets of binary features.", "sent2": "We describe a WordNet-based system for the extraction of semantic relations between pairs of nominals appearing in English texts.", "label": 1}
{"sent1": "Particularly, we acquire and employ three novel types of knowledge: (1) semantic classes of nouns with a high and low tendency to encode causality along with information regarding metonymies, (2) data-driven semantic classes of verbal events with the least tendency to encode causality, and (3) tendencies of verb frames to encode causality.", "sent2": "In this work, we propose to identify causality in verbnoun pairs by exploiting deeper semantics of nouns and verbs.", "label": 1}
{"sent1": "We describe an experiment where we annotate 50 personal narratives from weblogs and experiment with methods for achieving higher annotation reliability.", "sent2": "We examine the performance of lower dimensional approximations of transitive verb tensors on a sentence plausibility/selectional preference task.", "label": 0}
{"sent1": "Even within the same project it often happens that di\u000berent tools will require di\u000berent ways to represent their linguistic data.", "sent2": "We develop a model rooted in game theory that generates these answers via strategic reasoning about possible unobserved domain-level user requirements.", "label": 0}
{"sent1": "At feature extraction stage, multiple specifications are clustered to extend the vocabulary of product features.", "sent2": "Other resources like segmenter, POS tagger or parser are not required.", "label": 1}
{"sent1": "But a robust agent can proactively seek new knowledge from a user, to help reduce subsequent task failures.", "sent2": "When the agent encounters unknown slotvalues, it may ask the user to repeat or reformulate the query.", "label": 1}
{"sent1": "We introduce a novel, less sparse, syntactic representation which leads to improvement in discourse relation recognition.", "sent2": "Finally, we demonstrate that classifiers trained on different representations, especially lexical ones, behave rather differently and thus could likely be combined in future systems.", "label": 1}
{"sent1": "We show that this method easily scales to billion-word monolingual corpora using a conventional (8 GB RAM) desktop machine.", "sent2": "We report on an experiment to track complex decision points in linguistic metadata annotation where the decision behavior of annotators is observed with an eyetracking device.", "label": 0}
{"sent1": "In this paper, we introduce an ontology-based extractive method for summarization.", "sent2": "It is based on mapping the text to concepts and representing the document and its sentences as graphs.", "label": 1}
{"sent1": "The learning method is competitive with previous single-system proposals for semantic role labelling, yields the best reported precision, and produces a rich output.", "sent2": "Secondly, we explore rule-based and learning techniques to extract predicate-argument structures from this enriched output.", "label": 1}
{"sent1": "The formalism allows a rich set of parse-tree features, including PCFGbased features, bigram and trigram dependency features, and surface features.", "sent2": "Applications are created by specifying a relatively small set of example utterance-action pairs grouped into contexts.", "label": 0}
{"sent1": "Our tagger and chunker use candidate POS tags or chunk tags of each word collected from automatically tagged data.", "sent2": "In this paper, we exploit the typed syntactic dependency theory for unsupervised induction and filling of semantics slots in spoken dialogue systems.", "label": 0}
{"sent1": "This paper is an attempt to distinguish between a ?semantically coherent?", "sent2": "Honorifics are used extensively in Japanese, reflecting the social relationship (e.g.", "label": 0}
{"sent1": "A surprising and exciting outcome was that student solutions or their combinations fared competitively on some tasks, demonstrating that even newcomers to the field can help improve the state-ofthe-art on hard NLP problems while simultaneously learning a great deal.", "sent2": "The problems, baseline code, and results are freely available.", "label": 1}
{"sent1": "Words, called selectors, are acquired which take the place of an instance of a target word in its local context.", "sent2": "They can be determined through (1) retrieval of information about interactional properties of specific objects and (2) determining functionally relevant objectindependent perceptual properties of the scene.", "label": 0}
{"sent1": "To this end, we propose a family of intuitive ?ABC?", "sent2": "For each of these levels, we further explore two ways of capturing long distance relations between language constituents: implicit modeling based on the length of distance and explicit modeling based on actual patterns of relations.", "label": 0}
{"sent1": "These models can be learned from sourceparsed bitext.", "sent2": "Our system can naturally make use of both constituent and non-constituent phrasal translations in the decoding phase.", "label": 1}
{"sent1": "This shared task not only unifies the shared tasks of the previous four years under a unique dependency-based formalism, but also extends them significantly: this year?s syntactic dependencies include more information such as named-entity boundaries; the semantic dependencies model roles of both verbal and nominal predicates.", "sent2": "In this paper, we define the shared task and describe how the data sets were created.", "label": 1}
{"sent1": "translation from a targetlanguage sentence to the source-language and back will have low expected loss.", "sent2": "We present a novel randomised language model which uses an online perfect hash function to efficiently deal with unbounded text streams.", "label": 0}
{"sent1": "We also cast the link detection subtask of TDT as a two-class classification problem in which the features of each sample consist of the generative log-likelihood ratios from each semantic class.", "sent2": "We identify two types of opinion-related entities ?", "label": 0}
{"sent1": "Although several methods exist today that serve this purpose, most of them rely on statistical data collected during lengthy training phases.", "sent2": "Our goal is to obtain a reliable method that exhibits an optimal efficiency/cost ratio, without lengthy training processes.", "label": 1}
{"sent1": "A recognized effective approach to word segmentation is Longest Matching, a method based on dictionary.", "sent2": "This paper presents example-based machine translation (MT) based on syntactic transfer, which selects the best translation by using models of statistical machine translation.", "label": 0}
{"sent1": "We present a new topic definition that has potential to model evolving events.", "sent2": "1", "label": 0}
{"sent1": "There are around 6000 sentences in the corpus with roughly 33000 marked named entity instances.", "sent2": "Secondly our approach does not increase the decoding complexity.", "label": 0}
{"sent1": "Our analysis reveals that a number of literature-based research tasks are preformed which can be served by both generic and contextually tailored preview summaries.", "sent2": "Based on this study, we describe the design of an implemented literature browsing support tool which helps readers of scientific literature decide whether or not to pursue and read a cited document.", "label": 1}
{"sent1": "More recently, digital libraries have begun to adopt faceted navigation for collections of scholarly holdings.", "sent2": "A key impediment to further adoption is the need for the creation of subject-oriented faceted metadata.", "label": 1}
{"sent1": "and the transliteration causes several variations of spelling.", "sent2": "Our method is useful for information retrieval, information extraction, question answering, and so on, because KATAKANA words tend to be used as ?loan words?", "label": 1}
{"sent1": "We present a manually-annotated corpus for argument recognition in online discussions.", "sent2": "In this paper, we show that significant improvements in the accuracy of well-known transition-based parsers can be obtained, without sacrificing efficiency, by enriching the parsers with simple transitions that act on buffer nodes.", "label": 0}
{"sent1": "Given a certain domain, DRE distinguishes between relevant and non-relevant texts by means of a Gaussian Mixture model that describes the frequency distribution of domain words inside a large-scale corpus.", "sent2": "However, a considerable number of messages in Twitter with high retweet counts are actually mundane posts by celebrities that are of interest to themselves and possibly their followers.", "label": 0}
{"sent1": "Using the proposed method, we create an emotion lexicon, compatible with the 20 emotion categories of the Geneva Emotion Wheel.", "sent2": "In this paper, we propose a computational method based on bootstrapping and corpus statistics to automatically associate English words with senses.", "label": 0}
{"sent1": "We present two simple paraphrase models, an association model and a vector space model, and train them jointly from question-answer pairs.", "sent2": "Our system PARASEMPRE improves stateof-the-art accuracies on two recently released question-answering datasets.", "label": 1}
{"sent1": "We introduce the first approach to parse sentences into this representation, providing a strong baseline for future improvement.", "sent2": "We further use algorithms for Sentiment Analysis in order to add a psychological dimension to the edges in the network.", "label": 0}
{"sent1": "The system was created under the close guidance of a team that included three deaf native signers and one ArSL interpreter.", "sent2": "We discuss problems inherent in the design and development of such translation systems and review previous ArSL machine translation systems, which all too often demonstrate a lack of collaboration between engineers and the deaf community.", "label": 1}
{"sent1": "This paper presents a study of the use of numerical hedges that is part of research investigating the process of rewriting difficult numerical expressions in simpler ways.", "sent2": "and it may also indicate the direction of approximation (e.g., ?more than?).", "label": 1}
{"sent1": "Diving deeper into the results, we provide an analysis in terms of the different question types and the ways in which the information asked for is encoded in the text.", "sent2": "In this paper, we discuss the first results for content assessment of reading comprehension activities for German and present results which are competitive with the current state of the art for English.", "label": 1}
{"sent1": "We formulate the task under the Contextual Preferences framework which broadly captures contextual aspects of inference.", "sent2": "We empirically demonstrate the application of our approach to parsing Modern Hebrew, obtaining 7% error reduction from previously reported results.", "label": 0}
{"sent1": "The first is the impossibility to capitalize on lessons learned over the different datasets available, due to the changing nature of traditional RTE evaluation settings.", "sent2": "We address two issues related to the development of systems for Recognizing Textual Entailment.", "label": 1}
{"sent1": "Our results show that existing similarity measures provide significantly different results, both in general performances and in relation distributions.", "sent2": "Scientific and technical texts are especially conducive to compounding, even in the languages that are not traditionally admitted as highly compounding ones.", "label": 0}
{"sent1": "Most of the tuning and feature selection efforts were originally aimed at task-A of the shared task.", "sent2": "First, we present a new technique for combining KB relations and surface text into a single graph representation that is much more compact than graphs used in prior work.", "label": 0}
{"sent1": "We start from the lexical features that were used in the 2013 shared tasks, we enhance the underlying lexicon and also introduce new features.", "sent2": "We focus our feature engineering effort mainly on TaskA.", "label": 1}
{"sent1": "We show that translation systems can address the L2 writing assistant task, reaching out-of-five word-based accuracy above 80 percent for 3 out of 4 language pairs.", "sent2": "We present a new dependency parsing method for Korean applying cross-lingual transfer learning and domain adaptation techniques.", "label": 0}
{"sent1": "Our approach is driven by two representations of discourse: a shallow sequential representation, and a deep one based on Rhetorical Structure Theory.", "sent2": "The aspect term extraction method is based on supervised learning algorithm, where we use different classifiers, and finally combine their outputs using a majority voting technique.", "label": 0}
{"sent1": "Motivated by these results, we describe a novel variant of an established procedure for training self-normalized models.", "sent2": "We integrate semantic information at two stages of the translation process of a state-ofthe-art SMT system.", "label": 0}
{"sent1": "A joint model is learned from the labeled data to map both the distributed representations of the contexts of ECs and EC types to a low dimensional space.", "sent2": "DefMiner achieves 85% F1 on a Wikipedia benchmark corpus, significantly improving the previous state-of-the-art by 8%.", "label": 0}
{"sent1": "A system that aims to resolve such references needs to tackle a complex task: objects and their visual features need to be determined, the referring expressions must be recognised, and extra-linguistic information such as eye gaze or pointing gestures need to be incorporated.", "sent2": "A large part of human communication involves referring to entities in the world and often these entities are objects that are visually present for the interlocutors.", "label": 1}
{"sent1": "The contest involves not only a test but also lectures, school visits and teaching material.", "sent2": "Experiments on the English Penn Treebank show that parsers based on our model perform better than conventional graph-based parsers.", "label": 0}
{"sent1": "Specifically, a plug-in architecture has been developed which allows components to be added to WordFreak for customized visualization, annotation specification, and automatic annotation, without re-compilation.", "sent2": "The APIs for these plug-ins provide mechanisms to allow automatic annotators or taggers to guide future annotation to supports active learning.", "label": 1}
{"sent1": "We also develop a efficient general search algorithm based on the MAP-EM framework to optimize this function.", "sent2": "Two systems are explained: System A for determining the sentiment of a phrase within a tweet and System B for determining the sentiment of a tweet.", "label": 0}
{"sent1": "Our method encompasses three tasks that have been previously handled separately: input segmentation, phoneme prediction, and sequence modeling.", "sent2": "In particular, our results show that size of the context window and dimensionality reduction play a key role in differentiating DSM performance on paradigmatic vs. syntagmatic relations.", "label": 0}
{"sent1": "Yet WordNet is limited, especially for inference between predicates.", "sent2": "To this end, mostly WordNet is utilized.", "label": 1}
{"sent1": "parts from the translations and apply structural correspondence learning (SCL) to find a low dimensional representation shared by the two languages.", "sent2": "The texts of each topic were provided in 10 languages (Arabic, Chinese, Czech, English, French, Greek, Hebrew, Hindi, Romanian, Spanish) and each participant generated summaries for at least 2 languages.", "label": 0}
{"sent1": "We present an analysis based on two different anaphora resolution systems.", "sent2": "In this paper we empirically evaluate whether using an off-the-shelf anaphora resolution algorithm can improve the performance of a baseline opinion mining system.", "label": 1}
{"sent1": "polarity and intensity.", "sent2": "Our experimental results show that our proposed approach improves the performance over a baseline that does not exploit hierarchical structure among the classes.", "label": 1}
{"sent1": "To improve topical blog post retrieval we incorporate textual credibility indicators in the retrieval process.", "sent2": "We show that this method easily scales to billion-word monolingual corpora using a conventional (8 GB RAM) desktop machine.", "label": 0}
{"sent1": "In this paper, we propose a method to jointly optimize the two-step CRFs and also a fast algorithm to realize it.", "sent2": "The unsupervised Data Oriented Parsing (uDOP) approach has been repeatedly reported to achieve state of the art performance in experiments on parsing of different corpora.", "label": 0}
{"sent1": "Empirical evaluation of both systems suggests that it is possible to bootstrap a field segmenter from a database alone.", "sent2": "The second approach combines unsupervised Hidden Markov modelling with language models.", "label": 1}
{"sent1": "An easy way out commercial translation systems usually offer their users is the possibility to add unknown words and their translations into a dedicated lexicon.", "sent2": "In this paper, we focus on how to conduct effective cross language text categorization.", "label": 0}
{"sent1": "Both methods ?", "sent2": "This technique uses Hidden Markov Model (HMM) alignment and Conditional Random Fields (CRF), a discriminative model.", "label": 0}
{"sent1": "More importantly, our model takes into account all the probabilities of different steps, such as segmentation, parsing, and translation.", "sent2": "The main advantage of our model is that we can make global decision to search for the best segmentation, parse-tree and translation in one step.", "label": 1}
{"sent1": "The proposed approach uses Persian and English corpora as well as a bilingual dictionary in order to make a  mapping between PWN synsets and Persian words.", "sent2": "Our method calculates a score  for each candidate synset of a given Persian word and for each of its translation, it selects the synset with maximum score  as a link to the Persian word.", "label": 1}
{"sent1": "To this end, we use a Support Vector Machine.", "sent2": "We perform a linear regression of the feature space against scores in the range [1:5].", "label": 1}
{"sent1": "We combine statistical knowledge with well known features in a Support Vector Machine pronoun resolution classifier.", "sent2": "We present results of the algorithm on a large corpus.", "label": 0}
{"sent1": "Two sets of features are proposed: one constrained, i.e.", "sent2": "This paper describes the features and the machine learning methods used by Dublin City University (DCU) and SYMANTEC for the WMT 2012 quality estimation task.", "label": 1}
{"sent1": "), as well as the presence of ambiguous discourse connectives in the English translation.", "sent2": "Furthermore, the mismatches between discourse expressions across languages significantly impact translation quality.", "label": 1}
{"sent1": "To demonstrate the effectiveness of our method, we conduct an experimental evaluation with a large-scale corpus consisting of 12,748 pairs of a document and its reference.", "sent2": "We describe a statistical approach for modelling and detecting dialogue acts in Instant Messaging dialogue.", "label": 0}
{"sent1": "We ranked candidate hyponyms on 75 categories of named entities and attained 53% mean average precision.", "sent2": "On TREC QA data our method produces a 9% improvement in performance.", "label": 1}
{"sent1": "With respect to confidence scores, the method tries to learn typical error patterns, which are then used for lattice correction, and applied just before standard lattice rescoring.", "sent2": "Our confidence measures are based on word posteriors and were improved by applying antimodels trained on anti-examples generated by the standard N-gram language model.", "label": 1}
{"sent1": "We focus on providing good statistical classifiers with a generalization ability for multi-label categorization and present a classifier design method based on model combination and F 1 -score maximization.", "sent2": "Text categorization is a fundamental task in natural language processing, and is generally defined as a multi-label categorization problem, where each text document is assigned to one or more categories.", "label": 1}
{"sent1": "In this paper, we assume that a set of rules is given and study the problem (MaxDL) of ordering them into an optimal decision list with respect to a given training set.", "sent2": "In each of these applications, ordering rules into a decision list is an important issue.", "label": 1}
{"sent1": "Despite the diversity of kernels and the near exhaustive trial-and-error on kernel combination, there lacks a clear understanding of how these kernels relate to each other and why some are superior than others.", "sent2": "This module, which creates extraction patterns starting from a user?s narrative task description, allows rapid customization to new extraction tasks.", "label": 0}
{"sent1": "This labeling problem, known as coding, consists of assigning standard medical codes (ICD9 and CPT) to patient records.", "sent2": "Each patient record can have several corresponding labels/codes, many of which are correlated to specific diseases.", "label": 1}
{"sent1": "Dispersion functions are utilized to minimize the redundancy.", "sent2": "rather than its raw distributional ?", "label": 0}
{"sent1": "In this work, we managed to extract more than 1.4 ?", "sent2": "Results on the task of suggesting word translations in context for 3 language pairs reveal the utility of the proposed contextualized models of crosslingual semantic similarity.", "label": 0}
{"sent1": "the POS tags of the words next to the word a that needs to be tagged and the context lexical information of a by Canonical Belief Network to together determine the POS tag of a.", "sent2": "Experiments on a Chinese corpus are conducted to compare our algorithm with the standard HMM-based POS tagging and the POS tagging software ICTCLAS3.0.", "label": 1}
{"sent1": "In particular, we deal with topic segmentation on multi-party meeting recording transcripts, which pose specific challenges for topic segmentation models.", "sent2": "We present a comparative study of two probabilistic mixture models.", "label": 1}
{"sent1": "Additionally, our approaches reduce segmentation errors up to 32.3%.", "sent2": "Results in terms of task success and human-likeness suggest that our unified approach performs better than greedy or random baselines.", "label": 0}
{"sent1": "A content model which follows the sequence of CoreSC categories observed in abstracts is used to provide the skeleton of the summary, making a distinction between dependent and independent categories.", "sent2": "Summary creation is also guided by the distribution of CoreSC categories found in the full articles, in order to adequately represent the article content.", "label": 1}
{"sent1": "We examine whether the knowledge extracted from texts through these models are compatible to the knowledge represented in images.", "sent2": "An extensive set of experiments demonstrates the effectiveness of our model.", "label": 0}
{"sent1": "We highlight several interesting observations: more definitions are introduced for conference and workshop papers over the years and that multiword terms account for slightly less than half of all terms.", "sent2": "The resulting automatically-acquired glossary represents the terminology defined over several thousand individual research articles.", "label": 1}
{"sent1": "Evaluation on threads from Yahoo!", "sent2": "To this end, we will compare several state-of-the-art approaches for Opinion Mining in newspaper articles in this paper.", "label": 0}
{"sent1": "While a tree-based model seems plausible for eye movements, we show that competitive results can be obtained with a linear CRF model.", "sent2": "Although we are still in the early stages of applying PRISMATIC to a wide variety of applications, we believe the resource will be of tremendous value for AI researchers, and we discuss some of potential applications in this paper.", "label": 0}
{"sent1": "Our method can easily include various features, for example, other parts of a parse tree or words the sentences contain.", "sent2": "We begin by describing a graph propagation framework inspired by previous work on constructing polarity lexicons from lexical graphs (Kim and Hovy, 2004; Hu and Liu, 2004; Esuli and Sabastiani, 2009; BlairGoldensohn et al, 2008; Rao and Ravichandran, 2009).", "label": 0}
{"sent1": "These operations capture linguistic differences such as word order and case marking.", "sent2": "Our model transforms a source-language parse tree into a target-language string by applying stochastic operations at each node.", "label": 1}
{"sent1": "This enable us to remove most of the thresholds and parameters from their model and to reach near state-of-the-art results (Wang et al., 2011) with a simpler system.", "sent2": "We improve on (Jin and Tanaka-Ishii, 2006) by adding normalization and viterbidecoding.", "label": 1}
{"sent1": "Furthermore, we apply domain adaptation, the pseudo-error sentences are from the source domain, and the real-error sentences are from the target domain.", "sent2": "Although the two approaches compete with one another, we demonstrate that these approaches are also complementary.", "label": 0}
{"sent1": "We relate this approach to contrastive estimation (Smith and Eisner, 2005a), apply the latter to grammar induction in six languages, and show that our new approach improves accuracy by 1?17% (absolute) over CE (and 8?30% over EM), achieving to our knowledge the best results on this task to date.", "sent2": "Simultaneous interpreting requires efficient use of highly specialised domain-specific terminology in the working languages of an interpreter with limited time to prepare for new topics.", "label": 0}
{"sent1": "We propose in this paper a maximum entropy approach for restoring diacritics in a document.", "sent2": "The approach can easily integrate and make effective use of diverse types of information; the model we propose integrates a wide array of lexical, segmentbased and part-of-speech tag features.", "label": 1}
{"sent1": "The ASR confidence feature indicates whether each word has been correctly recognized.", "sent2": "This paper proposes a named entity recognition (NER) method for speech recognition results that uses confidence on automatic speech recognition (ASR) as a feature.", "label": 1}
{"sent1": "In order to find the optimal context size, the proposed method automatically increases the context size when the contextual distribution after increasing it dose not agree with that of the current context.", "sent2": "Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus.", "label": 0}
{"sent1": "This makes these algorithms worth-studying for languages where resources are scarce.", "sent2": "We compare two approaches for inducing such languages.", "label": 0}
{"sent1": "We present a text encoding method for languages with affixational morphology in which the knowledge of word formation rules (which are quite restricted in Hebrew) helps in the disambiguation.", "sent2": "which deals with the data sparseness problem caused by the affixational morphology of the Hebrew language.", "label": 1}
{"sent1": "In fact, for these formalisms, premature ambiguity resolution makes parsing infeasible.", "sent2": "We describe a multi-tagging approach which maintains a suitable level of lexical category ambiguity for accurate and efficient CCG parsing.", "label": 1}
{"sent1": "We propose a probabilistic model for POS guessing of unknown words using global information as well as local information, and estimate its parameters using Gibbs sampling.", "sent2": "Such lexicons remain a scarce resource for most languages.", "label": 0}
{"sent1": "First, we employ the CrowdFlower platform to conduct an experiment on sub-sentential paraphrase acquisition with early exclusion of lowaccuracy crowdworkers.", "sent2": "The trainable part is formed by a set of random decision points that may be encountered during the process of receiving a system act and responding with a user act.", "label": 0}
{"sent1": "We conducted an experiment for collecting annotator actions and eye gaze during the annotation of predicate-argument relations in Japanese texts.", "sent2": "Since an annotator?s behaviour during annotation can be seen as reflecting her/his cognitive process during her/his attempt to understand the text for annotation, analysing the process of text annotation has potential to reveal useful information for NLP tasks, in particular semantic and discourse processing that require deeper language understanding.", "label": 1}
{"sent1": "This paper explores a range of methods for adapting a system for adding links to Wikipedia to cultural heritage items.", "sent2": "Formalized adjectival resources are, indeed, scarce for French and they mostly focus on morphological and syntactic information.", "label": 0}
{"sent1": "Experimental results show the impact of using increasingly constrained ?vertical layout language models?", "sent2": "It is shown that text line detection can be accurately solved using a formal methodology, as opposed to most of the proposed heuristic approaches found in the literature.", "label": 1}
{"sent1": "The paper focuses in particular on the modeling of nominal morphology.", "sent2": "This paper presents aspects of a computational model of the morphology of Plains Cree based on the technology of finite state transducers (FST).", "label": 1}
{"sent1": "in OntoNotes.", "sent2": "In this paper, we discuss the application of UBIU to the CONLL-2011 shared task on ?Modeling Unrestricted Coreference?", "label": 1}
{"sent1": "In this paper we present SeedLing, a seed corpus for the Human Language Project.", "sent2": "We first survey existing efforts to compile cross-linguistic resources, then describe our own approach.", "label": 1}
{"sent1": "Abductive EBL allows extending the deductive closure of the parser.", "sent2": "The paper shows that this accuracy loss is not due to the EBL framework as such, but to deductive parsing.", "label": 1}
{"sent1": "The influences of cognitive loading were investigated and some clear differences in behaviour were discovered.", "sent2": "In this paper, a statistical dialogue system providing restaurant information is evaluated in a set-up where the subjects used a driving simulator whilst talking to the system.", "label": 1}
{"sent1": "An implementation of our system is described, along with experiments and evaluation results on French news wires.", "sent2": "We describe the models and present evaluation results on three corpora with a wide range of conditions.", "label": 0}
{"sent1": "We use a knowledge-based system, based on manually implemented transducers, that reaches satisfactory performances.", "sent2": "We show that accounting for such can improve dialect detection accuracy by nearly 10% absolute.", "label": 0}
{"sent1": "We investigate automating the process of detecting errors in an XML representation of a digitized print dictionary using a hybrid approach that combines rulebased, feature-based, and language modelbased methods.", "sent2": "We investigate combining methods and show that using random forests is a promising approach.", "label": 1}
{"sent1": "In these cases, there appear to be great benefits in using hybrid systems which apply multiple analyses to the test cases.", "sent2": "knowledge-based and supervised machine learning.", "label": 0}
{"sent1": "These improvements in unsupervised methods are important especially in specialized social media domains such as Twitter where little training data is available.", "sent2": "It is completely unsupervised, with no manually labeled items, no external resources, only using parallel text that does not need to be easily alignable.", "label": 0}
{"sent1": "input behaviors.", "sent2": "In addition, we present a comparative analysis of the data to achieve a better understanding of users?", "label": 1}
{"sent1": "This work represents a first step in a project aimed at developing computational methods for deep assessment of quality in the domain of intelligence reports.", "sent2": "In this paper, we report a study on 430,000 unique tweets from Indian users, specifically Hindi-English bilinguals, to understand the language of preference, if any, for expressing opinion and sentiment.", "label": 0}
{"sent1": "Therefore tweets from other users can quickly overrun and become inconvenient to read.", "sent2": "However, Twitter does not have an effective user grouping mechanism.", "label": 1}
{"sent1": "Here, we present a new simple model of generalization in phonetic category learning, formalized in a hierarchical Bayesian framework.", "sent2": "We also describe the incremental message selection, aggregation, and generation method employed in the system.", "label": 0}
{"sent1": "(2009) and others).", "sent2": "In this paper, we extend such work to the problem of acquiring non-concatenative morphology, proposing a simple model of morphology that can handle both concatenative and non-concatenative morphology and applying Bayesian inference on two datasets of Arabic and English verbs to acquire lexica.", "label": 1}
{"sent1": "At the same time, many questions in the field of SLA remain unanswered.", "sent2": "There are few computational models of second language acquisition (SLA).", "label": 1}
{"sent1": "This system is straightforward in intuition and easy in implementation.", "sent2": "We adapt several machine translation evaluation metrics for features to cope with this difficulty, then train a regression model for the semantic similarity prediction.", "label": 1}
{"sent1": "We trained an SVM classifier with a linear kernel using a variety of features.", "sent2": "In this paper, we explore statistical techniques that can learn to identify the gender of authors in modern English text, such as web blogs and scientific papers.", "label": 0}
{"sent1": "For one benchmark, MAP improves from 0.2?0.29 (competitive baselines) to 0.42 (our system).", "sent2": "Extensive experiments on the ClueWeb corpus and parts of Freebase as our KG, using over a thousand telegraphic queries adapted from TREC, INEX, and WebQuestions, show the efficacy of our approach.", "label": 1}
{"sent1": "We further employ a K-Nearest Neighbor approach to estimate difficulty levels of newly posted questions, again by leveraging textual similarities.", "sent2": "By incorporating textual information, RCM can effectively deal with data sparseness problem.", "label": 1}
{"sent1": "Our approach achieves an SRL Fscore of 78.38% on the standard CoNLL 2009 dataset.", "sent2": "We propose an iSRL system that combines an incremental TAG parser with a semantically enriched lexicon, a role propagation algorithm, and a cascade of classifiers.", "label": 1}
{"sent1": "We present a new GFL/FUDG-annotated Chinese treebank with more than 18K tokens from Sina Weibo (the Chinese equivalent of Twitter).", "sent2": "We formulate the dependency parsing problem as many small and parallelizable arc prediction tasks: for each task, we use a programmable probabilistic firstorder logic to infer the dependency arc of a token in the sentence.", "label": 1}
{"sent1": "We further combine syntactic patterns with alignment model by using a partially supervised framework and investigate whether this combination is useful or not.", "sent2": "We propose an approach for recognizing identical real-world events based on a structured, event-oriented document representation.", "label": 0}
{"sent1": "In contrast to previous work, we first narrow down the gap between Egyptian and MSA by applying an automatic characterlevel transformational model that changes Egyptian to EG?, which looks similar to MSA.", "sent2": "Here, we focus on fully unsupervised relation extraction by employing the extended distributional hypothesis.", "label": 0}
{"sent1": "Recent approaches instead use more principled approximate inference techniques such as Gibbs sampling for parameter estimation.", "sent2": "Yet in practice we also need the single best alignment, which is difficult to find using Gibbs.", "label": 1}
{"sent1": "In addition, we constructed a topic feature, targeted to capture the global context information, using the latent dirichlet alocation (LDA) algorithm with unlabeled corpus.", "sent2": "The method developed is applied to the metonymy resolution task from SemEval 2007.", "label": 0}
{"sent1": "Unlike most of the recent approaches that are based on generating normalization dictionaries, the proposed approach performs normalization by considering the context of the non-standard words in the input text.", "sent2": "One month later, a test set containing 1,000 unidentified instances per language was released for evaluation.", "label": 0}
{"sent1": "We gathered training examples from English-Chinese parallel corpora, SEMCOR, and DSO corpus.", "sent2": "Coordination is an important and common syntactic construction which is not handled well by state of the art parsers.", "label": 0}
{"sent1": "used the official training data only (average  56 training examples per each sense).", "sent2": "Since data annotation is usually costly, methods to reduce the amount of data are needed.", "label": 0}
{"sent1": "Two main challenges of this task are the dearth of information in a single tweet and the rich entity mention variations.", "sent2": "To address these challenges, we propose a collective inference method that simultaneously resolves a set of mentions.", "label": 1}
{"sent1": "In particular, we present a detailed, empiricallygrounded model-selection comparison of HBMs vs. a simpler alternative based on clustering along with maximum likelihood estimation that we call linear competition learning (LCL).", "sent2": "Because this classifier learns and uses just a small number of dense features, it can work very fast, while achieving an about 2% improvement in unlabeled and labeled attachment scores on both English and Chinese datasets.", "label": 0}
{"sent1": "We investigate an alternative paradigm that does not require labeled corpora, avoiding the domain dependence of ACEstyle algorithms, and allowing the use of corpora of any size.", "sent2": "The Chinese comma signals the boundary of discourse units and also anchors discourse relations between adjacent text spans.", "label": 0}
{"sent1": "The proposed framework models the commonality among different relation types through a shared weight vector, enables knowledge learned from the auxiliary relation types to be transferred to the target relation type, and allows easy control of the tradeoff between precision and recall.", "sent2": "Empirical evaluation on the ACE 2004 data set shows that the proposed method substantially improves over two baseline methods.", "label": 1}
{"sent1": "We propose a generative model for expanding queries using external collections in which dependencies between queries, documents, and expansion documents are explicitly modeled.", "sent2": "Since the blogosphere is noisy, query expansion on the collection itself is rarely effective but external, edited collections are more suitable.", "label": 1}
{"sent1": "to the alignment graph used by this method, so as to explicitly represent the non-existence of coordinate structures in a sentence.", "sent2": "To take the detection of coordination into account, this paper introduces a ?bypass?", "label": 1}
{"sent1": "Unfortunately, such an approach often exacerbates the word spacing quality for user input, which has few or no spacing errors; such is the case, because a perfect WS model does not exist.", "sent2": "Rather, they consist of one or more text fragments.", "label": 0}
{"sent1": "We show an effective alternative whereby distant supervision is used to obtain training data: we use Wikipedia articles labelled with Freebase domains.", "sent2": "As a result, they have to be implemented from scratch.", "label": 0}
{"sent1": "In this paper, we illustrate that by applying a supervised incremental parsing model to unsupervised parsing; parsing with a linear time complexity will be faster than the other methods.", "sent2": "With only 15 training iterations with linear time complexity, we gain results comparable to those of other state of the art methods.", "label": 1}
{"sent1": "HMM (DHHMM) in which Chinese inner phonology information was used as one hidden layer and the BIO tags as another hidden layer.", "sent2": "We present a novel algorithm which automatically induces sub-structural alignments between context-free phrase structure trees in a fast and consistent fashion requiring little or no knowledge of the language pair.", "label": 0}
{"sent1": "The head labels in Task 2.1 are annotated with a sequence labeling model.", "sent2": "The reranking model achieved 1.12% absolute improvement on F1 over the Berkeley parser on a development set.", "label": 1}
{"sent1": "Uni-bi-trigram and syntactic rule mixed feature was found to provide the highest accuracy.", "sent2": "The model includes features of both parses, allowing transfer between the formalisms, while preserving parsing efficiency.", "label": 0}
{"sent1": "This enables us to exploit large amounts of unlabeled data with a skewed distribution.", "sent2": "A 10fold cross validation procedure shows that syllabification can be improved by incorporating this type of phonotactic knowledge.", "label": 0}
{"sent1": "We present an HMM-based approach and a maximum entropy model for speaker role labeling using Mandarin broadcast news speech.", "sent2": "part-of-speech tagging and constituent chunking, to more advanced annotations, such as syntactic, dialog act and predicate argument structure.", "label": 0}
{"sent1": "The model predicts the optimal sequence of segments that best summarize the document.", "sent2": "We evaluate our method by comparing the predicted summary with one generated by a human summarizer.", "label": 1}
{"sent1": "We present an applied prototype of an AAC-NLG system generating written output in English and Hebrew from a sequence of Bliss symbols.", "sent2": "Augmentative and Alternative Communication (AAC) deals with the development of devices and tools to enable basic conversation for language-impaired people.", "label": 1}
{"sent1": "Discarding FP from all LM histories clearly improves the performance.", "sent2": "Local perplexities, entropies and word rankings at positions following FP suggest that most FP indicate hesitations rather than restarts.", "label": 1}
{"sent1": "We report results for the RussianEnglish translation task.", "sent2": "Using a set of transcribed audio files collected from the TOEFL Practice Test Online (TPO), we conducted a sophisticated annotation of structural events, including clause boundaries and types, as well as disfluencies.", "label": 0}
{"sent1": "For the Spanish-English pair, the use of linguistic information to select parallel data is investigated.", "sent2": "Three language pairs are considered: SpanishEnglish and French-English in both directions and German-English in that direction.", "label": 1}
{"sent1": "We generate improved word alignment of the training data by incorporating an unsupervised transliteration mining module to GIZA++ and build a phrase-based machine translation system.", "sent2": "Finally, we find that a minimal amount of pre-processing can lead to better results than using either the raw data or highly processed data.", "label": 0}
{"sent1": "We use the Docent decoder, a local search decoder that translates at the document level.", "sent2": "Intuitively, a candidate is popular if it was discovered many times by other instances in the hyponym pattern.", "label": 0}
{"sent1": "The suggested keyphrases are not necessarily statistically frequent in the document, which indicates that our method is more flexible and reliable.", "sent2": "A MWE typically expresses concepts and ideas that usually cannot be expressed by a single word.", "label": 0}
{"sent1": "Our method achieves an overall accuracy of 89%.", "sent2": "We evaluate this method on a dataset of 18 acronyms found in biomedical text.", "label": 1}
{"sent1": "works of (Bodrumlu et al, 2009) and the standard probabilistic ones into a single framework.", "sent2": "We propose a minimally supervised bootstrapping algorithm that uses a single seed and a recursive lexico-syntactic pattern to learn the arguments and the supertypes of a diverse set of semantic relations from the Web.", "label": 0}
{"sent1": "The acquisition process makes no use of the metadata or links that have been manually built into the encyclopedia, and nouns in the network are automatically disambiguated to their corresponding noun senses without supervision.", "sent2": "For this task, we use the noun sense inventory of WordNet 3.0.", "label": 1}
{"sent1": "Moreover, the domain of a new target sentence may not be known, and one may not have significant amount of unlabeled data for every new domain.", "sent2": "In this paper we present our approach for assigning degrees of relational similarity to pairs of words in the SemEval-2012 Task 2.", "label": 0}
{"sent1": "Instead of simply using the best action output by the classifier, we determine the best action by looking into possible sequences of future actions and evaluating the final states realized by those action sequences.", "sent2": "We present a perceptron-based parameter optimization method for this learning framework and show its convergence properties.", "label": 1}
{"sent1": "Second, we present a probabilistic rule-based system that maps syntactic dependents to semantic arguments.", "sent2": "With simple rules, we classify about 47% of the entire PropBank arguments with over 90% confidence.", "label": 1}
{"sent1": "We also address challenges unique to the task of identifying biased writing within the specific context of Wikipedia?s neutrality policy.", "sent2": "Whereas Wikipedia currently uses only manual flagging to detect possible bias, our scheme provides a foundation for the automating of bias flagging by improving upon the methodology of annotation schemes in classic sentiment analysis.", "label": 1}
{"sent1": "If these referents are organized in terms of a taxonomy, there are two problems when establishing a reference that would distinguish an intended referent from its possible distractors.", "sent2": "The first one is the choice of the set of possible distractrors or contrast set in the given situation.", "label": 1}
{"sent1": "These representations are crucial to the development of an important class of corpus known as a proposition bank.", "sent2": "This paper presents an evaluation of an automated quality assurance technique for a type of semantic representation known as a predicate argument structure.", "label": 1}
{"sent1": "These extended named entities are hierarchical (with types and components) and compositional (with recursive type inclusion and metonymy annotation).", "sent2": "Human annotators used these guidelines to annotate a 1.3M word broadcast news corpus in French.", "label": 1}
{"sent1": "a positive impact of a large SSC despite of having wrong and missing annotations) are not fully correct.", "sent2": "We show that it is possible to automatically improve the quality and the quantity of the SSC annotations.", "label": 1}
{"sent1": "In the current study, we report efforts to partially bridge this gap.", "sent2": "The evaluation takes an argument of a verb like drive (e.g.", "label": 0}
{"sent1": "The new model is a direct translation model (DTM) formulation which allows easy integration of additional/alternative views of both source and target sentences such as segmentation for a source language such as Arabic, part-of-speech of both source and target, etc.", "sent2": "We show improvements over a state-of-the-art phrase-based decoder in Arabic-English translation.", "label": 1}
{"sent1": "Our model uses overlapping features such as morphemes and their contexts, and incorporates exponential priors inspired by the minimum description length (MDL) principle.", "sent2": "We present efficient algorithms for learning and inference by combining contrastive estimation with sampling.", "label": 1}
{"sent1": "However, unlike in human translation, these errors are rarely due to terminology inconsistency.", "sent2": "Nevertheless, translation inconsistencies often indicate translation errors.", "label": 1}
{"sent1": "Several approaches have been proposed to define the probability of different paths through the lattice with external tools like word segmenters, or by applying indicator features.", "sent2": "They are unable to handle long-range syntactic movement, but tree acceptors and transducers address this weakness (Knight and Graehl, 2005).", "label": 0}
{"sent1": "We further introduce two global scaling factors for re-estimation of the phrase table via posterior phrase alignment probabilities and a modified absolute discounting method that can be applied to fractional counts.", "sent2": "We are able to reduce already heavily pruned baseline phrase tables by more than 50% with little to no degradation in quality and occasionally slight improvement, without any increase in OOVs.", "label": 1}
{"sent1": "since the verbs ?enact?", "sent2": "Experiments show that web-scale data improves statistical dependency parsing, particularly for long dependency relationships.", "label": 0}
{"sent1": "They also can fail to remove PHI that is ambiguous between PHI and non-PHI.", "sent2": "Most approaches to deidentification rely heavily on dictionaries and heuristic rules; these approaches fail to remove most personal health information (PHI) that cannot be found in dictionaries.", "label": 1}
{"sent1": "Furthermore, we introduce biased potential functions that empirically drive CRFs towards performance improvements w.r.t.", "sent2": "The proposed framework is evaluated with several experiments run in Arabic, Chinese and English texts; a system based on the approach described here and submitted to the latest Automatic Content Extraction (ACE) evaluation achieved top-tier results in all three evaluation languages.", "label": 0}
{"sent1": "We then train a classifier with strong emphasis on the most generalizable features.", "sent2": "The current, most frequent coding approach involves manual labeling, which requires considerable human effort and is cumbersome for large patient databases.", "label": 0}
{"sent1": "The algorithm makes use of a new, frequency based, metric for time distributions and a resource free discriminative approach to transliteration.", "sent2": "We evaluate the algorithm on an English-Russian corpus, and show high level of NEs discovery in Russian.", "label": 1}
{"sent1": "We evaluate feature bagging on linear-chain conditional random fields for two natural-language tasks.", "sent2": "On both tasks, the feature-bagged CRF performs better than simply training a single CRF on all the features.", "label": 1}
{"sent1": "Each alignment link is represented with a set of feature functions extracted from linguistic features and input alignments.", "sent2": "However, these efforts have suffered from inadequate bag of words vector representations.", "label": 0}
{"sent1": "We give estimation and inference algorithms for these enhancements.", "sent2": "In this work, we address these limitations by enriching the model form.", "label": 1}
{"sent1": "The highly under-specified nature of these expressions fits well with our constraintbased representation of time, Time Calculus for Natural Language (TCNL).", "sent2": "We have developed and evaluated a Temporal Expression Anchoror (TEA), and the result shows that it performs significantly better than the baseline, and compares favorably with some of the closely related work.", "label": 1}
{"sent1": "The parsing model uses predicate-argument dependencies for training, which are derived from sequences of CCG lexical categories rather than full derivations.", "sent2": "For English?", "label": 0}
{"sent1": "In this paper we propose a forward translation model consisting of a set of maximum entropy classifiers: a separate classifier is trained for each (sufficiently frequent) source-side lemma.", "sent2": "The models are formulated so that alignment and parameter estimation can be performed efficiently.", "label": 0}
{"sent1": "We establish that the PropBank scheme is applicable to clinical Finnish as well as compatible with the SD scheme, with an overwhelming proportion of arguments being governed by the verb.", "sent2": "This allows argument candidates to be restricted to direct verb dependents, substantially simplifying the PropBank construction.", "label": 1}
{"sent1": "It has been shown to be reliably used by independent human coders, and has proven useful for various information access tasks.", "sent2": "We evaluate our approach on real microblog data sets.", "label": 0}
{"sent1": "online behaviors.", "sent2": "We show on dependency parsing tasks in 14 languages that with only 1% of fully labeled data, and light-feedback on the remaining 99% of the training data, our algorithm achieves, on average, only 5% lower performance than when training with fully annotated training set.", "label": 0}
{"sent1": "All the language pairs in our experiments were transliterated by applying this  technique in a single unified manner.", "sent2": "The  approach we take is that of hypothesis rescoring to integrate the models of two stateof-the-art techniques: phrase-based statistical  machine translation (SMT), and a joint multigram model.", "label": 1}
{"sent1": "Evaluation on the CoNLL-2010 shared task shows that our system achieves stable and competitive results for all the closed tasks.", "sent2": "Furthermore, post-deadline experiments show that the performance can be much further improved using a sufficient feature selection.", "label": 1}
{"sent1": "Opinion mining is considered a domaindependent task.", "sent2": "Finally, we describe a method for annotating clusters with usage examples.", "label": 0}
{"sent1": "premise where the premise part of a pattern is given by a SN.", "sent2": "Furthermore this paper describes how the patterns can be derived by relational statistical learning following the Minimum Description Length principle (MDL).", "label": 1}
{"sent1": "Unlike approaches based on rules, a machine learning approach holds the promise of learning robust, highcoverage sentiment classifiers from labeled examples.", "sent2": "Learning inference relations between verbs is at the heart of many semantic applications.", "label": 0}
{"sent1": "It requires a single language model (LM) history for each target hypothesis rather than two LM histories per hypothesis as in CKY.", "sent2": "In this paper we present an augmented LR decoding algorithm that builds on the original algorithm in (Watanabe et al., 2006b).", "label": 1}
{"sent1": "We also evaluated several kinds of wrappers for set expansion and showed that character-based wrappers perform better than HTML-based wrappers.", "sent2": "In this paper, we illustrated in detail the construction of character-level wrappers for set expansion implemented in SEAL.", "label": 1}
{"sent1": "We instead present a very simple yet theoretically motivated approach by extending the recent framework of ?violation-fixing perceptron?, using forced decoding to compute the target derivations.", "sent2": "Extensive phrase-based translation experiments on both Chinese-to-English and Spanish-to-English tasks show substantial gains in BLEU by up to +2.3/+2.0 on dev/test over MERT, thanks to 20M+ sparse features.", "label": 1}
{"sent1": "We find that the gender inference problem in quite diverse languages can be addressed using existing machinery.", "sent2": "Further, accuracy gains can be made by taking language-specific features into account.", "label": 1}
{"sent1": "(2) We present a novel way to integrate visual features into the LDA model using unsupervised clusters of images.", "sent2": "The clusters are directly interpretable and improve on our evaluation tasks.", "label": 1}
{"sent1": "We experiment with the different models which result from alternative methods of extracting a grammar from a treebank (retaining or discarding function labels, left binarization versus right binarization) and achieve a labeled Parseval F-score of 92.4 on Wall Street Journal Section 23 ?", "sent2": "A second set of features captures content properties based on phraseness, informativeness and keywordness measures.", "label": 0}
{"sent1": "The regularizer is a sum over inputs, so we can estimate it more accurately via a semi-supervised or transductive extension.", "sent2": "We present two methods to transform spoken language into grammatically correct sentences.", "label": 0}
{"sent1": "The techniques used in these papers are simple and the main results are found by understanding the structure of cycles in the directed graph (where words point to definitions).", "sent2": "Based on our earlier work (Levary et al., 2012), we study a different class of word definitions, namely those of the Free Association (FA) dataset (Nelson et al., 2004).", "label": 1}
{"sent1": "In this paper, we tackle this task as a supervised ranking problem.", "sent2": "The problem to replace a word with a synonym that fits well in its sentential context is known as the lexical substitution task.", "label": 1}
{"sent1": "Since corpus resources are scarce, we propose an alignment method between the syntactic trees of the Italian sentence and of its LIS translation.", "sent2": "To demonstrate the effectiveness of our proposed approach, we present the experimental results on the English Penn Treebank and the Chinese Penn Treebank.", "label": 0}
{"sent1": "We are interested in parsing constituencybased grammars such as HPSG and CCG using a small amount of data specific for the target formalism, and a large quantity of coarse CFG annotations from the Penn Treebank.", "sent2": "To differentiate them is useful for deep semantic processing and will thus benefit NLP applications such as question answering and machine translation, etc.", "label": 0}
{"sent1": "In this paper we explore the performance of transliteration systems on corpora that are varied in a controlled way.", "sent2": "This paper introduces a new task, called Open-Database Named-Entity Disambiguation (Open-DB NED), in which a system must be able to resolve named entities to symbols in an arbitrary database, without requiring labeled data for each new database.", "label": 0}
{"sent1": "Large-scale experiments on Arabic-English and Chinese-English show that our method produces significant translation quality gains by exploiting sparse features.", "sent2": "Our method, which is based on stochastic gradient descent with an adaptive learning rate, scales to millions of features and tuning sets with tens of thousands of sentences, while still converging after only a few epochs.", "label": 1}
{"sent1": "Results on five Chinese-English NIST tasks show that our model improves the baseline system by 1.32 BLEU and 1.53 TER on average.", "sent2": "Results of comparative study with other seven widely used reordering models will also be reported.", "label": 1}
{"sent1": "The goal of the study is to determine whether there are significant performance differences for the languages and to identify language-specific problems.", "sent2": "The algorithm is tested on semantically ambiguous words using data from Wikipedia, an online encyclopedia.", "label": 1}
{"sent1": "These models can be used at different points of a dialogue depending on contextual constraints.", "sent2": "Furthermore, to take into account that the probability of a user?s dialogue moves is not static during a dialogue we show how the same methodology can be used to generate dialogue move specific SLMs where certain dialogue moves are more probable than others.", "label": 1}
{"sent1": "In this paper, we implement both of these methods for selecting the conversational facial displays of an animated talking head and compare them in two user evaluations.", "sent2": "Finally, we demonstrate improved performance by combining complexity bounding methods with additional high precision constraints.", "label": 0}
{"sent1": "We attempt to extract relevant and significant information from the wider contextual scope of the conversation, and incorporate it into the SMT techniques.", "sent2": "We also discuss the advantages and limitations of this approach through our experimental results.", "label": 1}
{"sent1": "The REALM system, which combines HMMbased and n-gram-based language models, ranks candidate extractions by the likelihood that they are correct.", "sent2": "This technique allows us to efficiently test our model without needing a specialized parser, and to use the standard evaluation metric on the original Phrase Structure version of the treebank.", "label": 0}
{"sent1": "The study we performed focused on German, and we used the Tiger treebank as our resource.", "sent2": "We take three schemes of different type and granularity (those based on section names, argumentative zones and conceptual structure of documents) and investigate their applicability to biomedical abstracts.", "label": 0}
{"sent1": "We argue that complex linguistic constructions require grammatical information to be located in the same module, in order to avoid over-complicating the system architecture.", "sent2": "The inherent compositionality of metaphor makes it an important test case for compositional distributional semantic models (CDSMs).", "label": 0}
{"sent1": "Not every cause for parsing errors can be captured effectively by looking at word n-grams.", "sent2": "Disambiguation performance is evaluated by measuring matches of predicate-argument relations on two distinct test sets.", "label": 0}
{"sent1": "For the unstructured information, keyword-based query is used to retrieve the shortest text span containing the questions?s key terms.", "sent2": "In this paper, an extension of a dimensionality reduction algorithm called NONNEGATIVE MATRIX FACTORIZATION is presented that combines both ?bag of words?", "label": 0}
{"sent1": "Therefore the system must  be able  to generate arbitrary sequence of characters  in the target language, rather than words  chosen from a pre-determined vocabulary.", "sent2": "We evalauted our method automatically  relative to a set of human-annotated  reference transliterations as well as by  assessing it  for correctness using human  evaluators.", "label": 1}
{"sent1": "Participation was open to systems based on any approach.", "sent2": "The names of named entities very often occur as constituents of larger noun phrases which denote different types of entity.", "label": 0}
{"sent1": "We describe four subtasks covering two languages, English and Greek, and three speech application domains, travel reservation, tourism and finance.", "sent2": "The classification results are compared against the groundtruth.", "label": 1}
{"sent1": "Highquality data sets were constructed for four comparison types using multi-stage annotation procedures with a graded scale of similarity.", "sent2": "Nineteen teams submitted 38 systems.", "label": 1}
{"sent1": "We improve phrase ordering performance by lexicalizing the resulting rules in a small number of cases corresponding to function words.", "sent2": "These rules will be manually revised  before being applied to the WSD module in the English-to-Vietnamese Translation (EVT) system.", "label": 0}
{"sent1": "The task provided datasets containing manually annotated reviews of restaurants and laptops, as well as a common evaluation procedure.", "sent2": "Twenty constraints were found.", "label": 0}
{"sent1": "Such a costly process hinders our ability to evaluate an aligner under various types and levels of noise.", "sent2": "This paper describes the main components and functionality of the system, as well as the purposes and future use of the system, and surveys the research issues involved in its construction.", "label": 0}
{"sent1": "We present two ways to extend a DWL to improve its ability to model the word translation probability in a phrase-based machine translation (PBMT) system.", "sent2": "We also perform coreference resolution to deal with events having a large textual scope, which may span over several sentences (or even paragraphs).", "label": 0}
{"sent1": "In this paper, we analyze how to infer preferences from dialogue moves in actual conversations that involve bargaining or negotiation.", "sent2": "To this end, we propose a new annotation scheme to study how preferences are linguistically expressed in two different corpus genres.", "label": 1}
{"sent1": "Different approaches have been used to represent individual concepts, but current state-of-the-art techniques require extensive manual intervention to scale to arbitrary words and domains.", "sent2": "To overcome this challenge, we initiate a systematic comparison of automatically-derived corpus representations, based on various types of textual co-occurrence.", "label": 1}
{"sent1": "The goal of this paper is twofold: (i) to explore whether these hypotheses hold for entities, that is, whether several mentions in the same discourse (or the same collocation) tend to refer to the same entity or not, and (ii) test their impact in Named-Entity Disambiguation (NED).", "sent2": "(OSPC) hypotheses have been very influential in Word Sense Disambiguation.", "label": 1}
{"sent1": "In general, different systems have been developed for the two domains, despite the fact that the tasks in both domains share a number of characteristics.", "sent2": "Several event extraction tasks have been defined for both the newswire and biomedical domains.", "label": 1}
{"sent1": "In this paper, we define novel measures (both collocation based and context based measures) to measure the relative compositionality of MWEs of V-N type.", "sent2": "This paper describes a Natural Language Learning method that extracts knowledge in the form of semantic patterns with ontology elements associated to syntactic components in the text.", "label": 0}
{"sent1": "We argue that this coheres better with current thinking in linguistics and psycholinguistics.", "sent2": "It is also expected to immediately react to the instructions.", "label": 0}
{"sent1": "In the French-English task, we investigate the use of context-dependent alignment models.", "sent2": "Novelty of this work is three-fold: First, to the best of our knowledge, this is an early attempt to explore syllables in tweet normalization.", "label": 0}
{"sent1": "Previous methods have required the use of tools such as part-of-speech taggers, segmenters, morphological analyzers, and linguistic rules to produce state-of-the-art results.", "sent2": "This paper describes a simple yet novel method for constructing sets of 50-best parses based on a coarse-to-fine generative parser (Charniak, 2000).", "label": 0}
{"sent1": "We train probabilistic parsing models for resource-poor languages by transferring cross-lingual knowledge from resource-rich language with entropy regularization.", "sent2": "Our method can be used as a purely monolingual dependency parser, requiring no human translations for the test data, thus making it applicable to a wide range of resource-poor languages.", "label": 1}
{"sent1": "We tackle this issue with a new lattice rescoring algorithm and demonstrate its effectiveness empirically.", "sent2": "Our joint model builds on a well known recurrent neural network language model (Mikolov, 2012) augmented by a layer of additional inputs from the source language.", "label": 1}
{"sent1": "A lot of effort has been devoted to aspect detection and sentiment analysis under the assumption that every review has the same utility for related tasks.", "sent2": "Combining deep and shallow parsing resource through the common formalism of RMRS allows us to extract ontological relations in greater quantity and quality than possible with any of the methods independently.", "label": 0}
{"sent1": "Previous work on paraphrase acquisition has collected lexicalized pairs of expressions; however, the results do not ensure full coverage of the various paraphrase phenomena.", "sent2": "In particular, each component multinomial of a generative model can be turned into a miniature logistic regression model if feature locality permits.", "label": 0}
{"sent1": "The aim is to gain semantic interpretations of utterances that serve as a basis for multi-modal dialog management also in cases where the recognized word-stream is not grammatically correct.", "sent2": "We applied our method to a phoneme-to-text transcription task in Japanese and reduced about 10% of the errors in the results of an existing method.", "label": 0}
{"sent1": "We further implement six different methods for extracting whole-sentence corrections from the lattice.", "sent2": "Lastly, we show that our method outperforms methods based on recent related works from the viewpoints of model size and query speed when both optimization methods are used.", "label": 0}
{"sent1": "We analysed four corpora in terms of nineteen linguistic features which pose obstacles to reading comprehension for people with ASD.", "sent2": "Our proposed method employs statistical machine translation to improve question retrieval and enriches the question representation with the translated words from other languages via matrix factorization.", "label": 0}
{"sent1": "Although a coreference resolution system trained on the newswire domain performs well on newswire texts, there is a huge performance drop when it is applied to the biomedical domain.", "sent2": "In this paper we present some experiments on using such similarity measures for an old Natural Language Processing (NLP) problem.", "label": 0}
{"sent1": "Scientific and technical texts are especially conducive to compounding, even in the languages that are not traditionally admitted as highly compounding ones.", "sent2": "Compound rate in the text obviously depends on the language, but also on the genre and the domain.", "label": 1}
{"sent1": "In this paper, we extend the notion of a tree kernel over arbitrary sub-trees of the parse to the derivation trees and derived trees provided by the LTAG formalism, and in addition, we extend the original definition of the tree kernel, making it more lexicalized and more compact.", "sent2": "We propose the use of Lexicalized Tree Adjoining Grammar (LTAG) as a source of features that are useful for reranking the output of a statistical parser.", "label": 1}
{"sent1": "Log-linear models can easily encode the long-range dependencies inherent in coordination and extraction phenomena, which CCG was designed to handle.", "sent2": "Existing work has shown that using morphosyntactic information is an effective solution to data sparseness.", "label": 0}
{"sent1": "In this paper, we present a method to acquire content selection rules automatically from a corpus of text and associated semantics.", "sent2": "or ?align?", "label": 0}
{"sent1": "We present a Bayesian classifier for discriminating between documents with a preponderance of opinions such as editorials from regular news stories, and describe three unsupervised, statistical techniques for the significantly harder task of detecting opinions at the sentence level.", "sent2": "Substantial research effort has been invested in recent decades into the computational study and automatic processing of multi-party conversation.", "label": 0}
{"sent1": "This study explores an ME model with box-type inequality constraints, where the equality can be violated to reflect this unreliability.", "sent2": "We evaluate the inequality ME model using text categorization datasets.", "label": 1}
{"sent1": "With the availability of annotated corpora (Penn Discourse Treebank) statistical discourse parsers were developed.", "sent2": "Additionally, we extend our model to include morphemelevel and lexical information through a neural reranker.", "label": 0}
{"sent1": "In this new algorithm, instead, we only compute the approximate gains for the top-ranked features based on the models obtained from previous stages.", "sent2": "Experiments on WSJ data in Penn Treebank are conducted to show that the new algorithm greatly speeds up the feature selection process while maintaining the same quality of selected features.", "label": 1}
{"sent1": "These are the labels used by lexicographers developing WordNet.", "sent2": "The Valency Lexicon of Czech Verbs, Version 1.0 (VALLEX 1.0) is a collection of linguistically annotated data and documentation, resulting from an attempt at formal description of valency frames of Czech verbs.", "label": 0}
{"sent1": "The ranking rules are simple and effective, while machine learning can take more factors into account.", "sent2": "From the results of our experiments, this combination gives better performance than either of the two previous approaches.", "label": 1}
{"sent1": "We present and describe four classifiers for Chinese named entity recognition and describe various methods for combining their outputs.", "sent2": "We show specifically how to enhance a shift-reduce dependency parser with alignment features to resolve shift-reduce conflicts.", "label": 0}
{"sent1": "The idea of our approach is to exploit both the local and global properties of paragraphs.", "sent2": "Based on feature analysis of our learned models, we additionally make several theoretical contributions, including revealing a relationship between deceptive opinions and imaginative writing.", "label": 0}
{"sent1": "We find that individual systems tuned on the same data to Positive Diversity can be even more diverse than systems built using different data sets, while still obtaining good BLEU scores.", "sent2": "Errors introduced during PDF-totext conversion or poorly formatted examples can make the task of automatically analyzing the data more difficult, so we aim to clean and normalize the examples in order to maximize accuracy during analysis.", "label": 0}
{"sent1": "For further compression, deleting from oracle paraphrastic compressions preserves more meaning than deletion alone.", "sent2": "In either setting, paraphrastic compression shows promise for surpassing deletion-only methods.", "label": 1}
{"sent1": "We examine stance classification on a corpus of 4873 posts across 14 topics on ConvinceMe.net, ranging from the playful to the ideological.", "sent2": "We show that ideological debates feature a greater share of rebuttal posts, and that rebuttal posts are significantly harder to classify for stance, for both humans and trained classifiers.", "label": 1}
{"sent1": "We first produced high-level goldstandard sentiment dictionaries for two languages and then translated them automatically into third languages.", "sent2": "Those words that can be found in both target language word lists are likely to be useful because their word senses are likely to be similar to that of the two source languages.", "label": 1}
{"sent1": "To deal with large data, we use Count-Min sketch to store the approximate counts of all word pairs in a bounded space of 8GB.", "sent2": "We propose a novel method to construct semantic orientation lexicons using large data and a thesaurus.", "label": 1}
{"sent1": "This paper presents some empirical results on the challenges facing a machine-learning approach to this kind of opinion mining.", "sent2": "Some of the challenges include: the often considerable imbalance in the distribution of positive and negative samples; changes in the documents over time; and effective training and quantification procedures for reporting results.", "label": 1}
{"sent1": "Our case study focuses on the Dutch social movement between 1870 and 1940, and is based on biographical texts describing the lives of notable people in this movement.", "sent2": "The distance of instances in k-NN is computed by estimating the similarity measured by LSA and PLSA.", "label": 0}
{"sent1": "In this paper, we show how sentiment analysis can be used in tandem with effective visualizations to quantify and track emotions in many types of mail.", "sent2": "With the widespread use of email, we now have access to unprecedented amounts of text that we ourselves have written.", "label": 1}
{"sent1": "The target impressions are limited to those represented by three bipolar scales, ?Happy ?", "sent2": "Experiments on the WebQuestions question answering dataset show that our method achieves an F 1 of 53.3%, a substantial improvement over the state-of-the-art.", "label": 0}
{"sent1": "It is a preliminary implementation.", "sent2": "Our method also worked well for the top 100,000 results.", "label": 0}
{"sent1": "SVM-based classifiers achieve average F-scores of up to 51% for 4-way classification and 31% for 8-way classification, which is well above chance level.", "sent2": "The third model was a combination of the previous two models.", "label": 0}
{"sent1": "use ?", "sent2": "of ?", "label": 1}
{"sent1": "Recent works suggest that semantic orientation depends on application domains.", "sent2": "Moreover, we think that semantic orientation depends on the specific targets (features) that an opinion is applied to.", "label": 1}
{"sent1": "Using three popular similarity metrics, we replace unknown synsets in the test set with a similar synset from the training set.", "sent2": "An improvement of 6.2% is seen with respect to baseline using this approach.", "label": 1}
{"sent1": "We evaluate this unsupervised learning approach on three different domains: movie data, news resource, and meeting dialogues.", "sent2": "It is our opinion that question answering and multi-document summarization represent two complementary approaches to the same problem of satisfying complex user information needs.", "label": 0}
{"sent1": "However, tweets are filtered through streams of posts, so that a wider context, e.g.", "sent2": "In particular, morphological and semantic processing are employed to obtain a nominalized form which has to respect titles characteristics (in particular, relevance and catchiness).", "label": 0}
{"sent1": "A small subset of corresponding Czech and English sentences has been annotated by humans.", "sent2": "We discuss some of the problems we have experienced during the automatic transformation between annotation schemes and hint at some of the difficulties to be tackled by potential guidelines for dependency annotation of English.", "label": 1}
{"sent1": "VALLEX 1.0 is closely related to Prague Dependency Treebank.", "sent2": "The Valency Lexicon of Czech Verbs, Version 1.0 (VALLEX 1.0) is a collection of linguistically annotated data and documentation, resulting from an attempt at formal description of valency frames of Czech verbs.", "label": 1}
{"sent1": "We present an improved implementation, based on Tree Structured Stack (TSS), in which a transition is performed in O(1), resulting in a real lineartime algorithm, which is verified empirically.", "sent2": "In this study we try to learn automatically two classifications, \u0000\u0002\u0001\u0004\u0003\u0006\u0005\b\u0007 \t\f\u000b\u000e \u0004\u0005\f\u000f \u0010\u0011\u000f\u0013\u0012 and \u0000\u0002\u000b\u000e\u0010\u0014\u0003\u0016\u0015\f\u000b\u0017\u000f , relevant for this problem.", "label": 0}
{"sent1": "The system uses core technologies such as speaker segmentation, automatic speech recognition, transcription alignment, keyword extraction and speech indexing and retrieval to make spoken communications easy to navigate.", "sent2": "Comparative experiments with a real POS tagger produce lower results.", "label": 0}
{"sent1": "Leveraging combined representations of video clickstream interactions and forum activities, we seek to fundamentally understand traits that are predictive of decreasing engagement over time.", "sent2": "These operators are categorized: a pointing operator that transform a CB into a CE; a focalizing/shifting operator that reduces or shifts the CE into another CE, and finally a zoning operator that provides the wanted CE from this last CE.", "label": 0}
{"sent1": "However, the low participation (5-10%) in discussion forums, prompts the modeling of user behavior based on clickstream information.", "sent2": "In this paper we investigate automatic datatext alignment, i.e.", "label": 0}
{"sent1": "While this problem is partially solved for students that are active in online forums, this is not yet the case for the more general student population.", "sent2": "With high dropout rates as observed in many current larger-scale online courses, mechanisms that are able to predict student dropout become increasingly important.", "label": 1}
{"sent1": "Experiments with Penn Korean Treebank show that even using only the transferred features from Japanese achieves a high accuracy (81.6%) for Korean dependency parsing.", "sent2": "?work together?", "label": 0}
{"sent1": "Four different dependency treebanks are used for monolingual parsing, direct cross-lingual parsing, and a recently introduced crosslingual parsing approach that utilizes statistical machine translation and annotation projection.", "sent2": "We investigate the problem of using transliterations to correct errors produced by state-of-the-art G2P systems.", "label": 0}
{"sent1": "This context free grammar with sufficient encoded information is comparable with the state of the art parsing requirements for morphologically rich and closely related language variants Urdu/Hindi.", "sent2": "The extended parsing model and the linguistically rich grammar together provide us promising parsing results for both the language variants.", "label": 1}
{"sent1": "Many discriminative learning algorithms are sensitive to such shifts because highly indicative features may swamp other indicative features.", "sent2": "Retraining translation models yields modest improvements.", "label": 0}
{"sent1": "Domain-specific CFG language models are produced by first specialising the grammar using an automatic corpus-based method, and then compiling the resulting specialised grammars into CFG form.", "sent2": "We  also  demonstrate  how it can be used to improve existing applications  in  information  retrieval  and  summarization.", "label": 0}
{"sent1": "We propose a unified solution to detect unknown words in Chinese texts.", "sent2": "First, a morphological analysis is done to obtain initial segmentation and POS tags and then a chunker is used to detect unknown words.", "label": 1}
{"sent1": "A syntactic parser is used as the source model, and a novel type of TAG-based transducer is the channel model.", "sent2": "This paper describes a noisy channel model of speech repairs, which can identify and correct repairs in speech transcripts.", "label": 1}
{"sent1": "We construct a linear-chain Conditional Random Field based on pairs of questions and their possible answer sentences, learning the association between questions and answer types.", "sent2": "Our goal is to extract answers from preretrieved sentences for Question Answering (QA).", "label": 1}
{"sent1": "The other task looks to confirm explicit relation words for two entities.", "sent2": "One task is to determine if a sentence potentially contains a relation between two entities?", "label": 1}
{"sent1": "The system relies on deep syntactic and semantic analysis of questions only and is independent of relevant documents.", "sent2": "We propose to combine a K-Nearest Neighbors (KNN) classifier with a linear Conditional Random Fields (CRF) model under a semi-supervised learning framework to tackle these challenges.", "label": 0}
{"sent1": "The key idea is to develop the structural clues so that it achieves extremely high precision at the cost of recall.", "sent2": "In order to compensate for the low recall, we used massive collection of HTML documents.", "label": 1}
{"sent1": "Thus, this paper proposes a just-intime keyword extraction from meeting transcripts.", "sent2": "Scalable discriminative training methods are now broadly available for estimating phrase-based, feature-rich translation models.", "label": 0}
{"sent1": "Using an English comparable corpus of tech news, we built a dictionary of opaque coreferent mentions (only 3% are in WordNet).", "sent2": "Our dictionary can be integrated into any coreference system (it increases the performance of a state-of-the-art system by 1% F1 on all measures) and is easily extendable by using news aggregators.", "label": 1}
{"sent1": "of humorous and non-humorous speech, even when accounted for the gender and speaker differences.", "sent2": "In?", "label": 0}
{"sent1": "This model allows for using an arbitrarily large corpus in a very efficient way.", "sent2": "It also provides a natural platform for relevance weighting and selection.", "label": 1}
{"sent1": "In this paper, we propose a transliteration method that models both pronunciation and impression, whereas existing methods do not model impression.", "sent2": "However, because different Kanji characters convey different meanings and impressions, characters must be selected carefully.", "label": 1}
{"sent1": "We present two distinct methods for transliteration, one approach using an unsupervised phonetic transliteration method, and the other using the temporal distribution of candidate pairs.", "sent2": "Each of these approaches works quite well, but by combining the approaches one can achieve even better results.", "label": 1}
{"sent1": "The Jeopardy!", "sent2": "The last decade has seen many interesting applications of Question Answering (QA) technology.", "label": 1}
{"sent1": "We test our algorithm on German data and report improvements over three baselines including a reimplementation of Sporleder & Lapata?s (2006) work on paragraph segmentation.", "sent2": "We investigate the relation between paragraph boundaries and discourse cues, pronominalization and information structure.", "label": 1}
{"sent1": "Because PASs represent generalized structures for syntactical variants, patterns on PASs are expected to be more generalized than those on surface words.", "sent2": "This paper presents a method of automatically constructing information extraction patterns on predicate-argument structures (PASs) obtained by full parsing from a smaller training corpus.", "label": 1}
{"sent1": "However, it did not yield improvements when training on the Penn Treebank.", "sent2": "We show that VerbNet is more verb-specific and better able to generalise to new semantic role instances, while PropBank better captures some of the structural constraints among roles.", "label": 0}
{"sent1": "Model Tampering and Anchored Learning.", "sent2": "Deeper temporal reasoners struggle with this sparsity because the entire temporal picture is not represented.", "label": 0}
{"sent1": "Finally, we use this resource to determine NP structure using several statistical approaches, thus demonstrating the utility of the corpus.", "sent2": "This adds detail to the Penn Treebank that is necessary for many NLP applications.", "label": 1}
{"sent1": "We structure documents as graphs of event mentions and use graph kernels to measure the similarity between document pairs.", "sent2": "Our knowledge sources include the part-of-speech of neighboring words, single words in the surrounding context, local collocations, and syntactic relations.", "label": 0}
{"sent1": "Evaluating a parser on the same resource used to create it can lead to non-comparable accuracy scores and an over-optimistic view of parser performance.", "sent2": "This suggests that sentence type information available from intonational cues may be helpful for syntactic acquisition crosslinguistically.", "label": 0}
{"sent1": "data.", "sent2": "Our approach is incredibly simple, easy to implement as a preprocessing step (10 lines of Perl!)", "label": 1}
{"sent1": "In this paper, we study the domain adaptation problem from the instance weighting perspective.", "sent2": "We formally analyze and characterize the domain adaptation problem from a distributional view, and show that there are two distinct needs for adaptation, corresponding to the different distributions of instances and classification functions in the source and the target domains.", "label": 1}
{"sent1": "Here we develop the infinite tree, a new infinite model capable of representing recursive branching structure over an arbitrarily large set of hidden categories.", "sent2": "We augment the standard perceptron algorithm with a global integer linear programming formulation to optimize both local fit of information into each topic and global coherence across the entire overview.", "label": 0}
{"sent1": "Despite the differences between these two approaches, the supertaggers give similar improvements.", "sent2": "Inspired by the ?products of experts?", "label": 0}
{"sent1": "by bootstrapping on its output.", "sent2": "We have shown that even simple features like point-wise mutual information are useful for word-alignment task in English-Hindi parallel corpora.", "label": 0}
{"sent1": "Due to errors in the hypothesis alignment, decoding may result in ungrammatical combination outputs.", "sent2": "This paper describes an improved confusion network based method to combine outputs from multiple MT systems.", "label": 1}
{"sent1": "Because the PDTB covers the same text as the Penn TreeBank WSJ corpus, syntactic and discourse annotation can be compared.", "sent2": "Furthermore, we propose the use of standard parser evaluation methods for automatically evaluating the summarization quality of sentence condensation systems.", "label": 0}
{"sent1": "An appropriate model should be expressive enough to represent the information which is to be extracted from text without being overly complicated.", "sent2": "Four previously reported pattern models are evaluated using existing IE evaluation corpora and three dependency parsers.", "label": 1}
{"sent1": "However, until now, Lexical Chaining algorithms have only been proposed for English.", "sent2": "In this paper, we propose a greedy Language-Independent algorithm that automatically extracts Lexical Chains from texts.", "label": 1}
{"sent1": "So most IE training sets are relatively small.", "sent2": "Consequently, IE patterns learned from annotated training sets often have limited coverage.", "label": 1}
{"sent1": "Users can summarize the arguments about the topic in order to choose a more reasonable standpoint for decision making.", "sent2": "Such functions introduce new objects in the discourse context, that have to be taken into account in classical contextual processing tasks, such as reference resolution or question answering.", "label": 0}
{"sent1": "Corpus annotation schemes aim to encode such distinctions for NLP applications concerned with such tasks, such as information extraction, question answering, summarization, and generation.", "sent2": "The goal of this study is to improve the prediction results in cross-topic AA (CTAA), where the training data comes from one topic but the test data comes from another.", "label": 0}
{"sent1": "Capturing the nature and the number of semantic roles in a sentence is therefore fundamental to correctly describing the interface between grammar and meaning.", "sent2": "In this paper, we compare two annotation schemes, PropBank and VerbNet, in a task-independent, general way, analysing how well they fare in capturing the linguistic generalisations that are known to hold for semantic role labels, and consequently how well they grammaticalise aspects of meaning.", "label": 1}
{"sent1": "The combination metric outperforms the individual scores, but is bested by the entailment-based metric.", "sent2": "Combining the entailment and traditional features yields further improvements.", "label": 1}
{"sent1": "We then use this approach to investigate the benefits of introducing linguistic features into evaluation metrics.", "sent2": "The approach, experimentally validated on Turkish and isiZulu languages, gives high performance on test data and is comparable to a fully supervised method.", "label": 0}
{"sent1": "We present a new model that automatically learns syntactic constraints, including but not limited to constituent matching/violation, from training corpus.", "sent2": "The model brackets a source phrase as to whether it satisfies the learnt syntactic constraints.", "label": 1}
{"sent1": "We test our approach on three datasets, and compare a TSP-based decoder to the popular beam-search algorithm.", "sent2": "This approach achieved the best results on the SemEval 2012 Task 2, obtaining a Spearman correlation of 0.229 and an accuracy on reproducing human answers to MaxDiff questions of 39.4%.", "label": 0}
{"sent1": "In particular, our model is able to learn correlations among neighboring arcs (siblings and grandparents), word valency, and tendencies toward nearlyprojective parses.", "sent2": "The model parameters are learned in a max-margin framework by employing a linear programming relaxation.", "label": 1}
{"sent1": "a noun?s parent is often a verb).", "sent2": "Users can speak or type, and they can navigate and follow links using mouse clicks.", "label": 0}
{"sent1": "We consider several types of constraints that range from generic dependency conservation to language-specific annotation rules for auxiliary verb analysis.", "sent2": "We evaluate our approach on Bulgarian and Spanish CoNLL shared task data and show that we consistently outperform unsupervised methods and can outperform supervised learning for limited training data.", "label": 1}
{"sent1": "We found positive correlations between ROUGE scores and two different summary types, where only weak or negative correlations were found using other agreement measures.", "sent2": "However, we show that ROUGE may be sensitive to the choice of summarization style.", "label": 1}
{"sent1": "Applying a cross comprehension test on human authored short summaries from broadcast news, the level of subjectivity is gauged among four authors.", "sent2": "The official results confirm its effectiveness in English-Chinese bidirectional transliteration.", "label": 0}
{"sent1": "These experiments confirm that the tokenization method, the reference length selection scheme, and the use of sentence boundaries we introduce will increase the correlation between automatic and human evaluation scores.", "sent2": "For this purpose, we study the correlation between automatic and human evaluation scores on three MT evaluation corpora.", "label": 1}
{"sent1": "As a case study in one direction, we discuss the recent development of an automatic method for evaluating definition questions based on n-gram overlap, a commonlyused technique in summarization evaluation.", "sent2": "In the other direction, the move towards topic-oriented summaries requires an understanding of relevance and topicality, issues which have received attention in the question answering literature.", "label": 1}
{"sent1": "As the SCF is a relevant clue to learn the relation between syntax and semantic, the classification algorithm accuracy was remarkable enhanced.", "sent2": "In this article, we extend such work by studying the impact of the SCF tree kernel on both PropBank and FrameNet semantic roles.", "label": 1}
{"sent1": "are never encountered.", "sent2": "This work is, to our knowledge, a first attempt at a machine learning approach to cross-lingual coreference resolution, i.e.", "label": 0}
{"sent1": "We carried out a competitive evaluation of three leading treebank parsers on an annotated corpus from the human molecular biology domain, and on an extract from the Penn Treebank for comparison, performing a detailed analysis of the kinds of errors each parser made, along with a quantitative comparison of syntax usage between the two corpora.", "sent2": "It is not clear a priori how well parsers trained on the Penn Treebank will parse significantly different corpora without retraining.", "label": 1}
{"sent1": "The n-gram models may be of any order, operate in reverse (?right-to-left?", "sent2": "), and selectively replace certain words with their semantic classes.", "label": 1}
{"sent1": "Specialized queries are included to speed up several tasks, for example, the detection of new terms and concepts, or simple quality estimation without gold standard documents.", "sent2": "The development environment is modular and extensible by using Eclipse and the Apache UIMA framework.", "label": 1}
{"sent1": "This is particularly true for languages other than English, where labelled training data is not easily available.", "sent2": "Existing efforts to produce such lexicons exist, and to avoid duplicated effort, a principled way to combine multiple resources is required.", "label": 1}
{"sent1": "Previous approaches have relied on manually-generated rules and hand-crafted resources such as WordNet; our method requires neither yet achieves better performance than these prior approaches, measured both by comparison with a property norm-derived gold standard as well as direct human evaluation.", "sent2": "Our technique performs particularly well on extracting features relevant to a given concept, and suggests a number of promising areas for future focus.", "label": 1}
{"sent1": "Their leading explanation states that they are caused by visual acuity limitations on word recognition.", "sent2": "Some of the most robust effects of linguistic variables on eye movements in reading are those of word length.", "label": 1}
{"sent1": "In order to preserve the speaker?s individuality, we use a combined dictionary that was constructed from the source speaker?s vowels and target speaker?s consonants.", "sent2": "It was a follow-on to the English-only task organized in 2011.", "label": 0}
{"sent1": "We refer to this task as relevancy recognition.", "sent2": "In this paper we address this issue using an unsupervised test for intrinsic clustering quality.", "label": 0}
{"sent1": "Our experiments show that a significant proportion of errors can be detected by the two methods.", "sent2": "attribute.", "label": 0}
{"sent1": "The second method learns less restrictive patterns that include bags of words and relation-specific named entity tags.", "sent2": "Both methods improve the recall of the generic pattern method.", "label": 1}
{"sent1": "The main advantages over the popular active learning framework are that no seed annotated data is needed and that the reusability of the data is maintained.", "sent2": "We applied active annotation to named entity recognition in the biomedical domain and encouraging results were obtained.", "label": 1}
{"sent1": "In the evaluation using Formal Run and Reference Run data, there were several cases which our algorithm could not handle ellipsis correctly.", "sent2": "The challenge with regard to copying in Seq2Seq is that new machinery is needed to decide when to perform the operation.", "label": 0}
{"sent1": "We investigate whether automatic word-alignment in existing parallel corpora facilitates the classification of candidate expressions along a continuum ranging from literal and transparent expressions to idiomatic and opaque expressions.", "sent2": "In this paper, we present a recursive neural network (RNN) model that works on a syntactic tree.", "label": 0}
{"sent1": "This model includes the background information necessary to understand a natural language architectural description.", "sent2": "The ARC project (for Architecture Represented Computationally) is an attempt to reproduce in computer form the architectural historian?s mental model of the Gothic cathedral.", "label": 1}
{"sent1": "However, search still relies heavily on key words.", "sent2": "all members of academic staff) while the second method is based on automatic Named-Entity Recognition (NER).", "label": 0}
{"sent1": "Effective features include both stylistic ones (such as POS patterns) as well as content oriented ones.", "sent2": "An advantage of transformation-based learning is the readability of learned rules.", "label": 0}
{"sent1": "A set of author-specific topics are learnt over the ACL corpus, which ranges from 1965 to 2009.", "sent2": "We suggest a theory of the different types of academic collaboration, and use topic models to computationally identify these in Computational Linguistics literature.", "label": 1}
{"sent1": "Our results show that the combination of unter+noun must in fact be characterized as productive, and hence that a syntactic treatment is required.", "sent2": "Definitions from the Oxford Dictionary of English formed the sense inventories.", "label": 0}
{"sent1": "Our goal is to align a medium-sized corpus of parallel text, consisting of short news texts in Spanish with their simplified counterpart.", "sent2": "We view the answer type as a distribution, rather than a class in an ontology.", "label": 0}
{"sent1": "We also provide an analysis of summary specificity and the summary quality scores assigned by people.", "sent2": "We find that too much specificity could adversely affect the quality of content in the summary.", "label": 1}
{"sent1": "However, instead of aligning the inputs as a preprocess, we integrate the tasks of finding an alignment and selecting a merged sentence into a joint optimization problem, and learn parameters for this optimization using a structured online algorithm.", "sent2": "Evaluation by human judges shows that our technique produces fused sentences that are both informative and readable.", "label": 1}
{"sent1": "This abstract representation relies on the concept of Information Items (INIT), which we define as the smallest element of coherent information in a text or a sentence.", "sent2": "We propose a new, ambitious framework for abstractive summarization, which aims at selecting the content of a summary not from sentences, but from an abstract representation of the source documents.", "label": 1}
{"sent1": "Our system assigns a code configuration, predicting one or more codes for each document.", "sent2": "On Chinese-to-English translation, the absolute improvements in BLEU (caseinsensitive) range from 1.2 to 2.1.", "label": 0}
{"sent1": "In this paper, we present an approach to automatically analyze dictionaries to discover how names are composed and which variations typically occur.", "sent2": "Such refined dictionaries cover potential structural, lexical, orthographical, or morphological variations.", "label": 1}
{"sent1": "Understanding the structure of the embedding phrase can be an enormously beneficial first step to enhancing whatever processing is intended to follow the named entity recognition in the first place.", "sent2": "The joint model is trained only based on the annotated sentiment polarity of sentences, without any segmentation annotations.", "label": 0}
{"sent1": "Further, it identifies a range of NLP tools required, including: identifying synonyms, and resolving coreference and negated expressions.", "sent2": "The translation module also attempts to determine when a compound is translated using paraphrase and when it is translated into a Nominal compound.", "label": 0}
{"sent1": "indexing recommendations for  the genetics literature, including recommendations involving subheadings, which  is a novel application for the methods.", "sent2": "We  show that a generic representation of the  documents yields both better precision  and recall.", "label": 1}
{"sent1": "?ve Bayes methods and 2) Word Overlap methods, both of which rely on the extraction of syntactic features.", "sent2": "We have adopted a token-based approach to solve this task using 1) Na?", "label": 1}
{"sent1": "The system obtained a relative improvement in accuracy against the most-frequentclass baseline of 49.8% in the ?unseen contexts?", "sent2": "We use a Conditional Random Field (CRF), a discriminative model, which is estimated on a small supervised training set.", "label": 0}
{"sent1": "We also propose novel feature types regarding to sentence difference and semantic similarity based on our observations in the preliminary experiments.", "sent2": "Then after performing a text preprocessing, we extract multiple feature types with respect to surface text and grammar.", "label": 1}
{"sent1": "We describe an algorithm that detects such exceptional pairs and converts trees into vectors in a feature space.", "sent2": "In particular, substantial improvement is obtained over previously published results of worddistribution based systems when evaluation is done on a corpus of recorded and transcribed multi-party dialogs.", "label": 0}
{"sent1": "In this paper, we describe our extensions to the probabilistic translation model of Brown et al (1993) (as in Duygulu et al (2002)) that enable the creation of structured models of image objects.", "sent2": "This paper describes an unsupervised dynamic graphical model for morphological segmentation and bilingual morpheme alignment for statistical machine translation.", "label": 0}
{"sent1": "We describe EM-style parameter re-estimation procedures based on phrase alignment under the complete translation model incorporating reordering.", "sent2": "A pattern is defined in this work as a sequence of specialized Part-of-Speech (POS) tags that capture the structure of key sentences in the scientific literature.", "label": 0}
